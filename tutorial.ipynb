{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADNE Projeto.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Projeto 1 - ADNE\n",
        "##Tensorflow, Keras Sequencial e Keras Funcional"
      ],
      "metadata": {
        "id": "s8CyI0Z2lR5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introdução\n",
        "Neste trabalho de ADNE terei como objetivo demonstrar o bom uso do Tensorflow sem APIs mais high level (operações simples e low level do **Tensorflow default** (*vanilla*)) e de seguida com a API do Keras ambas a versão **sequencial** e **funcional** para construir redes neuronais. Na variante **sequencial**, o modelo é definido layer a layer sem extras nem branchings. Na **funcional** temos mais flexibilidade por já podemos ter os ditos branches que nos permitem ter vários outputs por exemplo, como é o caso da imagem abaixo. \n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Source: https://www.analyticsvidhya.com/blog/2021/07/understanding-sequential-vs-functional-api-in-keras/"
      ],
      "metadata": {
        "id": "cOHpOuiMxfCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow Vanilla"
      ],
      "metadata": {
        "id": "jjBoOSOMjHmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O tensorflow permite definir computações que são definidas por um **grafo**. Nestes grafos de computação, cada **nó representa uma operação** e cada **arco representa um tensor** que no fundo é uma matriz."
      ],
      "metadata": {
        "id": "JvtqIzhWmm7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparação dos dados\n",
        "Relativamente ao modelo a realizar, este terá como objetivo prever a força do cimento tendo em conta os atributos relativos à constituição do mesmo logo é um **problema de regressão** (tal será importante para decisões a tomar na configuração da rede mais à frente). Importante de referir que devemos fazer a standardização de todos os dados para prevenir problemas de instabilidades numéricas e colocarmos tudo na mesma escala como já faziamos para aprendizagem automática (**standardização**) e que, por ser um problema de regressão, a coluna com o valor objetivo também pode ser standardizada por não representar classes.\n",
        "\n",
        "Com o conjunto de dados que temos, primeiro fazemos o *shuffling* por não saber a ordem com que foram escritos para o ficheiro (podem estar por exemplo por ordem crescente e nós queremos que estejam completamente em bruto e misturados), separamos em **dois conjuntos independentes**. Um deles será o conjunto de **treino** que servirá para treinar o modelo e o outro, de **validação**, que nunca será observado pelo nosso modelo e que será usado no final para testar a performance do nosso modelo. "
      ],
      "metadata": {
        "id": "vdCew72aGzBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "\n",
        "#Standardização\n",
        "data = pd.read_csv('concrete.csv')  \n",
        "data = shuffle(data)\n",
        "data = data.to_numpy()\n",
        "means = np.mean(data,axis=0)\n",
        "stds = np.std(data,axis=0)\n",
        "data = (data-means)/stds\n",
        "\n",
        "#Conjunto de validação\n",
        "valid_Y = data[700:,[-1]]\n",
        "valid_X = data[700:,0:8]\n",
        "\n",
        "#Conjunto de treino\n",
        "Y = data[:700,[-1]]\n",
        "X = data[:700,0:8]"
      ],
      "metadata": {
        "id": "_r-KseItJnVi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorboard (opcionalmente)\n",
        "Não irei usar o tensorboard devido à **dificuldade acrescida** de fazer o plot simultâneo dos dois erros nessa ferramenta mas caso quisessemos ver a evolução dos erros ao longo das épocas seria a melhor escolha. \n",
        "\n",
        "Comecemos por fazer os imports necessários para o mesmo. No entanto, o importante aqui é definirmos uma diretoria para onde serão guardados os erros do nosso modelo para que depois possam ser vistos no tensorboard para vermos melhor as evoluções dos mesmos. Iremos usar o nome da diretoria com a data de agora para que a pasta não seja overwritten caso se faça mais que uma run e apenas crie duas com os nomes diferentes."
      ],
      "metadata": {
        "id": "WlNY1-x-DYUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from asyncore import write\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "root_logdir = \"logsConcrete\"\n",
        "log_dir = \"{}/model-{}/\".format(root_logdir, now)\n",
        "writer = tf.summary.create_file_writer(log_dir)\n"
      ],
      "metadata": {
        "id": "wxf5GtK4Ji1M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos definir estas funções auxiliares para depois vermos o grafo resultante falado na primeira secção."
      ],
      "metadata": {
        "id": "kOiq8yAi6G1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def create_graph(X):\n",
        "    _ = predict(X)\n",
        "\n",
        "def write_graph(X):\n",
        "    tf.summary.trace_on(graph=True)\n",
        "    create_graph(tf.constant(X.astype(np.float32)))\n",
        "    with writer.as_default():\n",
        "        tf.summary.trace_export(name=\"trace\",step=0)"
      ],
      "metadata": {
        "id": "dYzeHnewJ8WO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função para cada camada (layer)\n",
        "Esta função tem como objetivo definir uma parte da layer da nossa rede (sem a parte da ativação do neurónio que será explicada à frente). As *layers* terão um número de neurónios e receberão um determinado input (nas camadas intermédias o **input será o output da layer anterior**). A ideia é que cada layer dará um determinado peso a cada um dos inputs (multiplicando o input por esse peso) e somando um bias para que no caso em que os pesos sejam 0, o resultado da multiplicação não o seja (embora a probabilidade seja pouca por não termos muitos neurónios, logo será definido como 0). Estes pesos irão ser valores aleatórios retirados de uma distribuição normal com desvio padrão de 1 a dividir pelo número de neurónios da camada. \n",
        "\n",
        "Esta alteração de não usar o desvio padrão de 1 é para que, caso usemos uma rede grande existe uma possibilidade dos pesos aleatórios que serão escolhidos sejam muito altos e com o empilhar das várias camadas, esses pesos aumentarão para além do possível na representação do computador e pode haver overflow gerando NaNs. Assim, quanto mais neurónios tenhamos numa camada, menor os pesos iniciais serão (por causa do desvio padrão).\n",
        "\n",
        "Relativamente ao tipo de tensores criados, estes serão criados usando a função `Variable()` ao invés da `constant` porque, as do primeiro tipo permitem que os valores alterem. Isto é importante porque a ideia de redes neuronais é ir atualizando estas variáveis com o algoritmo de *backpropagation* logo precisam de ser mutáveis."
      ],
      "metadata": {
        "id": "TfEK1bM9J5Ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def layer(inputs,neurons,layer_name):\n",
        "  weights = tf.Variable(tf.random.normal((inputs.shape[1],neurons), stddev = 1/neurons ))\n",
        "  bias = tf.Variable(tf.zeros([neurons]))\n",
        "  return weights,bias\n"
      ],
      "metadata": {
        "id": "f9j1j1eCJwlS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criar rede neuronal\n",
        "Relativamente ao código da própria função de criar a rede na totalidade, esta recebe como parâmetros o input (os valores dos atributos) e uma lista em que cada posição representa o número de neurónios nessa *layer*, isto é, [4,2,1] representa uma rede com 3 camadas em que a primeira tem 4 neurónios, a segunda 2 e a última 1. O importante aqui é que cada *layer* recebe os valores do output da camada anterior para que, exista sempre uma **evolução sobre o trabalho feito pela camada anterior.**"
      ],
      "metadata": {
        "id": "WtNaVIIClnbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_network(X,layers):\n",
        "    network = []\n",
        "    variables = []\n",
        "    previous = X\n",
        "    for ix, neurons in enumerate(layers):\n",
        "        weights,bias = layer(previous,neurons,f'layer_{ix}')\n",
        "        network.append( (weights,bias) )\n",
        "        variables.extend( (weights,bias) )\n",
        "        previous = weights\n",
        "    return network, variables"
      ],
      "metadata": {
        "id": "MBHdWdpnJzxq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui iremos criar de facto a rede, neste caso com três layers tendo a primeira 4 neurónios. a segunda 4 e a de output apenas 1. As variáveis representam o que tentará ser otimizado pela rede (**os pesos e bias**)."
      ],
      "metadata": {
        "id": "_ISlmLx7mwqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [4,4,1]\n",
        "network ,variables = create_network(X,layers)"
      ],
      "metadata": {
        "id": "wS43JJpiJ3kw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Previsão pela rede\n",
        "Agora, para fazermos a previsão recebendo o input tenho de abordar a questão que referi no início relativamente às funções de ativação. O que cada camada efetivamente faz é, para cada camada, fazer a multiplicação matricial dos pesos, somar o valor do bias e finalmente aplicar uma **função de ativação**. \n",
        "\n",
        "Esta função tem como objetivo introduzir a tão necessária **não linearidade** em cada camada. Esta não linearidade é necessária para conseguirmos transformarmos a representação dos dados para algo que seja possível de classificar depois de todas essas transformações e, este classificador na representação original dos dados terá um aspeto curvo capaz de separar de uma forma correta os dados caso estes não sejam linearmente separáveis. \n",
        "\n",
        "Relativamente à **função de ativação** em si, existem inúmeros tipos por exemplo a sigmóide, relu e leaky relu. A razão de não ter escolhido a sigmoide está relacionada com o comportamento dela. Esta função nos seus extremos (0 e 1) tem um declive praticamente nulo o que representa uma derivada (gradientes) também perto de 0. Como multiplicamos todos os gradientes para atualizarmos os pesos e chegarmos aos ideais, esta multiplicação será cada vez mais baixa e acabará por ficar a 0, sendo assim o algoritmo de backpropagation inútil (gradientes nulos e não tem informação de como os atualizar cujo fenómeno tem como nome ***Vanishing Gradients***).\n",
        "\n",
        "Para circundarmos isto, o relu trata deste problema. Este tem o seguinte comportamento: caso o input seja negativo temos como output 0 e caso o input seja positivo, o output será igual ao input ficando assim com gradiente sempre 1 caso o neurónio ative. Isto resolveria o problema mas devido ao comportamento quando o input é negativo, caso os inputs comecem a ficar mais negativos, pelo output ser 0, os neurónios irão morrer e não serão mais utilizados. Para isto, usamos o **leaky relu** que ao invés de ter 0 como output no caso de input negativo, tem um ligeiro declive dando assim valores negativos (que já nos dão alguma informação de como atualizar as variáveis) ao invés de apenas 0.\n",
        "\n",
        "\n",
        "Outro aspeto importante está relacionado com que função de ativação usar na **camada de output**. Este é um tema que tem de ser analisado consoante o objetivo do problema. Neste caso temos um problema de regressão que consiste em prever um valor contínuo (força do cimento) logo não queremos restringir esse valor de maneira alguma logo não faria sentido usar por exemplo uma função sigmóide. Deste modo, usarmos o output da última camada **sem aplicar qualquer tipo de função de ativação** ficando assim com o valor final \"unbounded\". Isto foi feito dando um nome à ultima camada anteriormente e agora, quando chegarmos a esta, apenas faremos a multiplicação dos pesos e soma do bias."
      ],
      "metadata": {
        "id": "5IqL1i6EpR_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X):\n",
        "    net = X\n",
        "    layer = 1\n",
        "    for weights,bias in network[:-1]:\n",
        "        with tf.name_scope(f'Layer_{layer}'):\n",
        "            net = tf.add(tf.matmul(net, weights), bias,name='net')\n",
        "            net = tf.nn.leaky_relu(net, name=\"relu\")\n",
        "        layer += 1\n",
        "    weights,bias = network[-1]\n",
        "    with tf.name_scope('Output'):\n",
        "        net = tf.add(tf.matmul(net, weights), bias)\n",
        "    return tf.reshape(net, [-1])\n",
        "\n",
        "write_graph(X)"
      ],
      "metadata": {
        "id": "5nX4K6hvJ6Bb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função Loss\n",
        "Olhemos agora para a **função loss**. Esta tem como objetivo penalizar a rede neuronal de alguma forma logo queremos minimizar o valor desta função. Esta minimização será feita usando um \"optimizer\" que será explicado mais à frente como funciona quando o aplicar.\n",
        "\n",
        "Assim como para a função de ativação, também existem **diversas funções loss** e a escolha desta também **depende do objetivo do problema**. Neste caso, por ser um problema de regressão por estarmos a prever um valor, o tipo de função loss normalmente usada é a dos **mínimos erros quadrados**. O porquê de ser esta é devido a corresponder à solução de maximum likelihood se assumirmos que as previsões são afetadas por um erro com distribuição de probabilidades normal.\n",
        "\n",
        "Relativamente ao código em si, este tipo de loss funciona, tal como o nome indica, calculando o quadrado de todas as diferenças entre o valor previsto e o valor verdadeiro (que nos é dado pelas labels dos dados). De notar uma pequena diferença de que agora definimos as labels como `constant` visto não querermos que estas mudem agora. Finalmente temos de fazer a operação sobre o próprio tensor e para isso recorremos à função `reduce_mean`.\n",
        "\n"
      ],
      "metadata": {
        "id": "RDg2TFI77Jo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(X,Y):\n",
        "    yLabelsTensorflow = tf.constant(Y)\n",
        "    # individual\n",
        "    squaredErrorDifs = tf.math.square(yLabelsTensorflow - X)\n",
        "    # for tensor\n",
        "    meanSqLoss = tf.reduce_mean(squaredErrorDifs)\n",
        "    return meanSqLoss"
      ],
      "metadata": {
        "id": "IELfKus4J_DE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função do cálculo dos gradientes\n",
        "Agora temos de definir a função do gradiente que será extremamente importante no que toca a atingirmos a melhor solução (a que minimiza a função loss). Esta função pode ser representada como uma superfície num espaço multidimensional e o nosso objetivo é \"**deslizar**\" nessa superfície até **chegarmos ao mínimo**. \n",
        "\n",
        "A forma como vamos deslizar depende do tipo de otimizer que será falado à frente mas, para qualquer um dos tipos, precisamos dos gradientes de todas as funções relativamente a alguns parâmetros (multiplicações dos pesos, soma dos biases, funções de ativação e loss..), isto é, das derivadas das funções, para os **aplicar posteriormente com o optimizer que usarmos**. \n",
        "\n",
        "O cálculo dos gradientes pode ser um pouco \"tricky\" porque precisamos de guardar todos os gradientes associados a todas essas operações ao longo da network, por isso, o tensorflow dá-nos uma função que é a `GradientTape()` que nos permite fazer tudo dentro desse mesmo contexto (calcular o valor previsto e o respetivo valor de loss). Isto dar-nos-á os gradientes para este tensor."
      ],
      "metadata": {
        "id": "Amd-CZAVDsPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "moWJcHg_UieL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grad(X, y, layerVars):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_val = predict(X)\n",
        "        loss_cost_value = loss(loss_val, y)\n",
        "    return tape.gradient(loss_cost_value, layerVars), layerVars"
      ],
      "metadata": {
        "id": "v16vORv5KG3K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição dos hiperparâmetros e escolhas para treino\n",
        "Aqui iremos definir alguns parâmetros importantes no que toca ao treino do modelo. Começaremos pelo **optimizer**. Este tem como objectivo de aplicar a informação dada pelos gradientes de modo a atualizarmos os pesos (que são os parâmetros que estamos a tentar encontrar). Deste modo, o **Stochastic Gradient Descent** receberá o gradiente estimado, multiplica pela **learning rate** usada e usa a informação resultante para atualizar os pesos. Para o outro parâmetro da função do SGD, o **momentum** faz com que em vez de usarmos o gradiente como o valor representante da mudança dos nossos pesos, usamo-lo para alterar a velocidade sobre a qual estamos a descer. Resumidamente isto fará com que se estivermos a descer na **mesma direção, a velocidade irá aumentar** e caso mudemos de direção, a velocidade diminuirá (isto para **aumentar a velocidade do treino**).\n",
        "\n",
        "Os restantes parâmetros estão também relacionados. O que o SDG faz para maximizar a sua eficiência é, ao invés de cálcular os gradientes para cada exemplo individualmente e dar um pequeno passo correspondente, este **junta 128 elementos num batch**, calcula os seus gradientes e soma todos estes valores e assim apenas damos 1 passo representante de todos os 128 exemplos no batch, precisando assim de muitos menos passos para chegarmos a um possível mínimo.\n",
        "Relativamente ao **número de épocas**, este representa o número de passagens que faremos sobre todos os dados de treino."
      ],
      "metadata": {
        "id": "64EBWoSKJ4gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.optimizers.SGD(learning_rate=0.0001, momentum=0.9)\n",
        "batch_size = 128\n",
        "batches_per_epoch = X.shape[0]//batch_size\n",
        "epochs = 5000"
      ],
      "metadata": {
        "id": "-Fcfo4HwKLuO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinar modelo e calcular erros\n",
        "Agora que temos todas as funções necessárias criadas, faremos então o ciclo para o treino e validação do nosso modelo.\n",
        "Relativamente ao código em si, como foi explicado, uma **época consiste em calcular o gradiente para vários batches** logo terá uma estrutura de um `for` encapsulado. Depois, precisaremos de **calcular os gradientes** para os exemplos do batch e **aplicá-los com o optimizer** (SGD) para sabermos para onde deslizar. Com isto feito, faremos a **previsão** e o cálculo da **diferença entre o previsto e o real** para podermos calcular o valor das losses.\n",
        "No final, faço o print do erro médio de treino e de validação. Importante de referir que no cálculo da loss, como tinhamos standardizado os dados inicialmente, agora necessitamos de os \"**de-standardizar**\" por isso fazemos a operação de fazer a raíz quadrada e multiplicá-la pelo desvio padrão."
      ],
      "metadata": {
        "id": "FjMJYv0C3RVK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YGs7-Y3li_0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7530a30f-7b34-436b-f236-430dccebdfd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "Epoch: 2 Training Error: 112.52377 Validation Error: 112.69386\n",
            "Epoch: 3 Training Error: 112.26427 Validation Error: 112.432076\n",
            "Epoch: 4 Training Error: 112.00024 Validation Error: 112.16586\n",
            "Epoch: 5 Training Error: 111.73582 Validation Error: 111.899536\n",
            "Epoch: 6 Training Error: 111.4819 Validation Error: 111.64336\n",
            "Epoch: 7 Training Error: 111.23568 Validation Error: 111.39453\n",
            "Epoch: 8 Training Error: 111.00173 Validation Error: 111.15799\n",
            "Epoch: 9 Training Error: 110.78246 Validation Error: 110.93596\n",
            "Epoch: 10 Training Error: 110.57527 Validation Error: 110.726265\n",
            "Epoch: 11 Training Error: 110.395546 Validation Error: 110.544426\n",
            "Epoch: 12 Training Error: 110.2258 Validation Error: 110.372574\n",
            "Epoch: 13 Training Error: 110.056816 Validation Error: 110.20153\n",
            "Epoch: 14 Training Error: 109.891914 Validation Error: 110.03456\n",
            "Epoch: 15 Training Error: 109.74071 Validation Error: 109.881454\n",
            "Epoch: 16 Training Error: 109.602066 Validation Error: 109.74109\n",
            "Epoch: 17 Training Error: 109.469574 Validation Error: 109.60709\n",
            "Epoch: 18 Training Error: 109.34496 Validation Error: 109.4812\n",
            "Epoch: 19 Training Error: 109.22799 Validation Error: 109.36301\n",
            "Epoch: 20 Training Error: 109.11649 Validation Error: 109.2505\n",
            "Epoch: 21 Training Error: 109.00531 Validation Error: 109.13808\n",
            "Epoch: 22 Training Error: 108.90108 Validation Error: 109.03263\n",
            "Epoch: 23 Training Error: 108.800835 Validation Error: 108.931145\n",
            "Epoch: 24 Training Error: 108.70977 Validation Error: 108.83879\n",
            "Epoch: 25 Training Error: 108.62049 Validation Error: 108.7482\n",
            "Epoch: 26 Training Error: 108.537674 Validation Error: 108.6643\n",
            "Epoch: 27 Training Error: 108.45758 Validation Error: 108.58331\n",
            "Epoch: 28 Training Error: 108.38164 Validation Error: 108.506645\n",
            "Epoch: 29 Training Error: 108.30944 Validation Error: 108.433876\n",
            "Epoch: 30 Training Error: 108.23957 Validation Error: 108.36352\n",
            "Epoch: 31 Training Error: 108.17441 Validation Error: 108.29798\n",
            "Epoch: 32 Training Error: 108.111824 Validation Error: 108.235016\n",
            "Epoch: 33 Training Error: 108.053314 Validation Error: 108.17612\n",
            "Epoch: 34 Training Error: 107.99556 Validation Error: 108.11805\n",
            "Epoch: 35 Training Error: 107.94121 Validation Error: 108.06337\n",
            "Epoch: 36 Training Error: 107.88655 Validation Error: 108.0085\n",
            "Epoch: 37 Training Error: 107.83681 Validation Error: 107.95843\n",
            "Epoch: 38 Training Error: 107.78811 Validation Error: 107.90933\n",
            "Epoch: 39 Training Error: 107.737404 Validation Error: 107.85822\n",
            "Epoch: 40 Training Error: 107.69011 Validation Error: 107.81053\n",
            "Epoch: 41 Training Error: 107.644325 Validation Error: 107.76437\n",
            "Epoch: 42 Training Error: 107.59969 Validation Error: 107.71932\n",
            "Epoch: 43 Training Error: 107.5568 Validation Error: 107.676125\n",
            "Epoch: 44 Training Error: 107.5152 Validation Error: 107.63418\n",
            "Epoch: 45 Training Error: 107.475845 Validation Error: 107.59453\n",
            "Epoch: 46 Training Error: 107.43741 Validation Error: 107.5557\n",
            "Epoch: 47 Training Error: 107.401955 Validation Error: 107.519875\n",
            "Epoch: 48 Training Error: 107.36616 Validation Error: 107.483665\n",
            "Epoch: 49 Training Error: 107.33056 Validation Error: 107.44767\n",
            "Epoch: 50 Training Error: 107.29587 Validation Error: 107.41264\n",
            "Epoch: 51 Training Error: 107.265045 Validation Error: 107.38152\n",
            "Epoch: 52 Training Error: 107.23449 Validation Error: 107.35063\n",
            "Epoch: 53 Training Error: 107.20427 Validation Error: 107.32007\n",
            "Epoch: 54 Training Error: 107.17458 Validation Error: 107.29005\n",
            "Epoch: 55 Training Error: 107.14582 Validation Error: 107.26099\n",
            "Epoch: 56 Training Error: 107.11862 Validation Error: 107.233345\n",
            "Epoch: 57 Training Error: 107.0914 Validation Error: 107.205734\n",
            "Epoch: 58 Training Error: 107.06508 Validation Error: 107.179016\n",
            "Epoch: 59 Training Error: 107.04032 Validation Error: 107.1539\n",
            "Epoch: 60 Training Error: 107.01631 Validation Error: 107.12949\n",
            "Epoch: 61 Training Error: 106.99364 Validation Error: 107.10647\n",
            "Epoch: 62 Training Error: 106.97145 Validation Error: 107.08393\n",
            "Epoch: 63 Training Error: 106.94889 Validation Error: 107.06098\n",
            "Epoch: 64 Training Error: 106.92703 Validation Error: 107.03878\n",
            "Epoch: 65 Training Error: 106.90607 Validation Error: 107.01747\n",
            "Epoch: 66 Training Error: 106.88527 Validation Error: 106.99633\n",
            "Epoch: 67 Training Error: 106.865486 Validation Error: 106.97622\n",
            "Epoch: 68 Training Error: 106.846085 Validation Error: 106.95652\n",
            "Epoch: 69 Training Error: 106.82642 Validation Error: 106.93651\n",
            "Epoch: 70 Training Error: 106.80646 Validation Error: 106.916176\n",
            "Epoch: 71 Training Error: 106.78807 Validation Error: 106.897446\n",
            "Epoch: 72 Training Error: 106.770226 Validation Error: 106.879295\n",
            "Epoch: 73 Training Error: 106.75232 Validation Error: 106.861084\n",
            "Epoch: 74 Training Error: 106.7344 Validation Error: 106.84277\n",
            "Epoch: 75 Training Error: 106.71765 Validation Error: 106.825714\n",
            "Epoch: 76 Training Error: 106.701126 Validation Error: 106.808876\n",
            "Epoch: 77 Training Error: 106.68519 Validation Error: 106.79264\n",
            "Epoch: 78 Training Error: 106.66966 Validation Error: 106.776825\n",
            "Epoch: 79 Training Error: 106.654236 Validation Error: 106.7611\n",
            "Epoch: 80 Training Error: 106.638855 Validation Error: 106.74537\n",
            "Epoch: 81 Training Error: 106.62406 Validation Error: 106.730255\n",
            "Epoch: 82 Training Error: 106.60917 Validation Error: 106.71505\n",
            "Epoch: 83 Training Error: 106.59459 Validation Error: 106.700134\n",
            "Epoch: 84 Training Error: 106.58021 Validation Error: 106.68548\n",
            "Epoch: 85 Training Error: 106.56601 Validation Error: 106.67093\n",
            "Epoch: 86 Training Error: 106.55216 Validation Error: 106.65676\n",
            "Epoch: 87 Training Error: 106.53926 Validation Error: 106.64365\n",
            "Epoch: 88 Training Error: 106.5259 Validation Error: 106.630005\n",
            "Epoch: 89 Training Error: 106.513275 Validation Error: 106.6171\n",
            "Epoch: 90 Training Error: 106.500824 Validation Error: 106.60444\n",
            "Epoch: 91 Training Error: 106.487686 Validation Error: 106.59098\n",
            "Epoch: 92 Training Error: 106.47506 Validation Error: 106.577965\n",
            "Epoch: 93 Training Error: 106.46253 Validation Error: 106.56508\n",
            "Epoch: 94 Training Error: 106.45061 Validation Error: 106.552864\n",
            "Epoch: 95 Training Error: 106.438736 Validation Error: 106.54071\n",
            "Epoch: 96 Training Error: 106.427055 Validation Error: 106.52879\n",
            "Epoch: 97 Training Error: 106.41511 Validation Error: 106.51651\n",
            "Epoch: 98 Training Error: 106.40371 Validation Error: 106.50487\n",
            "Epoch: 99 Training Error: 106.39262 Validation Error: 106.49349\n",
            "Epoch: 100 Training Error: 106.381584 Validation Error: 106.48222\n",
            "Epoch: 101 Training Error: 106.37105 Validation Error: 106.471436\n",
            "Epoch: 102 Training Error: 106.3609 Validation Error: 106.461105\n",
            "Epoch: 103 Training Error: 106.35042 Validation Error: 106.45041\n",
            "Epoch: 104 Training Error: 106.34003 Validation Error: 106.43978\n",
            "Epoch: 105 Training Error: 106.32982 Validation Error: 106.42934\n",
            "Epoch: 106 Training Error: 106.31985 Validation Error: 106.41915\n",
            "Epoch: 107 Training Error: 106.30992 Validation Error: 106.40881\n",
            "Epoch: 108 Training Error: 106.30025 Validation Error: 106.39879\n",
            "Epoch: 109 Training Error: 106.29092 Validation Error: 106.389145\n",
            "Epoch: 110 Training Error: 106.28143 Validation Error: 106.37928\n",
            "Epoch: 111 Training Error: 106.272156 Validation Error: 106.369606\n",
            "Epoch: 112 Training Error: 106.26292 Validation Error: 106.36004\n",
            "Epoch: 113 Training Error: 106.25396 Validation Error: 106.35072\n",
            "Epoch: 114 Training Error: 106.245094 Validation Error: 106.34154\n",
            "Epoch: 115 Training Error: 106.23629 Validation Error: 106.332375\n",
            "Epoch: 116 Training Error: 106.22752 Validation Error: 106.323204\n",
            "Epoch: 117 Training Error: 106.218834 Validation Error: 106.31423\n",
            "Epoch: 118 Training Error: 106.21036 Validation Error: 106.305405\n",
            "Epoch: 119 Training Error: 106.202034 Validation Error: 106.29671\n",
            "Epoch: 120 Training Error: 106.19411 Validation Error: 106.28843\n",
            "Epoch: 121 Training Error: 106.18591 Validation Error: 106.27974\n",
            "Epoch: 122 Training Error: 106.1779 Validation Error: 106.27135\n",
            "Epoch: 123 Training Error: 106.1698 Validation Error: 106.26284\n",
            "Epoch: 124 Training Error: 106.16175 Validation Error: 106.254326\n",
            "Epoch: 125 Training Error: 106.15402 Validation Error: 106.24623\n",
            "Epoch: 126 Training Error: 106.14644 Validation Error: 106.23832\n",
            "Epoch: 127 Training Error: 106.13874 Validation Error: 106.23026\n",
            "Epoch: 128 Training Error: 106.131386 Validation Error: 106.22262\n",
            "Epoch: 129 Training Error: 106.124 Validation Error: 106.21499\n",
            "Epoch: 130 Training Error: 106.11689 Validation Error: 106.207565\n",
            "Epoch: 131 Training Error: 106.109566 Validation Error: 106.19996\n",
            "Epoch: 132 Training Error: 106.102295 Validation Error: 106.192245\n",
            "Epoch: 133 Training Error: 106.09514 Validation Error: 106.18478\n",
            "Epoch: 134 Training Error: 106.08801 Validation Error: 106.17732\n",
            "Epoch: 135 Training Error: 106.08086 Validation Error: 106.169975\n",
            "Epoch: 136 Training Error: 106.07383 Validation Error: 106.16261\n",
            "Epoch: 137 Training Error: 106.06698 Validation Error: 106.1554\n",
            "Epoch: 138 Training Error: 106.06032 Validation Error: 106.14847\n",
            "Epoch: 139 Training Error: 106.05392 Validation Error: 106.14171\n",
            "Epoch: 140 Training Error: 106.04739 Validation Error: 106.13486\n",
            "Epoch: 141 Training Error: 106.041115 Validation Error: 106.12818\n",
            "Epoch: 142 Training Error: 106.03469 Validation Error: 106.121574\n",
            "Epoch: 143 Training Error: 106.02815 Validation Error: 106.11481\n",
            "Epoch: 144 Training Error: 106.021965 Validation Error: 106.10842\n",
            "Epoch: 145 Training Error: 106.01568 Validation Error: 106.10196\n",
            "Epoch: 146 Training Error: 106.009514 Validation Error: 106.09561\n",
            "Epoch: 147 Training Error: 106.00334 Validation Error: 106.08926\n",
            "Epoch: 148 Training Error: 105.997185 Validation Error: 106.08297\n",
            "Epoch: 149 Training Error: 105.991135 Validation Error: 106.076546\n",
            "Epoch: 150 Training Error: 105.98489 Validation Error: 106.07012\n",
            "Epoch: 151 Training Error: 105.97892 Validation Error: 106.06393\n",
            "Epoch: 152 Training Error: 105.973015 Validation Error: 106.05785\n",
            "Epoch: 153 Training Error: 105.967155 Validation Error: 106.05183\n",
            "Epoch: 154 Training Error: 105.96164 Validation Error: 106.04613\n",
            "Epoch: 155 Training Error: 105.95613 Validation Error: 106.04048\n",
            "Epoch: 156 Training Error: 105.950714 Validation Error: 106.03487\n",
            "Epoch: 157 Training Error: 105.94521 Validation Error: 106.02914\n",
            "Epoch: 158 Training Error: 105.9398 Validation Error: 106.02352\n",
            "Epoch: 159 Training Error: 105.9344 Validation Error: 106.01796\n",
            "Epoch: 160 Training Error: 105.92922 Validation Error: 106.01258\n",
            "Epoch: 161 Training Error: 105.9241 Validation Error: 106.007324\n",
            "Epoch: 162 Training Error: 105.91911 Validation Error: 106.002144\n",
            "Epoch: 163 Training Error: 105.91407 Validation Error: 105.99684\n",
            "Epoch: 164 Training Error: 105.908775 Validation Error: 105.991394\n",
            "Epoch: 165 Training Error: 105.903595 Validation Error: 105.98593\n",
            "Epoch: 166 Training Error: 105.89849 Validation Error: 105.98063\n",
            "Epoch: 167 Training Error: 105.89356 Validation Error: 105.97555\n",
            "Epoch: 168 Training Error: 105.888596 Validation Error: 105.97047\n",
            "Epoch: 169 Training Error: 105.88361 Validation Error: 105.965294\n",
            "Epoch: 170 Training Error: 105.87857 Validation Error: 105.96008\n",
            "Epoch: 171 Training Error: 105.87365 Validation Error: 105.95504\n",
            "Epoch: 172 Training Error: 105.868904 Validation Error: 105.95012\n",
            "Epoch: 173 Training Error: 105.864334 Validation Error: 105.94535\n",
            "Epoch: 174 Training Error: 105.859955 Validation Error: 105.94078\n",
            "Epoch: 175 Training Error: 105.85547 Validation Error: 105.936134\n",
            "Epoch: 176 Training Error: 105.85095 Validation Error: 105.931465\n",
            "Epoch: 177 Training Error: 105.84644 Validation Error: 105.92681\n",
            "Epoch: 178 Training Error: 105.84178 Validation Error: 105.922066\n",
            "Epoch: 179 Training Error: 105.83738 Validation Error: 105.91752\n",
            "Epoch: 180 Training Error: 105.832985 Validation Error: 105.912964\n",
            "Epoch: 181 Training Error: 105.82861 Validation Error: 105.90836\n",
            "Epoch: 182 Training Error: 105.82428 Validation Error: 105.90391\n",
            "Epoch: 183 Training Error: 105.81997 Validation Error: 105.89946\n",
            "Epoch: 184 Training Error: 105.81587 Validation Error: 105.895256\n",
            "Epoch: 185 Training Error: 105.81174 Validation Error: 105.891045\n",
            "Epoch: 186 Training Error: 105.80752 Validation Error: 105.886765\n",
            "Epoch: 187 Training Error: 105.80348 Validation Error: 105.88265\n",
            "Epoch: 188 Training Error: 105.7995 Validation Error: 105.87844\n",
            "Epoch: 189 Training Error: 105.79554 Validation Error: 105.8744\n",
            "Epoch: 190 Training Error: 105.79166 Validation Error: 105.87036\n",
            "Epoch: 191 Training Error: 105.7876 Validation Error: 105.86618\n",
            "Epoch: 192 Training Error: 105.78386 Validation Error: 105.8623\n",
            "Epoch: 193 Training Error: 105.78002 Validation Error: 105.85831\n",
            "Epoch: 194 Training Error: 105.776115 Validation Error: 105.85426\n",
            "Epoch: 195 Training Error: 105.772316 Validation Error: 105.85039\n",
            "Epoch: 196 Training Error: 105.76833 Validation Error: 105.84623\n",
            "Epoch: 197 Training Error: 105.76456 Validation Error: 105.842384\n",
            "Epoch: 198 Training Error: 105.76077 Validation Error: 105.83851\n",
            "Epoch: 199 Training Error: 105.75713 Validation Error: 105.83469\n",
            "Epoch: 200 Training Error: 105.75355 Validation Error: 105.830925\n",
            "Epoch: 201 Training Error: 105.75002 Validation Error: 105.82728\n",
            "Epoch: 202 Training Error: 105.74655 Validation Error: 105.82357\n",
            "Epoch: 203 Training Error: 105.74295 Validation Error: 105.819855\n",
            "Epoch: 204 Training Error: 105.73953 Validation Error: 105.81627\n",
            "Epoch: 205 Training Error: 105.735954 Validation Error: 105.81252\n",
            "Epoch: 206 Training Error: 105.73238 Validation Error: 105.80886\n",
            "Epoch: 207 Training Error: 105.728806 Validation Error: 105.80516\n",
            "Epoch: 208 Training Error: 105.72531 Validation Error: 105.80161\n",
            "Epoch: 209 Training Error: 105.72179 Validation Error: 105.79808\n",
            "Epoch: 210 Training Error: 105.71825 Validation Error: 105.7945\n",
            "Epoch: 211 Training Error: 105.715034 Validation Error: 105.79107\n",
            "Epoch: 212 Training Error: 105.71184 Validation Error: 105.7877\n",
            "Epoch: 213 Training Error: 105.70867 Validation Error: 105.78437\n",
            "Epoch: 214 Training Error: 105.70567 Validation Error: 105.7811\n",
            "Epoch: 215 Training Error: 105.7028 Validation Error: 105.77793\n",
            "Epoch: 216 Training Error: 105.69977 Validation Error: 105.77476\n",
            "Epoch: 217 Training Error: 105.696754 Validation Error: 105.77153\n",
            "Epoch: 218 Training Error: 105.69362 Validation Error: 105.768234\n",
            "Epoch: 219 Training Error: 105.690445 Validation Error: 105.76495\n",
            "Epoch: 220 Training Error: 105.68738 Validation Error: 105.761734\n",
            "Epoch: 221 Training Error: 105.684494 Validation Error: 105.75867\n",
            "Epoch: 222 Training Error: 105.68175 Validation Error: 105.75571\n",
            "Epoch: 223 Training Error: 105.67881 Validation Error: 105.75263\n",
            "Epoch: 224 Training Error: 105.675964 Validation Error: 105.7497\n",
            "Epoch: 225 Training Error: 105.67301 Validation Error: 105.74679\n",
            "Epoch: 226 Training Error: 105.67026 Validation Error: 105.74391\n",
            "Epoch: 227 Training Error: 105.6675 Validation Error: 105.74107\n",
            "Epoch: 228 Training Error: 105.66469 Validation Error: 105.73824\n",
            "Epoch: 229 Training Error: 105.66169 Validation Error: 105.73522\n",
            "Epoch: 230 Training Error: 105.65881 Validation Error: 105.73219\n",
            "Epoch: 231 Training Error: 105.656075 Validation Error: 105.72928\n",
            "Epoch: 232 Training Error: 105.65345 Validation Error: 105.726494\n",
            "Epoch: 233 Training Error: 105.650856 Validation Error: 105.7237\n",
            "Epoch: 234 Training Error: 105.64824 Validation Error: 105.72088\n",
            "Epoch: 235 Training Error: 105.64565 Validation Error: 105.718\n",
            "Epoch: 236 Training Error: 105.64313 Validation Error: 105.71531\n",
            "Epoch: 237 Training Error: 105.64059 Validation Error: 105.71265\n",
            "Epoch: 238 Training Error: 105.63807 Validation Error: 105.70993\n",
            "Epoch: 239 Training Error: 105.63563 Validation Error: 105.70737\n",
            "Epoch: 240 Training Error: 105.63301 Validation Error: 105.704666\n",
            "Epoch: 241 Training Error: 105.63045 Validation Error: 105.701996\n",
            "Epoch: 242 Training Error: 105.62787 Validation Error: 105.69929\n",
            "Epoch: 243 Training Error: 105.62544 Validation Error: 105.696655\n",
            "Epoch: 244 Training Error: 105.62299 Validation Error: 105.694016\n",
            "Epoch: 245 Training Error: 105.62066 Validation Error: 105.6915\n",
            "Epoch: 246 Training Error: 105.61815 Validation Error: 105.688896\n",
            "Epoch: 247 Training Error: 105.61569 Validation Error: 105.68639\n",
            "Epoch: 248 Training Error: 105.61333 Validation Error: 105.68391\n",
            "Epoch: 249 Training Error: 105.61102 Validation Error: 105.68141\n",
            "Epoch: 250 Training Error: 105.60864 Validation Error: 105.67894\n",
            "Epoch: 251 Training Error: 105.60651 Validation Error: 105.67666\n",
            "Epoch: 252 Training Error: 105.60424 Validation Error: 105.67444\n",
            "Epoch: 253 Training Error: 105.60204 Validation Error: 105.6722\n",
            "Epoch: 254 Training Error: 105.59988 Validation Error: 105.66992\n",
            "Epoch: 255 Training Error: 105.59767 Validation Error: 105.66767\n",
            "Epoch: 256 Training Error: 105.59558 Validation Error: 105.66545\n",
            "Epoch: 257 Training Error: 105.59343 Validation Error: 105.663124\n",
            "Epoch: 258 Training Error: 105.5913 Validation Error: 105.66096\n",
            "Epoch: 259 Training Error: 105.58916 Validation Error: 105.65885\n",
            "Epoch: 260 Training Error: 105.58701 Validation Error: 105.65666\n",
            "Epoch: 261 Training Error: 105.58484 Validation Error: 105.654396\n",
            "Epoch: 262 Training Error: 105.582634 Validation Error: 105.65214\n",
            "Epoch: 263 Training Error: 105.58045 Validation Error: 105.649864\n",
            "Epoch: 264 Training Error: 105.57834 Validation Error: 105.64766\n",
            "Epoch: 265 Training Error: 105.57623 Validation Error: 105.645454\n",
            "Epoch: 266 Training Error: 105.57418 Validation Error: 105.643196\n",
            "Epoch: 267 Training Error: 105.572136 Validation Error: 105.64097\n",
            "Epoch: 268 Training Error: 105.57012 Validation Error: 105.63878\n",
            "Epoch: 269 Training Error: 105.56825 Validation Error: 105.636696\n",
            "Epoch: 270 Training Error: 105.56637 Validation Error: 105.63472\n",
            "Epoch: 271 Training Error: 105.56439 Validation Error: 105.63265\n",
            "Epoch: 272 Training Error: 105.56261 Validation Error: 105.6307\n",
            "Epoch: 273 Training Error: 105.56075 Validation Error: 105.62869\n",
            "Epoch: 274 Training Error: 105.55882 Validation Error: 105.62668\n",
            "Epoch: 275 Training Error: 105.556984 Validation Error: 105.62471\n",
            "Epoch: 276 Training Error: 105.555 Validation Error: 105.622665\n",
            "Epoch: 277 Training Error: 105.553085 Validation Error: 105.62071\n",
            "Epoch: 278 Training Error: 105.55119 Validation Error: 105.61869\n",
            "Epoch: 279 Training Error: 105.5493 Validation Error: 105.61659\n",
            "Epoch: 280 Training Error: 105.54747 Validation Error: 105.614624\n",
            "Epoch: 281 Training Error: 105.5457 Validation Error: 105.61273\n",
            "Epoch: 282 Training Error: 105.54397 Validation Error: 105.61095\n",
            "Epoch: 283 Training Error: 105.54227 Validation Error: 105.60921\n",
            "Epoch: 284 Training Error: 105.54048 Validation Error: 105.60751\n",
            "Epoch: 285 Training Error: 105.5388 Validation Error: 105.60572\n",
            "Epoch: 286 Training Error: 105.537155 Validation Error: 105.603874\n",
            "Epoch: 287 Training Error: 105.5355 Validation Error: 105.60206\n",
            "Epoch: 288 Training Error: 105.53378 Validation Error: 105.600266\n",
            "Epoch: 289 Training Error: 105.532104 Validation Error: 105.59832\n",
            "Epoch: 290 Training Error: 105.530556 Validation Error: 105.59649\n",
            "Epoch: 291 Training Error: 105.52899 Validation Error: 105.594795\n",
            "Epoch: 292 Training Error: 105.527435 Validation Error: 105.59308\n",
            "Epoch: 293 Training Error: 105.525826 Validation Error: 105.591324\n",
            "Epoch: 294 Training Error: 105.52431 Validation Error: 105.589645\n",
            "Epoch: 295 Training Error: 105.52275 Validation Error: 105.58799\n",
            "Epoch: 296 Training Error: 105.52121 Validation Error: 105.586266\n",
            "Epoch: 297 Training Error: 105.51968 Validation Error: 105.584564\n",
            "Epoch: 298 Training Error: 105.5182 Validation Error: 105.582855\n",
            "Epoch: 299 Training Error: 105.51675 Validation Error: 105.581215\n",
            "Epoch: 300 Training Error: 105.51532 Validation Error: 105.57962\n",
            "Epoch: 301 Training Error: 105.51386 Validation Error: 105.57799\n",
            "Epoch: 302 Training Error: 105.51245 Validation Error: 105.57643\n",
            "Epoch: 303 Training Error: 105.510994 Validation Error: 105.57484\n",
            "Epoch: 304 Training Error: 105.50957 Validation Error: 105.573265\n",
            "Epoch: 305 Training Error: 105.50806 Validation Error: 105.57165\n",
            "Epoch: 306 Training Error: 105.50656 Validation Error: 105.57007\n",
            "Epoch: 307 Training Error: 105.50516 Validation Error: 105.5685\n",
            "Epoch: 308 Training Error: 105.50378 Validation Error: 105.5669\n",
            "Epoch: 309 Training Error: 105.50236 Validation Error: 105.56538\n",
            "Epoch: 310 Training Error: 105.500946 Validation Error: 105.56384\n",
            "Epoch: 311 Training Error: 105.499626 Validation Error: 105.56225\n",
            "Epoch: 312 Training Error: 105.49822 Validation Error: 105.56073\n",
            "Epoch: 313 Training Error: 105.496826 Validation Error: 105.55926\n",
            "Epoch: 314 Training Error: 105.495384 Validation Error: 105.55778\n",
            "Epoch: 315 Training Error: 105.493935 Validation Error: 105.55626\n",
            "Epoch: 316 Training Error: 105.49247 Validation Error: 105.55482\n",
            "Epoch: 317 Training Error: 105.49107 Validation Error: 105.55333\n",
            "Epoch: 318 Training Error: 105.489655 Validation Error: 105.55191\n",
            "Epoch: 319 Training Error: 105.48831 Validation Error: 105.55039\n",
            "Epoch: 320 Training Error: 105.486824 Validation Error: 105.54889\n",
            "Epoch: 321 Training Error: 105.48544 Validation Error: 105.54739\n",
            "Epoch: 322 Training Error: 105.484146 Validation Error: 105.54591\n",
            "Epoch: 323 Training Error: 105.48282 Validation Error: 105.54444\n",
            "Epoch: 324 Training Error: 105.481544 Validation Error: 105.54296\n",
            "Epoch: 325 Training Error: 105.48022 Validation Error: 105.54153\n",
            "Epoch: 326 Training Error: 105.47894 Validation Error: 105.54017\n",
            "Epoch: 327 Training Error: 105.47762 Validation Error: 105.53878\n",
            "Epoch: 328 Training Error: 105.47634 Validation Error: 105.537384\n",
            "Epoch: 329 Training Error: 105.475136 Validation Error: 105.53599\n",
            "Epoch: 330 Training Error: 105.473976 Validation Error: 105.53465\n",
            "Epoch: 331 Training Error: 105.472755 Validation Error: 105.53323\n",
            "Epoch: 332 Training Error: 105.47146 Validation Error: 105.53194\n",
            "Epoch: 333 Training Error: 105.470314 Validation Error: 105.530655\n",
            "Epoch: 334 Training Error: 105.46907 Validation Error: 105.529366\n",
            "Epoch: 335 Training Error: 105.46793 Validation Error: 105.52809\n",
            "Epoch: 336 Training Error: 105.466805 Validation Error: 105.52686\n",
            "Epoch: 337 Training Error: 105.46568 Validation Error: 105.52561\n",
            "Epoch: 338 Training Error: 105.46458 Validation Error: 105.52431\n",
            "Epoch: 339 Training Error: 105.46349 Validation Error: 105.52305\n",
            "Epoch: 340 Training Error: 105.46249 Validation Error: 105.52173\n",
            "Epoch: 341 Training Error: 105.461365 Validation Error: 105.52036\n",
            "Epoch: 342 Training Error: 105.46023 Validation Error: 105.519005\n",
            "Epoch: 343 Training Error: 105.45908 Validation Error: 105.51777\n",
            "Epoch: 344 Training Error: 105.457924 Validation Error: 105.51647\n",
            "Epoch: 345 Training Error: 105.456726 Validation Error: 105.51519\n",
            "Epoch: 346 Training Error: 105.455475 Validation Error: 105.514046\n",
            "Epoch: 347 Training Error: 105.454475 Validation Error: 105.512886\n",
            "Epoch: 348 Training Error: 105.453545 Validation Error: 105.51178\n",
            "Epoch: 349 Training Error: 105.452484 Validation Error: 105.5106\n",
            "Epoch: 350 Training Error: 105.45136 Validation Error: 105.50939\n",
            "Epoch: 351 Training Error: 105.45023 Validation Error: 105.50817\n",
            "Epoch: 352 Training Error: 105.44916 Validation Error: 105.50693\n",
            "Epoch: 353 Training Error: 105.44815 Validation Error: 105.50575\n",
            "Epoch: 354 Training Error: 105.447014 Validation Error: 105.50465\n",
            "Epoch: 355 Training Error: 105.445946 Validation Error: 105.50351\n",
            "Epoch: 356 Training Error: 105.44482 Validation Error: 105.50239\n",
            "Epoch: 357 Training Error: 105.443695 Validation Error: 105.501175\n",
            "Epoch: 358 Training Error: 105.44256 Validation Error: 105.499954\n",
            "Epoch: 359 Training Error: 105.44145 Validation Error: 105.4988\n",
            "Epoch: 360 Training Error: 105.44047 Validation Error: 105.49771\n",
            "Epoch: 361 Training Error: 105.439545 Validation Error: 105.49655\n",
            "Epoch: 362 Training Error: 105.43845 Validation Error: 105.495445\n",
            "Epoch: 363 Training Error: 105.43739 Validation Error: 105.49426\n",
            "Epoch: 364 Training Error: 105.43641 Validation Error: 105.49314\n",
            "Epoch: 365 Training Error: 105.435425 Validation Error: 105.492065\n",
            "Epoch: 366 Training Error: 105.43448 Validation Error: 105.49105\n",
            "Epoch: 367 Training Error: 105.43357 Validation Error: 105.49001\n",
            "Epoch: 368 Training Error: 105.43263 Validation Error: 105.48899\n",
            "Epoch: 369 Training Error: 105.43155 Validation Error: 105.48796\n",
            "Epoch: 370 Training Error: 105.43043 Validation Error: 105.486916\n",
            "Epoch: 371 Training Error: 105.429375 Validation Error: 105.48588\n",
            "Epoch: 372 Training Error: 105.42835 Validation Error: 105.48475\n",
            "Epoch: 373 Training Error: 105.42733 Validation Error: 105.48367\n",
            "Epoch: 374 Training Error: 105.426285 Validation Error: 105.48257\n",
            "Epoch: 375 Training Error: 105.425186 Validation Error: 105.481384\n",
            "Epoch: 376 Training Error: 105.42416 Validation Error: 105.48016\n",
            "Epoch: 377 Training Error: 105.42319 Validation Error: 105.47908\n",
            "Epoch: 378 Training Error: 105.42225 Validation Error: 105.47801\n",
            "Epoch: 379 Training Error: 105.42126 Validation Error: 105.47697\n",
            "Epoch: 380 Training Error: 105.42028 Validation Error: 105.47595\n",
            "Epoch: 381 Training Error: 105.41935 Validation Error: 105.47494\n",
            "Epoch: 382 Training Error: 105.41849 Validation Error: 105.4739\n",
            "Epoch: 383 Training Error: 105.41763 Validation Error: 105.47291\n",
            "Epoch: 384 Training Error: 105.416824 Validation Error: 105.47199\n",
            "Epoch: 385 Training Error: 105.41596 Validation Error: 105.471115\n",
            "Epoch: 386 Training Error: 105.41509 Validation Error: 105.47024\n",
            "Epoch: 387 Training Error: 105.41425 Validation Error: 105.46929\n",
            "Epoch: 388 Training Error: 105.41341 Validation Error: 105.46832\n",
            "Epoch: 389 Training Error: 105.41254 Validation Error: 105.467354\n",
            "Epoch: 390 Training Error: 105.411674 Validation Error: 105.46631\n",
            "Epoch: 391 Training Error: 105.41083 Validation Error: 105.46535\n",
            "Epoch: 392 Training Error: 105.410034 Validation Error: 105.46436\n",
            "Epoch: 393 Training Error: 105.40921 Validation Error: 105.46338\n",
            "Epoch: 394 Training Error: 105.40848 Validation Error: 105.46245\n",
            "Epoch: 395 Training Error: 105.40769 Validation Error: 105.461586\n",
            "Epoch: 396 Training Error: 105.4069 Validation Error: 105.46078\n",
            "Epoch: 397 Training Error: 105.40602 Validation Error: 105.45983\n",
            "Epoch: 398 Training Error: 105.405106 Validation Error: 105.45893\n",
            "Epoch: 399 Training Error: 105.40424 Validation Error: 105.45796\n",
            "Epoch: 400 Training Error: 105.40338 Validation Error: 105.45713\n",
            "Epoch: 401 Training Error: 105.40259 Validation Error: 105.45619\n",
            "Epoch: 402 Training Error: 105.4018 Validation Error: 105.45531\n",
            "Epoch: 403 Training Error: 105.40102 Validation Error: 105.45443\n",
            "Epoch: 404 Training Error: 105.400246 Validation Error: 105.45355\n",
            "Epoch: 405 Training Error: 105.39951 Validation Error: 105.45261\n",
            "Epoch: 406 Training Error: 105.39871 Validation Error: 105.451675\n",
            "Epoch: 407 Training Error: 105.39784 Validation Error: 105.450874\n",
            "Epoch: 408 Training Error: 105.39707 Validation Error: 105.45002\n",
            "Epoch: 409 Training Error: 105.39631 Validation Error: 105.4491\n",
            "Epoch: 410 Training Error: 105.39553 Validation Error: 105.448265\n",
            "Epoch: 411 Training Error: 105.39475 Validation Error: 105.44744\n",
            "Epoch: 412 Training Error: 105.393974 Validation Error: 105.44658\n",
            "Epoch: 413 Training Error: 105.393295 Validation Error: 105.44567\n",
            "Epoch: 414 Training Error: 105.392586 Validation Error: 105.44475\n",
            "Epoch: 415 Training Error: 105.39189 Validation Error: 105.4439\n",
            "Epoch: 416 Training Error: 105.39117 Validation Error: 105.44301\n",
            "Epoch: 417 Training Error: 105.39041 Validation Error: 105.44222\n",
            "Epoch: 418 Training Error: 105.38965 Validation Error: 105.441475\n",
            "Epoch: 419 Training Error: 105.38896 Validation Error: 105.44069\n",
            "Epoch: 420 Training Error: 105.388245 Validation Error: 105.43993\n",
            "Epoch: 421 Training Error: 105.38752 Validation Error: 105.43907\n",
            "Epoch: 422 Training Error: 105.38683 Validation Error: 105.43825\n",
            "Epoch: 423 Training Error: 105.3861 Validation Error: 105.437416\n",
            "Epoch: 424 Training Error: 105.38541 Validation Error: 105.436584\n",
            "Epoch: 425 Training Error: 105.3847 Validation Error: 105.43578\n",
            "Epoch: 426 Training Error: 105.38401 Validation Error: 105.43494\n",
            "Epoch: 427 Training Error: 105.38336 Validation Error: 105.43409\n",
            "Epoch: 428 Training Error: 105.38265 Validation Error: 105.43334\n",
            "Epoch: 429 Training Error: 105.38193 Validation Error: 105.43257\n",
            "Epoch: 430 Training Error: 105.38123 Validation Error: 105.43172\n",
            "Epoch: 431 Training Error: 105.38051 Validation Error: 105.430916\n",
            "Epoch: 432 Training Error: 105.37984 Validation Error: 105.43011\n",
            "Epoch: 433 Training Error: 105.37914 Validation Error: 105.42936\n",
            "Epoch: 434 Training Error: 105.378456 Validation Error: 105.42859\n",
            "Epoch: 435 Training Error: 105.37777 Validation Error: 105.42782\n",
            "Epoch: 436 Training Error: 105.37708 Validation Error: 105.42698\n",
            "Epoch: 437 Training Error: 105.37643 Validation Error: 105.426186\n",
            "Epoch: 438 Training Error: 105.375755 Validation Error: 105.42544\n",
            "Epoch: 439 Training Error: 105.37505 Validation Error: 105.424706\n",
            "Epoch: 440 Training Error: 105.374374 Validation Error: 105.42392\n",
            "Epoch: 441 Training Error: 105.37365 Validation Error: 105.42311\n",
            "Epoch: 442 Training Error: 105.373 Validation Error: 105.422264\n",
            "Epoch: 443 Training Error: 105.37238 Validation Error: 105.42148\n",
            "Epoch: 444 Training Error: 105.37172 Validation Error: 105.42083\n",
            "Epoch: 445 Training Error: 105.371086 Validation Error: 105.42016\n",
            "Epoch: 446 Training Error: 105.370415 Validation Error: 105.41951\n",
            "Epoch: 447 Training Error: 105.36979 Validation Error: 105.41878\n",
            "Epoch: 448 Training Error: 105.369194 Validation Error: 105.41798\n",
            "Epoch: 449 Training Error: 105.368546 Validation Error: 105.41727\n",
            "Epoch: 450 Training Error: 105.36797 Validation Error: 105.4165\n",
            "Epoch: 451 Training Error: 105.36737 Validation Error: 105.41574\n",
            "Epoch: 452 Training Error: 105.36676 Validation Error: 105.415\n",
            "Epoch: 453 Training Error: 105.36613 Validation Error: 105.41428\n",
            "Epoch: 454 Training Error: 105.36551 Validation Error: 105.413605\n",
            "Epoch: 455 Training Error: 105.364845 Validation Error: 105.412834\n",
            "Epoch: 456 Training Error: 105.36421 Validation Error: 105.41212\n",
            "Epoch: 457 Training Error: 105.363625 Validation Error: 105.41131\n",
            "Epoch: 458 Training Error: 105.362976 Validation Error: 105.41059\n",
            "Epoch: 459 Training Error: 105.362366 Validation Error: 105.409935\n",
            "Epoch: 460 Training Error: 105.36175 Validation Error: 105.409225\n",
            "Epoch: 461 Training Error: 105.361145 Validation Error: 105.40858\n",
            "Epoch: 462 Training Error: 105.36053 Validation Error: 105.40785\n",
            "Epoch: 463 Training Error: 105.35992 Validation Error: 105.407234\n",
            "Epoch: 464 Training Error: 105.35933 Validation Error: 105.40649\n",
            "Epoch: 465 Training Error: 105.35874 Validation Error: 105.405716\n",
            "Epoch: 466 Training Error: 105.35813 Validation Error: 105.40505\n",
            "Epoch: 467 Training Error: 105.35759 Validation Error: 105.404335\n",
            "Epoch: 468 Training Error: 105.35701 Validation Error: 105.403694\n",
            "Epoch: 469 Training Error: 105.35647 Validation Error: 105.40304\n",
            "Epoch: 470 Training Error: 105.355896 Validation Error: 105.40243\n",
            "Epoch: 471 Training Error: 105.355316 Validation Error: 105.40182\n",
            "Epoch: 472 Training Error: 105.35476 Validation Error: 105.401184\n",
            "Epoch: 473 Training Error: 105.3542 Validation Error: 105.40046\n",
            "Epoch: 474 Training Error: 105.3536 Validation Error: 105.399864\n",
            "Epoch: 475 Training Error: 105.35304 Validation Error: 105.399216\n",
            "Epoch: 476 Training Error: 105.35247 Validation Error: 105.39851\n",
            "Epoch: 477 Training Error: 105.35192 Validation Error: 105.397865\n",
            "Epoch: 478 Training Error: 105.35136 Validation Error: 105.39719\n",
            "Epoch: 479 Training Error: 105.350784 Validation Error: 105.39652\n",
            "Epoch: 480 Training Error: 105.35025 Validation Error: 105.39585\n",
            "Epoch: 481 Training Error: 105.3497 Validation Error: 105.395325\n",
            "Epoch: 482 Training Error: 105.349205 Validation Error: 105.39473\n",
            "Epoch: 483 Training Error: 105.34867 Validation Error: 105.39406\n",
            "Epoch: 484 Training Error: 105.34812 Validation Error: 105.39347\n",
            "Epoch: 485 Training Error: 105.347565 Validation Error: 105.39285\n",
            "Epoch: 486 Training Error: 105.347015 Validation Error: 105.392204\n",
            "Epoch: 487 Training Error: 105.34645 Validation Error: 105.3916\n",
            "Epoch: 488 Training Error: 105.34593 Validation Error: 105.39101\n",
            "Epoch: 489 Training Error: 105.34538 Validation Error: 105.39041\n",
            "Epoch: 490 Training Error: 105.34485 Validation Error: 105.38978\n",
            "Epoch: 491 Training Error: 105.34432 Validation Error: 105.389175\n",
            "Epoch: 492 Training Error: 105.3438 Validation Error: 105.388626\n",
            "Epoch: 493 Training Error: 105.34329 Validation Error: 105.388054\n",
            "Epoch: 494 Training Error: 105.3428 Validation Error: 105.38746\n",
            "Epoch: 495 Training Error: 105.34233 Validation Error: 105.38685\n",
            "Epoch: 496 Training Error: 105.34187 Validation Error: 105.38635\n",
            "Epoch: 497 Training Error: 105.34142 Validation Error: 105.38579\n",
            "Epoch: 498 Training Error: 105.34097 Validation Error: 105.38524\n",
            "Epoch: 499 Training Error: 105.3405 Validation Error: 105.3848\n",
            "Epoch: 500 Training Error: 105.34004 Validation Error: 105.38431\n",
            "Epoch: 501 Training Error: 105.33957 Validation Error: 105.383736\n",
            "Epoch: 502 Training Error: 105.339096 Validation Error: 105.3831\n",
            "Epoch: 503 Training Error: 105.33866 Validation Error: 105.382515\n",
            "Epoch: 504 Training Error: 105.33819 Validation Error: 105.38196\n",
            "Epoch: 505 Training Error: 105.337685 Validation Error: 105.381454\n",
            "Epoch: 506 Training Error: 105.33721 Validation Error: 105.38091\n",
            "Epoch: 507 Training Error: 105.336716 Validation Error: 105.38041\n",
            "Epoch: 508 Training Error: 105.3362 Validation Error: 105.379814\n",
            "Epoch: 509 Training Error: 105.33573 Validation Error: 105.3792\n",
            "Epoch: 510 Training Error: 105.33526 Validation Error: 105.37868\n",
            "Epoch: 511 Training Error: 105.334785 Validation Error: 105.37816\n",
            "Epoch: 512 Training Error: 105.334335 Validation Error: 105.377625\n",
            "Epoch: 513 Training Error: 105.333916 Validation Error: 105.37704\n",
            "Epoch: 514 Training Error: 105.33345 Validation Error: 105.37655\n",
            "Epoch: 515 Training Error: 105.333046 Validation Error: 105.376076\n",
            "Epoch: 516 Training Error: 105.33266 Validation Error: 105.375595\n",
            "Epoch: 517 Training Error: 105.332245 Validation Error: 105.37519\n",
            "Epoch: 518 Training Error: 105.331795 Validation Error: 105.37477\n",
            "Epoch: 519 Training Error: 105.33135 Validation Error: 105.3743\n",
            "Epoch: 520 Training Error: 105.33089 Validation Error: 105.37383\n",
            "Epoch: 521 Training Error: 105.33045 Validation Error: 105.373314\n",
            "Epoch: 522 Training Error: 105.329994 Validation Error: 105.37286\n",
            "Epoch: 523 Training Error: 105.329544 Validation Error: 105.37235\n",
            "Epoch: 524 Training Error: 105.32911 Validation Error: 105.371796\n",
            "Epoch: 525 Training Error: 105.32866 Validation Error: 105.37131\n",
            "Epoch: 526 Training Error: 105.32821 Validation Error: 105.37085\n",
            "Epoch: 527 Training Error: 105.32777 Validation Error: 105.37026\n",
            "Epoch: 528 Training Error: 105.32732 Validation Error: 105.369675\n",
            "Epoch: 529 Training Error: 105.326866 Validation Error: 105.369095\n",
            "Epoch: 530 Training Error: 105.32643 Validation Error: 105.36851\n",
            "Epoch: 531 Training Error: 105.32604 Validation Error: 105.36796\n",
            "Epoch: 532 Training Error: 105.32564 Validation Error: 105.367386\n",
            "Epoch: 533 Training Error: 105.32523 Validation Error: 105.3669\n",
            "Epoch: 534 Training Error: 105.3248 Validation Error: 105.36646\n",
            "Epoch: 535 Training Error: 105.324425 Validation Error: 105.365944\n",
            "Epoch: 536 Training Error: 105.32403 Validation Error: 105.36549\n",
            "Epoch: 537 Training Error: 105.32364 Validation Error: 105.36498\n",
            "Epoch: 538 Training Error: 105.323204 Validation Error: 105.36455\n",
            "Epoch: 539 Training Error: 105.32276 Validation Error: 105.364136\n",
            "Epoch: 540 Training Error: 105.32235 Validation Error: 105.363716\n",
            "Epoch: 541 Training Error: 105.321945 Validation Error: 105.363205\n",
            "Epoch: 542 Training Error: 105.32154 Validation Error: 105.36278\n",
            "Epoch: 543 Training Error: 105.32113 Validation Error: 105.36238\n",
            "Epoch: 544 Training Error: 105.320694 Validation Error: 105.36185\n",
            "Epoch: 545 Training Error: 105.32029 Validation Error: 105.36126\n",
            "Epoch: 546 Training Error: 105.31988 Validation Error: 105.36069\n",
            "Epoch: 547 Training Error: 105.319496 Validation Error: 105.36031\n",
            "Epoch: 548 Training Error: 105.31911 Validation Error: 105.35974\n",
            "Epoch: 549 Training Error: 105.31873 Validation Error: 105.359215\n",
            "Epoch: 550 Training Error: 105.31832 Validation Error: 105.358795\n",
            "Epoch: 551 Training Error: 105.31798 Validation Error: 105.358345\n",
            "Epoch: 552 Training Error: 105.317604 Validation Error: 105.35786\n",
            "Epoch: 553 Training Error: 105.317215 Validation Error: 105.35734\n",
            "Epoch: 554 Training Error: 105.31683 Validation Error: 105.35681\n",
            "Epoch: 555 Training Error: 105.316444 Validation Error: 105.356316\n",
            "Epoch: 556 Training Error: 105.31605 Validation Error: 105.35578\n",
            "Epoch: 557 Training Error: 105.31568 Validation Error: 105.355286\n",
            "Epoch: 558 Training Error: 105.315285 Validation Error: 105.35484\n",
            "Epoch: 559 Training Error: 105.31487 Validation Error: 105.35448\n",
            "Epoch: 560 Training Error: 105.31449 Validation Error: 105.354065\n",
            "Epoch: 561 Training Error: 105.31412 Validation Error: 105.353615\n",
            "Epoch: 562 Training Error: 105.31373 Validation Error: 105.35318\n",
            "Epoch: 563 Training Error: 105.31335 Validation Error: 105.352745\n",
            "Epoch: 564 Training Error: 105.31296 Validation Error: 105.35218\n",
            "Epoch: 565 Training Error: 105.31256 Validation Error: 105.351685\n",
            "Epoch: 566 Training Error: 105.31217 Validation Error: 105.3512\n",
            "Epoch: 567 Training Error: 105.31179 Validation Error: 105.3507\n",
            "Epoch: 568 Training Error: 105.31138 Validation Error: 105.350174\n",
            "Epoch: 569 Training Error: 105.31094 Validation Error: 105.34977\n",
            "Epoch: 570 Training Error: 105.31052 Validation Error: 105.349365\n",
            "Epoch: 571 Training Error: 105.31014 Validation Error: 105.34899\n",
            "Epoch: 572 Training Error: 105.309784 Validation Error: 105.34859\n",
            "Epoch: 573 Training Error: 105.309395 Validation Error: 105.34821\n",
            "Epoch: 574 Training Error: 105.30904 Validation Error: 105.34781\n",
            "Epoch: 575 Training Error: 105.30868 Validation Error: 105.347336\n",
            "Epoch: 576 Training Error: 105.30835 Validation Error: 105.346855\n",
            "Epoch: 577 Training Error: 105.30799 Validation Error: 105.34639\n",
            "Epoch: 578 Training Error: 105.3076 Validation Error: 105.346016\n",
            "Epoch: 579 Training Error: 105.30726 Validation Error: 105.34566\n",
            "Epoch: 580 Training Error: 105.306885 Validation Error: 105.34538\n",
            "Epoch: 581 Training Error: 105.30652 Validation Error: 105.34503\n",
            "Epoch: 582 Training Error: 105.30618 Validation Error: 105.34466\n",
            "Epoch: 583 Training Error: 105.30586 Validation Error: 105.34425\n",
            "Epoch: 584 Training Error: 105.30551 Validation Error: 105.343765\n",
            "Epoch: 585 Training Error: 105.30515 Validation Error: 105.34327\n",
            "Epoch: 586 Training Error: 105.30479 Validation Error: 105.342804\n",
            "Epoch: 587 Training Error: 105.30443 Validation Error: 105.34246\n",
            "Epoch: 588 Training Error: 105.30408 Validation Error: 105.34203\n",
            "Epoch: 589 Training Error: 105.303734 Validation Error: 105.3417\n",
            "Epoch: 590 Training Error: 105.30336 Validation Error: 105.341324\n",
            "Epoch: 591 Training Error: 105.303024 Validation Error: 105.340935\n",
            "Epoch: 592 Training Error: 105.30272 Validation Error: 105.34059\n",
            "Epoch: 593 Training Error: 105.3024 Validation Error: 105.3402\n",
            "Epoch: 594 Training Error: 105.3021 Validation Error: 105.33979\n",
            "Epoch: 595 Training Error: 105.30177 Validation Error: 105.33942\n",
            "Epoch: 596 Training Error: 105.30147 Validation Error: 105.33902\n",
            "Epoch: 597 Training Error: 105.301155 Validation Error: 105.338684\n",
            "Epoch: 598 Training Error: 105.30086 Validation Error: 105.33821\n",
            "Epoch: 599 Training Error: 105.30057 Validation Error: 105.3378\n",
            "Epoch: 600 Training Error: 105.300285 Validation Error: 105.337364\n",
            "Epoch: 601 Training Error: 105.30002 Validation Error: 105.33693\n",
            "Epoch: 602 Training Error: 105.29968 Validation Error: 105.33658\n",
            "Epoch: 603 Training Error: 105.29936 Validation Error: 105.336105\n",
            "Epoch: 604 Training Error: 105.298996 Validation Error: 105.335785\n",
            "Epoch: 605 Training Error: 105.29866 Validation Error: 105.335495\n",
            "Epoch: 606 Training Error: 105.29834 Validation Error: 105.335144\n",
            "Epoch: 607 Training Error: 105.29804 Validation Error: 105.33476\n",
            "Epoch: 608 Training Error: 105.297714 Validation Error: 105.33445\n",
            "Epoch: 609 Training Error: 105.29742 Validation Error: 105.33405\n",
            "Epoch: 610 Training Error: 105.297066 Validation Error: 105.33368\n",
            "Epoch: 611 Training Error: 105.296745 Validation Error: 105.33329\n",
            "Epoch: 612 Training Error: 105.29641 Validation Error: 105.332954\n",
            "Epoch: 613 Training Error: 105.29609 Validation Error: 105.33256\n",
            "Epoch: 614 Training Error: 105.29578 Validation Error: 105.33222\n",
            "Epoch: 615 Training Error: 105.29546 Validation Error: 105.33189\n",
            "Epoch: 616 Training Error: 105.295166 Validation Error: 105.33153\n",
            "Epoch: 617 Training Error: 105.294876 Validation Error: 105.331215\n",
            "Epoch: 618 Training Error: 105.2946 Validation Error: 105.330864\n",
            "Epoch: 619 Training Error: 105.29434 Validation Error: 105.33051\n",
            "Epoch: 620 Training Error: 105.29405 Validation Error: 105.33024\n",
            "Epoch: 621 Training Error: 105.293755 Validation Error: 105.32993\n",
            "Epoch: 622 Training Error: 105.29348 Validation Error: 105.32957\n",
            "Epoch: 623 Training Error: 105.2932 Validation Error: 105.32925\n",
            "Epoch: 624 Training Error: 105.29291 Validation Error: 105.32896\n",
            "Epoch: 625 Training Error: 105.29261 Validation Error: 105.328575\n",
            "Epoch: 626 Training Error: 105.29231 Validation Error: 105.3282\n",
            "Epoch: 627 Training Error: 105.29202 Validation Error: 105.32785\n",
            "Epoch: 628 Training Error: 105.29174 Validation Error: 105.32749\n",
            "Epoch: 629 Training Error: 105.29144 Validation Error: 105.327156\n",
            "Epoch: 630 Training Error: 105.291145 Validation Error: 105.32679\n",
            "Epoch: 631 Training Error: 105.29084 Validation Error: 105.326416\n",
            "Epoch: 632 Training Error: 105.29054 Validation Error: 105.326096\n",
            "Epoch: 633 Training Error: 105.29027 Validation Error: 105.32572\n",
            "Epoch: 634 Training Error: 105.28997 Validation Error: 105.3254\n",
            "Epoch: 635 Training Error: 105.28969 Validation Error: 105.32505\n",
            "Epoch: 636 Training Error: 105.28938 Validation Error: 105.32476\n",
            "Epoch: 637 Training Error: 105.289085 Validation Error: 105.32448\n",
            "Epoch: 638 Training Error: 105.2888 Validation Error: 105.32415\n",
            "Epoch: 639 Training Error: 105.288506 Validation Error: 105.323845\n",
            "Epoch: 640 Training Error: 105.28823 Validation Error: 105.32363\n",
            "Epoch: 641 Training Error: 105.28794 Validation Error: 105.32336\n",
            "Epoch: 642 Training Error: 105.28766 Validation Error: 105.323\n",
            "Epoch: 643 Training Error: 105.28737 Validation Error: 105.322655\n",
            "Epoch: 644 Training Error: 105.28708 Validation Error: 105.32228\n",
            "Epoch: 645 Training Error: 105.2868 Validation Error: 105.32194\n",
            "Epoch: 646 Training Error: 105.28652 Validation Error: 105.32159\n",
            "Epoch: 647 Training Error: 105.28626 Validation Error: 105.32139\n",
            "Epoch: 648 Training Error: 105.285995 Validation Error: 105.32109\n",
            "Epoch: 649 Training Error: 105.28576 Validation Error: 105.320915\n",
            "Epoch: 650 Training Error: 105.285515 Validation Error: 105.320625\n",
            "Epoch: 651 Training Error: 105.285255 Validation Error: 105.320366\n",
            "Epoch: 652 Training Error: 105.28498 Validation Error: 105.319984\n",
            "Epoch: 653 Training Error: 105.28469 Validation Error: 105.31958\n",
            "Epoch: 654 Training Error: 105.28442 Validation Error: 105.31926\n",
            "Epoch: 655 Training Error: 105.28414 Validation Error: 105.318886\n",
            "Epoch: 656 Training Error: 105.28388 Validation Error: 105.31851\n",
            "Epoch: 657 Training Error: 105.28361 Validation Error: 105.31816\n",
            "Epoch: 658 Training Error: 105.283356 Validation Error: 105.31784\n",
            "Epoch: 659 Training Error: 105.2831 Validation Error: 105.317505\n",
            "Epoch: 660 Training Error: 105.28284 Validation Error: 105.31714\n",
            "Epoch: 661 Training Error: 105.28258 Validation Error: 105.31683\n",
            "Epoch: 662 Training Error: 105.2823 Validation Error: 105.31646\n",
            "Epoch: 663 Training Error: 105.28205 Validation Error: 105.31615\n",
            "Epoch: 664 Training Error: 105.2818 Validation Error: 105.31589\n",
            "Epoch: 665 Training Error: 105.28153 Validation Error: 105.315575\n",
            "Epoch: 666 Training Error: 105.28126 Validation Error: 105.31524\n",
            "Epoch: 667 Training Error: 105.28102 Validation Error: 105.31509\n",
            "Epoch: 668 Training Error: 105.28081 Validation Error: 105.31495\n",
            "Epoch: 669 Training Error: 105.28057 Validation Error: 105.314735\n",
            "Epoch: 670 Training Error: 105.28032 Validation Error: 105.3144\n",
            "Epoch: 671 Training Error: 105.280045 Validation Error: 105.31408\n",
            "Epoch: 672 Training Error: 105.279785 Validation Error: 105.31369\n",
            "Epoch: 673 Training Error: 105.27953 Validation Error: 105.313416\n",
            "Epoch: 674 Training Error: 105.2793 Validation Error: 105.31306\n",
            "Epoch: 675 Training Error: 105.27905 Validation Error: 105.31274\n",
            "Epoch: 676 Training Error: 105.2788 Validation Error: 105.31237\n",
            "Epoch: 677 Training Error: 105.27853 Validation Error: 105.31196\n",
            "Epoch: 678 Training Error: 105.27828 Validation Error: 105.31162\n",
            "Epoch: 679 Training Error: 105.278015 Validation Error: 105.31132\n",
            "Epoch: 680 Training Error: 105.27777 Validation Error: 105.31105\n",
            "Epoch: 681 Training Error: 105.277504 Validation Error: 105.31079\n",
            "Epoch: 682 Training Error: 105.27728 Validation Error: 105.31052\n",
            "Epoch: 683 Training Error: 105.27706 Validation Error: 105.310295\n",
            "Epoch: 684 Training Error: 105.27686 Validation Error: 105.31008\n",
            "Epoch: 685 Training Error: 105.276634 Validation Error: 105.30983\n",
            "Epoch: 686 Training Error: 105.27638 Validation Error: 105.309525\n",
            "Epoch: 687 Training Error: 105.27614 Validation Error: 105.30916\n",
            "Epoch: 688 Training Error: 105.2759 Validation Error: 105.30888\n",
            "Epoch: 689 Training Error: 105.275665 Validation Error: 105.30861\n",
            "Epoch: 690 Training Error: 105.27543 Validation Error: 105.30831\n",
            "Epoch: 691 Training Error: 105.27519 Validation Error: 105.30803\n",
            "Epoch: 692 Training Error: 105.27494 Validation Error: 105.307625\n",
            "Epoch: 693 Training Error: 105.27472 Validation Error: 105.30738\n",
            "Epoch: 694 Training Error: 105.27448 Validation Error: 105.30707\n",
            "Epoch: 695 Training Error: 105.27425 Validation Error: 105.30678\n",
            "Epoch: 696 Training Error: 105.27401 Validation Error: 105.30652\n",
            "Epoch: 697 Training Error: 105.27377 Validation Error: 105.306206\n",
            "Epoch: 698 Training Error: 105.273544 Validation Error: 105.30594\n",
            "Epoch: 699 Training Error: 105.27331 Validation Error: 105.305565\n",
            "Epoch: 700 Training Error: 105.2731 Validation Error: 105.30526\n",
            "Epoch: 701 Training Error: 105.27289 Validation Error: 105.304955\n",
            "Epoch: 702 Training Error: 105.272675 Validation Error: 105.30474\n",
            "Epoch: 703 Training Error: 105.27245 Validation Error: 105.304405\n",
            "Epoch: 704 Training Error: 105.2722 Validation Error: 105.30403\n",
            "Epoch: 705 Training Error: 105.27199 Validation Error: 105.30377\n",
            "Epoch: 706 Training Error: 105.27179 Validation Error: 105.30354\n",
            "Epoch: 707 Training Error: 105.271576 Validation Error: 105.303345\n",
            "Epoch: 708 Training Error: 105.27138 Validation Error: 105.30309\n",
            "Epoch: 709 Training Error: 105.27116 Validation Error: 105.30285\n",
            "Epoch: 710 Training Error: 105.27094 Validation Error: 105.302574\n",
            "Epoch: 711 Training Error: 105.270744 Validation Error: 105.30232\n",
            "Epoch: 712 Training Error: 105.27053 Validation Error: 105.30198\n",
            "Epoch: 713 Training Error: 105.270325 Validation Error: 105.30163\n",
            "Epoch: 714 Training Error: 105.27011 Validation Error: 105.30134\n",
            "Epoch: 715 Training Error: 105.26989 Validation Error: 105.30104\n",
            "Epoch: 716 Training Error: 105.269684 Validation Error: 105.30072\n",
            "Epoch: 717 Training Error: 105.26948 Validation Error: 105.30043\n",
            "Epoch: 718 Training Error: 105.269264 Validation Error: 105.30015\n",
            "Epoch: 719 Training Error: 105.269066 Validation Error: 105.29982\n",
            "Epoch: 720 Training Error: 105.26884 Validation Error: 105.29951\n",
            "Epoch: 721 Training Error: 105.26863 Validation Error: 105.29925\n",
            "Epoch: 722 Training Error: 105.26844 Validation Error: 105.298935\n",
            "Epoch: 723 Training Error: 105.26822 Validation Error: 105.29865\n",
            "Epoch: 724 Training Error: 105.268005 Validation Error: 105.29844\n",
            "Epoch: 725 Training Error: 105.26779 Validation Error: 105.29819\n",
            "Epoch: 726 Training Error: 105.26762 Validation Error: 105.29791\n",
            "Epoch: 727 Training Error: 105.26742 Validation Error: 105.29769\n",
            "Epoch: 728 Training Error: 105.267235 Validation Error: 105.29749\n",
            "Epoch: 729 Training Error: 105.26704 Validation Error: 105.29718\n",
            "Epoch: 730 Training Error: 105.26682 Validation Error: 105.29692\n",
            "Epoch: 731 Training Error: 105.2666 Validation Error: 105.296745\n",
            "Epoch: 732 Training Error: 105.266365 Validation Error: 105.29655\n",
            "Epoch: 733 Training Error: 105.26615 Validation Error: 105.29639\n",
            "Epoch: 734 Training Error: 105.26594 Validation Error: 105.296135\n",
            "Epoch: 735 Training Error: 105.26572 Validation Error: 105.29595\n",
            "Epoch: 736 Training Error: 105.26549 Validation Error: 105.29576\n",
            "Epoch: 737 Training Error: 105.26529 Validation Error: 105.29556\n",
            "Epoch: 738 Training Error: 105.26511 Validation Error: 105.29531\n",
            "Epoch: 739 Training Error: 105.264915 Validation Error: 105.295006\n",
            "Epoch: 740 Training Error: 105.26472 Validation Error: 105.2947\n",
            "Epoch: 741 Training Error: 105.26454 Validation Error: 105.294464\n",
            "Epoch: 742 Training Error: 105.26437 Validation Error: 105.29426\n",
            "Epoch: 743 Training Error: 105.26418 Validation Error: 105.29409\n",
            "Epoch: 744 Training Error: 105.264 Validation Error: 105.293846\n",
            "Epoch: 745 Training Error: 105.26381 Validation Error: 105.29362\n",
            "Epoch: 746 Training Error: 105.26361 Validation Error: 105.293434\n",
            "Epoch: 747 Training Error: 105.26342 Validation Error: 105.293175\n",
            "Epoch: 748 Training Error: 105.26325 Validation Error: 105.292885\n",
            "Epoch: 749 Training Error: 105.26308 Validation Error: 105.2926\n",
            "Epoch: 750 Training Error: 105.262886 Validation Error: 105.29231\n",
            "Epoch: 751 Training Error: 105.2627 Validation Error: 105.292076\n",
            "Epoch: 752 Training Error: 105.26254 Validation Error: 105.29178\n",
            "Epoch: 753 Training Error: 105.26235 Validation Error: 105.29153\n",
            "Epoch: 754 Training Error: 105.26218 Validation Error: 105.29125\n",
            "Epoch: 755 Training Error: 105.262 Validation Error: 105.291016\n",
            "Epoch: 756 Training Error: 105.26183 Validation Error: 105.29078\n",
            "Epoch: 757 Training Error: 105.26168 Validation Error: 105.29054\n",
            "Epoch: 758 Training Error: 105.26152 Validation Error: 105.290306\n",
            "Epoch: 759 Training Error: 105.261345 Validation Error: 105.29006\n",
            "Epoch: 760 Training Error: 105.261154 Validation Error: 105.28983\n",
            "Epoch: 761 Training Error: 105.26097 Validation Error: 105.28965\n",
            "Epoch: 762 Training Error: 105.26077 Validation Error: 105.28942\n",
            "Epoch: 763 Training Error: 105.2606 Validation Error: 105.28915\n",
            "Epoch: 764 Training Error: 105.2604 Validation Error: 105.28895\n",
            "Epoch: 765 Training Error: 105.2602 Validation Error: 105.2888\n",
            "Epoch: 766 Training Error: 105.26001 Validation Error: 105.288605\n",
            "Epoch: 767 Training Error: 105.25983 Validation Error: 105.28834\n",
            "Epoch: 768 Training Error: 105.25965 Validation Error: 105.2881\n",
            "Epoch: 769 Training Error: 105.25949 Validation Error: 105.28788\n",
            "Epoch: 770 Training Error: 105.25932 Validation Error: 105.28767\n",
            "Epoch: 771 Training Error: 105.25916 Validation Error: 105.28743\n",
            "Epoch: 772 Training Error: 105.258965 Validation Error: 105.28719\n",
            "Epoch: 773 Training Error: 105.25882 Validation Error: 105.28695\n",
            "Epoch: 774 Training Error: 105.25865 Validation Error: 105.28668\n",
            "Epoch: 775 Training Error: 105.258484 Validation Error: 105.2865\n",
            "Epoch: 776 Training Error: 105.258316 Validation Error: 105.2863\n",
            "Epoch: 777 Training Error: 105.25813 Validation Error: 105.28607\n",
            "Epoch: 778 Training Error: 105.25797 Validation Error: 105.28587\n",
            "Epoch: 779 Training Error: 105.257805 Validation Error: 105.28564\n",
            "Epoch: 780 Training Error: 105.25764 Validation Error: 105.28545\n",
            "Epoch: 781 Training Error: 105.25746 Validation Error: 105.28526\n",
            "Epoch: 782 Training Error: 105.257324 Validation Error: 105.28499\n",
            "Epoch: 783 Training Error: 105.25715 Validation Error: 105.28485\n",
            "Epoch: 784 Training Error: 105.25697 Validation Error: 105.284706\n",
            "Epoch: 785 Training Error: 105.256836 Validation Error: 105.28442\n",
            "Epoch: 786 Training Error: 105.25668 Validation Error: 105.2842\n",
            "Epoch: 787 Training Error: 105.25652 Validation Error: 105.284\n",
            "Epoch: 788 Training Error: 105.256386 Validation Error: 105.28372\n",
            "Epoch: 789 Training Error: 105.25621 Validation Error: 105.28352\n",
            "Epoch: 790 Training Error: 105.25605 Validation Error: 105.28335\n",
            "Epoch: 791 Training Error: 105.255875 Validation Error: 105.283195\n",
            "Epoch: 792 Training Error: 105.25571 Validation Error: 105.28306\n",
            "Epoch: 793 Training Error: 105.255554 Validation Error: 105.28285\n",
            "Epoch: 794 Training Error: 105.2554 Validation Error: 105.28266\n",
            "Epoch: 795 Training Error: 105.25526 Validation Error: 105.282486\n",
            "Epoch: 796 Training Error: 105.2551 Validation Error: 105.2823\n",
            "Epoch: 797 Training Error: 105.25493 Validation Error: 105.28214\n",
            "Epoch: 798 Training Error: 105.25477 Validation Error: 105.28194\n",
            "Epoch: 799 Training Error: 105.25461 Validation Error: 105.28178\n",
            "Epoch: 800 Training Error: 105.25443 Validation Error: 105.28162\n",
            "Epoch: 801 Training Error: 105.25427 Validation Error: 105.28142\n",
            "Epoch: 802 Training Error: 105.25412 Validation Error: 105.28114\n",
            "Epoch: 803 Training Error: 105.253944 Validation Error: 105.28095\n",
            "Epoch: 804 Training Error: 105.25378 Validation Error: 105.28077\n",
            "Epoch: 805 Training Error: 105.2536 Validation Error: 105.28051\n",
            "Epoch: 806 Training Error: 105.253426 Validation Error: 105.28027\n",
            "Epoch: 807 Training Error: 105.25327 Validation Error: 105.280075\n",
            "Epoch: 808 Training Error: 105.2531 Validation Error: 105.27992\n",
            "Epoch: 809 Training Error: 105.25294 Validation Error: 105.27971\n",
            "Epoch: 810 Training Error: 105.25278 Validation Error: 105.27955\n",
            "Epoch: 811 Training Error: 105.252625 Validation Error: 105.27939\n",
            "Epoch: 812 Training Error: 105.252464 Validation Error: 105.27925\n",
            "Epoch: 813 Training Error: 105.252304 Validation Error: 105.27913\n",
            "Epoch: 814 Training Error: 105.252144 Validation Error: 105.27894\n",
            "Epoch: 815 Training Error: 105.25198 Validation Error: 105.27866\n",
            "Epoch: 816 Training Error: 105.251816 Validation Error: 105.27848\n",
            "Epoch: 817 Training Error: 105.25167 Validation Error: 105.278206\n",
            "Epoch: 818 Training Error: 105.25151 Validation Error: 105.278046\n",
            "Epoch: 819 Training Error: 105.25136 Validation Error: 105.27791\n",
            "Epoch: 820 Training Error: 105.2512 Validation Error: 105.27782\n",
            "Epoch: 821 Training Error: 105.251045 Validation Error: 105.27767\n",
            "Epoch: 822 Training Error: 105.2509 Validation Error: 105.2776\n",
            "Epoch: 823 Training Error: 105.25075 Validation Error: 105.2775\n",
            "Epoch: 824 Training Error: 105.250595 Validation Error: 105.27728\n",
            "Epoch: 825 Training Error: 105.25045 Validation Error: 105.27711\n",
            "Epoch: 826 Training Error: 105.25029 Validation Error: 105.276924\n",
            "Epoch: 827 Training Error: 105.25014 Validation Error: 105.27667\n",
            "Epoch: 828 Training Error: 105.249985 Validation Error: 105.27646\n",
            "Epoch: 829 Training Error: 105.24984 Validation Error: 105.27622\n",
            "Epoch: 830 Training Error: 105.24969 Validation Error: 105.27605\n",
            "Epoch: 831 Training Error: 105.24954 Validation Error: 105.27589\n",
            "Epoch: 832 Training Error: 105.249405 Validation Error: 105.275764\n",
            "Epoch: 833 Training Error: 105.24925 Validation Error: 105.27555\n",
            "Epoch: 834 Training Error: 105.249115 Validation Error: 105.27533\n",
            "Epoch: 835 Training Error: 105.24898 Validation Error: 105.275116\n",
            "Epoch: 836 Training Error: 105.24883 Validation Error: 105.2749\n",
            "Epoch: 837 Training Error: 105.24868 Validation Error: 105.27466\n",
            "Epoch: 838 Training Error: 105.24854 Validation Error: 105.27443\n",
            "Epoch: 839 Training Error: 105.24839 Validation Error: 105.27422\n",
            "Epoch: 840 Training Error: 105.24826 Validation Error: 105.27409\n",
            "Epoch: 841 Training Error: 105.248146 Validation Error: 105.273895\n",
            "Epoch: 842 Training Error: 105.24801 Validation Error: 105.273674\n",
            "Epoch: 843 Training Error: 105.24789 Validation Error: 105.27346\n",
            "Epoch: 844 Training Error: 105.24776 Validation Error: 105.2733\n",
            "Epoch: 845 Training Error: 105.2476 Validation Error: 105.27317\n",
            "Epoch: 846 Training Error: 105.247444 Validation Error: 105.27303\n",
            "Epoch: 847 Training Error: 105.2473 Validation Error: 105.27287\n",
            "Epoch: 848 Training Error: 105.24715 Validation Error: 105.27271\n",
            "Epoch: 849 Training Error: 105.24701 Validation Error: 105.272575\n",
            "Epoch: 850 Training Error: 105.24687 Validation Error: 105.27245\n",
            "Epoch: 851 Training Error: 105.24673 Validation Error: 105.27234\n",
            "Epoch: 852 Training Error: 105.24659 Validation Error: 105.272255\n",
            "Epoch: 853 Training Error: 105.24647 Validation Error: 105.27216\n",
            "Epoch: 854 Training Error: 105.24634 Validation Error: 105.272125\n",
            "Epoch: 855 Training Error: 105.24623 Validation Error: 105.27202\n",
            "Epoch: 856 Training Error: 105.24612 Validation Error: 105.271965\n",
            "Epoch: 857 Training Error: 105.24599 Validation Error: 105.271805\n",
            "Epoch: 858 Training Error: 105.24588 Validation Error: 105.27171\n",
            "Epoch: 859 Training Error: 105.24573 Validation Error: 105.271454\n",
            "Epoch: 860 Training Error: 105.24559 Validation Error: 105.27128\n",
            "Epoch: 861 Training Error: 105.24547 Validation Error: 105.27116\n",
            "Epoch: 862 Training Error: 105.245316 Validation Error: 105.27092\n",
            "Epoch: 863 Training Error: 105.24518 Validation Error: 105.27076\n",
            "Epoch: 864 Training Error: 105.24504 Validation Error: 105.2706\n",
            "Epoch: 865 Training Error: 105.244896 Validation Error: 105.27036\n",
            "Epoch: 866 Training Error: 105.24474 Validation Error: 105.27013\n",
            "Epoch: 867 Training Error: 105.2446 Validation Error: 105.26986\n",
            "Epoch: 868 Training Error: 105.244446 Validation Error: 105.26962\n",
            "Epoch: 869 Training Error: 105.24431 Validation Error: 105.26948\n",
            "Epoch: 870 Training Error: 105.24419 Validation Error: 105.26931\n",
            "Epoch: 871 Training Error: 105.24405 Validation Error: 105.26911\n",
            "Epoch: 872 Training Error: 105.24393 Validation Error: 105.26897\n",
            "Epoch: 873 Training Error: 105.24379 Validation Error: 105.26879\n",
            "Epoch: 874 Training Error: 105.24365 Validation Error: 105.268616\n",
            "Epoch: 875 Training Error: 105.243515 Validation Error: 105.26846\n",
            "Epoch: 876 Training Error: 105.243385 Validation Error: 105.26833\n",
            "Epoch: 877 Training Error: 105.24326 Validation Error: 105.26814\n",
            "Epoch: 878 Training Error: 105.243126 Validation Error: 105.26798\n",
            "Epoch: 879 Training Error: 105.24299 Validation Error: 105.26773\n",
            "Epoch: 880 Training Error: 105.24285 Validation Error: 105.26759\n",
            "Epoch: 881 Training Error: 105.242744 Validation Error: 105.267555\n",
            "Epoch: 882 Training Error: 105.24264 Validation Error: 105.26751\n",
            "Epoch: 883 Training Error: 105.2425 Validation Error: 105.26738\n",
            "Epoch: 884 Training Error: 105.2424 Validation Error: 105.267235\n",
            "Epoch: 885 Training Error: 105.24228 Validation Error: 105.26708\n",
            "Epoch: 886 Training Error: 105.242165 Validation Error: 105.26696\n",
            "Epoch: 887 Training Error: 105.24203 Validation Error: 105.26675\n",
            "Epoch: 888 Training Error: 105.24188 Validation Error: 105.26649\n",
            "Epoch: 889 Training Error: 105.24176 Validation Error: 105.26631\n",
            "Epoch: 890 Training Error: 105.241646 Validation Error: 105.26625\n",
            "Epoch: 891 Training Error: 105.24152 Validation Error: 105.266136\n",
            "Epoch: 892 Training Error: 105.24141 Validation Error: 105.266014\n",
            "Epoch: 893 Training Error: 105.24125 Validation Error: 105.26574\n",
            "Epoch: 894 Training Error: 105.24112 Validation Error: 105.265625\n",
            "Epoch: 895 Training Error: 105.24098 Validation Error: 105.26543\n",
            "Epoch: 896 Training Error: 105.24086 Validation Error: 105.26525\n",
            "Epoch: 897 Training Error: 105.24076 Validation Error: 105.265114\n",
            "Epoch: 898 Training Error: 105.24065 Validation Error: 105.26495\n",
            "Epoch: 899 Training Error: 105.240524 Validation Error: 105.26478\n",
            "Epoch: 900 Training Error: 105.24044 Validation Error: 105.26472\n",
            "Epoch: 901 Training Error: 105.2403 Validation Error: 105.2645\n",
            "Epoch: 902 Training Error: 105.240204 Validation Error: 105.26437\n",
            "Epoch: 903 Training Error: 105.24005 Validation Error: 105.2641\n",
            "Epoch: 904 Training Error: 105.23994 Validation Error: 105.26389\n",
            "Epoch: 905 Training Error: 105.239815 Validation Error: 105.26373\n",
            "Epoch: 906 Training Error: 105.23969 Validation Error: 105.26356\n",
            "Epoch: 907 Training Error: 105.23958 Validation Error: 105.26347\n",
            "Epoch: 908 Training Error: 105.239456 Validation Error: 105.26325\n",
            "Epoch: 909 Training Error: 105.23933 Validation Error: 105.26305\n",
            "Epoch: 910 Training Error: 105.23922 Validation Error: 105.26286\n",
            "Epoch: 911 Training Error: 105.239105 Validation Error: 105.26269\n",
            "Epoch: 912 Training Error: 105.23898 Validation Error: 105.26254\n",
            "Epoch: 913 Training Error: 105.23887 Validation Error: 105.262375\n",
            "Epoch: 914 Training Error: 105.23875 Validation Error: 105.26221\n",
            "Epoch: 915 Training Error: 105.23863 Validation Error: 105.26202\n",
            "Epoch: 916 Training Error: 105.23851 Validation Error: 105.26194\n",
            "Epoch: 917 Training Error: 105.23841 Validation Error: 105.2619\n",
            "Epoch: 918 Training Error: 105.238304 Validation Error: 105.26182\n",
            "Epoch: 919 Training Error: 105.2382 Validation Error: 105.261696\n",
            "Epoch: 920 Training Error: 105.2381 Validation Error: 105.26164\n",
            "Epoch: 921 Training Error: 105.238 Validation Error: 105.26158\n",
            "Epoch: 922 Training Error: 105.2379 Validation Error: 105.26146\n",
            "Epoch: 923 Training Error: 105.2378 Validation Error: 105.26136\n",
            "Epoch: 924 Training Error: 105.237686 Validation Error: 105.26119\n",
            "Epoch: 925 Training Error: 105.23755 Validation Error: 105.26097\n",
            "Epoch: 926 Training Error: 105.23743 Validation Error: 105.26076\n",
            "Epoch: 927 Training Error: 105.2373 Validation Error: 105.260544\n",
            "Epoch: 928 Training Error: 105.237175 Validation Error: 105.26041\n",
            "Epoch: 929 Training Error: 105.23706 Validation Error: 105.26022\n",
            "Epoch: 930 Training Error: 105.23694 Validation Error: 105.26007\n",
            "Epoch: 931 Training Error: 105.236824 Validation Error: 105.25999\n",
            "Epoch: 932 Training Error: 105.236725 Validation Error: 105.25991\n",
            "Epoch: 933 Training Error: 105.236626 Validation Error: 105.25979\n",
            "Epoch: 934 Training Error: 105.2365 Validation Error: 105.2596\n",
            "Epoch: 935 Training Error: 105.236374 Validation Error: 105.259415\n",
            "Epoch: 936 Training Error: 105.23627 Validation Error: 105.25928\n",
            "Epoch: 937 Training Error: 105.23617 Validation Error: 105.259155\n",
            "Epoch: 938 Training Error: 105.23607 Validation Error: 105.2591\n",
            "Epoch: 939 Training Error: 105.23597 Validation Error: 105.25899\n",
            "Epoch: 940 Training Error: 105.235855 Validation Error: 105.25882\n",
            "Epoch: 941 Training Error: 105.23573 Validation Error: 105.25863\n",
            "Epoch: 942 Training Error: 105.23562 Validation Error: 105.258446\n",
            "Epoch: 943 Training Error: 105.23548 Validation Error: 105.25822\n",
            "Epoch: 944 Training Error: 105.23537 Validation Error: 105.25802\n",
            "Epoch: 945 Training Error: 105.23526 Validation Error: 105.25784\n",
            "Epoch: 946 Training Error: 105.23516 Validation Error: 105.25772\n",
            "Epoch: 947 Training Error: 105.23507 Validation Error: 105.25762\n",
            "Epoch: 948 Training Error: 105.23497 Validation Error: 105.25752\n",
            "Epoch: 949 Training Error: 105.234856 Validation Error: 105.25729\n",
            "Epoch: 950 Training Error: 105.23473 Validation Error: 105.25706\n",
            "Epoch: 951 Training Error: 105.234634 Validation Error: 105.25692\n",
            "Epoch: 952 Training Error: 105.234535 Validation Error: 105.25672\n",
            "Epoch: 953 Training Error: 105.23445 Validation Error: 105.25666\n",
            "Epoch: 954 Training Error: 105.23434 Validation Error: 105.25648\n",
            "Epoch: 955 Training Error: 105.23424 Validation Error: 105.2564\n",
            "Epoch: 956 Training Error: 105.23414 Validation Error: 105.2563\n",
            "Epoch: 957 Training Error: 105.234024 Validation Error: 105.25614\n",
            "Epoch: 958 Training Error: 105.23391 Validation Error: 105.255974\n",
            "Epoch: 959 Training Error: 105.23381 Validation Error: 105.25584\n",
            "Epoch: 960 Training Error: 105.2337 Validation Error: 105.25569\n",
            "Epoch: 961 Training Error: 105.23359 Validation Error: 105.25553\n",
            "Epoch: 962 Training Error: 105.23349 Validation Error: 105.2554\n",
            "Epoch: 963 Training Error: 105.2334 Validation Error: 105.25536\n",
            "Epoch: 964 Training Error: 105.233315 Validation Error: 105.2553\n",
            "Epoch: 965 Training Error: 105.23324 Validation Error: 105.255264\n",
            "Epoch: 966 Training Error: 105.233154 Validation Error: 105.25522\n",
            "Epoch: 967 Training Error: 105.23306 Validation Error: 105.25514\n",
            "Epoch: 968 Training Error: 105.23296 Validation Error: 105.25504\n",
            "Epoch: 969 Training Error: 105.23288 Validation Error: 105.25493\n",
            "Epoch: 970 Training Error: 105.232765 Validation Error: 105.25477\n",
            "Epoch: 971 Training Error: 105.232666 Validation Error: 105.25462\n",
            "Epoch: 972 Training Error: 105.23255 Validation Error: 105.25447\n",
            "Epoch: 973 Training Error: 105.23247 Validation Error: 105.25437\n",
            "Epoch: 974 Training Error: 105.23238 Validation Error: 105.25426\n",
            "Epoch: 975 Training Error: 105.23227 Validation Error: 105.25411\n",
            "Epoch: 976 Training Error: 105.23217 Validation Error: 105.25396\n",
            "Epoch: 977 Training Error: 105.23207 Validation Error: 105.25384\n",
            "Epoch: 978 Training Error: 105.23196 Validation Error: 105.2537\n",
            "Epoch: 979 Training Error: 105.23187 Validation Error: 105.253624\n",
            "Epoch: 980 Training Error: 105.23174 Validation Error: 105.25339\n",
            "Epoch: 981 Training Error: 105.231636 Validation Error: 105.25321\n",
            "Epoch: 982 Training Error: 105.23156 Validation Error: 105.25319\n",
            "Epoch: 983 Training Error: 105.23147 Validation Error: 105.2531\n",
            "Epoch: 984 Training Error: 105.23136 Validation Error: 105.25286\n",
            "Epoch: 985 Training Error: 105.23127 Validation Error: 105.25276\n",
            "Epoch: 986 Training Error: 105.23116 Validation Error: 105.25256\n",
            "Epoch: 987 Training Error: 105.231064 Validation Error: 105.25238\n",
            "Epoch: 988 Training Error: 105.23097 Validation Error: 105.25228\n",
            "Epoch: 989 Training Error: 105.23087 Validation Error: 105.25209\n",
            "Epoch: 990 Training Error: 105.230774 Validation Error: 105.25193\n",
            "Epoch: 991 Training Error: 105.23069 Validation Error: 105.25178\n",
            "Epoch: 992 Training Error: 105.23059 Validation Error: 105.25173\n",
            "Epoch: 993 Training Error: 105.23049 Validation Error: 105.25162\n",
            "Epoch: 994 Training Error: 105.23038 Validation Error: 105.25147\n",
            "Epoch: 995 Training Error: 105.23028 Validation Error: 105.25138\n",
            "Epoch: 996 Training Error: 105.23019 Validation Error: 105.2513\n",
            "Epoch: 997 Training Error: 105.2301 Validation Error: 105.2512\n",
            "Epoch: 998 Training Error: 105.23001 Validation Error: 105.251\n",
            "Epoch: 999 Training Error: 105.22993 Validation Error: 105.25085\n",
            "Epoch: 1000 Training Error: 105.22983 Validation Error: 105.25071\n",
            "Epoch: 1001 Training Error: 105.229744 Validation Error: 105.250534\n",
            "Epoch: 1002 Training Error: 105.22965 Validation Error: 105.25041\n",
            "Epoch: 1003 Training Error: 105.22957 Validation Error: 105.250336\n",
            "Epoch: 1004 Training Error: 105.22948 Validation Error: 105.25025\n",
            "Epoch: 1005 Training Error: 105.22938 Validation Error: 105.250084\n",
            "Epoch: 1006 Training Error: 105.229294 Validation Error: 105.249985\n",
            "Epoch: 1007 Training Error: 105.22922 Validation Error: 105.2499\n",
            "Epoch: 1008 Training Error: 105.22913 Validation Error: 105.249825\n",
            "Epoch: 1009 Training Error: 105.229065 Validation Error: 105.24975\n",
            "Epoch: 1010 Training Error: 105.229 Validation Error: 105.249664\n",
            "Epoch: 1011 Training Error: 105.22892 Validation Error: 105.2496\n",
            "Epoch: 1012 Training Error: 105.22883 Validation Error: 105.249466\n",
            "Epoch: 1013 Training Error: 105.22873 Validation Error: 105.24933\n",
            "Epoch: 1014 Training Error: 105.22863 Validation Error: 105.249176\n",
            "Epoch: 1015 Training Error: 105.22853 Validation Error: 105.249\n",
            "Epoch: 1016 Training Error: 105.22845 Validation Error: 105.248795\n",
            "Epoch: 1017 Training Error: 105.22835 Validation Error: 105.248604\n",
            "Epoch: 1018 Training Error: 105.22827 Validation Error: 105.248405\n",
            "Epoch: 1019 Training Error: 105.228195 Validation Error: 105.24823\n",
            "Epoch: 1020 Training Error: 105.228096 Validation Error: 105.24817\n",
            "Epoch: 1021 Training Error: 105.22801 Validation Error: 105.24811\n",
            "Epoch: 1022 Training Error: 105.22792 Validation Error: 105.24805\n",
            "Epoch: 1023 Training Error: 105.227844 Validation Error: 105.247986\n",
            "Epoch: 1024 Training Error: 105.22776 Validation Error: 105.247856\n",
            "Epoch: 1025 Training Error: 105.22768 Validation Error: 105.24777\n",
            "Epoch: 1026 Training Error: 105.22758 Validation Error: 105.24768\n",
            "Epoch: 1027 Training Error: 105.227486 Validation Error: 105.24755\n",
            "Epoch: 1028 Training Error: 105.22741 Validation Error: 105.24744\n",
            "Epoch: 1029 Training Error: 105.22731 Validation Error: 105.2473\n",
            "Epoch: 1030 Training Error: 105.22724 Validation Error: 105.2473\n",
            "Epoch: 1031 Training Error: 105.227165 Validation Error: 105.24721\n",
            "Epoch: 1032 Training Error: 105.22707 Validation Error: 105.24714\n",
            "Epoch: 1033 Training Error: 105.227005 Validation Error: 105.247086\n",
            "Epoch: 1034 Training Error: 105.2269 Validation Error: 105.24695\n",
            "Epoch: 1035 Training Error: 105.226814 Validation Error: 105.24689\n",
            "Epoch: 1036 Training Error: 105.22674 Validation Error: 105.24673\n",
            "Epoch: 1037 Training Error: 105.22666 Validation Error: 105.246635\n",
            "Epoch: 1038 Training Error: 105.22658 Validation Error: 105.246475\n",
            "Epoch: 1039 Training Error: 105.226494 Validation Error: 105.24628\n",
            "Epoch: 1040 Training Error: 105.2264 Validation Error: 105.24614\n",
            "Epoch: 1041 Training Error: 105.22632 Validation Error: 105.24594\n",
            "Epoch: 1042 Training Error: 105.22624 Validation Error: 105.24578\n",
            "Epoch: 1043 Training Error: 105.22616 Validation Error: 105.24568\n",
            "Epoch: 1044 Training Error: 105.22607 Validation Error: 105.24559\n",
            "Epoch: 1045 Training Error: 105.22598 Validation Error: 105.24548\n",
            "Epoch: 1046 Training Error: 105.22589 Validation Error: 105.245384\n",
            "Epoch: 1047 Training Error: 105.225815 Validation Error: 105.24527\n",
            "Epoch: 1048 Training Error: 105.225746 Validation Error: 105.24521\n",
            "Epoch: 1049 Training Error: 105.225655 Validation Error: 105.245094\n",
            "Epoch: 1050 Training Error: 105.22558 Validation Error: 105.24497\n",
            "Epoch: 1051 Training Error: 105.225494 Validation Error: 105.24484\n",
            "Epoch: 1052 Training Error: 105.22541 Validation Error: 105.2447\n",
            "Epoch: 1053 Training Error: 105.225334 Validation Error: 105.24458\n",
            "Epoch: 1054 Training Error: 105.22524 Validation Error: 105.244484\n",
            "Epoch: 1055 Training Error: 105.22516 Validation Error: 105.24436\n",
            "Epoch: 1056 Training Error: 105.225075 Validation Error: 105.244225\n",
            "Epoch: 1057 Training Error: 105.22498 Validation Error: 105.244125\n",
            "Epoch: 1058 Training Error: 105.2249 Validation Error: 105.244064\n",
            "Epoch: 1059 Training Error: 105.2248 Validation Error: 105.24389\n",
            "Epoch: 1060 Training Error: 105.2247 Validation Error: 105.243835\n",
            "Epoch: 1061 Training Error: 105.2246 Validation Error: 105.24376\n",
            "Epoch: 1062 Training Error: 105.22451 Validation Error: 105.24364\n",
            "Epoch: 1063 Training Error: 105.22443 Validation Error: 105.243515\n",
            "Epoch: 1064 Training Error: 105.224335 Validation Error: 105.2434\n",
            "Epoch: 1065 Training Error: 105.22426 Validation Error: 105.243286\n",
            "Epoch: 1066 Training Error: 105.22416 Validation Error: 105.24319\n",
            "Epoch: 1067 Training Error: 105.224075 Validation Error: 105.24303\n",
            "Epoch: 1068 Training Error: 105.224 Validation Error: 105.24293\n",
            "Epoch: 1069 Training Error: 105.223915 Validation Error: 105.24289\n",
            "Epoch: 1070 Training Error: 105.22384 Validation Error: 105.24277\n",
            "Epoch: 1071 Training Error: 105.22376 Validation Error: 105.24271\n",
            "Epoch: 1072 Training Error: 105.22369 Validation Error: 105.24264\n",
            "Epoch: 1073 Training Error: 105.223625 Validation Error: 105.24259\n",
            "Epoch: 1074 Training Error: 105.22355 Validation Error: 105.2425\n",
            "Epoch: 1075 Training Error: 105.22348 Validation Error: 105.24243\n",
            "Epoch: 1076 Training Error: 105.223404 Validation Error: 105.2423\n",
            "Epoch: 1077 Training Error: 105.22333 Validation Error: 105.24223\n",
            "Epoch: 1078 Training Error: 105.22327 Validation Error: 105.24214\n",
            "Epoch: 1079 Training Error: 105.22319 Validation Error: 105.24204\n",
            "Epoch: 1080 Training Error: 105.223114 Validation Error: 105.241905\n",
            "Epoch: 1081 Training Error: 105.22304 Validation Error: 105.24182\n",
            "Epoch: 1082 Training Error: 105.22298 Validation Error: 105.24182\n",
            "Epoch: 1083 Training Error: 105.22291 Validation Error: 105.24169\n",
            "Epoch: 1084 Training Error: 105.22283 Validation Error: 105.241585\n",
            "Epoch: 1085 Training Error: 105.22277 Validation Error: 105.24151\n",
            "Epoch: 1086 Training Error: 105.2227 Validation Error: 105.24143\n",
            "Epoch: 1087 Training Error: 105.22263 Validation Error: 105.24132\n",
            "Epoch: 1088 Training Error: 105.222565 Validation Error: 105.24125\n",
            "Epoch: 1089 Training Error: 105.222496 Validation Error: 105.241196\n",
            "Epoch: 1090 Training Error: 105.22242 Validation Error: 105.24112\n",
            "Epoch: 1091 Training Error: 105.22236 Validation Error: 105.24098\n",
            "Epoch: 1092 Training Error: 105.22228 Validation Error: 105.24086\n",
            "Epoch: 1093 Training Error: 105.2222 Validation Error: 105.240746\n",
            "Epoch: 1094 Training Error: 105.22212 Validation Error: 105.240585\n",
            "Epoch: 1095 Training Error: 105.222046 Validation Error: 105.2405\n",
            "Epoch: 1096 Training Error: 105.22197 Validation Error: 105.2404\n",
            "Epoch: 1097 Training Error: 105.221886 Validation Error: 105.240234\n",
            "Epoch: 1098 Training Error: 105.22181 Validation Error: 105.24009\n",
            "Epoch: 1099 Training Error: 105.22172 Validation Error: 105.239975\n",
            "Epoch: 1100 Training Error: 105.22165 Validation Error: 105.23986\n",
            "Epoch: 1101 Training Error: 105.22157 Validation Error: 105.23974\n",
            "Epoch: 1102 Training Error: 105.2215 Validation Error: 105.2397\n",
            "Epoch: 1103 Training Error: 105.22141 Validation Error: 105.23956\n",
            "Epoch: 1104 Training Error: 105.22134 Validation Error: 105.239456\n",
            "Epoch: 1105 Training Error: 105.221245 Validation Error: 105.23932\n",
            "Epoch: 1106 Training Error: 105.22118 Validation Error: 105.23926\n",
            "Epoch: 1107 Training Error: 105.2211 Validation Error: 105.23918\n",
            "Epoch: 1108 Training Error: 105.22104 Validation Error: 105.23912\n",
            "Epoch: 1109 Training Error: 105.22096 Validation Error: 105.23902\n",
            "Epoch: 1110 Training Error: 105.22091 Validation Error: 105.239006\n",
            "Epoch: 1111 Training Error: 105.22084 Validation Error: 105.23895\n",
            "Epoch: 1112 Training Error: 105.22079 Validation Error: 105.23889\n",
            "Epoch: 1113 Training Error: 105.22071 Validation Error: 105.23879\n",
            "Epoch: 1114 Training Error: 105.220665 Validation Error: 105.23869\n",
            "Epoch: 1115 Training Error: 105.22061 Validation Error: 105.238716\n",
            "Epoch: 1116 Training Error: 105.22055 Validation Error: 105.238655\n",
            "Epoch: 1117 Training Error: 105.22049 Validation Error: 105.23858\n",
            "Epoch: 1118 Training Error: 105.2204 Validation Error: 105.238434\n",
            "Epoch: 1119 Training Error: 105.220314 Validation Error: 105.23826\n",
            "Epoch: 1120 Training Error: 105.22024 Validation Error: 105.23818\n",
            "Epoch: 1121 Training Error: 105.22018 Validation Error: 105.238106\n",
            "Epoch: 1122 Training Error: 105.2201 Validation Error: 105.23802\n",
            "Epoch: 1123 Training Error: 105.22004 Validation Error: 105.23797\n",
            "Epoch: 1124 Training Error: 105.21998 Validation Error: 105.23782\n",
            "Epoch: 1125 Training Error: 105.21992 Validation Error: 105.23782\n",
            "Epoch: 1126 Training Error: 105.219864 Validation Error: 105.237785\n",
            "Epoch: 1127 Training Error: 105.219795 Validation Error: 105.23766\n",
            "Epoch: 1128 Training Error: 105.21972 Validation Error: 105.237526\n",
            "Epoch: 1129 Training Error: 105.21964 Validation Error: 105.2374\n",
            "Epoch: 1130 Training Error: 105.21957 Validation Error: 105.237274\n",
            "Epoch: 1131 Training Error: 105.21949 Validation Error: 105.23716\n",
            "Epoch: 1132 Training Error: 105.21942 Validation Error: 105.23705\n",
            "Epoch: 1133 Training Error: 105.219345 Validation Error: 105.236916\n",
            "Epoch: 1134 Training Error: 105.21927 Validation Error: 105.23676\n",
            "Epoch: 1135 Training Error: 105.21919 Validation Error: 105.236626\n",
            "Epoch: 1136 Training Error: 105.21912 Validation Error: 105.236565\n",
            "Epoch: 1137 Training Error: 105.21905 Validation Error: 105.236465\n",
            "Epoch: 1138 Training Error: 105.21898 Validation Error: 105.23637\n",
            "Epoch: 1139 Training Error: 105.21892 Validation Error: 105.23633\n",
            "Epoch: 1140 Training Error: 105.21888 Validation Error: 105.23631\n",
            "Epoch: 1141 Training Error: 105.21881 Validation Error: 105.23621\n",
            "Epoch: 1142 Training Error: 105.21874 Validation Error: 105.23614\n",
            "Epoch: 1143 Training Error: 105.2187 Validation Error: 105.236115\n",
            "Epoch: 1144 Training Error: 105.21864 Validation Error: 105.23609\n",
            "Epoch: 1145 Training Error: 105.2186 Validation Error: 105.23605\n",
            "Epoch: 1146 Training Error: 105.21854 Validation Error: 105.23594\n",
            "Epoch: 1147 Training Error: 105.218475 Validation Error: 105.235855\n",
            "Epoch: 1148 Training Error: 105.2184 Validation Error: 105.2357\n",
            "Epoch: 1149 Training Error: 105.21832 Validation Error: 105.23554\n",
            "Epoch: 1150 Training Error: 105.21826 Validation Error: 105.23544\n",
            "Epoch: 1151 Training Error: 105.21821 Validation Error: 105.2354\n",
            "Epoch: 1152 Training Error: 105.21813 Validation Error: 105.23527\n",
            "Epoch: 1153 Training Error: 105.21806 Validation Error: 105.23512\n",
            "Epoch: 1154 Training Error: 105.217995 Validation Error: 105.23502\n",
            "Epoch: 1155 Training Error: 105.21793 Validation Error: 105.23493\n",
            "Epoch: 1156 Training Error: 105.217865 Validation Error: 105.23481\n",
            "Epoch: 1157 Training Error: 105.2178 Validation Error: 105.23471\n",
            "Epoch: 1158 Training Error: 105.217735 Validation Error: 105.23462\n",
            "Epoch: 1159 Training Error: 105.21769 Validation Error: 105.23456\n",
            "Epoch: 1160 Training Error: 105.21763 Validation Error: 105.2345\n",
            "Epoch: 1161 Training Error: 105.21756 Validation Error: 105.23445\n",
            "Epoch: 1162 Training Error: 105.217514 Validation Error: 105.23438\n",
            "Epoch: 1163 Training Error: 105.21745 Validation Error: 105.23436\n",
            "Epoch: 1164 Training Error: 105.2174 Validation Error: 105.23428\n",
            "Epoch: 1165 Training Error: 105.21732 Validation Error: 105.234184\n",
            "Epoch: 1166 Training Error: 105.21728 Validation Error: 105.23416\n",
            "Epoch: 1167 Training Error: 105.217224 Validation Error: 105.23406\n",
            "Epoch: 1168 Training Error: 105.21716 Validation Error: 105.233986\n",
            "Epoch: 1169 Training Error: 105.2171 Validation Error: 105.23384\n",
            "Epoch: 1170 Training Error: 105.21704 Validation Error: 105.233765\n",
            "Epoch: 1171 Training Error: 105.21698 Validation Error: 105.23363\n",
            "Epoch: 1172 Training Error: 105.21691 Validation Error: 105.23349\n",
            "Epoch: 1173 Training Error: 105.21685 Validation Error: 105.23337\n",
            "Epoch: 1174 Training Error: 105.21678 Validation Error: 105.233315\n",
            "Epoch: 1175 Training Error: 105.21673 Validation Error: 105.23324\n",
            "Epoch: 1176 Training Error: 105.21667 Validation Error: 105.2332\n",
            "Epoch: 1177 Training Error: 105.21661 Validation Error: 105.23314\n",
            "Epoch: 1178 Training Error: 105.21655 Validation Error: 105.23306\n",
            "Epoch: 1179 Training Error: 105.21651 Validation Error: 105.23298\n",
            "Epoch: 1180 Training Error: 105.21644 Validation Error: 105.23288\n",
            "Epoch: 1181 Training Error: 105.21639 Validation Error: 105.23284\n",
            "Epoch: 1182 Training Error: 105.21633 Validation Error: 105.2328\n",
            "Epoch: 1183 Training Error: 105.21628 Validation Error: 105.232765\n",
            "Epoch: 1184 Training Error: 105.21623 Validation Error: 105.23273\n",
            "Epoch: 1185 Training Error: 105.21618 Validation Error: 105.232666\n",
            "Epoch: 1186 Training Error: 105.2161 Validation Error: 105.23257\n",
            "Epoch: 1187 Training Error: 105.21606 Validation Error: 105.23249\n",
            "Epoch: 1188 Training Error: 105.215996 Validation Error: 105.23237\n",
            "Epoch: 1189 Training Error: 105.215935 Validation Error: 105.23231\n",
            "Epoch: 1190 Training Error: 105.21588 Validation Error: 105.232285\n",
            "Epoch: 1191 Training Error: 105.21582 Validation Error: 105.232216\n",
            "Epoch: 1192 Training Error: 105.21578 Validation Error: 105.23218\n",
            "Epoch: 1193 Training Error: 105.21573 Validation Error: 105.23217\n",
            "Epoch: 1194 Training Error: 105.21568 Validation Error: 105.23212\n",
            "Epoch: 1195 Training Error: 105.21563 Validation Error: 105.232056\n",
            "Epoch: 1196 Training Error: 105.21557 Validation Error: 105.23194\n",
            "Epoch: 1197 Training Error: 105.21552 Validation Error: 105.23187\n",
            "Epoch: 1198 Training Error: 105.21545 Validation Error: 105.23172\n",
            "Epoch: 1199 Training Error: 105.21539 Validation Error: 105.23164\n",
            "Epoch: 1200 Training Error: 105.21533 Validation Error: 105.231544\n",
            "Epoch: 1201 Training Error: 105.215256 Validation Error: 105.23144\n",
            "Epoch: 1202 Training Error: 105.21521 Validation Error: 105.2314\n",
            "Epoch: 1203 Training Error: 105.21513 Validation Error: 105.2313\n",
            "Epoch: 1204 Training Error: 105.21507 Validation Error: 105.23117\n",
            "Epoch: 1205 Training Error: 105.21501 Validation Error: 105.23109\n",
            "Epoch: 1206 Training Error: 105.21495 Validation Error: 105.23101\n",
            "Epoch: 1207 Training Error: 105.21491 Validation Error: 105.23095\n",
            "Epoch: 1208 Training Error: 105.21485 Validation Error: 105.23087\n",
            "Epoch: 1209 Training Error: 105.21478 Validation Error: 105.2308\n",
            "Epoch: 1210 Training Error: 105.21474 Validation Error: 105.23075\n",
            "Epoch: 1211 Training Error: 105.21468 Validation Error: 105.23064\n",
            "Epoch: 1212 Training Error: 105.21464 Validation Error: 105.23056\n",
            "Epoch: 1213 Training Error: 105.21458 Validation Error: 105.23052\n",
            "Epoch: 1214 Training Error: 105.21452 Validation Error: 105.23046\n",
            "Epoch: 1215 Training Error: 105.21446 Validation Error: 105.2304\n",
            "Epoch: 1216 Training Error: 105.21441 Validation Error: 105.230354\n",
            "Epoch: 1217 Training Error: 105.21436 Validation Error: 105.2303\n",
            "Epoch: 1218 Training Error: 105.21429 Validation Error: 105.23015\n",
            "Epoch: 1219 Training Error: 105.21421 Validation Error: 105.22999\n",
            "Epoch: 1220 Training Error: 105.21415 Validation Error: 105.22989\n",
            "Epoch: 1221 Training Error: 105.21409 Validation Error: 105.22973\n",
            "Epoch: 1222 Training Error: 105.214035 Validation Error: 105.22963\n",
            "Epoch: 1223 Training Error: 105.213974 Validation Error: 105.22955\n",
            "Epoch: 1224 Training Error: 105.21393 Validation Error: 105.22944\n",
            "Epoch: 1225 Training Error: 105.21387 Validation Error: 105.22938\n",
            "Epoch: 1226 Training Error: 105.21383 Validation Error: 105.2293\n",
            "Epoch: 1227 Training Error: 105.21377 Validation Error: 105.22923\n",
            "Epoch: 1228 Training Error: 105.2137 Validation Error: 105.22913\n",
            "Epoch: 1229 Training Error: 105.21365 Validation Error: 105.22906\n",
            "Epoch: 1230 Training Error: 105.2136 Validation Error: 105.2289\n",
            "Epoch: 1231 Training Error: 105.213554 Validation Error: 105.22877\n",
            "Epoch: 1232 Training Error: 105.2135 Validation Error: 105.22869\n",
            "Epoch: 1233 Training Error: 105.213455 Validation Error: 105.22862\n",
            "Epoch: 1234 Training Error: 105.2134 Validation Error: 105.228546\n",
            "Epoch: 1235 Training Error: 105.213356 Validation Error: 105.228455\n",
            "Epoch: 1236 Training Error: 105.213295 Validation Error: 105.22837\n",
            "Epoch: 1237 Training Error: 105.21324 Validation Error: 105.22827\n",
            "Epoch: 1238 Training Error: 105.21319 Validation Error: 105.22817\n",
            "Epoch: 1239 Training Error: 105.21316 Validation Error: 105.22806\n",
            "Epoch: 1240 Training Error: 105.213104 Validation Error: 105.227974\n",
            "Epoch: 1241 Training Error: 105.21306 Validation Error: 105.2279\n",
            "Epoch: 1242 Training Error: 105.213005 Validation Error: 105.22782\n",
            "Epoch: 1243 Training Error: 105.21295 Validation Error: 105.227745\n",
            "Epoch: 1244 Training Error: 105.21289 Validation Error: 105.227684\n",
            "Epoch: 1245 Training Error: 105.212845 Validation Error: 105.22762\n",
            "Epoch: 1246 Training Error: 105.21281 Validation Error: 105.22752\n",
            "Epoch: 1247 Training Error: 105.21278 Validation Error: 105.22741\n",
            "Epoch: 1248 Training Error: 105.21275 Validation Error: 105.22731\n",
            "Epoch: 1249 Training Error: 105.21273 Validation Error: 105.22723\n",
            "Epoch: 1250 Training Error: 105.212685 Validation Error: 105.227135\n",
            "Epoch: 1251 Training Error: 105.21267 Validation Error: 105.227036\n",
            "Epoch: 1252 Training Error: 105.212616 Validation Error: 105.226974\n",
            "Epoch: 1253 Training Error: 105.21257 Validation Error: 105.2269\n",
            "Epoch: 1254 Training Error: 105.21255 Validation Error: 105.22684\n",
            "Epoch: 1255 Training Error: 105.21248 Validation Error: 105.226776\n",
            "Epoch: 1256 Training Error: 105.212395 Validation Error: 105.22674\n",
            "Epoch: 1257 Training Error: 105.21233 Validation Error: 105.22668\n",
            "Epoch: 1258 Training Error: 105.21224 Validation Error: 105.22664\n",
            "Epoch: 1259 Training Error: 105.21218 Validation Error: 105.22656\n",
            "Epoch: 1260 Training Error: 105.212135 Validation Error: 105.2265\n",
            "Epoch: 1261 Training Error: 105.212074 Validation Error: 105.226425\n",
            "Epoch: 1262 Training Error: 105.212006 Validation Error: 105.2264\n",
            "Epoch: 1263 Training Error: 105.21196 Validation Error: 105.22634\n",
            "Epoch: 1264 Training Error: 105.21191 Validation Error: 105.22628\n",
            "Epoch: 1265 Training Error: 105.21186 Validation Error: 105.22624\n",
            "Epoch: 1266 Training Error: 105.2118 Validation Error: 105.22619\n",
            "Epoch: 1267 Training Error: 105.21174 Validation Error: 105.22614\n",
            "Epoch: 1268 Training Error: 105.211685 Validation Error: 105.226105\n",
            "Epoch: 1269 Training Error: 105.21163 Validation Error: 105.22605\n",
            "Epoch: 1270 Training Error: 105.211586 Validation Error: 105.226006\n",
            "Epoch: 1271 Training Error: 105.21153 Validation Error: 105.22593\n",
            "Epoch: 1272 Training Error: 105.21147 Validation Error: 105.22587\n",
            "Epoch: 1273 Training Error: 105.21143 Validation Error: 105.22579\n",
            "Epoch: 1274 Training Error: 105.21139 Validation Error: 105.22573\n",
            "Epoch: 1275 Training Error: 105.211365 Validation Error: 105.22563\n",
            "Epoch: 1276 Training Error: 105.21131 Validation Error: 105.22555\n",
            "Epoch: 1277 Training Error: 105.21129 Validation Error: 105.22544\n",
            "Epoch: 1278 Training Error: 105.21125 Validation Error: 105.22537\n",
            "Epoch: 1279 Training Error: 105.211174 Validation Error: 105.22534\n",
            "Epoch: 1280 Training Error: 105.21113 Validation Error: 105.22527\n",
            "Epoch: 1281 Training Error: 105.211075 Validation Error: 105.225204\n",
            "Epoch: 1282 Training Error: 105.21104 Validation Error: 105.225136\n",
            "Epoch: 1283 Training Error: 105.21099 Validation Error: 105.22504\n",
            "Epoch: 1284 Training Error: 105.21095 Validation Error: 105.224945\n",
            "Epoch: 1285 Training Error: 105.21092 Validation Error: 105.224846\n",
            "Epoch: 1286 Training Error: 105.21089 Validation Error: 105.22476\n",
            "Epoch: 1287 Training Error: 105.21084 Validation Error: 105.224686\n",
            "Epoch: 1288 Training Error: 105.21078 Validation Error: 105.22461\n",
            "Epoch: 1289 Training Error: 105.21072 Validation Error: 105.22455\n",
            "Epoch: 1290 Training Error: 105.21068 Validation Error: 105.22447\n",
            "Epoch: 1291 Training Error: 105.21062 Validation Error: 105.22441\n",
            "Epoch: 1292 Training Error: 105.21056 Validation Error: 105.22435\n",
            "Epoch: 1293 Training Error: 105.21054 Validation Error: 105.22429\n",
            "Epoch: 1294 Training Error: 105.21048 Validation Error: 105.224236\n",
            "Epoch: 1295 Training Error: 105.210464 Validation Error: 105.22415\n",
            "Epoch: 1296 Training Error: 105.21042 Validation Error: 105.22409\n",
            "Epoch: 1297 Training Error: 105.21039 Validation Error: 105.224014\n",
            "Epoch: 1298 Training Error: 105.21034 Validation Error: 105.22395\n",
            "Epoch: 1299 Training Error: 105.21029 Validation Error: 105.2239\n",
            "Epoch: 1300 Training Error: 105.21024 Validation Error: 105.22382\n",
            "Epoch: 1301 Training Error: 105.21019 Validation Error: 105.22374\n",
            "Epoch: 1302 Training Error: 105.21013 Validation Error: 105.22369\n",
            "Epoch: 1303 Training Error: 105.210075 Validation Error: 105.223625\n",
            "Epoch: 1304 Training Error: 105.210014 Validation Error: 105.22359\n",
            "Epoch: 1305 Training Error: 105.20997 Validation Error: 105.22352\n",
            "Epoch: 1306 Training Error: 105.209915 Validation Error: 105.223465\n",
            "Epoch: 1307 Training Error: 105.20984 Validation Error: 105.22343\n",
            "Epoch: 1308 Training Error: 105.20979 Validation Error: 105.223366\n",
            "Epoch: 1309 Training Error: 105.20973 Validation Error: 105.22331\n",
            "Epoch: 1310 Training Error: 105.20968 Validation Error: 105.22324\n",
            "Epoch: 1311 Training Error: 105.20962 Validation Error: 105.223206\n",
            "Epoch: 1312 Training Error: 105.20957 Validation Error: 105.223145\n",
            "Epoch: 1313 Training Error: 105.2095 Validation Error: 105.22309\n",
            "Epoch: 1314 Training Error: 105.20946 Validation Error: 105.22304\n",
            "Epoch: 1315 Training Error: 105.209404 Validation Error: 105.22297\n",
            "Epoch: 1316 Training Error: 105.20938 Validation Error: 105.22287\n",
            "Epoch: 1317 Training Error: 105.20936 Validation Error: 105.22279\n",
            "Epoch: 1318 Training Error: 105.209305 Validation Error: 105.22273\n",
            "Epoch: 1319 Training Error: 105.20927 Validation Error: 105.22266\n",
            "Epoch: 1320 Training Error: 105.20927 Validation Error: 105.222565\n",
            "Epoch: 1321 Training Error: 105.20923 Validation Error: 105.222496\n",
            "Epoch: 1322 Training Error: 105.20918 Validation Error: 105.22244\n",
            "Epoch: 1323 Training Error: 105.20913 Validation Error: 105.22238\n",
            "Epoch: 1324 Training Error: 105.2091 Validation Error: 105.22233\n",
            "Epoch: 1325 Training Error: 105.209045 Validation Error: 105.22227\n",
            "Epoch: 1326 Training Error: 105.20899 Validation Error: 105.22218\n",
            "Epoch: 1327 Training Error: 105.20892 Validation Error: 105.22213\n",
            "Epoch: 1328 Training Error: 105.20887 Validation Error: 105.222084\n",
            "Epoch: 1329 Training Error: 105.20881 Validation Error: 105.22202\n",
            "Epoch: 1330 Training Error: 105.208755 Validation Error: 105.221985\n",
            "Epoch: 1331 Training Error: 105.208694 Validation Error: 105.22193\n",
            "Epoch: 1332 Training Error: 105.20866 Validation Error: 105.22187\n",
            "Epoch: 1333 Training Error: 105.208595 Validation Error: 105.22185\n",
            "Epoch: 1334 Training Error: 105.208534 Validation Error: 105.22181\n",
            "Epoch: 1335 Training Error: 105.208496 Validation Error: 105.22173\n",
            "Epoch: 1336 Training Error: 105.20845 Validation Error: 105.22169\n",
            "Epoch: 1337 Training Error: 105.2084 Validation Error: 105.221634\n",
            "Epoch: 1338 Training Error: 105.20835 Validation Error: 105.22159\n",
            "Epoch: 1339 Training Error: 105.20831 Validation Error: 105.221535\n",
            "Epoch: 1340 Training Error: 105.20826 Validation Error: 105.2215\n",
            "Epoch: 1341 Training Error: 105.20821 Validation Error: 105.221436\n",
            "Epoch: 1342 Training Error: 105.20816 Validation Error: 105.22145\n",
            "Epoch: 1343 Training Error: 105.20812 Validation Error: 105.22136\n",
            "Epoch: 1344 Training Error: 105.20808 Validation Error: 105.22128\n",
            "Epoch: 1345 Training Error: 105.20804 Validation Error: 105.221214\n",
            "Epoch: 1346 Training Error: 105.208 Validation Error: 105.221146\n",
            "Epoch: 1347 Training Error: 105.20794 Validation Error: 105.221085\n",
            "Epoch: 1348 Training Error: 105.2079 Validation Error: 105.22102\n",
            "Epoch: 1349 Training Error: 105.20788 Validation Error: 105.22094\n",
            "Epoch: 1350 Training Error: 105.20784 Validation Error: 105.22084\n",
            "Epoch: 1351 Training Error: 105.20781 Validation Error: 105.22077\n",
            "Epoch: 1352 Training Error: 105.20778 Validation Error: 105.22069\n",
            "Epoch: 1353 Training Error: 105.207726 Validation Error: 105.22065\n",
            "Epoch: 1354 Training Error: 105.20767 Validation Error: 105.220604\n",
            "Epoch: 1355 Training Error: 105.20763 Validation Error: 105.22057\n",
            "Epoch: 1356 Training Error: 105.20757 Validation Error: 105.22053\n",
            "Epoch: 1357 Training Error: 105.20753 Validation Error: 105.22047\n",
            "Epoch: 1358 Training Error: 105.20749 Validation Error: 105.22041\n",
            "Epoch: 1359 Training Error: 105.20745 Validation Error: 105.22035\n",
            "Epoch: 1360 Training Error: 105.20741 Validation Error: 105.22029\n",
            "Epoch: 1361 Training Error: 105.207375 Validation Error: 105.220215\n",
            "Epoch: 1362 Training Error: 105.20735 Validation Error: 105.22013\n",
            "Epoch: 1363 Training Error: 105.20729 Validation Error: 105.22009\n",
            "Epoch: 1364 Training Error: 105.20725 Validation Error: 105.220055\n",
            "Epoch: 1365 Training Error: 105.2072 Validation Error: 105.22002\n",
            "Epoch: 1366 Training Error: 105.20717 Validation Error: 105.21996\n",
            "Epoch: 1367 Training Error: 105.20713 Validation Error: 105.219894\n",
            "Epoch: 1368 Training Error: 105.20708 Validation Error: 105.219826\n",
            "Epoch: 1369 Training Error: 105.207054 Validation Error: 105.219765\n",
            "Epoch: 1370 Training Error: 105.20699 Validation Error: 105.21972\n",
            "Epoch: 1371 Training Error: 105.206955 Validation Error: 105.219666\n",
            "Epoch: 1372 Training Error: 105.20692 Validation Error: 105.21962\n",
            "Epoch: 1373 Training Error: 105.20688 Validation Error: 105.21957\n",
            "Epoch: 1374 Training Error: 105.206825 Validation Error: 105.21952\n",
            "Epoch: 1375 Training Error: 105.20678 Validation Error: 105.21948\n",
            "Epoch: 1376 Training Error: 105.20676 Validation Error: 105.219406\n",
            "Epoch: 1377 Training Error: 105.20672 Validation Error: 105.219315\n",
            "Epoch: 1378 Training Error: 105.206696 Validation Error: 105.219246\n",
            "Epoch: 1379 Training Error: 105.20664 Validation Error: 105.219185\n",
            "Epoch: 1380 Training Error: 105.206604 Validation Error: 105.21912\n",
            "Epoch: 1381 Training Error: 105.206566 Validation Error: 105.219055\n",
            "Epoch: 1382 Training Error: 105.20653 Validation Error: 105.21901\n",
            "Epoch: 1383 Training Error: 105.206505 Validation Error: 105.21897\n",
            "Epoch: 1384 Training Error: 105.20647 Validation Error: 105.21891\n",
            "Epoch: 1385 Training Error: 105.20643 Validation Error: 105.21886\n",
            "Epoch: 1386 Training Error: 105.20638 Validation Error: 105.21882\n",
            "Epoch: 1387 Training Error: 105.206345 Validation Error: 105.21876\n",
            "Epoch: 1388 Training Error: 105.20631 Validation Error: 105.21872\n",
            "Epoch: 1389 Training Error: 105.20627 Validation Error: 105.21864\n",
            "Epoch: 1390 Training Error: 105.20623 Validation Error: 105.218605\n",
            "Epoch: 1391 Training Error: 105.20619 Validation Error: 105.218575\n",
            "Epoch: 1392 Training Error: 105.20615 Validation Error: 105.21852\n",
            "Epoch: 1393 Training Error: 105.20611 Validation Error: 105.21848\n",
            "Epoch: 1394 Training Error: 105.20607 Validation Error: 105.21846\n",
            "Epoch: 1395 Training Error: 105.20605 Validation Error: 105.21838\n",
            "Epoch: 1396 Training Error: 105.20602 Validation Error: 105.21834\n",
            "Epoch: 1397 Training Error: 105.20598 Validation Error: 105.218285\n",
            "Epoch: 1398 Training Error: 105.20595 Validation Error: 105.21823\n",
            "Epoch: 1399 Training Error: 105.20591 Validation Error: 105.21817\n",
            "Epoch: 1400 Training Error: 105.20587 Validation Error: 105.218124\n",
            "Epoch: 1401 Training Error: 105.20585 Validation Error: 105.21805\n",
            "Epoch: 1402 Training Error: 105.205795 Validation Error: 105.217995\n",
            "Epoch: 1403 Training Error: 105.205734 Validation Error: 105.217964\n",
            "Epoch: 1404 Training Error: 105.205696 Validation Error: 105.21793\n",
            "Epoch: 1405 Training Error: 105.20564 Validation Error: 105.21789\n",
            "Epoch: 1406 Training Error: 105.20561 Validation Error: 105.217834\n",
            "Epoch: 1407 Training Error: 105.205574 Validation Error: 105.21779\n",
            "Epoch: 1408 Training Error: 105.20552 Validation Error: 105.21775\n",
            "Epoch: 1409 Training Error: 105.20548 Validation Error: 105.21771\n",
            "Epoch: 1410 Training Error: 105.205444 Validation Error: 105.21763\n",
            "Epoch: 1411 Training Error: 105.20541 Validation Error: 105.21756\n",
            "Epoch: 1412 Training Error: 105.20536 Validation Error: 105.21754\n",
            "Epoch: 1413 Training Error: 105.20532 Validation Error: 105.2175\n",
            "Epoch: 1414 Training Error: 105.20527 Validation Error: 105.21752\n",
            "Epoch: 1415 Training Error: 105.20522 Validation Error: 105.21749\n",
            "Epoch: 1416 Training Error: 105.2052 Validation Error: 105.21744\n",
            "Epoch: 1417 Training Error: 105.20516 Validation Error: 105.217354\n",
            "Epoch: 1418 Training Error: 105.20511 Validation Error: 105.21732\n",
            "Epoch: 1419 Training Error: 105.20507 Validation Error: 105.21728\n",
            "Epoch: 1420 Training Error: 105.20503 Validation Error: 105.21726\n",
            "Epoch: 1421 Training Error: 105.20499 Validation Error: 105.217224\n",
            "Epoch: 1422 Training Error: 105.20495 Validation Error: 105.2172\n",
            "Epoch: 1423 Training Error: 105.20491 Validation Error: 105.21714\n",
            "Epoch: 1424 Training Error: 105.204865 Validation Error: 105.21712\n",
            "Epoch: 1425 Training Error: 105.204834 Validation Error: 105.21708\n",
            "Epoch: 1426 Training Error: 105.204796 Validation Error: 105.21704\n",
            "Epoch: 1427 Training Error: 105.204765 Validation Error: 105.21702\n",
            "Epoch: 1428 Training Error: 105.20473 Validation Error: 105.216965\n",
            "Epoch: 1429 Training Error: 105.2047 Validation Error: 105.21698\n",
            "Epoch: 1430 Training Error: 105.20466 Validation Error: 105.2169\n",
            "Epoch: 1431 Training Error: 105.20463 Validation Error: 105.21688\n",
            "Epoch: 1432 Training Error: 105.2046 Validation Error: 105.2169\n",
            "Epoch: 1433 Training Error: 105.204575 Validation Error: 105.21689\n",
            "Epoch: 1434 Training Error: 105.20455 Validation Error: 105.21689\n",
            "Epoch: 1435 Training Error: 105.20451 Validation Error: 105.21684\n",
            "Epoch: 1436 Training Error: 105.20449 Validation Error: 105.21685\n",
            "Epoch: 1437 Training Error: 105.20446 Validation Error: 105.21684\n",
            "Epoch: 1438 Training Error: 105.20442 Validation Error: 105.21678\n",
            "Epoch: 1439 Training Error: 105.2044 Validation Error: 105.21678\n",
            "Epoch: 1440 Training Error: 105.20435 Validation Error: 105.21667\n",
            "Epoch: 1441 Training Error: 105.204315 Validation Error: 105.21659\n",
            "Epoch: 1442 Training Error: 105.204254 Validation Error: 105.21649\n",
            "Epoch: 1443 Training Error: 105.2042 Validation Error: 105.21639\n",
            "Epoch: 1444 Training Error: 105.204155 Validation Error: 105.216255\n",
            "Epoch: 1445 Training Error: 105.2041 Validation Error: 105.21618\n",
            "Epoch: 1446 Training Error: 105.20406 Validation Error: 105.21613\n",
            "Epoch: 1447 Training Error: 105.20404 Validation Error: 105.2161\n",
            "Epoch: 1448 Training Error: 105.20399 Validation Error: 105.21607\n",
            "Epoch: 1449 Training Error: 105.20395 Validation Error: 105.21602\n",
            "Epoch: 1450 Training Error: 105.2039 Validation Error: 105.21594\n",
            "Epoch: 1451 Training Error: 105.20388 Validation Error: 105.215935\n",
            "Epoch: 1452 Training Error: 105.20383 Validation Error: 105.21582\n",
            "Epoch: 1453 Training Error: 105.203804 Validation Error: 105.21576\n",
            "Epoch: 1454 Training Error: 105.203766 Validation Error: 105.21572\n",
            "Epoch: 1455 Training Error: 105.20373 Validation Error: 105.215706\n",
            "Epoch: 1456 Training Error: 105.20369 Validation Error: 105.21566\n",
            "Epoch: 1457 Training Error: 105.20365 Validation Error: 105.21561\n",
            "Epoch: 1458 Training Error: 105.20363 Validation Error: 105.21556\n",
            "Epoch: 1459 Training Error: 105.20359 Validation Error: 105.21551\n",
            "Epoch: 1460 Training Error: 105.20357 Validation Error: 105.21551\n",
            "Epoch: 1461 Training Error: 105.20353 Validation Error: 105.215485\n",
            "Epoch: 1462 Training Error: 105.20349 Validation Error: 105.21539\n",
            "Epoch: 1463 Training Error: 105.20345 Validation Error: 105.21535\n",
            "Epoch: 1464 Training Error: 105.20343 Validation Error: 105.21533\n",
            "Epoch: 1465 Training Error: 105.20339 Validation Error: 105.21531\n",
            "Epoch: 1466 Training Error: 105.203354 Validation Error: 105.21527\n",
            "Epoch: 1467 Training Error: 105.203316 Validation Error: 105.215225\n",
            "Epoch: 1468 Training Error: 105.20329 Validation Error: 105.21519\n",
            "Epoch: 1469 Training Error: 105.20328 Validation Error: 105.21521\n",
            "Epoch: 1470 Training Error: 105.20324 Validation Error: 105.21521\n",
            "Epoch: 1471 Training Error: 105.20323 Validation Error: 105.215195\n",
            "Epoch: 1472 Training Error: 105.20318 Validation Error: 105.21512\n",
            "Epoch: 1473 Training Error: 105.20317 Validation Error: 105.21515\n",
            "Epoch: 1474 Training Error: 105.20313 Validation Error: 105.21511\n",
            "Epoch: 1475 Training Error: 105.203094 Validation Error: 105.21502\n",
            "Epoch: 1476 Training Error: 105.20307 Validation Error: 105.215\n",
            "Epoch: 1477 Training Error: 105.20302 Validation Error: 105.214935\n",
            "Epoch: 1478 Training Error: 105.20298 Validation Error: 105.214874\n",
            "Epoch: 1479 Training Error: 105.20294 Validation Error: 105.21481\n",
            "Epoch: 1480 Training Error: 105.202866 Validation Error: 105.21468\n",
            "Epoch: 1481 Training Error: 105.202835 Validation Error: 105.21462\n",
            "Epoch: 1482 Training Error: 105.202805 Validation Error: 105.214584\n",
            "Epoch: 1483 Training Error: 105.20278 Validation Error: 105.214584\n",
            "Epoch: 1484 Training Error: 105.20277 Validation Error: 105.214584\n",
            "Epoch: 1485 Training Error: 105.20276 Validation Error: 105.214584\n",
            "Epoch: 1486 Training Error: 105.202736 Validation Error: 105.214584\n",
            "Epoch: 1487 Training Error: 105.20272 Validation Error: 105.214584\n",
            "Epoch: 1488 Training Error: 105.20268 Validation Error: 105.21454\n",
            "Epoch: 1489 Training Error: 105.20263 Validation Error: 105.21444\n",
            "Epoch: 1490 Training Error: 105.2026 Validation Error: 105.21435\n",
            "Epoch: 1491 Training Error: 105.202545 Validation Error: 105.21427\n",
            "Epoch: 1492 Training Error: 105.20252 Validation Error: 105.21424\n",
            "Epoch: 1493 Training Error: 105.202484 Validation Error: 105.21419\n",
            "Epoch: 1494 Training Error: 105.202446 Validation Error: 105.21413\n",
            "Epoch: 1495 Training Error: 105.20242 Validation Error: 105.21411\n",
            "Epoch: 1496 Training Error: 105.202385 Validation Error: 105.21405\n",
            "Epoch: 1497 Training Error: 105.20235 Validation Error: 105.21401\n",
            "Epoch: 1498 Training Error: 105.202324 Validation Error: 105.213974\n",
            "Epoch: 1499 Training Error: 105.20229 Validation Error: 105.21397\n",
            "Epoch: 1500 Training Error: 105.202255 Validation Error: 105.213905\n",
            "Epoch: 1501 Training Error: 105.20221 Validation Error: 105.21384\n",
            "Epoch: 1502 Training Error: 105.20219 Validation Error: 105.21379\n",
            "Epoch: 1503 Training Error: 105.20217 Validation Error: 105.21383\n",
            "Epoch: 1504 Training Error: 105.202156 Validation Error: 105.21381\n",
            "Epoch: 1505 Training Error: 105.20215 Validation Error: 105.21384\n",
            "Epoch: 1506 Training Error: 105.20213 Validation Error: 105.21384\n",
            "Epoch: 1507 Training Error: 105.20211 Validation Error: 105.21381\n",
            "Epoch: 1508 Training Error: 105.20207 Validation Error: 105.21377\n",
            "Epoch: 1509 Training Error: 105.20205 Validation Error: 105.21374\n",
            "Epoch: 1510 Training Error: 105.20202 Validation Error: 105.2137\n",
            "Epoch: 1511 Training Error: 105.20197 Validation Error: 105.213615\n",
            "Epoch: 1512 Training Error: 105.20192 Validation Error: 105.213554\n",
            "Epoch: 1513 Training Error: 105.20189 Validation Error: 105.21348\n",
            "Epoch: 1514 Training Error: 105.20186 Validation Error: 105.213455\n",
            "Epoch: 1515 Training Error: 105.20181 Validation Error: 105.213394\n",
            "Epoch: 1516 Training Error: 105.201775 Validation Error: 105.213326\n",
            "Epoch: 1517 Training Error: 105.20175 Validation Error: 105.21332\n",
            "Epoch: 1518 Training Error: 105.2017 Validation Error: 105.21322\n",
            "Epoch: 1519 Training Error: 105.20162 Validation Error: 105.21303\n",
            "Epoch: 1520 Training Error: 105.201584 Validation Error: 105.21298\n",
            "Epoch: 1521 Training Error: 105.201546 Validation Error: 105.212906\n",
            "Epoch: 1522 Training Error: 105.201515 Validation Error: 105.21288\n",
            "Epoch: 1523 Training Error: 105.201515 Validation Error: 105.21289\n",
            "Epoch: 1524 Training Error: 105.20146 Validation Error: 105.21281\n",
            "Epoch: 1525 Training Error: 105.20142 Validation Error: 105.21275\n",
            "Epoch: 1526 Training Error: 105.2014 Validation Error: 105.212715\n",
            "Epoch: 1527 Training Error: 105.20136 Validation Error: 105.212654\n",
            "Epoch: 1528 Training Error: 105.20134 Validation Error: 105.21265\n",
            "Epoch: 1529 Training Error: 105.20131 Validation Error: 105.21263\n",
            "Epoch: 1530 Training Error: 105.20126 Validation Error: 105.212555\n",
            "Epoch: 1531 Training Error: 105.201225 Validation Error: 105.212494\n",
            "Epoch: 1532 Training Error: 105.20119 Validation Error: 105.21245\n",
            "Epoch: 1533 Training Error: 105.20115 Validation Error: 105.21238\n",
            "Epoch: 1534 Training Error: 105.20111 Validation Error: 105.21232\n",
            "Epoch: 1535 Training Error: 105.201065 Validation Error: 105.21224\n",
            "Epoch: 1536 Training Error: 105.20104 Validation Error: 105.21224\n",
            "Epoch: 1537 Training Error: 105.20101 Validation Error: 105.21217\n",
            "Epoch: 1538 Training Error: 105.200966 Validation Error: 105.212105\n",
            "Epoch: 1539 Training Error: 105.20093 Validation Error: 105.21202\n",
            "Epoch: 1540 Training Error: 105.200874 Validation Error: 105.21192\n",
            "Epoch: 1541 Training Error: 105.20085 Validation Error: 105.21188\n",
            "Epoch: 1542 Training Error: 105.20083 Validation Error: 105.21184\n",
            "Epoch: 1543 Training Error: 105.20079 Validation Error: 105.21177\n",
            "Epoch: 1544 Training Error: 105.20075 Validation Error: 105.2117\n",
            "Epoch: 1545 Training Error: 105.2007 Validation Error: 105.211624\n",
            "Epoch: 1546 Training Error: 105.200676 Validation Error: 105.21156\n",
            "Epoch: 1547 Training Error: 105.20064 Validation Error: 105.21151\n",
            "Epoch: 1548 Training Error: 105.200615 Validation Error: 105.21147\n",
            "Epoch: 1549 Training Error: 105.20059 Validation Error: 105.21143\n",
            "Epoch: 1550 Training Error: 105.200554 Validation Error: 105.21139\n",
            "Epoch: 1551 Training Error: 105.200516 Validation Error: 105.211365\n",
            "Epoch: 1552 Training Error: 105.20049 Validation Error: 105.21131\n",
            "Epoch: 1553 Training Error: 105.200455 Validation Error: 105.211235\n",
            "Epoch: 1554 Training Error: 105.20042 Validation Error: 105.21116\n",
            "Epoch: 1555 Training Error: 105.20038 Validation Error: 105.21111\n",
            "Epoch: 1556 Training Error: 105.200356 Validation Error: 105.211075\n",
            "Epoch: 1557 Training Error: 105.20032 Validation Error: 105.210976\n",
            "Epoch: 1558 Training Error: 105.200294 Validation Error: 105.2109\n",
            "Epoch: 1559 Training Error: 105.200264 Validation Error: 105.21084\n",
            "Epoch: 1560 Training Error: 105.20024 Validation Error: 105.210815\n",
            "Epoch: 1561 Training Error: 105.2002 Validation Error: 105.21076\n",
            "Epoch: 1562 Training Error: 105.20018 Validation Error: 105.21074\n",
            "Epoch: 1563 Training Error: 105.20016 Validation Error: 105.210724\n",
            "Epoch: 1564 Training Error: 105.20012 Validation Error: 105.210686\n",
            "Epoch: 1565 Training Error: 105.200096 Validation Error: 105.21064\n",
            "Epoch: 1566 Training Error: 105.20006 Validation Error: 105.21058\n",
            "Epoch: 1567 Training Error: 105.20002 Validation Error: 105.21055\n",
            "Epoch: 1568 Training Error: 105.19999 Validation Error: 105.210526\n",
            "Epoch: 1569 Training Error: 105.19996 Validation Error: 105.210464\n",
            "Epoch: 1570 Training Error: 105.19993 Validation Error: 105.2104\n",
            "Epoch: 1571 Training Error: 105.199905 Validation Error: 105.21033\n",
            "Epoch: 1572 Training Error: 105.19989 Validation Error: 105.21024\n",
            "Epoch: 1573 Training Error: 105.199844 Validation Error: 105.21023\n",
            "Epoch: 1574 Training Error: 105.19983 Validation Error: 105.21018\n",
            "Epoch: 1575 Training Error: 105.19979 Validation Error: 105.210144\n",
            "Epoch: 1576 Training Error: 105.19975 Validation Error: 105.21011\n",
            "Epoch: 1577 Training Error: 105.19973 Validation Error: 105.21007\n",
            "Epoch: 1578 Training Error: 105.19971 Validation Error: 105.21003\n",
            "Epoch: 1579 Training Error: 105.19967 Validation Error: 105.20999\n",
            "Epoch: 1580 Training Error: 105.19963 Validation Error: 105.20998\n",
            "Epoch: 1581 Training Error: 105.19961 Validation Error: 105.20995\n",
            "Epoch: 1582 Training Error: 105.199585 Validation Error: 105.20991\n",
            "Epoch: 1583 Training Error: 105.19955 Validation Error: 105.20989\n",
            "Epoch: 1584 Training Error: 105.19951 Validation Error: 105.20991\n",
            "Epoch: 1585 Training Error: 105.19947 Validation Error: 105.20993\n",
            "Epoch: 1586 Training Error: 105.19945 Validation Error: 105.20987\n",
            "Epoch: 1587 Training Error: 105.19942 Validation Error: 105.20984\n",
            "Epoch: 1588 Training Error: 105.19938 Validation Error: 105.20978\n",
            "Epoch: 1589 Training Error: 105.199356 Validation Error: 105.20972\n",
            "Epoch: 1590 Training Error: 105.19932 Validation Error: 105.20964\n",
            "Epoch: 1591 Training Error: 105.199295 Validation Error: 105.20962\n",
            "Epoch: 1592 Training Error: 105.19926 Validation Error: 105.20958\n",
            "Epoch: 1593 Training Error: 105.199234 Validation Error: 105.20957\n",
            "Epoch: 1594 Training Error: 105.199196 Validation Error: 105.20953\n",
            "Epoch: 1595 Training Error: 105.19916 Validation Error: 105.209496\n",
            "Epoch: 1596 Training Error: 105.199135 Validation Error: 105.209496\n",
            "Epoch: 1597 Training Error: 105.19912 Validation Error: 105.20944\n",
            "Epoch: 1598 Training Error: 105.19908 Validation Error: 105.20938\n",
            "Epoch: 1599 Training Error: 105.19906 Validation Error: 105.20934\n",
            "Epoch: 1600 Training Error: 105.199036 Validation Error: 105.2093\n",
            "Epoch: 1601 Training Error: 105.199 Validation Error: 105.209206\n",
            "Epoch: 1602 Training Error: 105.19898 Validation Error: 105.20916\n",
            "Epoch: 1603 Training Error: 105.198944 Validation Error: 105.2091\n",
            "Epoch: 1604 Training Error: 105.19894 Validation Error: 105.20903\n",
            "Epoch: 1605 Training Error: 105.19892 Validation Error: 105.20895\n",
            "Epoch: 1606 Training Error: 105.1989 Validation Error: 105.20889\n",
            "Epoch: 1607 Training Error: 105.19888 Validation Error: 105.20885\n",
            "Epoch: 1608 Training Error: 105.198875 Validation Error: 105.20879\n",
            "Epoch: 1609 Training Error: 105.19884 Validation Error: 105.20877\n",
            "Epoch: 1610 Training Error: 105.1988 Validation Error: 105.20873\n",
            "Epoch: 1611 Training Error: 105.19877 Validation Error: 105.208694\n",
            "Epoch: 1612 Training Error: 105.19877 Validation Error: 105.20865\n",
            "Epoch: 1613 Training Error: 105.198746 Validation Error: 105.20861\n",
            "Epoch: 1614 Training Error: 105.19874 Validation Error: 105.20856\n",
            "Epoch: 1615 Training Error: 105.1987 Validation Error: 105.208534\n",
            "Epoch: 1616 Training Error: 105.19866 Validation Error: 105.20851\n",
            "Epoch: 1617 Training Error: 105.19867 Validation Error: 105.20847\n",
            "Epoch: 1618 Training Error: 105.19866 Validation Error: 105.208435\n",
            "Epoch: 1619 Training Error: 105.19864 Validation Error: 105.20838\n",
            "Epoch: 1620 Training Error: 105.19861 Validation Error: 105.208336\n",
            "Epoch: 1621 Training Error: 105.19856 Validation Error: 105.20831\n",
            "Epoch: 1622 Training Error: 105.198524 Validation Error: 105.208275\n",
            "Epoch: 1623 Training Error: 105.1985 Validation Error: 105.20824\n",
            "Epoch: 1624 Training Error: 105.19843 Validation Error: 105.20821\n",
            "Epoch: 1625 Training Error: 105.1984 Validation Error: 105.208176\n",
            "Epoch: 1626 Training Error: 105.198364 Validation Error: 105.20814\n",
            "Epoch: 1627 Training Error: 105.198326 Validation Error: 105.208115\n",
            "Epoch: 1628 Training Error: 105.19831 Validation Error: 105.20806\n",
            "Epoch: 1629 Training Error: 105.19827 Validation Error: 105.20802\n",
            "Epoch: 1630 Training Error: 105.19825 Validation Error: 105.207985\n",
            "Epoch: 1631 Training Error: 105.19823 Validation Error: 105.20796\n",
            "Epoch: 1632 Training Error: 105.1982 Validation Error: 105.2079\n",
            "Epoch: 1633 Training Error: 105.19819 Validation Error: 105.20786\n",
            "Epoch: 1634 Training Error: 105.19819 Validation Error: 105.20781\n",
            "Epoch: 1635 Training Error: 105.198166 Validation Error: 105.20779\n",
            "Epoch: 1636 Training Error: 105.198135 Validation Error: 105.20775\n",
            "Epoch: 1637 Training Error: 105.19813 Validation Error: 105.207726\n",
            "Epoch: 1638 Training Error: 105.19809 Validation Error: 105.2077\n",
            "Epoch: 1639 Training Error: 105.19806 Validation Error: 105.207664\n",
            "Epoch: 1640 Training Error: 105.19804 Validation Error: 105.20764\n",
            "Epoch: 1641 Training Error: 105.19801 Validation Error: 105.2076\n",
            "Epoch: 1642 Training Error: 105.19799 Validation Error: 105.207565\n",
            "Epoch: 1643 Training Error: 105.19795 Validation Error: 105.20753\n",
            "Epoch: 1644 Training Error: 105.197914 Validation Error: 105.20749\n",
            "Epoch: 1645 Training Error: 105.19789 Validation Error: 105.20745\n",
            "Epoch: 1646 Training Error: 105.19784 Validation Error: 105.20743\n",
            "Epoch: 1647 Training Error: 105.1978 Validation Error: 105.20739\n",
            "Epoch: 1648 Training Error: 105.19778 Validation Error: 105.20735\n",
            "Epoch: 1649 Training Error: 105.197754 Validation Error: 105.2073\n",
            "Epoch: 1650 Training Error: 105.197716 Validation Error: 105.207275\n",
            "Epoch: 1651 Training Error: 105.19768 Validation Error: 105.20724\n",
            "Epoch: 1652 Training Error: 105.19764 Validation Error: 105.2072\n",
            "Epoch: 1653 Training Error: 105.197586 Validation Error: 105.20719\n",
            "Epoch: 1654 Training Error: 105.19754 Validation Error: 105.20719\n",
            "Epoch: 1655 Training Error: 105.19752 Validation Error: 105.20715\n",
            "Epoch: 1656 Training Error: 105.19748 Validation Error: 105.207115\n",
            "Epoch: 1657 Training Error: 105.19745 Validation Error: 105.20708\n",
            "Epoch: 1658 Training Error: 105.19742 Validation Error: 105.207054\n",
            "Epoch: 1659 Training Error: 105.19738 Validation Error: 105.20708\n",
            "Epoch: 1660 Training Error: 105.19735 Validation Error: 105.20706\n",
            "Epoch: 1661 Training Error: 105.19733 Validation Error: 105.207054\n",
            "Epoch: 1662 Training Error: 105.1973 Validation Error: 105.20704\n",
            "Epoch: 1663 Training Error: 105.19728 Validation Error: 105.207054\n",
            "Epoch: 1664 Training Error: 105.19725 Validation Error: 105.207016\n",
            "Epoch: 1665 Training Error: 105.19723 Validation Error: 105.20692\n",
            "Epoch: 1666 Training Error: 105.197205 Validation Error: 105.20684\n",
            "Epoch: 1667 Training Error: 105.19718 Validation Error: 105.206795\n",
            "Epoch: 1668 Training Error: 105.19715 Validation Error: 105.206764\n",
            "Epoch: 1669 Training Error: 105.19713 Validation Error: 105.206726\n",
            "Epoch: 1670 Training Error: 105.197105 Validation Error: 105.20668\n",
            "Epoch: 1671 Training Error: 105.19708 Validation Error: 105.206665\n",
            "Epoch: 1672 Training Error: 105.19705 Validation Error: 105.20666\n",
            "Epoch: 1673 Training Error: 105.19703 Validation Error: 105.20664\n",
            "Epoch: 1674 Training Error: 105.19701 Validation Error: 105.206604\n",
            "Epoch: 1675 Training Error: 105.196976 Validation Error: 105.206566\n",
            "Epoch: 1676 Training Error: 105.19695 Validation Error: 105.20653\n",
            "Epoch: 1677 Training Error: 105.196915 Validation Error: 105.206505\n",
            "Epoch: 1678 Training Error: 105.19689 Validation Error: 105.20647\n",
            "Epoch: 1679 Training Error: 105.19687 Validation Error: 105.20642\n",
            "Epoch: 1680 Training Error: 105.196846 Validation Error: 105.20635\n",
            "Epoch: 1681 Training Error: 105.196815 Validation Error: 105.20632\n",
            "Epoch: 1682 Training Error: 105.19678 Validation Error: 105.20627\n",
            "Epoch: 1683 Training Error: 105.196754 Validation Error: 105.20622\n",
            "Epoch: 1684 Training Error: 105.19674 Validation Error: 105.206154\n",
            "Epoch: 1685 Training Error: 105.19671 Validation Error: 105.20613\n",
            "Epoch: 1686 Training Error: 105.19669 Validation Error: 105.206085\n",
            "Epoch: 1687 Training Error: 105.19668 Validation Error: 105.20602\n",
            "Epoch: 1688 Training Error: 105.196655 Validation Error: 105.20598\n",
            "Epoch: 1689 Training Error: 105.19663 Validation Error: 105.205956\n",
            "Epoch: 1690 Training Error: 105.196594 Validation Error: 105.20595\n",
            "Epoch: 1691 Training Error: 105.19657 Validation Error: 105.205894\n",
            "Epoch: 1692 Training Error: 105.19654 Validation Error: 105.20587\n",
            "Epoch: 1693 Training Error: 105.19652 Validation Error: 105.20586\n",
            "Epoch: 1694 Training Error: 105.196495 Validation Error: 105.20583\n",
            "Epoch: 1695 Training Error: 105.19648 Validation Error: 105.205795\n",
            "Epoch: 1696 Training Error: 105.19646 Validation Error: 105.20574\n",
            "Epoch: 1697 Training Error: 105.19644 Validation Error: 105.20571\n",
            "Epoch: 1698 Training Error: 105.1964 Validation Error: 105.205696\n",
            "Epoch: 1699 Training Error: 105.196396 Validation Error: 105.20564\n",
            "Epoch: 1700 Training Error: 105.196365 Validation Error: 105.20561\n",
            "Epoch: 1701 Training Error: 105.196335 Validation Error: 105.2056\n",
            "Epoch: 1702 Training Error: 105.196304 Validation Error: 105.205574\n",
            "Epoch: 1703 Training Error: 105.19628 Validation Error: 105.205536\n",
            "Epoch: 1704 Training Error: 105.19626 Validation Error: 105.2055\n",
            "Epoch: 1705 Training Error: 105.19622 Validation Error: 105.20548\n",
            "Epoch: 1706 Training Error: 105.196205 Validation Error: 105.20546\n",
            "Epoch: 1707 Training Error: 105.19618 Validation Error: 105.20541\n",
            "Epoch: 1708 Training Error: 105.19617 Validation Error: 105.20536\n",
            "Epoch: 1709 Training Error: 105.196144 Validation Error: 105.20531\n",
            "Epoch: 1710 Training Error: 105.19612 Validation Error: 105.20527\n",
            "Epoch: 1711 Training Error: 105.1961 Validation Error: 105.205246\n",
            "Epoch: 1712 Training Error: 105.19606 Validation Error: 105.20521\n",
            "Epoch: 1713 Training Error: 105.19602 Validation Error: 105.205185\n",
            "Epoch: 1714 Training Error: 105.19601 Validation Error: 105.20515\n",
            "Epoch: 1715 Training Error: 105.19597 Validation Error: 105.205124\n",
            "Epoch: 1716 Training Error: 105.195946 Validation Error: 105.20511\n",
            "Epoch: 1717 Training Error: 105.19591 Validation Error: 105.205086\n",
            "Epoch: 1718 Training Error: 105.195885 Validation Error: 105.20506\n",
            "Epoch: 1719 Training Error: 105.19587 Validation Error: 105.20501\n",
            "Epoch: 1720 Training Error: 105.19585 Validation Error: 105.205\n",
            "Epoch: 1721 Training Error: 105.19582 Validation Error: 105.20499\n",
            "Epoch: 1722 Training Error: 105.19579 Validation Error: 105.20493\n",
            "Epoch: 1723 Training Error: 105.19577 Validation Error: 105.20491\n",
            "Epoch: 1724 Training Error: 105.19576 Validation Error: 105.20487\n",
            "Epoch: 1725 Training Error: 105.19573 Validation Error: 105.204834\n",
            "Epoch: 1726 Training Error: 105.19571 Validation Error: 105.20479\n",
            "Epoch: 1727 Training Error: 105.19569 Validation Error: 105.20475\n",
            "Epoch: 1728 Training Error: 105.195656 Validation Error: 105.20471\n",
            "Epoch: 1729 Training Error: 105.19565 Validation Error: 105.20466\n",
            "Epoch: 1730 Training Error: 105.195625 Validation Error: 105.20463\n",
            "Epoch: 1731 Training Error: 105.195595 Validation Error: 105.20459\n",
            "Epoch: 1732 Training Error: 105.19559 Validation Error: 105.20453\n",
            "Epoch: 1733 Training Error: 105.19556 Validation Error: 105.20449\n",
            "Epoch: 1734 Training Error: 105.19553 Validation Error: 105.20445\n",
            "Epoch: 1735 Training Error: 105.19551 Validation Error: 105.2044\n",
            "Epoch: 1736 Training Error: 105.19549 Validation Error: 105.20436\n",
            "Epoch: 1737 Training Error: 105.19547 Validation Error: 105.20432\n",
            "Epoch: 1738 Training Error: 105.19546 Validation Error: 105.20428\n",
            "Epoch: 1739 Training Error: 105.195435 Validation Error: 105.20424\n",
            "Epoch: 1740 Training Error: 105.19541 Validation Error: 105.204216\n",
            "Epoch: 1741 Training Error: 105.19539 Validation Error: 105.20416\n",
            "Epoch: 1742 Training Error: 105.19535 Validation Error: 105.20414\n",
            "Epoch: 1743 Training Error: 105.19531 Validation Error: 105.204124\n",
            "Epoch: 1744 Training Error: 105.19529 Validation Error: 105.20409\n",
            "Epoch: 1745 Training Error: 105.195274 Validation Error: 105.204056\n",
            "Epoch: 1746 Training Error: 105.19525 Validation Error: 105.20402\n",
            "Epoch: 1747 Training Error: 105.19524 Validation Error: 105.20398\n",
            "Epoch: 1748 Training Error: 105.19522 Validation Error: 105.203926\n",
            "Epoch: 1749 Training Error: 105.19521 Validation Error: 105.20389\n",
            "Epoch: 1750 Training Error: 105.19518 Validation Error: 105.203865\n",
            "Epoch: 1751 Training Error: 105.19515 Validation Error: 105.20384\n",
            "Epoch: 1752 Training Error: 105.195114 Validation Error: 105.203804\n",
            "Epoch: 1753 Training Error: 105.19508 Validation Error: 105.20379\n",
            "Epoch: 1754 Training Error: 105.19506 Validation Error: 105.20374\n",
            "Epoch: 1755 Training Error: 105.195045 Validation Error: 105.203705\n",
            "Epoch: 1756 Training Error: 105.195045 Validation Error: 105.20367\n",
            "Epoch: 1757 Training Error: 105.19504 Validation Error: 105.20364\n",
            "Epoch: 1758 Training Error: 105.195015 Validation Error: 105.20361\n",
            "Epoch: 1759 Training Error: 105.195015 Validation Error: 105.203575\n",
            "Epoch: 1760 Training Error: 105.194984 Validation Error: 105.20355\n",
            "Epoch: 1761 Training Error: 105.19496 Validation Error: 105.20353\n",
            "Epoch: 1762 Training Error: 105.19494 Validation Error: 105.20351\n",
            "Epoch: 1763 Training Error: 105.1949 Validation Error: 105.203476\n",
            "Epoch: 1764 Training Error: 105.194885 Validation Error: 105.20345\n",
            "Epoch: 1765 Training Error: 105.194916 Validation Error: 105.20341\n",
            "Epoch: 1766 Training Error: 105.194885 Validation Error: 105.20338\n",
            "Epoch: 1767 Training Error: 105.194885 Validation Error: 105.20333\n",
            "Epoch: 1768 Training Error: 105.19488 Validation Error: 105.20331\n",
            "Epoch: 1769 Training Error: 105.19485 Validation Error: 105.203255\n",
            "Epoch: 1770 Training Error: 105.19484 Validation Error: 105.20323\n",
            "Epoch: 1771 Training Error: 105.19484 Validation Error: 105.20319\n",
            "Epoch: 1772 Training Error: 105.19481 Validation Error: 105.20317\n",
            "Epoch: 1773 Training Error: 105.194786 Validation Error: 105.20313\n",
            "Epoch: 1774 Training Error: 105.19475 Validation Error: 105.2031\n",
            "Epoch: 1775 Training Error: 105.19469 Validation Error: 105.20308\n",
            "Epoch: 1776 Training Error: 105.19465 Validation Error: 105.20304\n",
            "Epoch: 1777 Training Error: 105.194626 Validation Error: 105.20302\n",
            "Epoch: 1778 Training Error: 105.19459 Validation Error: 105.202995\n",
            "Epoch: 1779 Training Error: 105.194565 Validation Error: 105.20297\n",
            "Epoch: 1780 Training Error: 105.19451 Validation Error: 105.20296\n",
            "Epoch: 1781 Training Error: 105.19449 Validation Error: 105.202934\n",
            "Epoch: 1782 Training Error: 105.194466 Validation Error: 105.202896\n",
            "Epoch: 1783 Training Error: 105.19445 Validation Error: 105.20286\n",
            "Epoch: 1784 Training Error: 105.19444 Validation Error: 105.20282\n",
            "Epoch: 1785 Training Error: 105.19443 Validation Error: 105.20277\n",
            "Epoch: 1786 Training Error: 105.19441 Validation Error: 105.202736\n",
            "Epoch: 1787 Training Error: 105.194374 Validation Error: 105.202705\n",
            "Epoch: 1788 Training Error: 105.19433 Validation Error: 105.2027\n",
            "Epoch: 1789 Training Error: 105.194305 Validation Error: 105.20267\n",
            "Epoch: 1790 Training Error: 105.19429 Validation Error: 105.202644\n",
            "Epoch: 1791 Training Error: 105.19427 Validation Error: 105.20262\n",
            "Epoch: 1792 Training Error: 105.19424 Validation Error: 105.2026\n",
            "Epoch: 1793 Training Error: 105.19424 Validation Error: 105.202545\n",
            "Epoch: 1794 Training Error: 105.19423 Validation Error: 105.20252\n",
            "Epoch: 1795 Training Error: 105.19424 Validation Error: 105.20247\n",
            "Epoch: 1796 Training Error: 105.19423 Validation Error: 105.202446\n",
            "Epoch: 1797 Training Error: 105.19423 Validation Error: 105.20241\n",
            "Epoch: 1798 Training Error: 105.19421 Validation Error: 105.202385\n",
            "Epoch: 1799 Training Error: 105.19419 Validation Error: 105.20236\n",
            "Epoch: 1800 Training Error: 105.194176 Validation Error: 105.20233\n",
            "Epoch: 1801 Training Error: 105.19415 Validation Error: 105.20231\n",
            "Epoch: 1802 Training Error: 105.19414 Validation Error: 105.202286\n",
            "Epoch: 1803 Training Error: 105.19413 Validation Error: 105.20225\n",
            "Epoch: 1804 Training Error: 105.194115 Validation Error: 105.202225\n",
            "Epoch: 1805 Training Error: 105.1941 Validation Error: 105.202194\n",
            "Epoch: 1806 Training Error: 105.19407 Validation Error: 105.202156\n",
            "Epoch: 1807 Training Error: 105.194016 Validation Error: 105.20213\n",
            "Epoch: 1808 Training Error: 105.19398 Validation Error: 105.20211\n",
            "Epoch: 1809 Training Error: 105.193954 Validation Error: 105.20209\n",
            "Epoch: 1810 Training Error: 105.19393 Validation Error: 105.20205\n",
            "Epoch: 1811 Training Error: 105.1939 Validation Error: 105.20202\n",
            "Epoch: 1812 Training Error: 105.19392 Validation Error: 105.20199\n",
            "Epoch: 1813 Training Error: 105.19392 Validation Error: 105.20196\n",
            "Epoch: 1814 Training Error: 105.19389 Validation Error: 105.20192\n",
            "Epoch: 1815 Training Error: 105.19388 Validation Error: 105.2019\n",
            "Epoch: 1816 Training Error: 105.193855 Validation Error: 105.20187\n",
            "Epoch: 1817 Training Error: 105.19384 Validation Error: 105.201836\n",
            "Epoch: 1818 Training Error: 105.1938 Validation Error: 105.20181\n",
            "Epoch: 1819 Training Error: 105.19378 Validation Error: 105.20178\n",
            "Epoch: 1820 Training Error: 105.19374 Validation Error: 105.20175\n",
            "Epoch: 1821 Training Error: 105.1937 Validation Error: 105.20172\n",
            "Epoch: 1822 Training Error: 105.1937 Validation Error: 105.2017\n",
            "Epoch: 1823 Training Error: 105.19366 Validation Error: 105.20168\n",
            "Epoch: 1824 Training Error: 105.19363 Validation Error: 105.20166\n",
            "Epoch: 1825 Training Error: 105.193596 Validation Error: 105.20164\n",
            "Epoch: 1826 Training Error: 105.19353 Validation Error: 105.20162\n",
            "Epoch: 1827 Training Error: 105.193504 Validation Error: 105.2016\n",
            "Epoch: 1828 Training Error: 105.19348 Validation Error: 105.20158\n",
            "Epoch: 1829 Training Error: 105.19346 Validation Error: 105.201546\n",
            "Epoch: 1830 Training Error: 105.19344 Validation Error: 105.201515\n",
            "Epoch: 1831 Training Error: 105.193405 Validation Error: 105.201485\n",
            "Epoch: 1832 Training Error: 105.19338 Validation Error: 105.20146\n",
            "Epoch: 1833 Training Error: 105.19336 Validation Error: 105.20142\n",
            "Epoch: 1834 Training Error: 105.19333 Validation Error: 105.201385\n",
            "Epoch: 1835 Training Error: 105.19332 Validation Error: 105.20135\n",
            "Epoch: 1836 Training Error: 105.193306 Validation Error: 105.20131\n",
            "Epoch: 1837 Training Error: 105.193306 Validation Error: 105.20128\n",
            "Epoch: 1838 Training Error: 105.19329 Validation Error: 105.20125\n",
            "Epoch: 1839 Training Error: 105.19329 Validation Error: 105.20121\n",
            "Epoch: 1840 Training Error: 105.19325 Validation Error: 105.2012\n",
            "Epoch: 1841 Training Error: 105.19323 Validation Error: 105.20119\n",
            "Epoch: 1842 Training Error: 105.19321 Validation Error: 105.201164\n",
            "Epoch: 1843 Training Error: 105.19319 Validation Error: 105.20114\n",
            "Epoch: 1844 Training Error: 105.193146 Validation Error: 105.201126\n",
            "Epoch: 1845 Training Error: 105.19311 Validation Error: 105.20111\n",
            "Epoch: 1846 Training Error: 105.19307 Validation Error: 105.2011\n",
            "Epoch: 1847 Training Error: 105.19305 Validation Error: 105.20109\n",
            "Epoch: 1848 Training Error: 105.193016 Validation Error: 105.20105\n",
            "Epoch: 1849 Training Error: 105.192986 Validation Error: 105.20105\n",
            "Epoch: 1850 Training Error: 105.192955 Validation Error: 105.20103\n",
            "Epoch: 1851 Training Error: 105.19295 Validation Error: 105.201004\n",
            "Epoch: 1852 Training Error: 105.19291 Validation Error: 105.20099\n",
            "Epoch: 1853 Training Error: 105.192894 Validation Error: 105.20095\n",
            "Epoch: 1854 Training Error: 105.19287 Validation Error: 105.200935\n",
            "Epoch: 1855 Training Error: 105.192856 Validation Error: 105.20089\n",
            "Epoch: 1856 Training Error: 105.19285 Validation Error: 105.20087\n",
            "Epoch: 1857 Training Error: 105.19283 Validation Error: 105.20083\n",
            "Epoch: 1858 Training Error: 105.19281 Validation Error: 105.20083\n",
            "Epoch: 1859 Training Error: 105.192795 Validation Error: 105.200806\n",
            "Epoch: 1860 Training Error: 105.19277 Validation Error: 105.200775\n",
            "Epoch: 1861 Training Error: 105.19275 Validation Error: 105.20075\n",
            "Epoch: 1862 Training Error: 105.19272 Validation Error: 105.20074\n",
            "Epoch: 1863 Training Error: 105.19271 Validation Error: 105.200714\n",
            "Epoch: 1864 Training Error: 105.192696 Validation Error: 105.20067\n",
            "Epoch: 1865 Training Error: 105.19267 Validation Error: 105.200615\n",
            "Epoch: 1866 Training Error: 105.19266 Validation Error: 105.20059\n",
            "Epoch: 1867 Training Error: 105.192635 Validation Error: 105.20054\n",
            "Epoch: 1868 Training Error: 105.19261 Validation Error: 105.20053\n",
            "Epoch: 1869 Training Error: 105.1926 Validation Error: 105.20049\n",
            "Epoch: 1870 Training Error: 105.19256 Validation Error: 105.20046\n",
            "Epoch: 1871 Training Error: 105.19254 Validation Error: 105.20043\n",
            "Epoch: 1872 Training Error: 105.19252 Validation Error: 105.20039\n",
            "Epoch: 1873 Training Error: 105.19252 Validation Error: 105.200356\n",
            "Epoch: 1874 Training Error: 105.19251 Validation Error: 105.20032\n",
            "Epoch: 1875 Training Error: 105.192474 Validation Error: 105.20032\n",
            "Epoch: 1876 Training Error: 105.192444 Validation Error: 105.2003\n",
            "Epoch: 1877 Training Error: 105.19242 Validation Error: 105.20033\n",
            "Epoch: 1878 Training Error: 105.1924 Validation Error: 105.20033\n",
            "Epoch: 1879 Training Error: 105.192375 Validation Error: 105.2003\n",
            "Epoch: 1880 Training Error: 105.19236 Validation Error: 105.20028\n",
            "Epoch: 1881 Training Error: 105.192345 Validation Error: 105.200264\n",
            "Epoch: 1882 Training Error: 105.19232 Validation Error: 105.20028\n",
            "Epoch: 1883 Training Error: 105.1923 Validation Error: 105.200264\n",
            "Epoch: 1884 Training Error: 105.192276 Validation Error: 105.20024\n",
            "Epoch: 1885 Training Error: 105.19226 Validation Error: 105.2002\n",
            "Epoch: 1886 Training Error: 105.19224 Validation Error: 105.200165\n",
            "Epoch: 1887 Training Error: 105.19221 Validation Error: 105.20016\n",
            "Epoch: 1888 Training Error: 105.1922 Validation Error: 105.20013\n",
            "Epoch: 1889 Training Error: 105.19217 Validation Error: 105.200096\n",
            "Epoch: 1890 Training Error: 105.19216 Validation Error: 105.200066\n",
            "Epoch: 1891 Training Error: 105.19214 Validation Error: 105.20002\n",
            "Epoch: 1892 Training Error: 105.19212 Validation Error: 105.19999\n",
            "Epoch: 1893 Training Error: 105.1921 Validation Error: 105.19998\n",
            "Epoch: 1894 Training Error: 105.192085 Validation Error: 105.19996\n",
            "Epoch: 1895 Training Error: 105.19206 Validation Error: 105.19989\n",
            "Epoch: 1896 Training Error: 105.19206 Validation Error: 105.199844\n",
            "Epoch: 1897 Training Error: 105.19204 Validation Error: 105.19983\n",
            "Epoch: 1898 Training Error: 105.19201 Validation Error: 105.19982\n",
            "Epoch: 1899 Training Error: 105.192 Validation Error: 105.19985\n",
            "Epoch: 1900 Training Error: 105.191986 Validation Error: 105.19985\n",
            "Epoch: 1901 Training Error: 105.19197 Validation Error: 105.19988\n",
            "Epoch: 1902 Training Error: 105.19196 Validation Error: 105.19987\n",
            "Epoch: 1903 Training Error: 105.19193 Validation Error: 105.199844\n",
            "Epoch: 1904 Training Error: 105.191925 Validation Error: 105.19983\n",
            "Epoch: 1905 Training Error: 105.19191 Validation Error: 105.199844\n",
            "Epoch: 1906 Training Error: 105.19191 Validation Error: 105.19987\n",
            "Epoch: 1907 Training Error: 105.19189 Validation Error: 105.199844\n",
            "Epoch: 1908 Training Error: 105.19187 Validation Error: 105.19982\n",
            "Epoch: 1909 Training Error: 105.19185 Validation Error: 105.19977\n",
            "Epoch: 1910 Training Error: 105.19181 Validation Error: 105.19969\n",
            "Epoch: 1911 Training Error: 105.19179 Validation Error: 105.199646\n",
            "Epoch: 1912 Training Error: 105.191765 Validation Error: 105.19961\n",
            "Epoch: 1913 Training Error: 105.191734 Validation Error: 105.19952\n",
            "Epoch: 1914 Training Error: 105.19171 Validation Error: 105.199455\n",
            "Epoch: 1915 Training Error: 105.191696 Validation Error: 105.199394\n",
            "Epoch: 1916 Training Error: 105.19169 Validation Error: 105.19935\n",
            "Epoch: 1917 Training Error: 105.191666 Validation Error: 105.19935\n",
            "Epoch: 1918 Training Error: 105.191635 Validation Error: 105.19932\n",
            "Epoch: 1919 Training Error: 105.19163 Validation Error: 105.19931\n",
            "Epoch: 1920 Training Error: 105.1916 Validation Error: 105.199295\n",
            "Epoch: 1921 Training Error: 105.191574 Validation Error: 105.19927\n",
            "Epoch: 1922 Training Error: 105.19157 Validation Error: 105.19926\n",
            "Epoch: 1923 Training Error: 105.19155 Validation Error: 105.19925\n",
            "Epoch: 1924 Training Error: 105.19153 Validation Error: 105.199234\n",
            "Epoch: 1925 Training Error: 105.19151 Validation Error: 105.19922\n",
            "Epoch: 1926 Training Error: 105.1915 Validation Error: 105.19922\n",
            "Epoch: 1927 Training Error: 105.191475 Validation Error: 105.19921\n",
            "Epoch: 1928 Training Error: 105.19146 Validation Error: 105.19921\n",
            "Epoch: 1929 Training Error: 105.19145 Validation Error: 105.199196\n",
            "Epoch: 1930 Training Error: 105.19144 Validation Error: 105.199196\n",
            "Epoch: 1931 Training Error: 105.191414 Validation Error: 105.19916\n",
            "Epoch: 1932 Training Error: 105.19139 Validation Error: 105.19911\n",
            "Epoch: 1933 Training Error: 105.191376 Validation Error: 105.19912\n",
            "Epoch: 1934 Training Error: 105.19136 Validation Error: 105.1991\n",
            "Epoch: 1935 Training Error: 105.19132 Validation Error: 105.199036\n",
            "Epoch: 1936 Training Error: 105.191315 Validation Error: 105.19902\n",
            "Epoch: 1937 Training Error: 105.1913 Validation Error: 105.19902\n",
            "Epoch: 1938 Training Error: 105.19129 Validation Error: 105.199036\n",
            "Epoch: 1939 Training Error: 105.19128 Validation Error: 105.19902\n",
            "Epoch: 1940 Training Error: 105.19128 Validation Error: 105.199036\n",
            "Epoch: 1941 Training Error: 105.19128 Validation Error: 105.199036\n",
            "Epoch: 1942 Training Error: 105.19128 Validation Error: 105.19906\n",
            "Epoch: 1943 Training Error: 105.19126 Validation Error: 105.19906\n",
            "Epoch: 1944 Training Error: 105.19125 Validation Error: 105.19904\n",
            "Epoch: 1945 Training Error: 105.191216 Validation Error: 105.198975\n",
            "Epoch: 1946 Training Error: 105.1912 Validation Error: 105.198975\n",
            "Epoch: 1947 Training Error: 105.19118 Validation Error: 105.19888\n",
            "Epoch: 1948 Training Error: 105.191154 Validation Error: 105.198875\n",
            "Epoch: 1949 Training Error: 105.191124 Validation Error: 105.19882\n",
            "Epoch: 1950 Training Error: 105.1911 Validation Error: 105.19877\n",
            "Epoch: 1951 Training Error: 105.191086 Validation Error: 105.19876\n",
            "Epoch: 1952 Training Error: 105.19106 Validation Error: 105.19872\n",
            "Epoch: 1953 Training Error: 105.19104 Validation Error: 105.19866\n",
            "Epoch: 1954 Training Error: 105.19102 Validation Error: 105.1986\n",
            "Epoch: 1955 Training Error: 105.19099 Validation Error: 105.19857\n",
            "Epoch: 1956 Training Error: 105.19096 Validation Error: 105.19853\n",
            "Epoch: 1957 Training Error: 105.19094 Validation Error: 105.19847\n",
            "Epoch: 1958 Training Error: 105.19092 Validation Error: 105.19843\n",
            "Epoch: 1959 Training Error: 105.1909 Validation Error: 105.19843\n",
            "Epoch: 1960 Training Error: 105.19089 Validation Error: 105.1984\n",
            "Epoch: 1961 Training Error: 105.190865 Validation Error: 105.19837\n",
            "Epoch: 1962 Training Error: 105.19085 Validation Error: 105.19835\n",
            "Epoch: 1963 Training Error: 105.19084 Validation Error: 105.19833\n",
            "Epoch: 1964 Training Error: 105.19082 Validation Error: 105.198296\n",
            "Epoch: 1965 Training Error: 105.1908 Validation Error: 105.19825\n",
            "Epoch: 1966 Training Error: 105.19078 Validation Error: 105.19823\n",
            "Epoch: 1967 Training Error: 105.190765 Validation Error: 105.19821\n",
            "Epoch: 1968 Training Error: 105.19074 Validation Error: 105.19817\n",
            "Epoch: 1969 Training Error: 105.19073 Validation Error: 105.19813\n",
            "Epoch: 1970 Training Error: 105.190704 Validation Error: 105.19806\n",
            "Epoch: 1971 Training Error: 105.19069 Validation Error: 105.19803\n",
            "Epoch: 1972 Training Error: 105.19067 Validation Error: 105.19801\n",
            "Epoch: 1973 Training Error: 105.19065 Validation Error: 105.19799\n",
            "Epoch: 1974 Training Error: 105.19064 Validation Error: 105.19794\n",
            "Epoch: 1975 Training Error: 105.19063 Validation Error: 105.19789\n",
            "Epoch: 1976 Training Error: 105.19061 Validation Error: 105.19784\n",
            "Epoch: 1977 Training Error: 105.19061 Validation Error: 105.19779\n",
            "Epoch: 1978 Training Error: 105.19061 Validation Error: 105.197754\n",
            "Epoch: 1979 Training Error: 105.19061 Validation Error: 105.197716\n",
            "Epoch: 1980 Training Error: 105.19059 Validation Error: 105.1977\n",
            "Epoch: 1981 Training Error: 105.19057 Validation Error: 105.19769\n",
            "Epoch: 1982 Training Error: 105.190544 Validation Error: 105.19766\n",
            "Epoch: 1983 Training Error: 105.19053 Validation Error: 105.197655\n",
            "Epoch: 1984 Training Error: 105.19053 Validation Error: 105.19762\n",
            "Epoch: 1985 Training Error: 105.19049 Validation Error: 105.1976\n",
            "Epoch: 1986 Training Error: 105.19048 Validation Error: 105.197586\n",
            "Epoch: 1987 Training Error: 105.19045 Validation Error: 105.19758\n",
            "Epoch: 1988 Training Error: 105.19043 Validation Error: 105.19758\n",
            "Epoch: 1989 Training Error: 105.19041 Validation Error: 105.197556\n",
            "Epoch: 1990 Training Error: 105.19038 Validation Error: 105.197525\n",
            "Epoch: 1991 Training Error: 105.19037 Validation Error: 105.1975\n",
            "Epoch: 1992 Training Error: 105.190346 Validation Error: 105.19749\n",
            "Epoch: 1993 Training Error: 105.190315 Validation Error: 105.19748\n",
            "Epoch: 1994 Training Error: 105.19031 Validation Error: 105.197464\n",
            "Epoch: 1995 Training Error: 105.19028 Validation Error: 105.19748\n",
            "Epoch: 1996 Training Error: 105.19027 Validation Error: 105.19745\n",
            "Epoch: 1997 Training Error: 105.19024 Validation Error: 105.197426\n",
            "Epoch: 1998 Training Error: 105.19023 Validation Error: 105.19742\n",
            "Epoch: 1999 Training Error: 105.19021 Validation Error: 105.19739\n",
            "Epoch: 2000 Training Error: 105.19019 Validation Error: 105.197365\n",
            "Epoch: 2001 Training Error: 105.19017 Validation Error: 105.197365\n",
            "Epoch: 2002 Training Error: 105.190155 Validation Error: 105.19735\n",
            "Epoch: 2003 Training Error: 105.19014 Validation Error: 105.19733\n",
            "Epoch: 2004 Training Error: 105.19012 Validation Error: 105.19729\n",
            "Epoch: 2005 Training Error: 105.19011 Validation Error: 105.19725\n",
            "Epoch: 2006 Training Error: 105.190094 Validation Error: 105.19724\n",
            "Epoch: 2007 Training Error: 105.19007 Validation Error: 105.19719\n",
            "Epoch: 2008 Training Error: 105.190056 Validation Error: 105.19715\n",
            "Epoch: 2009 Training Error: 105.19004 Validation Error: 105.197105\n",
            "Epoch: 2010 Training Error: 105.19003 Validation Error: 105.19707\n",
            "Epoch: 2011 Training Error: 105.19 Validation Error: 105.19705\n",
            "Epoch: 2012 Training Error: 105.189995 Validation Error: 105.19705\n",
            "Epoch: 2013 Training Error: 105.18997 Validation Error: 105.19703\n",
            "Epoch: 2014 Training Error: 105.18994 Validation Error: 105.197014\n",
            "Epoch: 2015 Training Error: 105.18993 Validation Error: 105.19701\n",
            "Epoch: 2016 Training Error: 105.1899 Validation Error: 105.196976\n",
            "Epoch: 2017 Training Error: 105.1899 Validation Error: 105.196976\n",
            "Epoch: 2018 Training Error: 105.18988 Validation Error: 105.19695\n",
            "Epoch: 2019 Training Error: 105.18987 Validation Error: 105.19697\n",
            "Epoch: 2020 Training Error: 105.18986 Validation Error: 105.196976\n",
            "Epoch: 2021 Training Error: 105.18984 Validation Error: 105.196976\n",
            "Epoch: 2022 Training Error: 105.189835 Validation Error: 105.19701\n",
            "Epoch: 2023 Training Error: 105.18982 Validation Error: 105.19695\n",
            "Epoch: 2024 Training Error: 105.189804 Validation Error: 105.19695\n",
            "Epoch: 2025 Training Error: 105.189804 Validation Error: 105.19699\n",
            "Epoch: 2026 Training Error: 105.1898 Validation Error: 105.19699\n",
            "Epoch: 2027 Training Error: 105.18978 Validation Error: 105.19695\n",
            "Epoch: 2028 Training Error: 105.18976 Validation Error: 105.196915\n",
            "Epoch: 2029 Training Error: 105.18974 Validation Error: 105.196915\n",
            "Epoch: 2030 Training Error: 105.18974 Validation Error: 105.196945\n",
            "Epoch: 2031 Training Error: 105.18974 Validation Error: 105.19697\n",
            "Epoch: 2032 Training Error: 105.18974 Validation Error: 105.19697\n",
            "Epoch: 2033 Training Error: 105.18972 Validation Error: 105.19693\n",
            "Epoch: 2034 Training Error: 105.189705 Validation Error: 105.19693\n",
            "Epoch: 2035 Training Error: 105.1897 Validation Error: 105.196915\n",
            "Epoch: 2036 Training Error: 105.18967 Validation Error: 105.19685\n",
            "Epoch: 2037 Training Error: 105.189644 Validation Error: 105.196815\n",
            "Epoch: 2038 Training Error: 105.18962 Validation Error: 105.19677\n",
            "Epoch: 2039 Training Error: 105.1896 Validation Error: 105.19674\n",
            "Epoch: 2040 Training Error: 105.18958 Validation Error: 105.19671\n",
            "Epoch: 2041 Training Error: 105.18958 Validation Error: 105.19673\n",
            "Epoch: 2042 Training Error: 105.18957 Validation Error: 105.19672\n",
            "Epoch: 2043 Training Error: 105.18956 Validation Error: 105.19669\n",
            "Epoch: 2044 Training Error: 105.18953 Validation Error: 105.19668\n",
            "Epoch: 2045 Training Error: 105.18952 Validation Error: 105.19664\n",
            "Epoch: 2046 Training Error: 105.18951 Validation Error: 105.19663\n",
            "Epoch: 2047 Training Error: 105.18948 Validation Error: 105.196556\n",
            "Epoch: 2048 Training Error: 105.189445 Validation Error: 105.196495\n",
            "Epoch: 2049 Training Error: 105.18943 Validation Error: 105.19646\n",
            "Epoch: 2050 Training Error: 105.18941 Validation Error: 105.1964\n",
            "Epoch: 2051 Training Error: 105.189384 Validation Error: 105.19634\n",
            "Epoch: 2052 Training Error: 105.18937 Validation Error: 105.196304\n",
            "Epoch: 2053 Training Error: 105.18935 Validation Error: 105.19624\n",
            "Epoch: 2054 Training Error: 105.18933 Validation Error: 105.19622\n",
            "Epoch: 2055 Training Error: 105.18932 Validation Error: 105.196205\n",
            "Epoch: 2056 Training Error: 105.18931 Validation Error: 105.19618\n",
            "Epoch: 2057 Training Error: 105.18929 Validation Error: 105.19616\n",
            "Epoch: 2058 Training Error: 105.18927 Validation Error: 105.19613\n",
            "Epoch: 2059 Training Error: 105.18926 Validation Error: 105.19612\n",
            "Epoch: 2060 Training Error: 105.18925 Validation Error: 105.1961\n",
            "Epoch: 2061 Training Error: 105.18923 Validation Error: 105.19606\n",
            "Epoch: 2062 Training Error: 105.18921 Validation Error: 105.19606\n",
            "Epoch: 2063 Training Error: 105.18919 Validation Error: 105.19606\n",
            "Epoch: 2064 Training Error: 105.18917 Validation Error: 105.196045\n",
            "Epoch: 2065 Training Error: 105.18916 Validation Error: 105.19602\n",
            "Epoch: 2066 Training Error: 105.18915 Validation Error: 105.195984\n",
            "Epoch: 2067 Training Error: 105.189125 Validation Error: 105.19593\n",
            "Epoch: 2068 Training Error: 105.18911 Validation Error: 105.19592\n",
            "Epoch: 2069 Training Error: 105.189095 Validation Error: 105.19592\n",
            "Epoch: 2070 Training Error: 105.18909 Validation Error: 105.19591\n",
            "Epoch: 2071 Training Error: 105.18907 Validation Error: 105.19591\n",
            "Epoch: 2072 Training Error: 105.18906 Validation Error: 105.195885\n",
            "Epoch: 2073 Training Error: 105.18903 Validation Error: 105.19586\n",
            "Epoch: 2074 Training Error: 105.18903 Validation Error: 105.19587\n",
            "Epoch: 2075 Training Error: 105.189026 Validation Error: 105.19586\n",
            "Epoch: 2076 Training Error: 105.18901 Validation Error: 105.19586\n",
            "Epoch: 2077 Training Error: 105.18899 Validation Error: 105.19585\n",
            "Epoch: 2078 Training Error: 105.18897 Validation Error: 105.19583\n",
            "Epoch: 2079 Training Error: 105.18897 Validation Error: 105.19582\n",
            "Epoch: 2080 Training Error: 105.18896 Validation Error: 105.19579\n",
            "Epoch: 2081 Training Error: 105.18895 Validation Error: 105.19577\n",
            "Epoch: 2082 Training Error: 105.188934 Validation Error: 105.195786\n",
            "Epoch: 2083 Training Error: 105.18892 Validation Error: 105.19577\n",
            "Epoch: 2084 Training Error: 105.18892 Validation Error: 105.195786\n",
            "Epoch: 2085 Training Error: 105.18891 Validation Error: 105.19579\n",
            "Epoch: 2086 Training Error: 105.18891 Validation Error: 105.19581\n",
            "Epoch: 2087 Training Error: 105.18889 Validation Error: 105.19577\n",
            "Epoch: 2088 Training Error: 105.18886 Validation Error: 105.19573\n",
            "Epoch: 2089 Training Error: 105.188835 Validation Error: 105.19567\n",
            "Epoch: 2090 Training Error: 105.18881 Validation Error: 105.19561\n",
            "Epoch: 2091 Training Error: 105.1888 Validation Error: 105.195595\n",
            "Epoch: 2092 Training Error: 105.18879 Validation Error: 105.19559\n",
            "Epoch: 2093 Training Error: 105.188774 Validation Error: 105.19553\n",
            "Epoch: 2094 Training Error: 105.18875 Validation Error: 105.195526\n",
            "Epoch: 2095 Training Error: 105.18875 Validation Error: 105.195526\n",
            "Epoch: 2096 Training Error: 105.18872 Validation Error: 105.19549\n",
            "Epoch: 2097 Training Error: 105.18871 Validation Error: 105.19545\n",
            "Epoch: 2098 Training Error: 105.18868 Validation Error: 105.19539\n",
            "Epoch: 2099 Training Error: 105.188675 Validation Error: 105.19532\n",
            "Epoch: 2100 Training Error: 105.188675 Validation Error: 105.19529\n",
            "Epoch: 2101 Training Error: 105.18866 Validation Error: 105.19526\n",
            "Epoch: 2102 Training Error: 105.18865 Validation Error: 105.19524\n",
            "Epoch: 2103 Training Error: 105.18864 Validation Error: 105.19521\n",
            "Epoch: 2104 Training Error: 105.18862 Validation Error: 105.1952\n",
            "Epoch: 2105 Training Error: 105.1886 Validation Error: 105.1952\n",
            "Epoch: 2106 Training Error: 105.188576 Validation Error: 105.19518\n",
            "Epoch: 2107 Training Error: 105.18856 Validation Error: 105.1952\n",
            "Epoch: 2108 Training Error: 105.18855 Validation Error: 105.1952\n",
            "Epoch: 2109 Training Error: 105.18854 Validation Error: 105.19516\n",
            "Epoch: 2110 Training Error: 105.18852 Validation Error: 105.19512\n",
            "Epoch: 2111 Training Error: 105.188515 Validation Error: 105.1951\n",
            "Epoch: 2112 Training Error: 105.1885 Validation Error: 105.195076\n",
            "Epoch: 2113 Training Error: 105.188484 Validation Error: 105.19502\n",
            "Epoch: 2114 Training Error: 105.18848 Validation Error: 105.195015\n",
            "Epoch: 2115 Training Error: 105.18846 Validation Error: 105.19498\n",
            "Epoch: 2116 Training Error: 105.18848 Validation Error: 105.19494\n",
            "Epoch: 2117 Training Error: 105.188446 Validation Error: 105.19492\n",
            "Epoch: 2118 Training Error: 105.18844 Validation Error: 105.194916\n",
            "Epoch: 2119 Training Error: 105.18842 Validation Error: 105.194885\n",
            "Epoch: 2120 Training Error: 105.188416 Validation Error: 105.19486\n",
            "Epoch: 2121 Training Error: 105.188385 Validation Error: 105.19486\n",
            "Epoch: 2122 Training Error: 105.188385 Validation Error: 105.19484\n",
            "Epoch: 2123 Training Error: 105.18838 Validation Error: 105.194824\n",
            "Epoch: 2124 Training Error: 105.18835 Validation Error: 105.19481\n",
            "Epoch: 2125 Training Error: 105.188324 Validation Error: 105.19481\n",
            "Epoch: 2126 Training Error: 105.18832 Validation Error: 105.194786\n",
            "Epoch: 2127 Training Error: 105.188286 Validation Error: 105.19478\n",
            "Epoch: 2128 Training Error: 105.18828 Validation Error: 105.19476\n",
            "Epoch: 2129 Training Error: 105.18825 Validation Error: 105.194786\n",
            "Epoch: 2130 Training Error: 105.188225 Validation Error: 105.19478\n",
            "Epoch: 2131 Training Error: 105.18821 Validation Error: 105.19475\n",
            "Epoch: 2132 Training Error: 105.18821 Validation Error: 105.19471\n",
            "Epoch: 2133 Training Error: 105.1882 Validation Error: 105.1947\n",
            "Epoch: 2134 Training Error: 105.18819 Validation Error: 105.194664\n",
            "Epoch: 2135 Training Error: 105.18818 Validation Error: 105.19464\n",
            "Epoch: 2136 Training Error: 105.18819 Validation Error: 105.1946\n",
            "Epoch: 2137 Training Error: 105.18818 Validation Error: 105.19457\n",
            "Epoch: 2138 Training Error: 105.18816 Validation Error: 105.194565\n",
            "Epoch: 2139 Training Error: 105.18814 Validation Error: 105.194565\n",
            "Epoch: 2140 Training Error: 105.188126 Validation Error: 105.19455\n",
            "Epoch: 2141 Training Error: 105.188126 Validation Error: 105.19453\n",
            "Epoch: 2142 Training Error: 105.18811 Validation Error: 105.19451\n",
            "Epoch: 2143 Training Error: 105.18809 Validation Error: 105.1945\n",
            "Epoch: 2144 Training Error: 105.18808 Validation Error: 105.19447\n",
            "Epoch: 2145 Training Error: 105.188065 Validation Error: 105.19447\n",
            "Epoch: 2146 Training Error: 105.18804 Validation Error: 105.194466\n",
            "Epoch: 2147 Training Error: 105.18804 Validation Error: 105.19444\n",
            "Epoch: 2148 Training Error: 105.18801 Validation Error: 105.19443\n",
            "Epoch: 2149 Training Error: 105.188 Validation Error: 105.194405\n",
            "Epoch: 2150 Training Error: 105.18799 Validation Error: 105.194405\n",
            "Epoch: 2151 Training Error: 105.187965 Validation Error: 105.19439\n",
            "Epoch: 2152 Training Error: 105.187965 Validation Error: 105.194374\n",
            "Epoch: 2153 Training Error: 105.18794 Validation Error: 105.194374\n",
            "Epoch: 2154 Training Error: 105.18793 Validation Error: 105.194374\n",
            "Epoch: 2155 Training Error: 105.18791 Validation Error: 105.194374\n",
            "Epoch: 2156 Training Error: 105.18789 Validation Error: 105.19439\n",
            "Epoch: 2157 Training Error: 105.18789 Validation Error: 105.194374\n",
            "Epoch: 2158 Training Error: 105.18787 Validation Error: 105.19435\n",
            "Epoch: 2159 Training Error: 105.18787 Validation Error: 105.19433\n",
            "Epoch: 2160 Training Error: 105.187836 Validation Error: 105.19429\n",
            "Epoch: 2161 Training Error: 105.18783 Validation Error: 105.194305\n",
            "Epoch: 2162 Training Error: 105.18781 Validation Error: 105.194275\n",
            "Epoch: 2163 Training Error: 105.187805 Validation Error: 105.19425\n",
            "Epoch: 2164 Training Error: 105.18779 Validation Error: 105.19424\n",
            "Epoch: 2165 Training Error: 105.187775 Validation Error: 105.194214\n",
            "Epoch: 2166 Training Error: 105.18777 Validation Error: 105.194176\n",
            "Epoch: 2167 Training Error: 105.18775 Validation Error: 105.19415\n",
            "Epoch: 2168 Training Error: 105.18774 Validation Error: 105.19413\n",
            "Epoch: 2169 Training Error: 105.18774 Validation Error: 105.1941\n",
            "Epoch: 2170 Training Error: 105.18773 Validation Error: 105.19409\n",
            "Epoch: 2171 Training Error: 105.187706 Validation Error: 105.19409\n",
            "Epoch: 2172 Training Error: 105.18769 Validation Error: 105.19408\n",
            "Epoch: 2173 Training Error: 105.18767 Validation Error: 105.19405\n",
            "Epoch: 2174 Training Error: 105.18767 Validation Error: 105.194016\n",
            "Epoch: 2175 Training Error: 105.18765 Validation Error: 105.19399\n",
            "Epoch: 2176 Training Error: 105.18763 Validation Error: 105.19396\n",
            "Epoch: 2177 Training Error: 105.187614 Validation Error: 105.193954\n",
            "Epoch: 2178 Training Error: 105.1876 Validation Error: 105.19392\n",
            "Epoch: 2179 Training Error: 105.18759 Validation Error: 105.19389\n",
            "Epoch: 2180 Training Error: 105.18758 Validation Error: 105.19388\n",
            "Epoch: 2181 Training Error: 105.18757 Validation Error: 105.19386\n",
            "Epoch: 2182 Training Error: 105.18755 Validation Error: 105.193855\n",
            "Epoch: 2183 Training Error: 105.18755 Validation Error: 105.19383\n",
            "Epoch: 2184 Training Error: 105.18753 Validation Error: 105.19383\n",
            "Epoch: 2185 Training Error: 105.187515 Validation Error: 105.19383\n",
            "Epoch: 2186 Training Error: 105.1875 Validation Error: 105.19383\n",
            "Epoch: 2187 Training Error: 105.18749 Validation Error: 105.193794\n",
            "Epoch: 2188 Training Error: 105.18747 Validation Error: 105.19376\n",
            "Epoch: 2189 Training Error: 105.18747 Validation Error: 105.193726\n",
            "Epoch: 2190 Training Error: 105.18744 Validation Error: 105.19372\n",
            "Epoch: 2191 Training Error: 105.18743 Validation Error: 105.193695\n",
            "Epoch: 2192 Training Error: 105.187416 Validation Error: 105.19366\n",
            "Epoch: 2193 Training Error: 105.1874 Validation Error: 105.19366\n",
            "Epoch: 2194 Training Error: 105.18739 Validation Error: 105.19364\n",
            "Epoch: 2195 Training Error: 105.18738 Validation Error: 105.19362\n",
            "Epoch: 2196 Training Error: 105.18736 Validation Error: 105.19362\n",
            "Epoch: 2197 Training Error: 105.187355 Validation Error: 105.1936\n",
            "Epoch: 2198 Training Error: 105.18734 Validation Error: 105.193596\n",
            "Epoch: 2199 Training Error: 105.18733 Validation Error: 105.1936\n",
            "Epoch: 2200 Training Error: 105.18732 Validation Error: 105.193596\n",
            "Epoch: 2201 Training Error: 105.1873 Validation Error: 105.193565\n",
            "Epoch: 2202 Training Error: 105.187294 Validation Error: 105.19356\n",
            "Epoch: 2203 Training Error: 105.18726 Validation Error: 105.193504\n",
            "Epoch: 2204 Training Error: 105.187256 Validation Error: 105.193504\n",
            "Epoch: 2205 Training Error: 105.187256 Validation Error: 105.19352\n",
            "Epoch: 2206 Training Error: 105.18723 Validation Error: 105.19347\n",
            "Epoch: 2207 Training Error: 105.18722 Validation Error: 105.19343\n",
            "Epoch: 2208 Training Error: 105.18722 Validation Error: 105.193405\n",
            "Epoch: 2209 Training Error: 105.1872 Validation Error: 105.19336\n",
            "Epoch: 2210 Training Error: 105.187195 Validation Error: 105.193344\n",
            "Epoch: 2211 Training Error: 105.18718 Validation Error: 105.19332\n",
            "Epoch: 2212 Training Error: 105.187164 Validation Error: 105.19329\n",
            "Epoch: 2213 Training Error: 105.18716 Validation Error: 105.19328\n",
            "Epoch: 2214 Training Error: 105.18714 Validation Error: 105.19325\n",
            "Epoch: 2215 Training Error: 105.187126 Validation Error: 105.193245\n",
            "Epoch: 2216 Training Error: 105.18712 Validation Error: 105.193245\n",
            "Epoch: 2217 Training Error: 105.1871 Validation Error: 105.19322\n",
            "Epoch: 2218 Training Error: 105.187096 Validation Error: 105.19319\n",
            "Epoch: 2219 Training Error: 105.18708 Validation Error: 105.19317\n",
            "Epoch: 2220 Training Error: 105.18708 Validation Error: 105.193146\n",
            "Epoch: 2221 Training Error: 105.18706 Validation Error: 105.19313\n",
            "Epoch: 2222 Training Error: 105.18704 Validation Error: 105.19312\n",
            "Epoch: 2223 Training Error: 105.18702 Validation Error: 105.19312\n",
            "Epoch: 2224 Training Error: 105.187004 Validation Error: 105.19311\n",
            "Epoch: 2225 Training Error: 105.187004 Validation Error: 105.193085\n",
            "Epoch: 2226 Training Error: 105.187 Validation Error: 105.19307\n",
            "Epoch: 2227 Training Error: 105.18698 Validation Error: 105.19305\n",
            "Epoch: 2228 Training Error: 105.18698 Validation Error: 105.193016\n",
            "Epoch: 2229 Training Error: 105.186966 Validation Error: 105.19299\n",
            "Epoch: 2230 Training Error: 105.18694 Validation Error: 105.19299\n",
            "Epoch: 2231 Training Error: 105.18694 Validation Error: 105.19297\n",
            "Epoch: 2232 Training Error: 105.18693 Validation Error: 105.19297\n",
            "Epoch: 2233 Training Error: 105.18693 Validation Error: 105.192955\n",
            "Epoch: 2234 Training Error: 105.18692 Validation Error: 105.19295\n",
            "Epoch: 2235 Training Error: 105.18692 Validation Error: 105.19292\n",
            "Epoch: 2236 Training Error: 105.18692 Validation Error: 105.192894\n",
            "Epoch: 2237 Training Error: 105.186905 Validation Error: 105.19287\n",
            "Epoch: 2238 Training Error: 105.18689 Validation Error: 105.19285\n",
            "Epoch: 2239 Training Error: 105.18689 Validation Error: 105.19283\n",
            "Epoch: 2240 Training Error: 105.18688 Validation Error: 105.19282\n",
            "Epoch: 2241 Training Error: 105.18686 Validation Error: 105.19281\n",
            "Epoch: 2242 Training Error: 105.186844 Validation Error: 105.192795\n",
            "Epoch: 2243 Training Error: 105.18683 Validation Error: 105.19277\n",
            "Epoch: 2244 Training Error: 105.18683 Validation Error: 105.19276\n",
            "Epoch: 2245 Training Error: 105.18682 Validation Error: 105.19275\n",
            "Epoch: 2246 Training Error: 105.186806 Validation Error: 105.19273\n",
            "Epoch: 2247 Training Error: 105.18679 Validation Error: 105.19271\n",
            "Epoch: 2248 Training Error: 105.18678 Validation Error: 105.192696\n",
            "Epoch: 2249 Training Error: 105.18678 Validation Error: 105.19267\n",
            "Epoch: 2250 Training Error: 105.18677 Validation Error: 105.19266\n",
            "Epoch: 2251 Training Error: 105.18677 Validation Error: 105.19264\n",
            "Epoch: 2252 Training Error: 105.18676 Validation Error: 105.192635\n",
            "Epoch: 2253 Training Error: 105.186745 Validation Error: 105.19262\n",
            "Epoch: 2254 Training Error: 105.18671 Validation Error: 105.19261\n",
            "Epoch: 2255 Training Error: 105.18669 Validation Error: 105.1926\n",
            "Epoch: 2256 Training Error: 105.18667 Validation Error: 105.19258\n",
            "Epoch: 2257 Training Error: 105.18665 Validation Error: 105.19257\n",
            "Epoch: 2258 Training Error: 105.18665 Validation Error: 105.19256\n",
            "Epoch: 2259 Training Error: 105.186646 Validation Error: 105.19254\n",
            "Epoch: 2260 Training Error: 105.18663 Validation Error: 105.19252\n",
            "Epoch: 2261 Training Error: 105.18663 Validation Error: 105.19251\n",
            "Epoch: 2262 Training Error: 105.18665 Validation Error: 105.1925\n",
            "Epoch: 2263 Training Error: 105.186646 Validation Error: 105.192474\n",
            "Epoch: 2264 Training Error: 105.18665 Validation Error: 105.19246\n",
            "Epoch: 2265 Training Error: 105.18663 Validation Error: 105.19246\n",
            "Epoch: 2266 Training Error: 105.18662 Validation Error: 105.19244\n",
            "Epoch: 2267 Training Error: 105.186584 Validation Error: 105.19242\n",
            "Epoch: 2268 Training Error: 105.186554 Validation Error: 105.192406\n",
            "Epoch: 2269 Training Error: 105.18655 Validation Error: 105.1924\n",
            "Epoch: 2270 Training Error: 105.18651 Validation Error: 105.192375\n",
            "Epoch: 2271 Training Error: 105.18647 Validation Error: 105.192375\n",
            "Epoch: 2272 Training Error: 105.18645 Validation Error: 105.192375\n",
            "Epoch: 2273 Training Error: 105.18642 Validation Error: 105.19236\n",
            "Epoch: 2274 Training Error: 105.18641 Validation Error: 105.192345\n",
            "Epoch: 2275 Training Error: 105.186386 Validation Error: 105.192345\n",
            "Epoch: 2276 Training Error: 105.18637 Validation Error: 105.19234\n",
            "Epoch: 2277 Training Error: 105.18637 Validation Error: 105.19232\n",
            "Epoch: 2278 Training Error: 105.186356 Validation Error: 105.19231\n",
            "Epoch: 2279 Training Error: 105.18635 Validation Error: 105.19228\n",
            "Epoch: 2280 Training Error: 105.18633 Validation Error: 105.192276\n",
            "Epoch: 2281 Training Error: 105.18632 Validation Error: 105.192276\n",
            "Epoch: 2282 Training Error: 105.18631 Validation Error: 105.192245\n",
            "Epoch: 2283 Training Error: 105.186295 Validation Error: 105.19226\n",
            "Epoch: 2284 Training Error: 105.18628 Validation Error: 105.19226\n",
            "Epoch: 2285 Training Error: 105.18627 Validation Error: 105.19226\n",
            "Epoch: 2286 Training Error: 105.18626 Validation Error: 105.192245\n",
            "Epoch: 2287 Training Error: 105.18625 Validation Error: 105.19221\n",
            "Epoch: 2288 Training Error: 105.18623 Validation Error: 105.192184\n",
            "Epoch: 2289 Training Error: 105.18622 Validation Error: 105.19216\n",
            "Epoch: 2290 Training Error: 105.18622 Validation Error: 105.19214\n",
            "Epoch: 2291 Training Error: 105.18621 Validation Error: 105.19211\n",
            "Epoch: 2292 Training Error: 105.186195 Validation Error: 105.192085\n",
            "Epoch: 2293 Training Error: 105.18618 Validation Error: 105.19207\n",
            "Epoch: 2294 Training Error: 105.18617 Validation Error: 105.19205\n",
            "Epoch: 2295 Training Error: 105.18615 Validation Error: 105.19206\n",
            "Epoch: 2296 Training Error: 105.18612 Validation Error: 105.19205\n",
            "Epoch: 2297 Training Error: 105.18612 Validation Error: 105.19201\n",
            "Epoch: 2298 Training Error: 105.18611 Validation Error: 105.19201\n",
            "Epoch: 2299 Training Error: 105.18608 Validation Error: 105.191986\n",
            "Epoch: 2300 Training Error: 105.18608 Validation Error: 105.19197\n",
            "Epoch: 2301 Training Error: 105.18606 Validation Error: 105.19196\n",
            "Epoch: 2302 Training Error: 105.18604 Validation Error: 105.19196\n",
            "Epoch: 2303 Training Error: 105.186035 Validation Error: 105.19196\n",
            "Epoch: 2304 Training Error: 105.18602 Validation Error: 105.19196\n",
            "Epoch: 2305 Training Error: 105.18601 Validation Error: 105.19196\n",
            "Epoch: 2306 Training Error: 105.186 Validation Error: 105.19195\n",
            "Epoch: 2307 Training Error: 105.18598 Validation Error: 105.19195\n",
            "Epoch: 2308 Training Error: 105.18598 Validation Error: 105.19195\n",
            "Epoch: 2309 Training Error: 105.18596 Validation Error: 105.191925\n",
            "Epoch: 2310 Training Error: 105.18594 Validation Error: 105.1919\n",
            "Epoch: 2311 Training Error: 105.18594 Validation Error: 105.19191\n",
            "Epoch: 2312 Training Error: 105.185936 Validation Error: 105.19189\n",
            "Epoch: 2313 Training Error: 105.18592 Validation Error: 105.191864\n",
            "Epoch: 2314 Training Error: 105.18591 Validation Error: 105.19185\n",
            "Epoch: 2315 Training Error: 105.1859 Validation Error: 105.191864\n",
            "Epoch: 2316 Training Error: 105.18588 Validation Error: 105.19185\n",
            "Epoch: 2317 Training Error: 105.18588 Validation Error: 105.191864\n",
            "Epoch: 2318 Training Error: 105.18588 Validation Error: 105.19189\n",
            "Epoch: 2319 Training Error: 105.18588 Validation Error: 105.19191\n",
            "Epoch: 2320 Training Error: 105.18588 Validation Error: 105.19195\n",
            "Epoch: 2321 Training Error: 105.18588 Validation Error: 105.19193\n",
            "Epoch: 2322 Training Error: 105.18588 Validation Error: 105.19195\n",
            "Epoch: 2323 Training Error: 105.18588 Validation Error: 105.19197\n",
            "Epoch: 2324 Training Error: 105.18588 Validation Error: 105.19196\n",
            "Epoch: 2325 Training Error: 105.18586 Validation Error: 105.191925\n",
            "Epoch: 2326 Training Error: 105.185844 Validation Error: 105.19193\n",
            "Epoch: 2327 Training Error: 105.18584 Validation Error: 105.1919\n",
            "Epoch: 2328 Training Error: 105.18584 Validation Error: 105.1919\n",
            "Epoch: 2329 Training Error: 105.18584 Validation Error: 105.191925\n",
            "Epoch: 2330 Training Error: 105.18581 Validation Error: 105.19187\n",
            "Epoch: 2331 Training Error: 105.18578 Validation Error: 105.19183\n",
            "Epoch: 2332 Training Error: 105.1858 Validation Error: 105.19187\n",
            "Epoch: 2333 Training Error: 105.18578 Validation Error: 105.191864\n",
            "Epoch: 2334 Training Error: 105.185776 Validation Error: 105.19183\n",
            "Epoch: 2335 Training Error: 105.18576 Validation Error: 105.191826\n",
            "Epoch: 2336 Training Error: 105.18576 Validation Error: 105.191826\n",
            "Epoch: 2337 Training Error: 105.185745 Validation Error: 105.1918\n",
            "Epoch: 2338 Training Error: 105.18572 Validation Error: 105.19177\n",
            "Epoch: 2339 Training Error: 105.18571 Validation Error: 105.191734\n",
            "Epoch: 2340 Training Error: 105.1857 Validation Error: 105.191734\n",
            "Epoch: 2341 Training Error: 105.18568 Validation Error: 105.191696\n",
            "Epoch: 2342 Training Error: 105.18568 Validation Error: 105.19169\n",
            "Epoch: 2343 Training Error: 105.18566 Validation Error: 105.191666\n",
            "Epoch: 2344 Training Error: 105.185646 Validation Error: 105.191635\n",
            "Epoch: 2345 Training Error: 105.18562 Validation Error: 105.1916\n",
            "Epoch: 2346 Training Error: 105.18562 Validation Error: 105.19163\n",
            "Epoch: 2347 Training Error: 105.18561 Validation Error: 105.19161\n",
            "Epoch: 2348 Training Error: 105.1856 Validation Error: 105.19159\n",
            "Epoch: 2349 Training Error: 105.18557 Validation Error: 105.191536\n",
            "Epoch: 2350 Training Error: 105.18557 Validation Error: 105.19155\n",
            "Epoch: 2351 Training Error: 105.18557 Validation Error: 105.19157\n",
            "Epoch: 2352 Training Error: 105.18557 Validation Error: 105.191574\n",
            "Epoch: 2353 Training Error: 105.185585 Validation Error: 105.19159\n",
            "Epoch: 2354 Training Error: 105.18557 Validation Error: 105.19157\n",
            "Epoch: 2355 Training Error: 105.18557 Validation Error: 105.1916\n",
            "Epoch: 2356 Training Error: 105.18557 Validation Error: 105.1916\n",
            "Epoch: 2357 Training Error: 105.18556 Validation Error: 105.1916\n",
            "Epoch: 2358 Training Error: 105.18557 Validation Error: 105.19161\n",
            "Epoch: 2359 Training Error: 105.18562 Validation Error: 105.191696\n",
            "Epoch: 2360 Training Error: 105.18568 Validation Error: 105.1918\n",
            "Epoch: 2361 Training Error: 105.1857 Validation Error: 105.19183\n",
            "Epoch: 2362 Training Error: 105.18564 Validation Error: 105.19175\n",
            "Epoch: 2363 Training Error: 105.18561 Validation Error: 105.191696\n",
            "Epoch: 2364 Training Error: 105.18557 Validation Error: 105.19165\n",
            "Epoch: 2365 Training Error: 105.18555 Validation Error: 105.1916\n",
            "Epoch: 2366 Training Error: 105.18554 Validation Error: 105.191574\n",
            "Epoch: 2367 Training Error: 105.18551 Validation Error: 105.19157\n",
            "Epoch: 2368 Training Error: 105.185486 Validation Error: 105.19151\n",
            "Epoch: 2369 Training Error: 105.18547 Validation Error: 105.19149\n",
            "Epoch: 2370 Training Error: 105.185486 Validation Error: 105.19151\n",
            "Epoch: 2371 Training Error: 105.18547 Validation Error: 105.19149\n",
            "Epoch: 2372 Training Error: 105.18545 Validation Error: 105.19146\n",
            "Epoch: 2373 Training Error: 105.18543 Validation Error: 105.19145\n",
            "Epoch: 2374 Training Error: 105.185425 Validation Error: 105.19143\n",
            "Epoch: 2375 Training Error: 105.18541 Validation Error: 105.19139\n",
            "Epoch: 2376 Training Error: 105.18539 Validation Error: 105.19136\n",
            "Epoch: 2377 Training Error: 105.18535 Validation Error: 105.1913\n",
            "Epoch: 2378 Training Error: 105.185326 Validation Error: 105.19122\n",
            "Epoch: 2379 Training Error: 105.18529 Validation Error: 105.19119\n",
            "Epoch: 2380 Training Error: 105.185265 Validation Error: 105.191154\n",
            "Epoch: 2381 Training Error: 105.185234 Validation Error: 105.19108\n",
            "Epoch: 2382 Training Error: 105.18521 Validation Error: 105.191025\n",
            "Epoch: 2383 Training Error: 105.185196 Validation Error: 105.19099\n",
            "Epoch: 2384 Training Error: 105.18519 Validation Error: 105.19096\n",
            "Epoch: 2385 Training Error: 105.18517 Validation Error: 105.190956\n",
            "Epoch: 2386 Training Error: 105.185165 Validation Error: 105.190926\n",
            "Epoch: 2387 Training Error: 105.18515 Validation Error: 105.19092\n",
            "Epoch: 2388 Training Error: 105.185135 Validation Error: 105.19094\n",
            "Epoch: 2389 Training Error: 105.185135 Validation Error: 105.19094\n",
            "Epoch: 2390 Training Error: 105.18513 Validation Error: 105.19094\n",
            "Epoch: 2391 Training Error: 105.18513 Validation Error: 105.190926\n",
            "Epoch: 2392 Training Error: 105.18511 Validation Error: 105.19092\n",
            "Epoch: 2393 Training Error: 105.18511 Validation Error: 105.190926\n",
            "Epoch: 2394 Training Error: 105.18509 Validation Error: 105.190865\n",
            "Epoch: 2395 Training Error: 105.185074 Validation Error: 105.19085\n",
            "Epoch: 2396 Training Error: 105.18507 Validation Error: 105.19085\n",
            "Epoch: 2397 Training Error: 105.18507 Validation Error: 105.190865\n",
            "Epoch: 2398 Training Error: 105.18505 Validation Error: 105.19083\n",
            "Epoch: 2399 Training Error: 105.185036 Validation Error: 105.19082\n",
            "Epoch: 2400 Training Error: 105.18503 Validation Error: 105.1908\n",
            "Epoch: 2401 Training Error: 105.18501 Validation Error: 105.19078\n",
            "Epoch: 2402 Training Error: 105.185 Validation Error: 105.19074\n",
            "Epoch: 2403 Training Error: 105.18499 Validation Error: 105.19072\n",
            "Epoch: 2404 Training Error: 105.18499 Validation Error: 105.190704\n",
            "Epoch: 2405 Training Error: 105.18499 Validation Error: 105.19073\n",
            "Epoch: 2406 Training Error: 105.18499 Validation Error: 105.19073\n",
            "Epoch: 2407 Training Error: 105.184975 Validation Error: 105.190704\n",
            "Epoch: 2408 Training Error: 105.18496 Validation Error: 105.190704\n",
            "Epoch: 2409 Training Error: 105.18496 Validation Error: 105.19073\n",
            "Epoch: 2410 Training Error: 105.18496 Validation Error: 105.19073\n",
            "Epoch: 2411 Training Error: 105.18495 Validation Error: 105.19073\n",
            "Epoch: 2412 Training Error: 105.18495 Validation Error: 105.190704\n",
            "Epoch: 2413 Training Error: 105.18493 Validation Error: 105.19069\n",
            "Epoch: 2414 Training Error: 105.18491 Validation Error: 105.19067\n",
            "Epoch: 2415 Training Error: 105.1849 Validation Error: 105.19064\n",
            "Epoch: 2416 Training Error: 105.1849 Validation Error: 105.19064\n",
            "Epoch: 2417 Training Error: 105.18489 Validation Error: 105.19063\n",
            "Epoch: 2418 Training Error: 105.184875 Validation Error: 105.190605\n",
            "Epoch: 2419 Training Error: 105.184875 Validation Error: 105.190605\n",
            "Epoch: 2420 Training Error: 105.18486 Validation Error: 105.190605\n",
            "Epoch: 2421 Training Error: 105.18486 Validation Error: 105.19059\n",
            "Epoch: 2422 Training Error: 105.18485 Validation Error: 105.19059\n",
            "Epoch: 2423 Training Error: 105.18485 Validation Error: 105.19059\n",
            "Epoch: 2424 Training Error: 105.18485 Validation Error: 105.19059\n",
            "Epoch: 2425 Training Error: 105.18483 Validation Error: 105.19058\n",
            "Epoch: 2426 Training Error: 105.18483 Validation Error: 105.19059\n",
            "Epoch: 2427 Training Error: 105.18483 Validation Error: 105.190605\n",
            "Epoch: 2428 Training Error: 105.18483 Validation Error: 105.19063\n",
            "Epoch: 2429 Training Error: 105.18483 Validation Error: 105.19061\n",
            "Epoch: 2430 Training Error: 105.184814 Validation Error: 105.19061\n",
            "Epoch: 2431 Training Error: 105.18483 Validation Error: 105.19064\n",
            "Epoch: 2432 Training Error: 105.18483 Validation Error: 105.19064\n",
            "Epoch: 2433 Training Error: 105.18484 Validation Error: 105.19068\n",
            "Epoch: 2434 Training Error: 105.18486 Validation Error: 105.19073\n",
            "Epoch: 2435 Training Error: 105.18485 Validation Error: 105.19072\n",
            "Epoch: 2436 Training Error: 105.184814 Validation Error: 105.19065\n",
            "Epoch: 2437 Training Error: 105.18479 Validation Error: 105.19059\n",
            "Epoch: 2438 Training Error: 105.18478 Validation Error: 105.19059\n",
            "Epoch: 2439 Training Error: 105.18476 Validation Error: 105.19057\n",
            "Epoch: 2440 Training Error: 105.184715 Validation Error: 105.19047\n",
            "Epoch: 2441 Training Error: 105.18468 Validation Error: 105.19041\n",
            "Epoch: 2442 Training Error: 105.18466 Validation Error: 105.19038\n",
            "Epoch: 2443 Training Error: 105.18466 Validation Error: 105.19037\n",
            "Epoch: 2444 Training Error: 105.184654 Validation Error: 105.19037\n",
            "Epoch: 2445 Training Error: 105.18464 Validation Error: 105.190346\n",
            "Epoch: 2446 Training Error: 105.184616 Validation Error: 105.190315\n",
            "Epoch: 2447 Training Error: 105.184616 Validation Error: 105.19029\n",
            "Epoch: 2448 Training Error: 105.18459 Validation Error: 105.190254\n",
            "Epoch: 2449 Training Error: 105.18459 Validation Error: 105.190254\n",
            "Epoch: 2450 Training Error: 105.18458 Validation Error: 105.19024\n",
            "Epoch: 2451 Training Error: 105.18456 Validation Error: 105.19024\n",
            "Epoch: 2452 Training Error: 105.184555 Validation Error: 105.190216\n",
            "Epoch: 2453 Training Error: 105.184525 Validation Error: 105.19017\n",
            "Epoch: 2454 Training Error: 105.184525 Validation Error: 105.19017\n",
            "Epoch: 2455 Training Error: 105.1845 Validation Error: 105.19013\n",
            "Epoch: 2456 Training Error: 105.18449 Validation Error: 105.190094\n",
            "Epoch: 2457 Training Error: 105.18449 Validation Error: 105.19011\n",
            "Epoch: 2458 Training Error: 105.18448 Validation Error: 105.19008\n",
            "Epoch: 2459 Training Error: 105.18446 Validation Error: 105.19003\n",
            "Epoch: 2460 Training Error: 105.18444 Validation Error: 105.19\n",
            "Epoch: 2461 Training Error: 105.18444 Validation Error: 105.189995\n",
            "Epoch: 2462 Training Error: 105.184425 Validation Error: 105.18997\n",
            "Epoch: 2463 Training Error: 105.18442 Validation Error: 105.18996\n",
            "Epoch: 2464 Training Error: 105.1844 Validation Error: 105.18992\n",
            "Epoch: 2465 Training Error: 105.1844 Validation Error: 105.18993\n",
            "Epoch: 2466 Training Error: 105.18439 Validation Error: 105.18993\n",
            "Epoch: 2467 Training Error: 105.18438 Validation Error: 105.1899\n",
            "Epoch: 2468 Training Error: 105.184364 Validation Error: 105.1899\n",
            "Epoch: 2469 Training Error: 105.18436 Validation Error: 105.18987\n",
            "Epoch: 2470 Training Error: 105.18436 Validation Error: 105.18987\n",
            "Epoch: 2471 Training Error: 105.18434 Validation Error: 105.18986\n",
            "Epoch: 2472 Training Error: 105.18434 Validation Error: 105.18984\n",
            "Epoch: 2473 Training Error: 105.184326 Validation Error: 105.18984\n",
            "Epoch: 2474 Training Error: 105.184326 Validation Error: 105.18984\n",
            "Epoch: 2475 Training Error: 105.18432 Validation Error: 105.18984\n",
            "Epoch: 2476 Training Error: 105.1843 Validation Error: 105.18984\n",
            "Epoch: 2477 Training Error: 105.18429 Validation Error: 105.189804\n",
            "Epoch: 2478 Training Error: 105.18428 Validation Error: 105.1898\n",
            "Epoch: 2479 Training Error: 105.18428 Validation Error: 105.18974\n",
            "Epoch: 2480 Training Error: 105.18425 Validation Error: 105.189735\n",
            "Epoch: 2481 Training Error: 105.18425 Validation Error: 105.18974\n",
            "Epoch: 2482 Training Error: 105.18424 Validation Error: 105.18974\n",
            "Epoch: 2483 Training Error: 105.18424 Validation Error: 105.18974\n",
            "Epoch: 2484 Training Error: 105.18423 Validation Error: 105.18972\n",
            "Epoch: 2485 Training Error: 105.18423 Validation Error: 105.18972\n",
            "Epoch: 2486 Training Error: 105.18422 Validation Error: 105.18972\n",
            "Epoch: 2487 Training Error: 105.184204 Validation Error: 105.189705\n",
            "Epoch: 2488 Training Error: 105.184204 Validation Error: 105.18972\n",
            "Epoch: 2489 Training Error: 105.184204 Validation Error: 105.189705\n",
            "Epoch: 2490 Training Error: 105.18419 Validation Error: 105.189735\n",
            "Epoch: 2491 Training Error: 105.18419 Validation Error: 105.18972\n",
            "Epoch: 2492 Training Error: 105.18418 Validation Error: 105.1897\n",
            "Epoch: 2493 Training Error: 105.18418 Validation Error: 105.189705\n",
            "Epoch: 2494 Training Error: 105.18415 Validation Error: 105.1897\n",
            "Epoch: 2495 Training Error: 105.18414 Validation Error: 105.18966\n",
            "Epoch: 2496 Training Error: 105.18414 Validation Error: 105.18966\n",
            "Epoch: 2497 Training Error: 105.18414 Validation Error: 105.18968\n",
            "Epoch: 2498 Training Error: 105.18413 Validation Error: 105.189644\n",
            "Epoch: 2499 Training Error: 105.18411 Validation Error: 105.18964\n",
            "Epoch: 2500 Training Error: 105.184105 Validation Error: 105.18964\n",
            "Epoch: 2501 Training Error: 105.184105 Validation Error: 105.18964\n",
            "Epoch: 2502 Training Error: 105.184105 Validation Error: 105.189606\n",
            "Epoch: 2503 Training Error: 105.18409 Validation Error: 105.1896\n",
            "Epoch: 2504 Training Error: 105.18407 Validation Error: 105.18956\n",
            "Epoch: 2505 Training Error: 105.18405 Validation Error: 105.18953\n",
            "Epoch: 2506 Training Error: 105.184044 Validation Error: 105.1895\n",
            "Epoch: 2507 Training Error: 105.18403 Validation Error: 105.18947\n",
            "Epoch: 2508 Training Error: 105.18401 Validation Error: 105.189445\n",
            "Epoch: 2509 Training Error: 105.184006 Validation Error: 105.18942\n",
            "Epoch: 2510 Training Error: 105.18399 Validation Error: 105.189384\n",
            "Epoch: 2511 Training Error: 105.18399 Validation Error: 105.18937\n",
            "Epoch: 2512 Training Error: 105.18397 Validation Error: 105.18936\n",
            "Epoch: 2513 Training Error: 105.18397 Validation Error: 105.18937\n",
            "Epoch: 2514 Training Error: 105.18395 Validation Error: 105.18937\n",
            "Epoch: 2515 Training Error: 105.18395 Validation Error: 105.18937\n",
            "Epoch: 2516 Training Error: 105.18393 Validation Error: 105.18933\n",
            "Epoch: 2517 Training Error: 105.18393 Validation Error: 105.18932\n",
            "Epoch: 2518 Training Error: 105.183914 Validation Error: 105.18933\n",
            "Epoch: 2519 Training Error: 105.183914 Validation Error: 105.18933\n",
            "Epoch: 2520 Training Error: 105.18391 Validation Error: 105.18931\n",
            "Epoch: 2521 Training Error: 105.18389 Validation Error: 105.189285\n",
            "Epoch: 2522 Training Error: 105.183876 Validation Error: 105.18926\n",
            "Epoch: 2523 Training Error: 105.183876 Validation Error: 105.18926\n",
            "Epoch: 2524 Training Error: 105.18387 Validation Error: 105.18925\n",
            "Epoch: 2525 Training Error: 105.18387 Validation Error: 105.18923\n",
            "Epoch: 2526 Training Error: 105.18387 Validation Error: 105.18926\n",
            "Epoch: 2527 Training Error: 105.18385 Validation Error: 105.18925\n",
            "Epoch: 2528 Training Error: 105.183846 Validation Error: 105.18923\n",
            "Epoch: 2529 Training Error: 105.18383 Validation Error: 105.18919\n",
            "Epoch: 2530 Training Error: 105.183815 Validation Error: 105.18917\n",
            "Epoch: 2531 Training Error: 105.183815 Validation Error: 105.18915\n",
            "Epoch: 2532 Training Error: 105.18381 Validation Error: 105.18915\n",
            "Epoch: 2533 Training Error: 105.18381 Validation Error: 105.18915\n",
            "Epoch: 2534 Training Error: 105.18378 Validation Error: 105.189125\n",
            "Epoch: 2535 Training Error: 105.18378 Validation Error: 105.18913\n",
            "Epoch: 2536 Training Error: 105.18377 Validation Error: 105.189125\n",
            "Epoch: 2537 Training Error: 105.18377 Validation Error: 105.18913\n",
            "Epoch: 2538 Training Error: 105.183754 Validation Error: 105.18911\n",
            "Epoch: 2539 Training Error: 105.18375 Validation Error: 105.189095\n",
            "Epoch: 2540 Training Error: 105.18373 Validation Error: 105.18909\n",
            "Epoch: 2541 Training Error: 105.183716 Validation Error: 105.18905\n",
            "Epoch: 2542 Training Error: 105.18371 Validation Error: 105.18903\n",
            "Epoch: 2543 Training Error: 105.18369 Validation Error: 105.18899\n",
            "Epoch: 2544 Training Error: 105.18369 Validation Error: 105.18899\n",
            "Epoch: 2545 Training Error: 105.18368 Validation Error: 105.18896\n",
            "Epoch: 2546 Training Error: 105.18367 Validation Error: 105.18896\n",
            "Epoch: 2547 Training Error: 105.18367 Validation Error: 105.188934\n",
            "Epoch: 2548 Training Error: 105.183655 Validation Error: 105.188934\n",
            "Epoch: 2549 Training Error: 105.183655 Validation Error: 105.18891\n",
            "Epoch: 2550 Training Error: 105.18364 Validation Error: 105.18891\n",
            "Epoch: 2551 Training Error: 105.18364 Validation Error: 105.18891\n",
            "Epoch: 2552 Training Error: 105.18363 Validation Error: 105.18887\n",
            "Epoch: 2553 Training Error: 105.18362 Validation Error: 105.18887\n",
            "Epoch: 2554 Training Error: 105.18362 Validation Error: 105.18887\n",
            "Epoch: 2555 Training Error: 105.18361 Validation Error: 105.18886\n",
            "Epoch: 2556 Training Error: 105.18359 Validation Error: 105.188835\n",
            "Epoch: 2557 Training Error: 105.18359 Validation Error: 105.18882\n",
            "Epoch: 2558 Training Error: 105.18358 Validation Error: 105.188835\n",
            "Epoch: 2559 Training Error: 105.18357 Validation Error: 105.188835\n",
            "Epoch: 2560 Training Error: 105.18357 Validation Error: 105.18881\n",
            "Epoch: 2561 Training Error: 105.183556 Validation Error: 105.1888\n",
            "Epoch: 2562 Training Error: 105.18354 Validation Error: 105.188774\n",
            "Epoch: 2563 Training Error: 105.18354 Validation Error: 105.18875\n",
            "Epoch: 2564 Training Error: 105.18353 Validation Error: 105.188736\n",
            "Epoch: 2565 Training Error: 105.18352 Validation Error: 105.18872\n",
            "Epoch: 2566 Training Error: 105.18352 Validation Error: 105.1887\n",
            "Epoch: 2567 Training Error: 105.18351 Validation Error: 105.18868\n",
            "Epoch: 2568 Training Error: 105.18351 Validation Error: 105.188675\n",
            "Epoch: 2569 Training Error: 105.18351 Validation Error: 105.18865\n",
            "Epoch: 2570 Training Error: 105.18351 Validation Error: 105.18862\n",
            "Epoch: 2571 Training Error: 105.183495 Validation Error: 105.18862\n",
            "Epoch: 2572 Training Error: 105.183495 Validation Error: 105.188614\n",
            "Epoch: 2573 Training Error: 105.18347 Validation Error: 105.188614\n",
            "Epoch: 2574 Training Error: 105.18347 Validation Error: 105.188614\n",
            "Epoch: 2575 Training Error: 105.18346 Validation Error: 105.188614\n",
            "Epoch: 2576 Training Error: 105.18344 Validation Error: 105.1886\n",
            "Epoch: 2577 Training Error: 105.18343 Validation Error: 105.188614\n",
            "Epoch: 2578 Training Error: 105.18342 Validation Error: 105.1886\n",
            "Epoch: 2579 Training Error: 105.18342 Validation Error: 105.188576\n",
            "Epoch: 2580 Training Error: 105.1834 Validation Error: 105.188576\n",
            "Epoch: 2581 Training Error: 105.1834 Validation Error: 105.18855\n",
            "Epoch: 2582 Training Error: 105.183395 Validation Error: 105.18854\n",
            "Epoch: 2583 Training Error: 105.1834 Validation Error: 105.188515\n",
            "Epoch: 2584 Training Error: 105.1834 Validation Error: 105.1885\n",
            "Epoch: 2585 Training Error: 105.183395 Validation Error: 105.188484\n",
            "Epoch: 2586 Training Error: 105.18338 Validation Error: 105.18848\n",
            "Epoch: 2587 Training Error: 105.18337 Validation Error: 105.18848\n",
            "Epoch: 2588 Training Error: 105.18336 Validation Error: 105.18846\n",
            "Epoch: 2589 Training Error: 105.18334 Validation Error: 105.188446\n",
            "Epoch: 2590 Training Error: 105.183334 Validation Error: 105.188446\n",
            "Epoch: 2591 Training Error: 105.18332 Validation Error: 105.18846\n",
            "Epoch: 2592 Training Error: 105.183304 Validation Error: 105.18846\n",
            "Epoch: 2593 Training Error: 105.1833 Validation Error: 105.188446\n",
            "Epoch: 2594 Training Error: 105.1833 Validation Error: 105.18844\n",
            "Epoch: 2595 Training Error: 105.18328 Validation Error: 105.18842\n",
            "Epoch: 2596 Training Error: 105.18327 Validation Error: 105.188416\n",
            "Epoch: 2597 Training Error: 105.18326 Validation Error: 105.1884\n",
            "Epoch: 2598 Training Error: 105.18326 Validation Error: 105.188385\n",
            "Epoch: 2599 Training Error: 105.18324 Validation Error: 105.18836\n",
            "Epoch: 2600 Training Error: 105.18324 Validation Error: 105.18836\n",
            "Epoch: 2601 Training Error: 105.183235 Validation Error: 105.18835\n",
            "Epoch: 2602 Training Error: 105.18322 Validation Error: 105.18834\n",
            "Epoch: 2603 Training Error: 105.18322 Validation Error: 105.18834\n",
            "Epoch: 2604 Training Error: 105.183205 Validation Error: 105.188324\n",
            "Epoch: 2605 Training Error: 105.183205 Validation Error: 105.18832\n",
            "Epoch: 2606 Training Error: 105.183205 Validation Error: 105.18834\n",
            "Epoch: 2607 Training Error: 105.1832 Validation Error: 105.188324\n",
            "Epoch: 2608 Training Error: 105.18318 Validation Error: 105.18832\n",
            "Epoch: 2609 Training Error: 105.18318 Validation Error: 105.18832\n",
            "Epoch: 2610 Training Error: 105.18317 Validation Error: 105.188286\n",
            "Epoch: 2611 Training Error: 105.18316 Validation Error: 105.18826\n",
            "Epoch: 2612 Training Error: 105.18316 Validation Error: 105.18824\n",
            "Epoch: 2613 Training Error: 105.18314 Validation Error: 105.18821\n",
            "Epoch: 2614 Training Error: 105.18316 Validation Error: 105.18819\n",
            "Epoch: 2615 Training Error: 105.18314 Validation Error: 105.18819\n",
            "Epoch: 2616 Training Error: 105.183136 Validation Error: 105.18819\n",
            "Epoch: 2617 Training Error: 105.18312 Validation Error: 105.18816\n",
            "Epoch: 2618 Training Error: 105.18312 Validation Error: 105.18816\n",
            "Epoch: 2619 Training Error: 105.183105 Validation Error: 105.18815\n",
            "Epoch: 2620 Training Error: 105.1831 Validation Error: 105.18815\n",
            "Epoch: 2621 Training Error: 105.1831 Validation Error: 105.18816\n",
            "Epoch: 2622 Training Error: 105.18308 Validation Error: 105.18814\n",
            "Epoch: 2623 Training Error: 105.18307 Validation Error: 105.18814\n",
            "Epoch: 2624 Training Error: 105.18307 Validation Error: 105.188126\n",
            "Epoch: 2625 Training Error: 105.18306 Validation Error: 105.188126\n",
            "Epoch: 2626 Training Error: 105.18306 Validation Error: 105.1881\n",
            "Epoch: 2627 Training Error: 105.183044 Validation Error: 105.18809\n",
            "Epoch: 2628 Training Error: 105.18303 Validation Error: 105.18809\n",
            "Epoch: 2629 Training Error: 105.18303 Validation Error: 105.188065\n",
            "Epoch: 2630 Training Error: 105.18302 Validation Error: 105.188065\n",
            "Epoch: 2631 Training Error: 105.18301 Validation Error: 105.188065\n",
            "Epoch: 2632 Training Error: 105.183 Validation Error: 105.18805\n",
            "Epoch: 2633 Training Error: 105.183 Validation Error: 105.18805\n",
            "Epoch: 2634 Training Error: 105.18298 Validation Error: 105.18804\n",
            "Epoch: 2635 Training Error: 105.18298 Validation Error: 105.18804\n",
            "Epoch: 2636 Training Error: 105.18297 Validation Error: 105.188\n",
            "Epoch: 2637 Training Error: 105.18297 Validation Error: 105.18797\n",
            "Epoch: 2638 Training Error: 105.18297 Validation Error: 105.187965\n",
            "Epoch: 2639 Training Error: 105.18296 Validation Error: 105.18795\n",
            "Epoch: 2640 Training Error: 105.182945 Validation Error: 105.18795\n",
            "Epoch: 2641 Training Error: 105.182945 Validation Error: 105.18793\n",
            "Epoch: 2642 Training Error: 105.18293 Validation Error: 105.18791\n",
            "Epoch: 2643 Training Error: 105.18293 Validation Error: 105.187904\n",
            "Epoch: 2644 Training Error: 105.18292 Validation Error: 105.18789\n",
            "Epoch: 2645 Training Error: 105.18291 Validation Error: 105.18789\n",
            "Epoch: 2646 Training Error: 105.18291 Validation Error: 105.187874\n",
            "Epoch: 2647 Training Error: 105.1829 Validation Error: 105.18787\n",
            "Epoch: 2648 Training Error: 105.1829 Validation Error: 105.187836\n",
            "Epoch: 2649 Training Error: 105.1829 Validation Error: 105.18783\n",
            "Epoch: 2650 Training Error: 105.1829 Validation Error: 105.18781\n",
            "Epoch: 2651 Training Error: 105.18287 Validation Error: 105.18781\n",
            "Epoch: 2652 Training Error: 105.18286 Validation Error: 105.18781\n",
            "Epoch: 2653 Training Error: 105.18286 Validation Error: 105.18779\n",
            "Epoch: 2654 Training Error: 105.18286 Validation Error: 105.18777\n",
            "Epoch: 2655 Training Error: 105.18286 Validation Error: 105.18774\n",
            "Epoch: 2656 Training Error: 105.18286 Validation Error: 105.18773\n",
            "Epoch: 2657 Training Error: 105.18283 Validation Error: 105.18773\n",
            "Epoch: 2658 Training Error: 105.18281 Validation Error: 105.18774\n",
            "Epoch: 2659 Training Error: 105.182785 Validation Error: 105.18774\n",
            "Epoch: 2660 Training Error: 105.182785 Validation Error: 105.18774\n",
            "Epoch: 2661 Training Error: 105.18277 Validation Error: 105.18771\n",
            "Epoch: 2662 Training Error: 105.18277 Validation Error: 105.18771\n",
            "Epoch: 2663 Training Error: 105.18277 Validation Error: 105.18771\n",
            "Epoch: 2664 Training Error: 105.18276 Validation Error: 105.18769\n",
            "Epoch: 2665 Training Error: 105.18276 Validation Error: 105.187675\n",
            "Epoch: 2666 Training Error: 105.18277 Validation Error: 105.18767\n",
            "Epoch: 2667 Training Error: 105.18276 Validation Error: 105.18765\n",
            "Epoch: 2668 Training Error: 105.18275 Validation Error: 105.18764\n",
            "Epoch: 2669 Training Error: 105.18275 Validation Error: 105.18763\n",
            "Epoch: 2670 Training Error: 105.18273 Validation Error: 105.18763\n",
            "Epoch: 2671 Training Error: 105.18273 Validation Error: 105.187614\n",
            "Epoch: 2672 Training Error: 105.182724 Validation Error: 105.1876\n",
            "Epoch: 2673 Training Error: 105.182724 Validation Error: 105.18759\n",
            "Epoch: 2674 Training Error: 105.182724 Validation Error: 105.18758\n",
            "Epoch: 2675 Training Error: 105.18271 Validation Error: 105.18758\n",
            "Epoch: 2676 Training Error: 105.18269 Validation Error: 105.18757\n",
            "Epoch: 2677 Training Error: 105.18269 Validation Error: 105.18755\n",
            "Epoch: 2678 Training Error: 105.18269 Validation Error: 105.18754\n",
            "Epoch: 2679 Training Error: 105.18269 Validation Error: 105.18753\n",
            "Epoch: 2680 Training Error: 105.18269 Validation Error: 105.18753\n",
            "Epoch: 2681 Training Error: 105.18267 Validation Error: 105.18753\n",
            "Epoch: 2682 Training Error: 105.182686 Validation Error: 105.187515\n",
            "Epoch: 2683 Training Error: 105.18267 Validation Error: 105.1875\n",
            "Epoch: 2684 Training Error: 105.18267 Validation Error: 105.18749\n",
            "Epoch: 2685 Training Error: 105.18267 Validation Error: 105.18748\n",
            "Epoch: 2686 Training Error: 105.18267 Validation Error: 105.18748\n",
            "Epoch: 2687 Training Error: 105.18265 Validation Error: 105.18747\n",
            "Epoch: 2688 Training Error: 105.18263 Validation Error: 105.187454\n",
            "Epoch: 2689 Training Error: 105.182625 Validation Error: 105.187454\n",
            "Epoch: 2690 Training Error: 105.182594 Validation Error: 105.187454\n",
            "Epoch: 2691 Training Error: 105.182594 Validation Error: 105.187454\n",
            "Epoch: 2692 Training Error: 105.18259 Validation Error: 105.18744\n",
            "Epoch: 2693 Training Error: 105.18259 Validation Error: 105.18743\n",
            "Epoch: 2694 Training Error: 105.18257 Validation Error: 105.187416\n",
            "Epoch: 2695 Training Error: 105.182556 Validation Error: 105.187416\n",
            "Epoch: 2696 Training Error: 105.18255 Validation Error: 105.187416\n",
            "Epoch: 2697 Training Error: 105.18253 Validation Error: 105.187416\n",
            "Epoch: 2698 Training Error: 105.18253 Validation Error: 105.18739\n",
            "Epoch: 2699 Training Error: 105.18253 Validation Error: 105.18738\n",
            "Epoch: 2700 Training Error: 105.18253 Validation Error: 105.187355\n",
            "Epoch: 2701 Training Error: 105.182526 Validation Error: 105.187355\n",
            "Epoch: 2702 Training Error: 105.18251 Validation Error: 105.18734\n",
            "Epoch: 2703 Training Error: 105.18251 Validation Error: 105.18734\n",
            "Epoch: 2704 Training Error: 105.182495 Validation Error: 105.18733\n",
            "Epoch: 2705 Training Error: 105.18249 Validation Error: 105.18733\n",
            "Epoch: 2706 Training Error: 105.18249 Validation Error: 105.18732\n",
            "Epoch: 2707 Training Error: 105.18247 Validation Error: 105.1873\n",
            "Epoch: 2708 Training Error: 105.18246 Validation Error: 105.1873\n",
            "Epoch: 2709 Training Error: 105.18246 Validation Error: 105.18728\n",
            "Epoch: 2710 Training Error: 105.18246 Validation Error: 105.18726\n",
            "Epoch: 2711 Training Error: 105.18245 Validation Error: 105.18726\n",
            "Epoch: 2712 Training Error: 105.18245 Validation Error: 105.187256\n",
            "Epoch: 2713 Training Error: 105.182434 Validation Error: 105.18724\n",
            "Epoch: 2714 Training Error: 105.18243 Validation Error: 105.18724\n",
            "Epoch: 2715 Training Error: 105.18241 Validation Error: 105.18724\n",
            "Epoch: 2716 Training Error: 105.182396 Validation Error: 105.18723\n",
            "Epoch: 2717 Training Error: 105.18239 Validation Error: 105.18723\n",
            "Epoch: 2718 Training Error: 105.18237 Validation Error: 105.18723\n",
            "Epoch: 2719 Training Error: 105.18237 Validation Error: 105.1872\n",
            "Epoch: 2720 Training Error: 105.18236 Validation Error: 105.187195\n",
            "Epoch: 2721 Training Error: 105.18236 Validation Error: 105.187164\n",
            "Epoch: 2722 Training Error: 105.18235 Validation Error: 105.18718\n",
            "Epoch: 2723 Training Error: 105.182335 Validation Error: 105.1872\n",
            "Epoch: 2724 Training Error: 105.182335 Validation Error: 105.18722\n",
            "Epoch: 2725 Training Error: 105.18232 Validation Error: 105.1872\n",
            "Epoch: 2726 Training Error: 105.18231 Validation Error: 105.187195\n",
            "Epoch: 2727 Training Error: 105.18231 Validation Error: 105.187164\n",
            "Epoch: 2728 Training Error: 105.18231 Validation Error: 105.18716\n",
            "Epoch: 2729 Training Error: 105.18231 Validation Error: 105.187126\n",
            "Epoch: 2730 Training Error: 105.18231 Validation Error: 105.1871\n",
            "Epoch: 2731 Training Error: 105.18231 Validation Error: 105.18708\n",
            "Epoch: 2732 Training Error: 105.1823 Validation Error: 105.187096\n",
            "Epoch: 2733 Training Error: 105.18229 Validation Error: 105.18708\n",
            "Epoch: 2734 Training Error: 105.182274 Validation Error: 105.187065\n",
            "Epoch: 2735 Training Error: 105.18226 Validation Error: 105.187065\n",
            "Epoch: 2736 Training Error: 105.18225 Validation Error: 105.187065\n",
            "Epoch: 2737 Training Error: 105.18225 Validation Error: 105.18706\n",
            "Epoch: 2738 Training Error: 105.182236 Validation Error: 105.18706\n",
            "Epoch: 2739 Training Error: 105.182236 Validation Error: 105.18704\n",
            "Epoch: 2740 Training Error: 105.18222 Validation Error: 105.187065\n",
            "Epoch: 2741 Training Error: 105.18222 Validation Error: 105.187065\n",
            "Epoch: 2742 Training Error: 105.18222 Validation Error: 105.1871\n",
            "Epoch: 2743 Training Error: 105.18221 Validation Error: 105.18712\n",
            "Epoch: 2744 Training Error: 105.18221 Validation Error: 105.18712\n",
            "Epoch: 2745 Training Error: 105.1822 Validation Error: 105.187096\n",
            "Epoch: 2746 Training Error: 105.1822 Validation Error: 105.187096\n",
            "Epoch: 2747 Training Error: 105.18219 Validation Error: 105.187065\n",
            "Epoch: 2748 Training Error: 105.18219 Validation Error: 105.18708\n",
            "Epoch: 2749 Training Error: 105.182175 Validation Error: 105.187065\n",
            "Epoch: 2750 Training Error: 105.18216 Validation Error: 105.18704\n",
            "Epoch: 2751 Training Error: 105.18216 Validation Error: 105.18704\n",
            "Epoch: 2752 Training Error: 105.18215 Validation Error: 105.187004\n",
            "Epoch: 2753 Training Error: 105.18215 Validation Error: 105.187004\n",
            "Epoch: 2754 Training Error: 105.18214 Validation Error: 105.18698\n",
            "Epoch: 2755 Training Error: 105.18212 Validation Error: 105.186966\n",
            "Epoch: 2756 Training Error: 105.18212 Validation Error: 105.18696\n",
            "Epoch: 2757 Training Error: 105.18211 Validation Error: 105.18696\n",
            "Epoch: 2758 Training Error: 105.18211 Validation Error: 105.18693\n",
            "Epoch: 2759 Training Error: 105.1821 Validation Error: 105.18689\n",
            "Epoch: 2760 Training Error: 105.18208 Validation Error: 105.18688\n",
            "Epoch: 2761 Training Error: 105.18208 Validation Error: 105.18687\n",
            "Epoch: 2762 Training Error: 105.18208 Validation Error: 105.186844\n",
            "Epoch: 2763 Training Error: 105.182076 Validation Error: 105.18683\n",
            "Epoch: 2764 Training Error: 105.18206 Validation Error: 105.18683\n",
            "Epoch: 2765 Training Error: 105.18206 Validation Error: 105.186806\n",
            "Epoch: 2766 Training Error: 105.18206 Validation Error: 105.18679\n",
            "Epoch: 2767 Training Error: 105.18205 Validation Error: 105.18678\n",
            "Epoch: 2768 Training Error: 105.18205 Validation Error: 105.18677\n",
            "Epoch: 2769 Training Error: 105.18204 Validation Error: 105.18677\n",
            "Epoch: 2770 Training Error: 105.18204 Validation Error: 105.18676\n",
            "Epoch: 2771 Training Error: 105.18202 Validation Error: 105.18677\n",
            "Epoch: 2772 Training Error: 105.18202 Validation Error: 105.18676\n",
            "Epoch: 2773 Training Error: 105.182014 Validation Error: 105.18678\n",
            "Epoch: 2774 Training Error: 105.182014 Validation Error: 105.18677\n",
            "Epoch: 2775 Training Error: 105.182014 Validation Error: 105.18676\n",
            "Epoch: 2776 Training Error: 105.182 Validation Error: 105.18676\n",
            "Epoch: 2777 Training Error: 105.181984 Validation Error: 105.186745\n",
            "Epoch: 2778 Training Error: 105.181984 Validation Error: 105.18676\n",
            "Epoch: 2779 Training Error: 105.18198 Validation Error: 105.18676\n",
            "Epoch: 2780 Training Error: 105.18198 Validation Error: 105.18673\n",
            "Epoch: 2781 Training Error: 105.18196 Validation Error: 105.18672\n",
            "Epoch: 2782 Training Error: 105.18196 Validation Error: 105.18671\n",
            "Epoch: 2783 Training Error: 105.18196 Validation Error: 105.18668\n",
            "Epoch: 2784 Training Error: 105.18195 Validation Error: 105.18668\n",
            "Epoch: 2785 Training Error: 105.18195 Validation Error: 105.18665\n",
            "Epoch: 2786 Training Error: 105.18195 Validation Error: 105.18665\n",
            "Epoch: 2787 Training Error: 105.18194 Validation Error: 105.186646\n",
            "Epoch: 2788 Training Error: 105.18194 Validation Error: 105.18663\n",
            "Epoch: 2789 Training Error: 105.18194 Validation Error: 105.18661\n",
            "Epoch: 2790 Training Error: 105.18194 Validation Error: 105.18659\n",
            "Epoch: 2791 Training Error: 105.18192 Validation Error: 105.18661\n",
            "Epoch: 2792 Training Error: 105.18192 Validation Error: 105.18659\n",
            "Epoch: 2793 Training Error: 105.181915 Validation Error: 105.186584\n",
            "Epoch: 2794 Training Error: 105.1819 Validation Error: 105.186584\n",
            "Epoch: 2795 Training Error: 105.181885 Validation Error: 105.186584\n",
            "Epoch: 2796 Training Error: 105.18188 Validation Error: 105.18657\n",
            "Epoch: 2797 Training Error: 105.18188 Validation Error: 105.18657\n",
            "Epoch: 2798 Training Error: 105.18186 Validation Error: 105.186554\n",
            "Epoch: 2799 Training Error: 105.18186 Validation Error: 105.18655\n",
            "Epoch: 2800 Training Error: 105.18186 Validation Error: 105.18651\n",
            "Epoch: 2801 Training Error: 105.18185 Validation Error: 105.18649\n",
            "Epoch: 2802 Training Error: 105.18185 Validation Error: 105.186485\n",
            "Epoch: 2803 Training Error: 105.18185 Validation Error: 105.18647\n",
            "Epoch: 2804 Training Error: 105.18184 Validation Error: 105.186455\n",
            "Epoch: 2805 Training Error: 105.18184 Validation Error: 105.18645\n",
            "Epoch: 2806 Training Error: 105.18184 Validation Error: 105.18643\n",
            "Epoch: 2807 Training Error: 105.18184 Validation Error: 105.18642\n",
            "Epoch: 2808 Training Error: 105.18182 Validation Error: 105.18642\n",
            "Epoch: 2809 Training Error: 105.181816 Validation Error: 105.18641\n",
            "Epoch: 2810 Training Error: 105.181816 Validation Error: 105.18639\n",
            "Epoch: 2811 Training Error: 105.1818 Validation Error: 105.18639\n",
            "Epoch: 2812 Training Error: 105.181786 Validation Error: 105.186386\n",
            "Epoch: 2813 Training Error: 105.181786 Validation Error: 105.18637\n",
            "Epoch: 2814 Training Error: 105.181786 Validation Error: 105.186356\n",
            "Epoch: 2815 Training Error: 105.18178 Validation Error: 105.186356\n",
            "Epoch: 2816 Training Error: 105.181786 Validation Error: 105.18635\n",
            "Epoch: 2817 Training Error: 105.181786 Validation Error: 105.18633\n",
            "Epoch: 2818 Training Error: 105.18178 Validation Error: 105.18633\n",
            "Epoch: 2819 Training Error: 105.18176 Validation Error: 105.18632\n",
            "Epoch: 2820 Training Error: 105.18175 Validation Error: 105.18631\n",
            "Epoch: 2821 Training Error: 105.18175 Validation Error: 105.18631\n",
            "Epoch: 2822 Training Error: 105.18174 Validation Error: 105.186295\n",
            "Epoch: 2823 Training Error: 105.181725 Validation Error: 105.186295\n",
            "Epoch: 2824 Training Error: 105.18171 Validation Error: 105.186295\n",
            "Epoch: 2825 Training Error: 105.1817 Validation Error: 105.186295\n",
            "Epoch: 2826 Training Error: 105.18169 Validation Error: 105.18628\n",
            "Epoch: 2827 Training Error: 105.18169 Validation Error: 105.18627\n",
            "Epoch: 2828 Training Error: 105.18168 Validation Error: 105.18627\n",
            "Epoch: 2829 Training Error: 105.18168 Validation Error: 105.18626\n",
            "Epoch: 2830 Training Error: 105.18166 Validation Error: 105.18625\n",
            "Epoch: 2831 Training Error: 105.18165 Validation Error: 105.18625\n",
            "Epoch: 2832 Training Error: 105.18165 Validation Error: 105.18623\n",
            "Epoch: 2833 Training Error: 105.18164 Validation Error: 105.18625\n",
            "Epoch: 2834 Training Error: 105.181625 Validation Error: 105.18625\n",
            "Epoch: 2835 Training Error: 105.18161 Validation Error: 105.18627\n",
            "Epoch: 2836 Training Error: 105.18161 Validation Error: 105.18626\n",
            "Epoch: 2837 Training Error: 105.1816 Validation Error: 105.18625\n",
            "Epoch: 2838 Training Error: 105.1816 Validation Error: 105.18625\n",
            "Epoch: 2839 Training Error: 105.18159 Validation Error: 105.18626\n",
            "Epoch: 2840 Training Error: 105.18159 Validation Error: 105.18626\n",
            "Epoch: 2841 Training Error: 105.18158 Validation Error: 105.18623\n",
            "Epoch: 2842 Training Error: 105.18159 Validation Error: 105.18627\n",
            "Epoch: 2843 Training Error: 105.18158 Validation Error: 105.18628\n",
            "Epoch: 2844 Training Error: 105.18158 Validation Error: 105.18626\n",
            "Epoch: 2845 Training Error: 105.181564 Validation Error: 105.18625\n",
            "Epoch: 2846 Training Error: 105.181564 Validation Error: 105.18627\n",
            "Epoch: 2847 Training Error: 105.18158 Validation Error: 105.186295\n",
            "Epoch: 2848 Training Error: 105.181564 Validation Error: 105.18628\n",
            "Epoch: 2849 Training Error: 105.181564 Validation Error: 105.18631\n",
            "Epoch: 2850 Training Error: 105.181564 Validation Error: 105.186295\n",
            "Epoch: 2851 Training Error: 105.181564 Validation Error: 105.186295\n",
            "Epoch: 2852 Training Error: 105.181564 Validation Error: 105.18632\n",
            "Epoch: 2853 Training Error: 105.18155 Validation Error: 105.18628\n",
            "Epoch: 2854 Training Error: 105.18154 Validation Error: 105.18625\n",
            "Epoch: 2855 Training Error: 105.18151 Validation Error: 105.18622\n",
            "Epoch: 2856 Training Error: 105.18151 Validation Error: 105.18622\n",
            "Epoch: 2857 Training Error: 105.18151 Validation Error: 105.18621\n",
            "Epoch: 2858 Training Error: 105.18151 Validation Error: 105.18621\n",
            "Epoch: 2859 Training Error: 105.1815 Validation Error: 105.18621\n",
            "Epoch: 2860 Training Error: 105.18149 Validation Error: 105.18618\n",
            "Epoch: 2861 Training Error: 105.18149 Validation Error: 105.18618\n",
            "Epoch: 2862 Training Error: 105.18147 Validation Error: 105.18616\n",
            "Epoch: 2863 Training Error: 105.18149 Validation Error: 105.18618\n",
            "Epoch: 2864 Training Error: 105.18149 Validation Error: 105.18618\n",
            "Epoch: 2865 Training Error: 105.1815 Validation Error: 105.18622\n",
            "Epoch: 2866 Training Error: 105.18151 Validation Error: 105.18626\n",
            "Epoch: 2867 Training Error: 105.18151 Validation Error: 105.18627\n",
            "Epoch: 2868 Training Error: 105.18154 Validation Error: 105.18631\n",
            "Epoch: 2869 Training Error: 105.18154 Validation Error: 105.18631\n",
            "Epoch: 2870 Training Error: 105.181526 Validation Error: 105.186295\n",
            "Epoch: 2871 Training Error: 105.18154 Validation Error: 105.18632\n",
            "Epoch: 2872 Training Error: 105.18154 Validation Error: 105.18632\n",
            "Epoch: 2873 Training Error: 105.18155 Validation Error: 105.18635\n",
            "Epoch: 2874 Training Error: 105.18154 Validation Error: 105.18633\n",
            "Epoch: 2875 Training Error: 105.18154 Validation Error: 105.18635\n",
            "Epoch: 2876 Training Error: 105.18154 Validation Error: 105.18633\n",
            "Epoch: 2877 Training Error: 105.18151 Validation Error: 105.18631\n",
            "Epoch: 2878 Training Error: 105.18151 Validation Error: 105.18628\n",
            "Epoch: 2879 Training Error: 105.18151 Validation Error: 105.18631\n",
            "Epoch: 2880 Training Error: 105.18151 Validation Error: 105.18631\n",
            "Epoch: 2881 Training Error: 105.18149 Validation Error: 105.18626\n",
            "Epoch: 2882 Training Error: 105.181465 Validation Error: 105.18621\n",
            "Epoch: 2883 Training Error: 105.18144 Validation Error: 105.18617\n",
            "Epoch: 2884 Training Error: 105.18145 Validation Error: 105.186195\n",
            "Epoch: 2885 Training Error: 105.18145 Validation Error: 105.18621\n",
            "Epoch: 2886 Training Error: 105.18145 Validation Error: 105.186195\n",
            "Epoch: 2887 Training Error: 105.18144 Validation Error: 105.18617\n",
            "Epoch: 2888 Training Error: 105.18144 Validation Error: 105.18618\n",
            "Epoch: 2889 Training Error: 105.18143 Validation Error: 105.18617\n",
            "Epoch: 2890 Training Error: 105.181404 Validation Error: 105.18612\n",
            "Epoch: 2891 Training Error: 105.18141 Validation Error: 105.186134\n",
            "Epoch: 2892 Training Error: 105.18141 Validation Error: 105.18616\n",
            "Epoch: 2893 Training Error: 105.181404 Validation Error: 105.186134\n",
            "Epoch: 2894 Training Error: 105.18139 Validation Error: 105.1861\n",
            "Epoch: 2895 Training Error: 105.18137 Validation Error: 105.18608\n",
            "Epoch: 2896 Training Error: 105.181366 Validation Error: 105.18607\n",
            "Epoch: 2897 Training Error: 105.18137 Validation Error: 105.1861\n",
            "Epoch: 2898 Training Error: 105.181404 Validation Error: 105.186134\n",
            "Epoch: 2899 Training Error: 105.181404 Validation Error: 105.18615\n",
            "Epoch: 2900 Training Error: 105.18141 Validation Error: 105.18616\n",
            "Epoch: 2901 Training Error: 105.181404 Validation Error: 105.18615\n",
            "Epoch: 2902 Training Error: 105.181404 Validation Error: 105.18615\n",
            "Epoch: 2903 Training Error: 105.181404 Validation Error: 105.186134\n",
            "Epoch: 2904 Training Error: 105.18139 Validation Error: 105.18612\n",
            "Epoch: 2905 Training Error: 105.181366 Validation Error: 105.1861\n",
            "Epoch: 2906 Training Error: 105.181366 Validation Error: 105.18607\n",
            "Epoch: 2907 Training Error: 105.18134 Validation Error: 105.18604\n",
            "Epoch: 2908 Training Error: 105.18131 Validation Error: 105.186\n",
            "Epoch: 2909 Training Error: 105.181274 Validation Error: 105.18594\n",
            "Epoch: 2910 Training Error: 105.18125 Validation Error: 105.1859\n",
            "Epoch: 2911 Training Error: 105.18123 Validation Error: 105.185844\n",
            "Epoch: 2912 Training Error: 105.18121 Validation Error: 105.185844\n",
            "Epoch: 2913 Training Error: 105.18121 Validation Error: 105.18582\n",
            "Epoch: 2914 Training Error: 105.18119 Validation Error: 105.18578\n",
            "Epoch: 2915 Training Error: 105.181175 Validation Error: 105.185776\n",
            "Epoch: 2916 Training Error: 105.18117 Validation Error: 105.18574\n",
            "Epoch: 2917 Training Error: 105.18117 Validation Error: 105.18571\n",
            "Epoch: 2918 Training Error: 105.18114 Validation Error: 105.185684\n",
            "Epoch: 2919 Training Error: 105.18113 Validation Error: 105.18566\n",
            "Epoch: 2920 Training Error: 105.18113 Validation Error: 105.18564\n",
            "Epoch: 2921 Training Error: 105.181114 Validation Error: 105.1856\n",
            "Epoch: 2922 Training Error: 105.181114 Validation Error: 105.1856\n",
            "Epoch: 2923 Training Error: 105.18111 Validation Error: 105.185585\n",
            "Epoch: 2924 Training Error: 105.18109 Validation Error: 105.185585\n",
            "Epoch: 2925 Training Error: 105.18109 Validation Error: 105.185585\n",
            "Epoch: 2926 Training Error: 105.18109 Validation Error: 105.18556\n",
            "Epoch: 2927 Training Error: 105.181076 Validation Error: 105.18554\n",
            "Epoch: 2928 Training Error: 105.181076 Validation Error: 105.18554\n",
            "Epoch: 2929 Training Error: 105.18107 Validation Error: 105.185524\n",
            "Epoch: 2930 Training Error: 105.18107 Validation Error: 105.18551\n",
            "Epoch: 2931 Training Error: 105.18105 Validation Error: 105.185524\n",
            "Epoch: 2932 Training Error: 105.18105 Validation Error: 105.18551\n",
            "Epoch: 2933 Training Error: 105.18104 Validation Error: 105.18551\n",
            "Epoch: 2934 Training Error: 105.18104 Validation Error: 105.18554\n",
            "Epoch: 2935 Training Error: 105.18104 Validation Error: 105.1855\n",
            "Epoch: 2936 Training Error: 105.18103 Validation Error: 105.18547\n",
            "Epoch: 2937 Training Error: 105.18103 Validation Error: 105.18547\n",
            "Epoch: 2938 Training Error: 105.18103 Validation Error: 105.18546\n",
            "Epoch: 2939 Training Error: 105.181015 Validation Error: 105.18547\n",
            "Epoch: 2940 Training Error: 105.181015 Validation Error: 105.18547\n",
            "Epoch: 2941 Training Error: 105.181015 Validation Error: 105.18545\n",
            "Epoch: 2942 Training Error: 105.181 Validation Error: 105.18545\n",
            "Epoch: 2943 Training Error: 105.18099 Validation Error: 105.18545\n",
            "Epoch: 2944 Training Error: 105.18099 Validation Error: 105.18543\n",
            "Epoch: 2945 Training Error: 105.18099 Validation Error: 105.18543\n",
            "Epoch: 2946 Training Error: 105.18098 Validation Error: 105.18541\n",
            "Epoch: 2947 Training Error: 105.18098 Validation Error: 105.1854\n",
            "Epoch: 2948 Training Error: 105.18097 Validation Error: 105.1854\n",
            "Epoch: 2949 Training Error: 105.18097 Validation Error: 105.18541\n",
            "Epoch: 2950 Training Error: 105.18097 Validation Error: 105.18541\n",
            "Epoch: 2951 Training Error: 105.180954 Validation Error: 105.18539\n",
            "Epoch: 2952 Training Error: 105.18094 Validation Error: 105.18536\n",
            "Epoch: 2953 Training Error: 105.18093 Validation Error: 105.185326\n",
            "Epoch: 2954 Training Error: 105.18093 Validation Error: 105.1853\n",
            "Epoch: 2955 Training Error: 105.18093 Validation Error: 105.1853\n",
            "Epoch: 2956 Training Error: 105.18093 Validation Error: 105.18527\n",
            "Epoch: 2957 Training Error: 105.180916 Validation Error: 105.18529\n",
            "Epoch: 2958 Training Error: 105.1809 Validation Error: 105.18527\n",
            "Epoch: 2959 Training Error: 105.1809 Validation Error: 105.18525\n",
            "Epoch: 2960 Training Error: 105.1809 Validation Error: 105.18523\n",
            "Epoch: 2961 Training Error: 105.1809 Validation Error: 105.18521\n",
            "Epoch: 2962 Training Error: 105.1809 Validation Error: 105.185196\n",
            "Epoch: 2963 Training Error: 105.18089 Validation Error: 105.185196\n",
            "Epoch: 2964 Training Error: 105.18088 Validation Error: 105.185196\n",
            "Epoch: 2965 Training Error: 105.18087 Validation Error: 105.18519\n",
            "Epoch: 2966 Training Error: 105.180855 Validation Error: 105.185196\n",
            "Epoch: 2967 Training Error: 105.180855 Validation Error: 105.18521\n",
            "Epoch: 2968 Training Error: 105.18084 Validation Error: 105.18521\n",
            "Epoch: 2969 Training Error: 105.18084 Validation Error: 105.18521\n",
            "Epoch: 2970 Training Error: 105.18083 Validation Error: 105.18521\n",
            "Epoch: 2971 Training Error: 105.18083 Validation Error: 105.18521\n",
            "Epoch: 2972 Training Error: 105.18083 Validation Error: 105.185196\n",
            "Epoch: 2973 Training Error: 105.18082 Validation Error: 105.185196\n",
            "Epoch: 2974 Training Error: 105.1808 Validation Error: 105.18517\n",
            "Epoch: 2975 Training Error: 105.1808 Validation Error: 105.185165\n",
            "Epoch: 2976 Training Error: 105.18079 Validation Error: 105.185135\n",
            "Epoch: 2977 Training Error: 105.18079 Validation Error: 105.18511\n",
            "Epoch: 2978 Training Error: 105.18079 Validation Error: 105.18511\n",
            "Epoch: 2979 Training Error: 105.18079 Validation Error: 105.18509\n",
            "Epoch: 2980 Training Error: 105.18078 Validation Error: 105.18509\n",
            "Epoch: 2981 Training Error: 105.18078 Validation Error: 105.18509\n",
            "Epoch: 2982 Training Error: 105.18078 Validation Error: 105.18509\n",
            "Epoch: 2983 Training Error: 105.180756 Validation Error: 105.185074\n",
            "Epoch: 2984 Training Error: 105.180756 Validation Error: 105.18507\n",
            "Epoch: 2985 Training Error: 105.180756 Validation Error: 105.18505\n",
            "Epoch: 2986 Training Error: 105.180756 Validation Error: 105.185036\n",
            "Epoch: 2987 Training Error: 105.180756 Validation Error: 105.18501\n",
            "Epoch: 2988 Training Error: 105.180756 Validation Error: 105.18501\n",
            "Epoch: 2989 Training Error: 105.180756 Validation Error: 105.18499\n",
            "Epoch: 2990 Training Error: 105.180756 Validation Error: 105.184975\n",
            "Epoch: 2991 Training Error: 105.18078 Validation Error: 105.18496\n",
            "Epoch: 2992 Training Error: 105.18078 Validation Error: 105.18496\n",
            "Epoch: 2993 Training Error: 105.18078 Validation Error: 105.18495\n",
            "Epoch: 2994 Training Error: 105.18078 Validation Error: 105.18494\n",
            "Epoch: 2995 Training Error: 105.18078 Validation Error: 105.18494\n",
            "Epoch: 2996 Training Error: 105.18076 Validation Error: 105.18493\n",
            "Epoch: 2997 Training Error: 105.180756 Validation Error: 105.18493\n",
            "Epoch: 2998 Training Error: 105.180756 Validation Error: 105.18491\n",
            "Epoch: 2999 Training Error: 105.18076 Validation Error: 105.18491\n",
            "Epoch: 3000 Training Error: 105.18078 Validation Error: 105.1849\n",
            "Epoch: 3001 Training Error: 105.18079 Validation Error: 105.1849\n",
            "Epoch: 3002 Training Error: 105.18082 Validation Error: 105.1849\n",
            "Epoch: 3003 Training Error: 105.1808 Validation Error: 105.1849\n",
            "Epoch: 3004 Training Error: 105.18078 Validation Error: 105.184875\n",
            "Epoch: 3005 Training Error: 105.18076 Validation Error: 105.184875\n",
            "Epoch: 3006 Training Error: 105.180756 Validation Error: 105.18486\n",
            "Epoch: 3007 Training Error: 105.18074 Validation Error: 105.18485\n",
            "Epoch: 3008 Training Error: 105.18073 Validation Error: 105.18485\n",
            "Epoch: 3009 Training Error: 105.18073 Validation Error: 105.18484\n",
            "Epoch: 3010 Training Error: 105.1807 Validation Error: 105.18483\n",
            "Epoch: 3011 Training Error: 105.18068 Validation Error: 105.18483\n",
            "Epoch: 3012 Training Error: 105.18068 Validation Error: 105.184814\n",
            "Epoch: 3013 Training Error: 105.18066 Validation Error: 105.1848\n",
            "Epoch: 3014 Training Error: 105.180664 Validation Error: 105.1848\n",
            "Epoch: 3015 Training Error: 105.18068 Validation Error: 105.18479\n",
            "Epoch: 3016 Training Error: 105.180695 Validation Error: 105.18479\n",
            "Epoch: 3017 Training Error: 105.180695 Validation Error: 105.18478\n",
            "Epoch: 3018 Training Error: 105.18068 Validation Error: 105.18476\n",
            "Epoch: 3019 Training Error: 105.18068 Validation Error: 105.18476\n",
            "Epoch: 3020 Training Error: 105.180664 Validation Error: 105.18475\n",
            "Epoch: 3021 Training Error: 105.180664 Validation Error: 105.18475\n",
            "Epoch: 3022 Training Error: 105.18066 Validation Error: 105.18474\n",
            "Epoch: 3023 Training Error: 105.18066 Validation Error: 105.18474\n",
            "Epoch: 3024 Training Error: 105.18064 Validation Error: 105.18472\n",
            "Epoch: 3025 Training Error: 105.18064 Validation Error: 105.18472\n",
            "Epoch: 3026 Training Error: 105.18062 Validation Error: 105.184715\n",
            "Epoch: 3027 Training Error: 105.180595 Validation Error: 105.1847\n",
            "Epoch: 3028 Training Error: 105.18058 Validation Error: 105.1847\n",
            "Epoch: 3029 Training Error: 105.180565 Validation Error: 105.1847\n",
            "Epoch: 3030 Training Error: 105.18054 Validation Error: 105.18469\n",
            "Epoch: 3031 Training Error: 105.18054 Validation Error: 105.18469\n",
            "Epoch: 3032 Training Error: 105.18053 Validation Error: 105.18468\n",
            "Epoch: 3033 Training Error: 105.18052 Validation Error: 105.18469\n",
            "Epoch: 3034 Training Error: 105.180504 Validation Error: 105.18469\n",
            "Epoch: 3035 Training Error: 105.1805 Validation Error: 105.18468\n",
            "Epoch: 3036 Training Error: 105.180504 Validation Error: 105.18466\n",
            "Epoch: 3037 Training Error: 105.1805 Validation Error: 105.184654\n",
            "Epoch: 3038 Training Error: 105.180504 Validation Error: 105.18464\n",
            "Epoch: 3039 Training Error: 105.18052 Validation Error: 105.184616\n",
            "Epoch: 3040 Training Error: 105.18052 Validation Error: 105.184616\n",
            "Epoch: 3041 Training Error: 105.180504 Validation Error: 105.1846\n",
            "Epoch: 3042 Training Error: 105.18048 Validation Error: 105.1846\n",
            "Epoch: 3043 Training Error: 105.18048 Validation Error: 105.1846\n",
            "Epoch: 3044 Training Error: 105.180466 Validation Error: 105.18459\n",
            "Epoch: 3045 Training Error: 105.18046 Validation Error: 105.18459\n",
            "Epoch: 3046 Training Error: 105.18046 Validation Error: 105.18459\n",
            "Epoch: 3047 Training Error: 105.18046 Validation Error: 105.18458\n",
            "Epoch: 3048 Training Error: 105.18044 Validation Error: 105.18456\n",
            "Epoch: 3049 Training Error: 105.18043 Validation Error: 105.18456\n",
            "Epoch: 3050 Training Error: 105.18043 Validation Error: 105.184555\n",
            "Epoch: 3051 Training Error: 105.18043 Validation Error: 105.184555\n",
            "Epoch: 3052 Training Error: 105.18044 Validation Error: 105.18454\n",
            "Epoch: 3053 Training Error: 105.18043 Validation Error: 105.184525\n",
            "Epoch: 3054 Training Error: 105.18043 Validation Error: 105.18452\n",
            "Epoch: 3055 Training Error: 105.18042 Validation Error: 105.18452\n",
            "Epoch: 3056 Training Error: 105.18042 Validation Error: 105.18452\n",
            "Epoch: 3057 Training Error: 105.180405 Validation Error: 105.1845\n",
            "Epoch: 3058 Training Error: 105.18038 Validation Error: 105.1845\n",
            "Epoch: 3059 Training Error: 105.18038 Validation Error: 105.1845\n",
            "Epoch: 3060 Training Error: 105.18037 Validation Error: 105.1845\n",
            "Epoch: 3061 Training Error: 105.18036 Validation Error: 105.18452\n",
            "Epoch: 3062 Training Error: 105.18036 Validation Error: 105.18452\n",
            "Epoch: 3063 Training Error: 105.18034 Validation Error: 105.1845\n",
            "Epoch: 3064 Training Error: 105.18034 Validation Error: 105.18449\n",
            "Epoch: 3065 Training Error: 105.18034 Validation Error: 105.18449\n",
            "Epoch: 3066 Training Error: 105.18033 Validation Error: 105.18449\n",
            "Epoch: 3067 Training Error: 105.18033 Validation Error: 105.18449\n",
            "Epoch: 3068 Training Error: 105.18032 Validation Error: 105.18449\n",
            "Epoch: 3069 Training Error: 105.18032 Validation Error: 105.18449\n",
            "Epoch: 3070 Training Error: 105.180305 Validation Error: 105.18446\n",
            "Epoch: 3071 Training Error: 105.180305 Validation Error: 105.18446\n",
            "Epoch: 3072 Training Error: 105.180305 Validation Error: 105.18444\n",
            "Epoch: 3073 Training Error: 105.180305 Validation Error: 105.18442\n",
            "Epoch: 3074 Training Error: 105.180305 Validation Error: 105.1844\n",
            "Epoch: 3075 Training Error: 105.180305 Validation Error: 105.18439\n",
            "Epoch: 3076 Training Error: 105.18032 Validation Error: 105.18438\n",
            "Epoch: 3077 Training Error: 105.18033 Validation Error: 105.184364\n",
            "Epoch: 3078 Training Error: 105.18032 Validation Error: 105.18436\n",
            "Epoch: 3079 Training Error: 105.18032 Validation Error: 105.18436\n",
            "Epoch: 3080 Training Error: 105.18032 Validation Error: 105.18434\n",
            "Epoch: 3081 Training Error: 105.18033 Validation Error: 105.18434\n",
            "Epoch: 3082 Training Error: 105.18033 Validation Error: 105.184326\n",
            "Epoch: 3083 Training Error: 105.18033 Validation Error: 105.184326\n",
            "Epoch: 3084 Training Error: 105.18029 Validation Error: 105.184326\n",
            "Epoch: 3085 Training Error: 105.18028 Validation Error: 105.18432\n",
            "Epoch: 3086 Training Error: 105.180244 Validation Error: 105.184326\n",
            "Epoch: 3087 Training Error: 105.180244 Validation Error: 105.18432\n",
            "Epoch: 3088 Training Error: 105.18023 Validation Error: 105.1843\n",
            "Epoch: 3089 Training Error: 105.18023 Validation Error: 105.1843\n",
            "Epoch: 3090 Training Error: 105.18022 Validation Error: 105.1843\n",
            "Epoch: 3091 Training Error: 105.18022 Validation Error: 105.18429\n",
            "Epoch: 3092 Training Error: 105.18021 Validation Error: 105.18429\n",
            "Epoch: 3093 Training Error: 105.18019 Validation Error: 105.18428\n",
            "Epoch: 3094 Training Error: 105.18018 Validation Error: 105.18428\n",
            "Epoch: 3095 Training Error: 105.18018 Validation Error: 105.18429\n",
            "Epoch: 3096 Training Error: 105.18017 Validation Error: 105.1843\n",
            "Epoch: 3097 Training Error: 105.18017 Validation Error: 105.18432\n",
            "Epoch: 3098 Training Error: 105.18017 Validation Error: 105.1843\n",
            "Epoch: 3099 Training Error: 105.18015 Validation Error: 105.18429\n",
            "Epoch: 3100 Training Error: 105.18015 Validation Error: 105.18428\n",
            "Epoch: 3101 Training Error: 105.180145 Validation Error: 105.18428\n",
            "Epoch: 3102 Training Error: 105.180145 Validation Error: 105.18428\n",
            "Epoch: 3103 Training Error: 105.180145 Validation Error: 105.18429\n",
            "Epoch: 3104 Training Error: 105.18013 Validation Error: 105.18429\n",
            "Epoch: 3105 Training Error: 105.18013 Validation Error: 105.18429\n",
            "Epoch: 3106 Training Error: 105.18013 Validation Error: 105.18429\n",
            "Epoch: 3107 Training Error: 105.18013 Validation Error: 105.18429\n",
            "Epoch: 3108 Training Error: 105.18012 Validation Error: 105.18429\n",
            "Epoch: 3109 Training Error: 105.18012 Validation Error: 105.18429\n",
            "Epoch: 3110 Training Error: 105.18011 Validation Error: 105.18428\n",
            "Epoch: 3111 Training Error: 105.18009 Validation Error: 105.18425\n",
            "Epoch: 3112 Training Error: 105.18009 Validation Error: 105.18425\n",
            "Epoch: 3113 Training Error: 105.18009 Validation Error: 105.18424\n",
            "Epoch: 3114 Training Error: 105.180084 Validation Error: 105.18424\n",
            "Epoch: 3115 Training Error: 105.180084 Validation Error: 105.18423\n",
            "Epoch: 3116 Training Error: 105.18007 Validation Error: 105.184204\n",
            "Epoch: 3117 Training Error: 105.18007 Validation Error: 105.18419\n",
            "Epoch: 3118 Training Error: 105.18007 Validation Error: 105.184204\n",
            "Epoch: 3119 Training Error: 105.18007 Validation Error: 105.184204\n",
            "Epoch: 3120 Training Error: 105.18005 Validation Error: 105.18422\n",
            "Epoch: 3121 Training Error: 105.18005 Validation Error: 105.18422\n",
            "Epoch: 3122 Training Error: 105.180046 Validation Error: 105.184204\n",
            "Epoch: 3123 Training Error: 105.180046 Validation Error: 105.18419\n",
            "Epoch: 3124 Training Error: 105.18003 Validation Error: 105.18415\n",
            "Epoch: 3125 Training Error: 105.18003 Validation Error: 105.18413\n",
            "Epoch: 3126 Training Error: 105.18002 Validation Error: 105.184105\n",
            "Epoch: 3127 Training Error: 105.18002 Validation Error: 105.184105\n",
            "Epoch: 3128 Training Error: 105.18001 Validation Error: 105.18409\n",
            "Epoch: 3129 Training Error: 105.17999 Validation Error: 105.18408\n",
            "Epoch: 3130 Training Error: 105.17999 Validation Error: 105.18409\n",
            "Epoch: 3131 Training Error: 105.17999 Validation Error: 105.184105\n",
            "Epoch: 3132 Training Error: 105.17999 Validation Error: 105.18409\n",
            "Epoch: 3133 Training Error: 105.179985 Validation Error: 105.18408\n",
            "Epoch: 3134 Training Error: 105.179985 Validation Error: 105.18405\n",
            "Epoch: 3135 Training Error: 105.179985 Validation Error: 105.184044\n",
            "Epoch: 3136 Training Error: 105.179985 Validation Error: 105.18403\n",
            "Epoch: 3137 Training Error: 105.17997 Validation Error: 105.18401\n",
            "Epoch: 3138 Training Error: 105.17997 Validation Error: 105.18401\n",
            "Epoch: 3139 Training Error: 105.179955 Validation Error: 105.18403\n",
            "Epoch: 3140 Training Error: 105.179955 Validation Error: 105.18403\n",
            "Epoch: 3141 Training Error: 105.17995 Validation Error: 105.18403\n",
            "Epoch: 3142 Training Error: 105.17995 Validation Error: 105.184044\n",
            "Epoch: 3143 Training Error: 105.17995 Validation Error: 105.184006\n",
            "Epoch: 3144 Training Error: 105.17993 Validation Error: 105.184006\n",
            "Epoch: 3145 Training Error: 105.17993 Validation Error: 105.18398\n",
            "Epoch: 3146 Training Error: 105.17993 Validation Error: 105.18398\n",
            "Epoch: 3147 Training Error: 105.17992 Validation Error: 105.18398\n",
            "Epoch: 3148 Training Error: 105.17992 Validation Error: 105.18397\n",
            "Epoch: 3149 Training Error: 105.17991 Validation Error: 105.18395\n",
            "Epoch: 3150 Training Error: 105.17991 Validation Error: 105.18395\n",
            "Epoch: 3151 Training Error: 105.17991 Validation Error: 105.18397\n",
            "Epoch: 3152 Training Error: 105.17989 Validation Error: 105.18395\n",
            "Epoch: 3153 Training Error: 105.17989 Validation Error: 105.18395\n",
            "Epoch: 3154 Training Error: 105.179886 Validation Error: 105.183945\n",
            "Epoch: 3155 Training Error: 105.179886 Validation Error: 105.18393\n",
            "Epoch: 3156 Training Error: 105.179886 Validation Error: 105.18393\n",
            "Epoch: 3157 Training Error: 105.17987 Validation Error: 105.183914\n",
            "Epoch: 3158 Training Error: 105.17987 Validation Error: 105.183914\n",
            "Epoch: 3159 Training Error: 105.179855 Validation Error: 105.18391\n",
            "Epoch: 3160 Training Error: 105.179855 Validation Error: 105.18391\n",
            "Epoch: 3161 Training Error: 105.179855 Validation Error: 105.18389\n",
            "Epoch: 3162 Training Error: 105.17985 Validation Error: 105.183876\n",
            "Epoch: 3163 Training Error: 105.17985 Validation Error: 105.183876\n",
            "Epoch: 3164 Training Error: 105.17985 Validation Error: 105.18387\n",
            "Epoch: 3165 Training Error: 105.17983 Validation Error: 105.18387\n",
            "Epoch: 3166 Training Error: 105.17983 Validation Error: 105.18387\n",
            "Epoch: 3167 Training Error: 105.17982 Validation Error: 105.18385\n",
            "Epoch: 3168 Training Error: 105.17982 Validation Error: 105.18385\n",
            "Epoch: 3169 Training Error: 105.17981 Validation Error: 105.18385\n",
            "Epoch: 3170 Training Error: 105.17981 Validation Error: 105.183846\n",
            "Epoch: 3171 Training Error: 105.17981 Validation Error: 105.183815\n",
            "Epoch: 3172 Training Error: 105.17981 Validation Error: 105.18379\n",
            "Epoch: 3173 Training Error: 105.179794 Validation Error: 105.183815\n",
            "Epoch: 3174 Training Error: 105.179794 Validation Error: 105.183815\n",
            "Epoch: 3175 Training Error: 105.179794 Validation Error: 105.183815\n",
            "Epoch: 3176 Training Error: 105.17979 Validation Error: 105.18381\n",
            "Epoch: 3177 Training Error: 105.17979 Validation Error: 105.18381\n",
            "Epoch: 3178 Training Error: 105.17979 Validation Error: 105.18381\n",
            "Epoch: 3179 Training Error: 105.17977 Validation Error: 105.183815\n",
            "Epoch: 3180 Training Error: 105.17977 Validation Error: 105.183815\n",
            "Epoch: 3181 Training Error: 105.179756 Validation Error: 105.183815\n",
            "Epoch: 3182 Training Error: 105.179756 Validation Error: 105.183815\n",
            "Epoch: 3183 Training Error: 105.179756 Validation Error: 105.18381\n",
            "Epoch: 3184 Training Error: 105.179756 Validation Error: 105.18383\n",
            "Epoch: 3185 Training Error: 105.179756 Validation Error: 105.183815\n",
            "Epoch: 3186 Training Error: 105.17975 Validation Error: 105.183815\n",
            "Epoch: 3187 Training Error: 105.17975 Validation Error: 105.18379\n",
            "Epoch: 3188 Training Error: 105.17972 Validation Error: 105.18377\n",
            "Epoch: 3189 Training Error: 105.17972 Validation Error: 105.183754\n",
            "Epoch: 3190 Training Error: 105.17971 Validation Error: 105.18373\n",
            "Epoch: 3191 Training Error: 105.17971 Validation Error: 105.18373\n",
            "Epoch: 3192 Training Error: 105.17971 Validation Error: 105.18373\n",
            "Epoch: 3193 Training Error: 105.17971 Validation Error: 105.18375\n",
            "Epoch: 3194 Training Error: 105.17971 Validation Error: 105.18378\n",
            "Epoch: 3195 Training Error: 105.17971 Validation Error: 105.18378\n",
            "Epoch: 3196 Training Error: 105.17971 Validation Error: 105.18377\n",
            "Epoch: 3197 Training Error: 105.179695 Validation Error: 105.183754\n",
            "Epoch: 3198 Training Error: 105.17968 Validation Error: 105.18373\n",
            "Epoch: 3199 Training Error: 105.17967 Validation Error: 105.18371\n",
            "Epoch: 3200 Training Error: 105.17967 Validation Error: 105.18368\n",
            "Epoch: 3201 Training Error: 105.17966 Validation Error: 105.18367\n",
            "Epoch: 3202 Training Error: 105.17966 Validation Error: 105.183655\n",
            "Epoch: 3203 Training Error: 105.17965 Validation Error: 105.18364\n",
            "Epoch: 3204 Training Error: 105.17965 Validation Error: 105.18363\n",
            "Epoch: 3205 Training Error: 105.179634 Validation Error: 105.18362\n",
            "Epoch: 3206 Training Error: 105.179634 Validation Error: 105.18362\n",
            "Epoch: 3207 Training Error: 105.179634 Validation Error: 105.18362\n",
            "Epoch: 3208 Training Error: 105.17962 Validation Error: 105.18361\n",
            "Epoch: 3209 Training Error: 105.17962 Validation Error: 105.18361\n",
            "Epoch: 3210 Training Error: 105.17962 Validation Error: 105.18361\n",
            "Epoch: 3211 Training Error: 105.17962 Validation Error: 105.18361\n",
            "Epoch: 3212 Training Error: 105.17961 Validation Error: 105.18358\n",
            "Epoch: 3213 Training Error: 105.179596 Validation Error: 105.183556\n",
            "Epoch: 3214 Training Error: 105.179596 Validation Error: 105.18354\n",
            "Epoch: 3215 Training Error: 105.179596 Validation Error: 105.18352\n",
            "Epoch: 3216 Training Error: 105.179596 Validation Error: 105.18352\n",
            "Epoch: 3217 Training Error: 105.17958 Validation Error: 105.18352\n",
            "Epoch: 3218 Training Error: 105.17957 Validation Error: 105.18352\n",
            "Epoch: 3219 Training Error: 105.17957 Validation Error: 105.18353\n",
            "Epoch: 3220 Training Error: 105.17957 Validation Error: 105.183556\n",
            "Epoch: 3221 Training Error: 105.17957 Validation Error: 105.183556\n",
            "Epoch: 3222 Training Error: 105.17957 Validation Error: 105.18357\n",
            "Epoch: 3223 Training Error: 105.17957 Validation Error: 105.183556\n",
            "Epoch: 3224 Training Error: 105.17956 Validation Error: 105.18354\n",
            "Epoch: 3225 Training Error: 105.17955 Validation Error: 105.18353\n",
            "Epoch: 3226 Training Error: 105.17955 Validation Error: 105.18353\n",
            "Epoch: 3227 Training Error: 105.17955 Validation Error: 105.18353\n",
            "Epoch: 3228 Training Error: 105.17955 Validation Error: 105.18354\n",
            "Epoch: 3229 Training Error: 105.179535 Validation Error: 105.18352\n",
            "Epoch: 3230 Training Error: 105.179535 Validation Error: 105.18351\n",
            "Epoch: 3231 Training Error: 105.17952 Validation Error: 105.183495\n",
            "Epoch: 3232 Training Error: 105.17952 Validation Error: 105.18348\n",
            "Epoch: 3233 Training Error: 105.17952 Validation Error: 105.18346\n",
            "Epoch: 3234 Training Error: 105.17951 Validation Error: 105.18344\n",
            "Epoch: 3235 Training Error: 105.17951 Validation Error: 105.18342\n",
            "Epoch: 3236 Training Error: 105.17951 Validation Error: 105.18342\n",
            "Epoch: 3237 Training Error: 105.17951 Validation Error: 105.18343\n",
            "Epoch: 3238 Training Error: 105.1795 Validation Error: 105.18344\n",
            "Epoch: 3239 Training Error: 105.17948 Validation Error: 105.18342\n",
            "Epoch: 3240 Training Error: 105.17948 Validation Error: 105.18342\n",
            "Epoch: 3241 Training Error: 105.17948 Validation Error: 105.1834\n",
            "Epoch: 3242 Training Error: 105.17948 Validation Error: 105.1834\n",
            "Epoch: 3243 Training Error: 105.179474 Validation Error: 105.18337\n",
            "Epoch: 3244 Training Error: 105.179474 Validation Error: 105.18336\n",
            "Epoch: 3245 Training Error: 105.17946 Validation Error: 105.18336\n",
            "Epoch: 3246 Training Error: 105.17946 Validation Error: 105.18337\n",
            "Epoch: 3247 Training Error: 105.17946 Validation Error: 105.18336\n",
            "Epoch: 3248 Training Error: 105.17946 Validation Error: 105.18334\n",
            "Epoch: 3249 Training Error: 105.17946 Validation Error: 105.18334\n",
            "Epoch: 3250 Training Error: 105.17944 Validation Error: 105.183334\n",
            "Epoch: 3251 Training Error: 105.179436 Validation Error: 105.183334\n",
            "Epoch: 3252 Training Error: 105.179436 Validation Error: 105.183334\n",
            "Epoch: 3253 Training Error: 105.179436 Validation Error: 105.183334\n",
            "Epoch: 3254 Training Error: 105.179436 Validation Error: 105.18336\n",
            "Epoch: 3255 Training Error: 105.179436 Validation Error: 105.18337\n",
            "Epoch: 3256 Training Error: 105.17942 Validation Error: 105.18337\n",
            "Epoch: 3257 Training Error: 105.17942 Validation Error: 105.18336\n",
            "Epoch: 3258 Training Error: 105.17942 Validation Error: 105.18337\n",
            "Epoch: 3259 Training Error: 105.17942 Validation Error: 105.18337\n",
            "Epoch: 3260 Training Error: 105.17942 Validation Error: 105.18337\n",
            "Epoch: 3261 Training Error: 105.17942 Validation Error: 105.183395\n",
            "Epoch: 3262 Training Error: 105.17942 Validation Error: 105.18342\n",
            "Epoch: 3263 Training Error: 105.17941 Validation Error: 105.183395\n",
            "Epoch: 3264 Training Error: 105.17941 Validation Error: 105.18336\n",
            "Epoch: 3265 Training Error: 105.17938 Validation Error: 105.18334\n",
            "Epoch: 3266 Training Error: 105.17938 Validation Error: 105.18332\n",
            "Epoch: 3267 Training Error: 105.17938 Validation Error: 105.183334\n",
            "Epoch: 3268 Training Error: 105.179375 Validation Error: 105.18332\n",
            "Epoch: 3269 Training Error: 105.179375 Validation Error: 105.18332\n",
            "Epoch: 3270 Training Error: 105.179375 Validation Error: 105.1833\n",
            "Epoch: 3271 Training Error: 105.17936 Validation Error: 105.18327\n",
            "Epoch: 3272 Training Error: 105.179344 Validation Error: 105.18326\n",
            "Epoch: 3273 Training Error: 105.17934 Validation Error: 105.18324\n",
            "Epoch: 3274 Training Error: 105.17934 Validation Error: 105.183235\n",
            "Epoch: 3275 Training Error: 105.17934 Validation Error: 105.18324\n",
            "Epoch: 3276 Training Error: 105.17934 Validation Error: 105.18322\n",
            "Epoch: 3277 Training Error: 105.17932 Validation Error: 105.183205\n",
            "Epoch: 3278 Training Error: 105.179306 Validation Error: 105.18318\n",
            "Epoch: 3279 Training Error: 105.179306 Validation Error: 105.1832\n",
            "Epoch: 3280 Training Error: 105.1793 Validation Error: 105.18317\n",
            "Epoch: 3281 Training Error: 105.1793 Validation Error: 105.18317\n",
            "Epoch: 3282 Training Error: 105.1793 Validation Error: 105.18317\n",
            "Epoch: 3283 Training Error: 105.17928 Validation Error: 105.18317\n",
            "Epoch: 3284 Training Error: 105.17928 Validation Error: 105.18317\n",
            "Epoch: 3285 Training Error: 105.17928 Validation Error: 105.18317\n",
            "Epoch: 3286 Training Error: 105.17928 Validation Error: 105.18317\n",
            "Epoch: 3287 Training Error: 105.17928 Validation Error: 105.18317\n",
            "Epoch: 3288 Training Error: 105.179276 Validation Error: 105.18317\n",
            "Epoch: 3289 Training Error: 105.179276 Validation Error: 105.1832\n",
            "Epoch: 3290 Training Error: 105.179276 Validation Error: 105.1832\n",
            "Epoch: 3291 Training Error: 105.179276 Validation Error: 105.18318\n",
            "Epoch: 3292 Training Error: 105.179276 Validation Error: 105.1832\n",
            "Epoch: 3293 Training Error: 105.179245 Validation Error: 105.18316\n",
            "Epoch: 3294 Training Error: 105.179245 Validation Error: 105.18316\n",
            "Epoch: 3295 Training Error: 105.179245 Validation Error: 105.183136\n",
            "Epoch: 3296 Training Error: 105.17924 Validation Error: 105.183105\n",
            "Epoch: 3297 Training Error: 105.17924 Validation Error: 105.18308\n",
            "Epoch: 3298 Training Error: 105.17922 Validation Error: 105.18307\n",
            "Epoch: 3299 Training Error: 105.17922 Validation Error: 105.18306\n",
            "Epoch: 3300 Training Error: 105.17922 Validation Error: 105.18306\n",
            "Epoch: 3301 Training Error: 105.17921 Validation Error: 105.183044\n",
            "Epoch: 3302 Training Error: 105.17921 Validation Error: 105.183044\n",
            "Epoch: 3303 Training Error: 105.1792 Validation Error: 105.18303\n",
            "Epoch: 3304 Training Error: 105.1792 Validation Error: 105.18302\n",
            "Epoch: 3305 Training Error: 105.1792 Validation Error: 105.18301\n",
            "Epoch: 3306 Training Error: 105.1792 Validation Error: 105.18301\n",
            "Epoch: 3307 Training Error: 105.179184 Validation Error: 105.183\n",
            "Epoch: 3308 Training Error: 105.179184 Validation Error: 105.183\n",
            "Epoch: 3309 Training Error: 105.17918 Validation Error: 105.18298\n",
            "Epoch: 3310 Training Error: 105.179184 Validation Error: 105.18298\n",
            "Epoch: 3311 Training Error: 105.17918 Validation Error: 105.18296\n",
            "Epoch: 3312 Training Error: 105.17918 Validation Error: 105.18296\n",
            "Epoch: 3313 Training Error: 105.17918 Validation Error: 105.182945\n",
            "Epoch: 3314 Training Error: 105.17918 Validation Error: 105.18293\n",
            "Epoch: 3315 Training Error: 105.17916 Validation Error: 105.18292\n",
            "Epoch: 3316 Training Error: 105.179146 Validation Error: 105.18293\n",
            "Epoch: 3317 Training Error: 105.179146 Validation Error: 105.18292\n",
            "Epoch: 3318 Training Error: 105.179146 Validation Error: 105.18291\n",
            "Epoch: 3319 Training Error: 105.17914 Validation Error: 105.1829\n",
            "Epoch: 3320 Training Error: 105.179146 Validation Error: 105.1829\n",
            "Epoch: 3321 Training Error: 105.179146 Validation Error: 105.182884\n",
            "Epoch: 3322 Training Error: 105.17914 Validation Error: 105.182884\n",
            "Epoch: 3323 Training Error: 105.17914 Validation Error: 105.182884\n",
            "Epoch: 3324 Training Error: 105.17914 Validation Error: 105.18287\n",
            "Epoch: 3325 Training Error: 105.179146 Validation Error: 105.182846\n",
            "Epoch: 3326 Training Error: 105.179146 Validation Error: 105.182846\n",
            "Epoch: 3327 Training Error: 105.179146 Validation Error: 105.182846\n",
            "Epoch: 3328 Training Error: 105.179146 Validation Error: 105.18283\n",
            "Epoch: 3329 Training Error: 105.179146 Validation Error: 105.18282\n",
            "Epoch: 3330 Training Error: 105.179146 Validation Error: 105.18282\n",
            "Epoch: 3331 Training Error: 105.179146 Validation Error: 105.18282\n",
            "Epoch: 3332 Training Error: 105.17914 Validation Error: 105.18281\n",
            "Epoch: 3333 Training Error: 105.17914 Validation Error: 105.18281\n",
            "Epoch: 3334 Training Error: 105.179146 Validation Error: 105.18279\n",
            "Epoch: 3335 Training Error: 105.179146 Validation Error: 105.18279\n",
            "Epoch: 3336 Training Error: 105.17914 Validation Error: 105.182785\n",
            "Epoch: 3337 Training Error: 105.17912 Validation Error: 105.182785\n",
            "Epoch: 3338 Training Error: 105.1791 Validation Error: 105.18277\n",
            "Epoch: 3339 Training Error: 105.17911 Validation Error: 105.18277\n",
            "Epoch: 3340 Training Error: 105.17907 Validation Error: 105.18277\n",
            "Epoch: 3341 Training Error: 105.17907 Validation Error: 105.18276\n",
            "Epoch: 3342 Training Error: 105.17906 Validation Error: 105.18276\n",
            "Epoch: 3343 Training Error: 105.17906 Validation Error: 105.18275\n",
            "Epoch: 3344 Training Error: 105.17905 Validation Error: 105.18275\n",
            "Epoch: 3345 Training Error: 105.17905 Validation Error: 105.18275\n",
            "Epoch: 3346 Training Error: 105.17905 Validation Error: 105.18273\n",
            "Epoch: 3347 Training Error: 105.17906 Validation Error: 105.182724\n",
            "Epoch: 3348 Training Error: 105.17907 Validation Error: 105.182724\n",
            "Epoch: 3349 Training Error: 105.17906 Validation Error: 105.18271\n",
            "Epoch: 3350 Training Error: 105.17906 Validation Error: 105.18271\n",
            "Epoch: 3351 Training Error: 105.17905 Validation Error: 105.18269\n",
            "Epoch: 3352 Training Error: 105.17904 Validation Error: 105.18269\n",
            "Epoch: 3353 Training Error: 105.17902 Validation Error: 105.18269\n",
            "Epoch: 3354 Training Error: 105.179 Validation Error: 105.18269\n",
            "Epoch: 3355 Training Error: 105.179 Validation Error: 105.18269\n",
            "Epoch: 3356 Training Error: 105.179 Validation Error: 105.182686\n",
            "Epoch: 3357 Training Error: 105.179 Validation Error: 105.18267\n",
            "Epoch: 3358 Training Error: 105.178986 Validation Error: 105.18267\n",
            "Epoch: 3359 Training Error: 105.179 Validation Error: 105.18266\n",
            "Epoch: 3360 Training Error: 105.178986 Validation Error: 105.18266\n",
            "Epoch: 3361 Training Error: 105.17897 Validation Error: 105.18266\n",
            "Epoch: 3362 Training Error: 105.17896 Validation Error: 105.18265\n",
            "Epoch: 3363 Training Error: 105.17897 Validation Error: 105.18263\n",
            "Epoch: 3364 Training Error: 105.17896 Validation Error: 105.18263\n",
            "Epoch: 3365 Training Error: 105.17896 Validation Error: 105.18263\n",
            "Epoch: 3366 Training Error: 105.17895 Validation Error: 105.182625\n",
            "Epoch: 3367 Training Error: 105.17894 Validation Error: 105.182625\n",
            "Epoch: 3368 Training Error: 105.17895 Validation Error: 105.18261\n",
            "Epoch: 3369 Training Error: 105.17896 Validation Error: 105.18261\n",
            "Epoch: 3370 Training Error: 105.17896 Validation Error: 105.182594\n",
            "Epoch: 3371 Training Error: 105.17895 Validation Error: 105.182594\n",
            "Epoch: 3372 Training Error: 105.17895 Validation Error: 105.18259\n",
            "Epoch: 3373 Training Error: 105.17894 Validation Error: 105.18259\n",
            "Epoch: 3374 Training Error: 105.178925 Validation Error: 105.18259\n",
            "Epoch: 3375 Training Error: 105.178925 Validation Error: 105.18257\n",
            "Epoch: 3376 Training Error: 105.17891 Validation Error: 105.18257\n",
            "Epoch: 3377 Training Error: 105.17891 Validation Error: 105.182556\n",
            "Epoch: 3378 Training Error: 105.1789 Validation Error: 105.182556\n",
            "Epoch: 3379 Training Error: 105.17889 Validation Error: 105.182556\n",
            "Epoch: 3380 Training Error: 105.17887 Validation Error: 105.182556\n",
            "Epoch: 3381 Training Error: 105.17887 Validation Error: 105.182556\n",
            "Epoch: 3382 Training Error: 105.17887 Validation Error: 105.18255\n",
            "Epoch: 3383 Training Error: 105.17887 Validation Error: 105.18253\n",
            "Epoch: 3384 Training Error: 105.17889 Validation Error: 105.182526\n",
            "Epoch: 3385 Training Error: 105.1789 Validation Error: 105.182526\n",
            "Epoch: 3386 Training Error: 105.1789 Validation Error: 105.18251\n",
            "Epoch: 3387 Training Error: 105.17889 Validation Error: 105.18251\n",
            "Epoch: 3388 Training Error: 105.17887 Validation Error: 105.182495\n",
            "Epoch: 3389 Training Error: 105.17886 Validation Error: 105.18249\n",
            "Epoch: 3390 Training Error: 105.17886 Validation Error: 105.18249\n",
            "Epoch: 3391 Training Error: 105.17886 Validation Error: 105.18249\n",
            "Epoch: 3392 Training Error: 105.17886 Validation Error: 105.18247\n",
            "Epoch: 3393 Training Error: 105.17886 Validation Error: 105.18247\n",
            "Epoch: 3394 Training Error: 105.17885 Validation Error: 105.18246\n",
            "Epoch: 3395 Training Error: 105.17885 Validation Error: 105.18246\n",
            "Epoch: 3396 Training Error: 105.17883 Validation Error: 105.18245\n",
            "Epoch: 3397 Training Error: 105.17883 Validation Error: 105.18245\n",
            "Epoch: 3398 Training Error: 105.178825 Validation Error: 105.18245\n",
            "Epoch: 3399 Training Error: 105.17881 Validation Error: 105.182434\n",
            "Epoch: 3400 Training Error: 105.178825 Validation Error: 105.182434\n",
            "Epoch: 3401 Training Error: 105.17881 Validation Error: 105.18243\n",
            "Epoch: 3402 Training Error: 105.17881 Validation Error: 105.18243\n",
            "Epoch: 3403 Training Error: 105.17881 Validation Error: 105.18241\n",
            "Epoch: 3404 Training Error: 105.178825 Validation Error: 105.18241\n",
            "Epoch: 3405 Training Error: 105.178825 Validation Error: 105.18241\n",
            "Epoch: 3406 Training Error: 105.17881 Validation Error: 105.182396\n",
            "Epoch: 3407 Training Error: 105.1788 Validation Error: 105.182396\n",
            "Epoch: 3408 Training Error: 105.17879 Validation Error: 105.18239\n",
            "Epoch: 3409 Training Error: 105.17879 Validation Error: 105.18239\n",
            "Epoch: 3410 Training Error: 105.17877 Validation Error: 105.18239\n",
            "Epoch: 3411 Training Error: 105.178764 Validation Error: 105.18237\n",
            "Epoch: 3412 Training Error: 105.17877 Validation Error: 105.18237\n",
            "Epoch: 3413 Training Error: 105.17877 Validation Error: 105.18236\n",
            "Epoch: 3414 Training Error: 105.17879 Validation Error: 105.18236\n",
            "Epoch: 3415 Training Error: 105.1788 Validation Error: 105.18236\n",
            "Epoch: 3416 Training Error: 105.17879 Validation Error: 105.18235\n",
            "Epoch: 3417 Training Error: 105.17877 Validation Error: 105.18235\n",
            "Epoch: 3418 Training Error: 105.178764 Validation Error: 105.182335\n",
            "Epoch: 3419 Training Error: 105.17875 Validation Error: 105.182335\n",
            "Epoch: 3420 Training Error: 105.178734 Validation Error: 105.18232\n",
            "Epoch: 3421 Training Error: 105.17873 Validation Error: 105.18232\n",
            "Epoch: 3422 Training Error: 105.17873 Validation Error: 105.18231\n",
            "Epoch: 3423 Training Error: 105.17873 Validation Error: 105.18231\n",
            "Epoch: 3424 Training Error: 105.17871 Validation Error: 105.18231\n",
            "Epoch: 3425 Training Error: 105.17871 Validation Error: 105.1823\n",
            "Epoch: 3426 Training Error: 105.17871 Validation Error: 105.1823\n",
            "Epoch: 3427 Training Error: 105.17873 Validation Error: 105.18229\n",
            "Epoch: 3428 Training Error: 105.178734 Validation Error: 105.18229\n",
            "Epoch: 3429 Training Error: 105.178734 Validation Error: 105.18229\n",
            "Epoch: 3430 Training Error: 105.178734 Validation Error: 105.182274\n",
            "Epoch: 3431 Training Error: 105.178734 Validation Error: 105.182274\n",
            "Epoch: 3432 Training Error: 105.17873 Validation Error: 105.18226\n",
            "Epoch: 3433 Training Error: 105.17873 Validation Error: 105.18226\n",
            "Epoch: 3434 Training Error: 105.178734 Validation Error: 105.18226\n",
            "Epoch: 3435 Training Error: 105.17873 Validation Error: 105.18225\n",
            "Epoch: 3436 Training Error: 105.178734 Validation Error: 105.18225\n",
            "Epoch: 3437 Training Error: 105.178764 Validation Error: 105.18226\n",
            "Epoch: 3438 Training Error: 105.17879 Validation Error: 105.18226\n",
            "Epoch: 3439 Training Error: 105.17879 Validation Error: 105.18226\n",
            "Epoch: 3440 Training Error: 105.17881 Validation Error: 105.18226\n",
            "Epoch: 3441 Training Error: 105.178825 Validation Error: 105.182274\n",
            "Epoch: 3442 Training Error: 105.178825 Validation Error: 105.18226\n",
            "Epoch: 3443 Training Error: 105.1788 Validation Error: 105.18225\n",
            "Epoch: 3444 Training Error: 105.17881 Validation Error: 105.18225\n",
            "Epoch: 3445 Training Error: 105.17877 Validation Error: 105.182236\n",
            "Epoch: 3446 Training Error: 105.178764 Validation Error: 105.18222\n",
            "Epoch: 3447 Training Error: 105.17875 Validation Error: 105.18221\n",
            "Epoch: 3448 Training Error: 105.17875 Validation Error: 105.18221\n",
            "Epoch: 3449 Training Error: 105.17873 Validation Error: 105.1822\n",
            "Epoch: 3450 Training Error: 105.178734 Validation Error: 105.1822\n",
            "Epoch: 3451 Training Error: 105.17873 Validation Error: 105.1822\n",
            "Epoch: 3452 Training Error: 105.17873 Validation Error: 105.18219\n",
            "Epoch: 3453 Training Error: 105.1787 Validation Error: 105.182175\n",
            "Epoch: 3454 Training Error: 105.17867 Validation Error: 105.18216\n",
            "Epoch: 3455 Training Error: 105.178665 Validation Error: 105.18215\n",
            "Epoch: 3456 Training Error: 105.178635 Validation Error: 105.18215\n",
            "Epoch: 3457 Training Error: 105.178635 Validation Error: 105.18214\n",
            "Epoch: 3458 Training Error: 105.178635 Validation Error: 105.18214\n",
            "Epoch: 3459 Training Error: 105.17863 Validation Error: 105.18212\n",
            "Epoch: 3460 Training Error: 105.17863 Validation Error: 105.18212\n",
            "Epoch: 3461 Training Error: 105.17863 Validation Error: 105.18211\n",
            "Epoch: 3462 Training Error: 105.17863 Validation Error: 105.18211\n",
            "Epoch: 3463 Training Error: 105.178635 Validation Error: 105.18211\n",
            "Epoch: 3464 Training Error: 105.17861 Validation Error: 105.1821\n",
            "Epoch: 3465 Training Error: 105.17861 Validation Error: 105.1821\n",
            "Epoch: 3466 Training Error: 105.17859 Validation Error: 105.18208\n",
            "Epoch: 3467 Training Error: 105.17857 Validation Error: 105.18208\n",
            "Epoch: 3468 Training Error: 105.178566 Validation Error: 105.182076\n",
            "Epoch: 3469 Training Error: 105.178566 Validation Error: 105.182076\n",
            "Epoch: 3470 Training Error: 105.178566 Validation Error: 105.18206\n",
            "Epoch: 3471 Training Error: 105.17855 Validation Error: 105.18206\n",
            "Epoch: 3472 Training Error: 105.17855 Validation Error: 105.18205\n",
            "Epoch: 3473 Training Error: 105.178535 Validation Error: 105.18205\n",
            "Epoch: 3474 Training Error: 105.178535 Validation Error: 105.18205\n",
            "Epoch: 3475 Training Error: 105.17853 Validation Error: 105.18204\n",
            "Epoch: 3476 Training Error: 105.17853 Validation Error: 105.18204\n",
            "Epoch: 3477 Training Error: 105.178535 Validation Error: 105.18204\n",
            "Epoch: 3478 Training Error: 105.178535 Validation Error: 105.18202\n",
            "Epoch: 3479 Training Error: 105.17853 Validation Error: 105.182014\n",
            "Epoch: 3480 Training Error: 105.17853 Validation Error: 105.182014\n",
            "Epoch: 3481 Training Error: 105.17851 Validation Error: 105.182014\n",
            "Epoch: 3482 Training Error: 105.17851 Validation Error: 105.182\n",
            "Epoch: 3483 Training Error: 105.17851 Validation Error: 105.182\n",
            "Epoch: 3484 Training Error: 105.17849 Validation Error: 105.181984\n",
            "Epoch: 3485 Training Error: 105.17849 Validation Error: 105.181984\n",
            "Epoch: 3486 Training Error: 105.178474 Validation Error: 105.18198\n",
            "Epoch: 3487 Training Error: 105.17847 Validation Error: 105.18198\n",
            "Epoch: 3488 Training Error: 105.17845 Validation Error: 105.18196\n",
            "Epoch: 3489 Training Error: 105.17847 Validation Error: 105.18196\n",
            "Epoch: 3490 Training Error: 105.17844 Validation Error: 105.18196\n",
            "Epoch: 3491 Training Error: 105.17844 Validation Error: 105.18195\n",
            "Epoch: 3492 Training Error: 105.17843 Validation Error: 105.18196\n",
            "Epoch: 3493 Training Error: 105.17843 Validation Error: 105.18195\n",
            "Epoch: 3494 Training Error: 105.17841 Validation Error: 105.18195\n",
            "Epoch: 3495 Training Error: 105.17841 Validation Error: 105.18194\n",
            "Epoch: 3496 Training Error: 105.1784 Validation Error: 105.18194\n",
            "Epoch: 3497 Training Error: 105.1784 Validation Error: 105.18194\n",
            "Epoch: 3498 Training Error: 105.17839 Validation Error: 105.18192\n",
            "Epoch: 3499 Training Error: 105.17839 Validation Error: 105.181915\n",
            "Epoch: 3500 Training Error: 105.17839 Validation Error: 105.181915\n",
            "Epoch: 3501 Training Error: 105.178375 Validation Error: 105.181915\n",
            "Epoch: 3502 Training Error: 105.178375 Validation Error: 105.181915\n",
            "Epoch: 3503 Training Error: 105.17836 Validation Error: 105.1819\n",
            "Epoch: 3504 Training Error: 105.17836 Validation Error: 105.1819\n",
            "Epoch: 3505 Training Error: 105.17835 Validation Error: 105.181885\n",
            "Epoch: 3506 Training Error: 105.17835 Validation Error: 105.181885\n",
            "Epoch: 3507 Training Error: 105.17835 Validation Error: 105.181885\n",
            "Epoch: 3508 Training Error: 105.17834 Validation Error: 105.181885\n",
            "Epoch: 3509 Training Error: 105.17835 Validation Error: 105.18186\n",
            "Epoch: 3510 Training Error: 105.17835 Validation Error: 105.18186\n",
            "Epoch: 3511 Training Error: 105.17836 Validation Error: 105.18185\n",
            "Epoch: 3512 Training Error: 105.17836 Validation Error: 105.18184\n",
            "Epoch: 3513 Training Error: 105.178375 Validation Error: 105.18184\n",
            "Epoch: 3514 Training Error: 105.17835 Validation Error: 105.18182\n",
            "Epoch: 3515 Training Error: 105.17835 Validation Error: 105.18182\n",
            "Epoch: 3516 Training Error: 105.17834 Validation Error: 105.18182\n",
            "Epoch: 3517 Training Error: 105.17834 Validation Error: 105.181816\n",
            "Epoch: 3518 Training Error: 105.17833 Validation Error: 105.181816\n",
            "Epoch: 3519 Training Error: 105.17833 Validation Error: 105.181816\n",
            "Epoch: 3520 Training Error: 105.178314 Validation Error: 105.1818\n",
            "Epoch: 3521 Training Error: 105.1783 Validation Error: 105.1818\n",
            "Epoch: 3522 Training Error: 105.1783 Validation Error: 105.181786\n",
            "Epoch: 3523 Training Error: 105.1783 Validation Error: 105.181786\n",
            "Epoch: 3524 Training Error: 105.17829 Validation Error: 105.181786\n",
            "Epoch: 3525 Training Error: 105.178276 Validation Error: 105.181786\n",
            "Epoch: 3526 Training Error: 105.17829 Validation Error: 105.18178\n",
            "Epoch: 3527 Training Error: 105.178276 Validation Error: 105.18176\n",
            "Epoch: 3528 Training Error: 105.178276 Validation Error: 105.18176\n",
            "Epoch: 3529 Training Error: 105.178276 Validation Error: 105.18175\n",
            "Epoch: 3530 Training Error: 105.178276 Validation Error: 105.18175\n",
            "Epoch: 3531 Training Error: 105.178276 Validation Error: 105.18175\n",
            "Epoch: 3532 Training Error: 105.17826 Validation Error: 105.18174\n",
            "Epoch: 3533 Training Error: 105.178276 Validation Error: 105.18174\n",
            "Epoch: 3534 Training Error: 105.178276 Validation Error: 105.181725\n",
            "Epoch: 3535 Training Error: 105.1783 Validation Error: 105.181725\n",
            "Epoch: 3536 Training Error: 105.1783 Validation Error: 105.181725\n",
            "Epoch: 3537 Training Error: 105.17829 Validation Error: 105.18171\n",
            "Epoch: 3538 Training Error: 105.178276 Validation Error: 105.1817\n",
            "Epoch: 3539 Training Error: 105.17826 Validation Error: 105.1817\n",
            "Epoch: 3540 Training Error: 105.17826 Validation Error: 105.18169\n",
            "Epoch: 3541 Training Error: 105.17826 Validation Error: 105.18169\n",
            "Epoch: 3542 Training Error: 105.17826 Validation Error: 105.18168\n",
            "Epoch: 3543 Training Error: 105.17825 Validation Error: 105.18168\n",
            "Epoch: 3544 Training Error: 105.17825 Validation Error: 105.18166\n",
            "Epoch: 3545 Training Error: 105.17825 Validation Error: 105.18166\n",
            "Epoch: 3546 Training Error: 105.17824 Validation Error: 105.18165\n",
            "Epoch: 3547 Training Error: 105.17824 Validation Error: 105.18165\n",
            "Epoch: 3548 Training Error: 105.17824 Validation Error: 105.18165\n",
            "Epoch: 3549 Training Error: 105.17824 Validation Error: 105.18164\n",
            "Epoch: 3550 Training Error: 105.17825 Validation Error: 105.18164\n",
            "Epoch: 3551 Training Error: 105.17826 Validation Error: 105.18164\n",
            "Epoch: 3552 Training Error: 105.17825 Validation Error: 105.18164\n",
            "Epoch: 3553 Training Error: 105.178276 Validation Error: 105.18164\n",
            "Epoch: 3554 Training Error: 105.17829 Validation Error: 105.18164\n",
            "Epoch: 3555 Training Error: 105.17826 Validation Error: 105.181625\n",
            "Epoch: 3556 Training Error: 105.17825 Validation Error: 105.181625\n",
            "Epoch: 3557 Training Error: 105.17825 Validation Error: 105.18161\n",
            "Epoch: 3558 Training Error: 105.17824 Validation Error: 105.1816\n",
            "Epoch: 3559 Training Error: 105.17824 Validation Error: 105.1816\n",
            "Epoch: 3560 Training Error: 105.17824 Validation Error: 105.1816\n",
            "Epoch: 3561 Training Error: 105.178215 Validation Error: 105.18159\n",
            "Epoch: 3562 Training Error: 105.1782 Validation Error: 105.18159\n",
            "Epoch: 3563 Training Error: 105.17819 Validation Error: 105.18158\n",
            "Epoch: 3564 Training Error: 105.1782 Validation Error: 105.18158\n",
            "Epoch: 3565 Training Error: 105.1782 Validation Error: 105.18158\n",
            "Epoch: 3566 Training Error: 105.17823 Validation Error: 105.18158\n",
            "Epoch: 3567 Training Error: 105.17823 Validation Error: 105.181564\n",
            "Epoch: 3568 Training Error: 105.178215 Validation Error: 105.181564\n",
            "Epoch: 3569 Training Error: 105.1782 Validation Error: 105.18155\n",
            "Epoch: 3570 Training Error: 105.17818 Validation Error: 105.18155\n",
            "Epoch: 3571 Training Error: 105.17816 Validation Error: 105.18154\n",
            "Epoch: 3572 Training Error: 105.178154 Validation Error: 105.18154\n",
            "Epoch: 3573 Training Error: 105.17814 Validation Error: 105.181526\n",
            "Epoch: 3574 Training Error: 105.17812 Validation Error: 105.181526\n",
            "Epoch: 3575 Training Error: 105.1781 Validation Error: 105.18151\n",
            "Epoch: 3576 Training Error: 105.1781 Validation Error: 105.18151\n",
            "Epoch: 3577 Training Error: 105.17809 Validation Error: 105.18151\n",
            "Epoch: 3578 Training Error: 105.17809 Validation Error: 105.1815\n",
            "Epoch: 3579 Training Error: 105.17809 Validation Error: 105.1815\n",
            "Epoch: 3580 Training Error: 105.17809 Validation Error: 105.18149\n",
            "Epoch: 3581 Training Error: 105.17809 Validation Error: 105.18149\n",
            "Epoch: 3582 Training Error: 105.17809 Validation Error: 105.18149\n",
            "Epoch: 3583 Training Error: 105.17808 Validation Error: 105.18147\n",
            "Epoch: 3584 Training Error: 105.17806 Validation Error: 105.18147\n",
            "Epoch: 3585 Training Error: 105.17806 Validation Error: 105.181465\n",
            "Epoch: 3586 Training Error: 105.17806 Validation Error: 105.181465\n",
            "Epoch: 3587 Training Error: 105.17808 Validation Error: 105.18145\n",
            "Epoch: 3588 Training Error: 105.17808 Validation Error: 105.18145\n",
            "Epoch: 3589 Training Error: 105.17808 Validation Error: 105.18144\n",
            "Epoch: 3590 Training Error: 105.17806 Validation Error: 105.18144\n",
            "Epoch: 3591 Training Error: 105.17806 Validation Error: 105.18144\n",
            "Epoch: 3592 Training Error: 105.17806 Validation Error: 105.18143\n",
            "Epoch: 3593 Training Error: 105.17809 Validation Error: 105.18143\n",
            "Epoch: 3594 Training Error: 105.17808 Validation Error: 105.18141\n",
            "Epoch: 3595 Training Error: 105.17809 Validation Error: 105.18141\n",
            "Epoch: 3596 Training Error: 105.17809 Validation Error: 105.18141\n",
            "Epoch: 3597 Training Error: 105.17809 Validation Error: 105.18141\n",
            "Epoch: 3598 Training Error: 105.1781 Validation Error: 105.18141\n",
            "Epoch: 3599 Training Error: 105.1781 Validation Error: 105.18141\n",
            "Epoch: 3600 Training Error: 105.1781 Validation Error: 105.18141\n",
            "Epoch: 3601 Training Error: 105.1781 Validation Error: 105.181404\n",
            "Epoch: 3602 Training Error: 105.1781 Validation Error: 105.181404\n",
            "Epoch: 3603 Training Error: 105.17809 Validation Error: 105.18139\n",
            "Epoch: 3604 Training Error: 105.17809 Validation Error: 105.18139\n",
            "Epoch: 3605 Training Error: 105.17806 Validation Error: 105.18137\n",
            "Epoch: 3606 Training Error: 105.17806 Validation Error: 105.18137\n",
            "Epoch: 3607 Training Error: 105.17806 Validation Error: 105.181366\n",
            "Epoch: 3608 Training Error: 105.17808 Validation Error: 105.181366\n",
            "Epoch: 3609 Training Error: 105.17806 Validation Error: 105.181366\n",
            "Epoch: 3610 Training Error: 105.17806 Validation Error: 105.181366\n",
            "Epoch: 3611 Training Error: 105.17806 Validation Error: 105.18135\n",
            "Epoch: 3612 Training Error: 105.178055 Validation Error: 105.18135\n",
            "Epoch: 3613 Training Error: 105.17804 Validation Error: 105.18134\n",
            "Epoch: 3614 Training Error: 105.17804 Validation Error: 105.18134\n",
            "Epoch: 3615 Training Error: 105.17804 Validation Error: 105.18134\n",
            "Epoch: 3616 Training Error: 105.178024 Validation Error: 105.18133\n",
            "Epoch: 3617 Training Error: 105.17802 Validation Error: 105.18133\n",
            "Epoch: 3618 Training Error: 105.177986 Validation Error: 105.18131\n",
            "Epoch: 3619 Training Error: 105.177986 Validation Error: 105.18131\n",
            "Epoch: 3620 Training Error: 105.17798 Validation Error: 105.181305\n",
            "Epoch: 3621 Training Error: 105.17796 Validation Error: 105.18129\n",
            "Epoch: 3622 Training Error: 105.17796 Validation Error: 105.18129\n",
            "Epoch: 3623 Training Error: 105.177956 Validation Error: 105.18129\n",
            "Epoch: 3624 Training Error: 105.17794 Validation Error: 105.181274\n",
            "Epoch: 3625 Training Error: 105.177956 Validation Error: 105.181274\n",
            "Epoch: 3626 Training Error: 105.17794 Validation Error: 105.181274\n",
            "Epoch: 3627 Training Error: 105.17794 Validation Error: 105.18127\n",
            "Epoch: 3628 Training Error: 105.177956 Validation Error: 105.18127\n",
            "Epoch: 3629 Training Error: 105.17794 Validation Error: 105.18127\n",
            "Epoch: 3630 Training Error: 105.17794 Validation Error: 105.18125\n",
            "Epoch: 3631 Training Error: 105.177925 Validation Error: 105.18125\n",
            "Epoch: 3632 Training Error: 105.1779 Validation Error: 105.18124\n",
            "Epoch: 3633 Training Error: 105.17789 Validation Error: 105.18124\n",
            "Epoch: 3634 Training Error: 105.17789 Validation Error: 105.18123\n",
            "Epoch: 3635 Training Error: 105.17789 Validation Error: 105.18123\n",
            "Epoch: 3636 Training Error: 105.17788 Validation Error: 105.18123\n",
            "Epoch: 3637 Training Error: 105.177864 Validation Error: 105.18123\n",
            "Epoch: 3638 Training Error: 105.17786 Validation Error: 105.18123\n",
            "Epoch: 3639 Training Error: 105.17786 Validation Error: 105.18123\n",
            "Epoch: 3640 Training Error: 105.17784 Validation Error: 105.18121\n",
            "Epoch: 3641 Training Error: 105.17784 Validation Error: 105.18121\n",
            "Epoch: 3642 Training Error: 105.17784 Validation Error: 105.18121\n",
            "Epoch: 3643 Training Error: 105.17784 Validation Error: 105.181206\n",
            "Epoch: 3644 Training Error: 105.177826 Validation Error: 105.181206\n",
            "Epoch: 3645 Training Error: 105.177826 Validation Error: 105.18119\n",
            "Epoch: 3646 Training Error: 105.177826 Validation Error: 105.18119\n",
            "Epoch: 3647 Training Error: 105.177826 Validation Error: 105.181175\n",
            "Epoch: 3648 Training Error: 105.17782 Validation Error: 105.18119\n",
            "Epoch: 3649 Training Error: 105.17782 Validation Error: 105.18119\n",
            "Epoch: 3650 Training Error: 105.1778 Validation Error: 105.18119\n",
            "Epoch: 3651 Training Error: 105.1778 Validation Error: 105.18119\n",
            "Epoch: 3652 Training Error: 105.1778 Validation Error: 105.18119\n",
            "Epoch: 3653 Training Error: 105.1778 Validation Error: 105.18117\n",
            "Epoch: 3654 Training Error: 105.17779 Validation Error: 105.18117\n",
            "Epoch: 3655 Training Error: 105.17779 Validation Error: 105.18115\n",
            "Epoch: 3656 Training Error: 105.17779 Validation Error: 105.18115\n",
            "Epoch: 3657 Training Error: 105.17778 Validation Error: 105.18115\n",
            "Epoch: 3658 Training Error: 105.17778 Validation Error: 105.18114\n",
            "Epoch: 3659 Training Error: 105.17779 Validation Error: 105.18113\n",
            "Epoch: 3660 Training Error: 105.1778 Validation Error: 105.181114\n",
            "Epoch: 3661 Training Error: 105.17779 Validation Error: 105.181114\n",
            "Epoch: 3662 Training Error: 105.17779 Validation Error: 105.18111\n",
            "Epoch: 3663 Training Error: 105.17779 Validation Error: 105.18111\n",
            "Epoch: 3664 Training Error: 105.17778 Validation Error: 105.18111\n",
            "Epoch: 3665 Training Error: 105.17779 Validation Error: 105.18109\n",
            "Epoch: 3666 Training Error: 105.17779 Validation Error: 105.18109\n",
            "Epoch: 3667 Training Error: 105.17778 Validation Error: 105.181076\n",
            "Epoch: 3668 Training Error: 105.177765 Validation Error: 105.181076\n",
            "Epoch: 3669 Training Error: 105.177765 Validation Error: 105.181076\n",
            "Epoch: 3670 Training Error: 105.17778 Validation Error: 105.18107\n",
            "Epoch: 3671 Training Error: 105.17779 Validation Error: 105.18107\n",
            "Epoch: 3672 Training Error: 105.17779 Validation Error: 105.18105\n",
            "Epoch: 3673 Training Error: 105.17779 Validation Error: 105.18105\n",
            "Epoch: 3674 Training Error: 105.17778 Validation Error: 105.18105\n",
            "Epoch: 3675 Training Error: 105.17778 Validation Error: 105.18104\n",
            "Epoch: 3676 Training Error: 105.17778 Validation Error: 105.18103\n",
            "Epoch: 3677 Training Error: 105.177765 Validation Error: 105.18103\n",
            "Epoch: 3678 Training Error: 105.17774 Validation Error: 105.18103\n",
            "Epoch: 3679 Training Error: 105.17773 Validation Error: 105.18103\n",
            "Epoch: 3680 Training Error: 105.17772 Validation Error: 105.18103\n",
            "Epoch: 3681 Training Error: 105.17772 Validation Error: 105.18103\n",
            "Epoch: 3682 Training Error: 105.177704 Validation Error: 105.181015\n",
            "Epoch: 3683 Training Error: 105.177704 Validation Error: 105.181015\n",
            "Epoch: 3684 Training Error: 105.17769 Validation Error: 105.181015\n",
            "Epoch: 3685 Training Error: 105.17769 Validation Error: 105.181015\n",
            "Epoch: 3686 Training Error: 105.17768 Validation Error: 105.181015\n",
            "Epoch: 3687 Training Error: 105.17768 Validation Error: 105.181\n",
            "Epoch: 3688 Training Error: 105.177666 Validation Error: 105.181\n",
            "Epoch: 3689 Training Error: 105.177666 Validation Error: 105.181\n",
            "Epoch: 3690 Training Error: 105.17765 Validation Error: 105.181015\n",
            "Epoch: 3691 Training Error: 105.17765 Validation Error: 105.181\n",
            "Epoch: 3692 Training Error: 105.17765 Validation Error: 105.181\n",
            "Epoch: 3693 Training Error: 105.17765 Validation Error: 105.18098\n",
            "Epoch: 3694 Training Error: 105.17765 Validation Error: 105.18098\n",
            "Epoch: 3695 Training Error: 105.17764 Validation Error: 105.18098\n",
            "Epoch: 3696 Training Error: 105.17764 Validation Error: 105.18098\n",
            "Epoch: 3697 Training Error: 105.17763 Validation Error: 105.18098\n",
            "Epoch: 3698 Training Error: 105.17763 Validation Error: 105.18098\n",
            "Epoch: 3699 Training Error: 105.17763 Validation Error: 105.18097\n",
            "Epoch: 3700 Training Error: 105.17762 Validation Error: 105.18098\n",
            "Epoch: 3701 Training Error: 105.17762 Validation Error: 105.180954\n",
            "Epoch: 3702 Training Error: 105.17762 Validation Error: 105.180954\n",
            "Epoch: 3703 Training Error: 105.17762 Validation Error: 105.180954\n",
            "Epoch: 3704 Training Error: 105.17762 Validation Error: 105.18094\n",
            "Epoch: 3705 Training Error: 105.177605 Validation Error: 105.18093\n",
            "Epoch: 3706 Training Error: 105.177605 Validation Error: 105.18093\n",
            "Epoch: 3707 Training Error: 105.17759 Validation Error: 105.18093\n",
            "Epoch: 3708 Training Error: 105.17759 Validation Error: 105.180916\n",
            "Epoch: 3709 Training Error: 105.177605 Validation Error: 105.18089\n",
            "Epoch: 3710 Training Error: 105.177605 Validation Error: 105.18089\n",
            "Epoch: 3711 Training Error: 105.177605 Validation Error: 105.18088\n",
            "Epoch: 3712 Training Error: 105.177605 Validation Error: 105.18087\n",
            "Epoch: 3713 Training Error: 105.177605 Validation Error: 105.18087\n",
            "Epoch: 3714 Training Error: 105.17759 Validation Error: 105.18087\n",
            "Epoch: 3715 Training Error: 105.17759 Validation Error: 105.18087\n",
            "Epoch: 3716 Training Error: 105.17758 Validation Error: 105.18087\n",
            "Epoch: 3717 Training Error: 105.17758 Validation Error: 105.180855\n",
            "Epoch: 3718 Training Error: 105.17757 Validation Error: 105.180855\n",
            "Epoch: 3719 Training Error: 105.17757 Validation Error: 105.180855\n",
            "Epoch: 3720 Training Error: 105.17757 Validation Error: 105.180855\n",
            "Epoch: 3721 Training Error: 105.17757 Validation Error: 105.18084\n",
            "Epoch: 3722 Training Error: 105.17757 Validation Error: 105.18083\n",
            "Epoch: 3723 Training Error: 105.17758 Validation Error: 105.18082\n",
            "Epoch: 3724 Training Error: 105.17759 Validation Error: 105.18082\n",
            "Epoch: 3725 Training Error: 105.177605 Validation Error: 105.18082\n",
            "Epoch: 3726 Training Error: 105.17762 Validation Error: 105.1808\n",
            "Epoch: 3727 Training Error: 105.17763 Validation Error: 105.1808\n",
            "Epoch: 3728 Training Error: 105.17763 Validation Error: 105.1808\n",
            "Epoch: 3729 Training Error: 105.17762 Validation Error: 105.18079\n",
            "Epoch: 3730 Training Error: 105.17759 Validation Error: 105.18079\n",
            "Epoch: 3731 Training Error: 105.17757 Validation Error: 105.18078\n",
            "Epoch: 3732 Training Error: 105.17757 Validation Error: 105.18076\n",
            "Epoch: 3733 Training Error: 105.17757 Validation Error: 105.18076\n",
            "Epoch: 3734 Training Error: 105.17758 Validation Error: 105.18076\n",
            "Epoch: 3735 Training Error: 105.177605 Validation Error: 105.18076\n",
            "Epoch: 3736 Training Error: 105.17759 Validation Error: 105.18076\n",
            "Epoch: 3737 Training Error: 105.177605 Validation Error: 105.18076\n",
            "Epoch: 3738 Training Error: 105.17762 Validation Error: 105.18076\n",
            "Epoch: 3739 Training Error: 105.17763 Validation Error: 105.18076\n",
            "Epoch: 3740 Training Error: 105.17765 Validation Error: 105.18076\n",
            "Epoch: 3741 Training Error: 105.17764 Validation Error: 105.180756\n",
            "Epoch: 3742 Training Error: 105.17763 Validation Error: 105.180756\n",
            "Epoch: 3743 Training Error: 105.17764 Validation Error: 105.180756\n",
            "Epoch: 3744 Training Error: 105.17763 Validation Error: 105.18074\n",
            "Epoch: 3745 Training Error: 105.17762 Validation Error: 105.18074\n",
            "Epoch: 3746 Training Error: 105.177605 Validation Error: 105.18073\n",
            "Epoch: 3747 Training Error: 105.177605 Validation Error: 105.18073\n",
            "Epoch: 3748 Training Error: 105.177605 Validation Error: 105.18072\n",
            "Epoch: 3749 Training Error: 105.17762 Validation Error: 105.18072\n",
            "Epoch: 3750 Training Error: 105.17759 Validation Error: 105.18072\n",
            "Epoch: 3751 Training Error: 105.17757 Validation Error: 105.1807\n",
            "Epoch: 3752 Training Error: 105.17755 Validation Error: 105.180695\n",
            "Epoch: 3753 Training Error: 105.17755 Validation Error: 105.180695\n",
            "Epoch: 3754 Training Error: 105.17755 Validation Error: 105.180695\n",
            "Epoch: 3755 Training Error: 105.17754 Validation Error: 105.18068\n",
            "Epoch: 3756 Training Error: 105.17754 Validation Error: 105.180664\n",
            "Epoch: 3757 Training Error: 105.17751 Validation Error: 105.180664\n",
            "Epoch: 3758 Training Error: 105.177505 Validation Error: 105.18066\n",
            "Epoch: 3759 Training Error: 105.177505 Validation Error: 105.18066\n",
            "Epoch: 3760 Training Error: 105.177505 Validation Error: 105.18064\n",
            "Epoch: 3761 Training Error: 105.17749 Validation Error: 105.18064\n",
            "Epoch: 3762 Training Error: 105.17748 Validation Error: 105.18064\n",
            "Epoch: 3763 Training Error: 105.17747 Validation Error: 105.18063\n",
            "Epoch: 3764 Training Error: 105.17745 Validation Error: 105.18063\n",
            "Epoch: 3765 Training Error: 105.177444 Validation Error: 105.18062\n",
            "Epoch: 3766 Training Error: 105.177444 Validation Error: 105.18062\n",
            "Epoch: 3767 Training Error: 105.17743 Validation Error: 105.1806\n",
            "Epoch: 3768 Training Error: 105.17743 Validation Error: 105.1806\n",
            "Epoch: 3769 Training Error: 105.177414 Validation Error: 105.1806\n",
            "Epoch: 3770 Training Error: 105.17741 Validation Error: 105.1806\n",
            "Epoch: 3771 Training Error: 105.17741 Validation Error: 105.180595\n",
            "Epoch: 3772 Training Error: 105.17741 Validation Error: 105.180595\n",
            "Epoch: 3773 Training Error: 105.17741 Validation Error: 105.18058\n",
            "Epoch: 3774 Training Error: 105.177414 Validation Error: 105.18058\n",
            "Epoch: 3775 Training Error: 105.17741 Validation Error: 105.18058\n",
            "Epoch: 3776 Training Error: 105.17741 Validation Error: 105.180565\n",
            "Epoch: 3777 Training Error: 105.17741 Validation Error: 105.180565\n",
            "Epoch: 3778 Training Error: 105.177414 Validation Error: 105.18056\n",
            "Epoch: 3779 Training Error: 105.17743 Validation Error: 105.18056\n",
            "Epoch: 3780 Training Error: 105.17743 Validation Error: 105.18056\n",
            "Epoch: 3781 Training Error: 105.17739 Validation Error: 105.18054\n",
            "Epoch: 3782 Training Error: 105.17739 Validation Error: 105.18054\n",
            "Epoch: 3783 Training Error: 105.17741 Validation Error: 105.18054\n",
            "Epoch: 3784 Training Error: 105.17741 Validation Error: 105.18053\n",
            "Epoch: 3785 Training Error: 105.177414 Validation Error: 105.18053\n",
            "Epoch: 3786 Training Error: 105.177414 Validation Error: 105.18053\n",
            "Epoch: 3787 Training Error: 105.177414 Validation Error: 105.18053\n",
            "Epoch: 3788 Training Error: 105.17741 Validation Error: 105.18052\n",
            "Epoch: 3789 Training Error: 105.17741 Validation Error: 105.18052\n",
            "Epoch: 3790 Training Error: 105.17738 Validation Error: 105.180504\n",
            "Epoch: 3791 Training Error: 105.17737 Validation Error: 105.180504\n",
            "Epoch: 3792 Training Error: 105.17733 Validation Error: 105.180504\n",
            "Epoch: 3793 Training Error: 105.177315 Validation Error: 105.180504\n",
            "Epoch: 3794 Training Error: 105.17731 Validation Error: 105.180504\n",
            "Epoch: 3795 Training Error: 105.17731 Validation Error: 105.180504\n",
            "Epoch: 3796 Training Error: 105.17731 Validation Error: 105.1805\n",
            "Epoch: 3797 Training Error: 105.17731 Validation Error: 105.18048\n",
            "Epoch: 3798 Training Error: 105.17731 Validation Error: 105.18048\n",
            "Epoch: 3799 Training Error: 105.17731 Validation Error: 105.180466\n",
            "Epoch: 3800 Training Error: 105.17731 Validation Error: 105.180466\n",
            "Epoch: 3801 Training Error: 105.17729 Validation Error: 105.18046\n",
            "Epoch: 3802 Training Error: 105.17729 Validation Error: 105.18046\n",
            "Epoch: 3803 Training Error: 105.17729 Validation Error: 105.18046\n",
            "Epoch: 3804 Training Error: 105.17728 Validation Error: 105.18046\n",
            "Epoch: 3805 Training Error: 105.17728 Validation Error: 105.18046\n",
            "Epoch: 3806 Training Error: 105.17727 Validation Error: 105.18046\n",
            "Epoch: 3807 Training Error: 105.17725 Validation Error: 105.18046\n",
            "Epoch: 3808 Training Error: 105.17725 Validation Error: 105.18046\n",
            "Epoch: 3809 Training Error: 105.177246 Validation Error: 105.18046\n",
            "Epoch: 3810 Training Error: 105.177246 Validation Error: 105.18044\n",
            "Epoch: 3811 Training Error: 105.177246 Validation Error: 105.18043\n",
            "Epoch: 3812 Training Error: 105.177246 Validation Error: 105.18043\n",
            "Epoch: 3813 Training Error: 105.17723 Validation Error: 105.18044\n",
            "Epoch: 3814 Training Error: 105.17723 Validation Error: 105.18046\n",
            "Epoch: 3815 Training Error: 105.17723 Validation Error: 105.180466\n",
            "Epoch: 3816 Training Error: 105.177216 Validation Error: 105.18044\n",
            "Epoch: 3817 Training Error: 105.177216 Validation Error: 105.18043\n",
            "Epoch: 3818 Training Error: 105.177216 Validation Error: 105.18044\n",
            "Epoch: 3819 Training Error: 105.17721 Validation Error: 105.18043\n",
            "Epoch: 3820 Training Error: 105.17721 Validation Error: 105.18043\n",
            "Epoch: 3821 Training Error: 105.17721 Validation Error: 105.18043\n",
            "Epoch: 3822 Training Error: 105.17721 Validation Error: 105.18044\n",
            "Epoch: 3823 Training Error: 105.17721 Validation Error: 105.18044\n",
            "Epoch: 3824 Training Error: 105.17719 Validation Error: 105.18044\n",
            "Epoch: 3825 Training Error: 105.17719 Validation Error: 105.18043\n",
            "Epoch: 3826 Training Error: 105.17719 Validation Error: 105.18044\n",
            "Epoch: 3827 Training Error: 105.17719 Validation Error: 105.18043\n",
            "Epoch: 3828 Training Error: 105.17719 Validation Error: 105.18043\n",
            "Epoch: 3829 Training Error: 105.17718 Validation Error: 105.18042\n",
            "Epoch: 3830 Training Error: 105.17718 Validation Error: 105.180405\n",
            "Epoch: 3831 Training Error: 105.17718 Validation Error: 105.18043\n",
            "Epoch: 3832 Training Error: 105.17718 Validation Error: 105.18044\n",
            "Epoch: 3833 Training Error: 105.17718 Validation Error: 105.18046\n",
            "Epoch: 3834 Training Error: 105.17718 Validation Error: 105.18046\n",
            "Epoch: 3835 Training Error: 105.17719 Validation Error: 105.18046\n",
            "Epoch: 3836 Training Error: 105.17719 Validation Error: 105.180466\n",
            "Epoch: 3837 Training Error: 105.17719 Validation Error: 105.180466\n",
            "Epoch: 3838 Training Error: 105.17717 Validation Error: 105.18046\n",
            "Epoch: 3839 Training Error: 105.17717 Validation Error: 105.18043\n",
            "Epoch: 3840 Training Error: 105.177155 Validation Error: 105.180405\n",
            "Epoch: 3841 Training Error: 105.177155 Validation Error: 105.180405\n",
            "Epoch: 3842 Training Error: 105.177155 Validation Error: 105.180405\n",
            "Epoch: 3843 Training Error: 105.177155 Validation Error: 105.18043\n",
            "Epoch: 3844 Training Error: 105.17715 Validation Error: 105.180405\n",
            "Epoch: 3845 Training Error: 105.17715 Validation Error: 105.18039\n",
            "Epoch: 3846 Training Error: 105.17715 Validation Error: 105.180405\n",
            "Epoch: 3847 Training Error: 105.17713 Validation Error: 105.18038\n",
            "Epoch: 3848 Training Error: 105.17713 Validation Error: 105.18037\n",
            "Epoch: 3849 Training Error: 105.17712 Validation Error: 105.18036\n",
            "Epoch: 3850 Training Error: 105.17712 Validation Error: 105.18034\n",
            "Epoch: 3851 Training Error: 105.17712 Validation Error: 105.18034\n",
            "Epoch: 3852 Training Error: 105.17712 Validation Error: 105.18036\n",
            "Epoch: 3853 Training Error: 105.17711 Validation Error: 105.18036\n",
            "Epoch: 3854 Training Error: 105.17712 Validation Error: 105.18036\n",
            "Epoch: 3855 Training Error: 105.17712 Validation Error: 105.18037\n",
            "Epoch: 3856 Training Error: 105.17711 Validation Error: 105.18036\n",
            "Epoch: 3857 Training Error: 105.17709 Validation Error: 105.18032\n",
            "Epoch: 3858 Training Error: 105.17708 Validation Error: 105.180305\n",
            "Epoch: 3859 Training Error: 105.17709 Validation Error: 105.18034\n",
            "Epoch: 3860 Training Error: 105.17709 Validation Error: 105.18033\n",
            "Epoch: 3861 Training Error: 105.17711 Validation Error: 105.18034\n",
            "Epoch: 3862 Training Error: 105.17709 Validation Error: 105.18034\n",
            "Epoch: 3863 Training Error: 105.17709 Validation Error: 105.18034\n",
            "Epoch: 3864 Training Error: 105.17709 Validation Error: 105.18033\n",
            "Epoch: 3865 Training Error: 105.17709 Validation Error: 105.18034\n",
            "Epoch: 3866 Training Error: 105.17709 Validation Error: 105.18034\n",
            "Epoch: 3867 Training Error: 105.17709 Validation Error: 105.18034\n",
            "Epoch: 3868 Training Error: 105.17709 Validation Error: 105.18036\n",
            "Epoch: 3869 Training Error: 105.17711 Validation Error: 105.18038\n",
            "Epoch: 3870 Training Error: 105.17711 Validation Error: 105.18039\n",
            "Epoch: 3871 Training Error: 105.17709 Validation Error: 105.18038\n",
            "Epoch: 3872 Training Error: 105.17711 Validation Error: 105.18038\n",
            "Epoch: 3873 Training Error: 105.17712 Validation Error: 105.180405\n",
            "Epoch: 3874 Training Error: 105.17712 Validation Error: 105.18043\n",
            "Epoch: 3875 Training Error: 105.17711 Validation Error: 105.180405\n",
            "Epoch: 3876 Training Error: 105.17709 Validation Error: 105.18037\n",
            "Epoch: 3877 Training Error: 105.17708 Validation Error: 105.18034\n",
            "Epoch: 3878 Training Error: 105.177055 Validation Error: 105.18033\n",
            "Epoch: 3879 Training Error: 105.17704 Validation Error: 105.18029\n",
            "Epoch: 3880 Training Error: 105.17703 Validation Error: 105.18028\n",
            "Epoch: 3881 Training Error: 105.17702 Validation Error: 105.180244\n",
            "Epoch: 3882 Training Error: 105.17701 Validation Error: 105.18021\n",
            "Epoch: 3883 Training Error: 105.17701 Validation Error: 105.18018\n",
            "Epoch: 3884 Training Error: 105.176994 Validation Error: 105.18017\n",
            "Epoch: 3885 Training Error: 105.176994 Validation Error: 105.18015\n",
            "Epoch: 3886 Training Error: 105.176994 Validation Error: 105.18017\n",
            "Epoch: 3887 Training Error: 105.176994 Validation Error: 105.18018\n",
            "Epoch: 3888 Training Error: 105.176994 Validation Error: 105.18017\n",
            "Epoch: 3889 Training Error: 105.176994 Validation Error: 105.18018\n",
            "Epoch: 3890 Training Error: 105.17698 Validation Error: 105.18017\n",
            "Epoch: 3891 Training Error: 105.17698 Validation Error: 105.18015\n",
            "Epoch: 3892 Training Error: 105.17697 Validation Error: 105.18015\n",
            "Epoch: 3893 Training Error: 105.17697 Validation Error: 105.180145\n",
            "Epoch: 3894 Training Error: 105.17697 Validation Error: 105.18013\n",
            "Epoch: 3895 Training Error: 105.176956 Validation Error: 105.18012\n",
            "Epoch: 3896 Training Error: 105.176956 Validation Error: 105.18009\n",
            "Epoch: 3897 Training Error: 105.176956 Validation Error: 105.18009\n",
            "Epoch: 3898 Training Error: 105.176956 Validation Error: 105.180084\n",
            "Epoch: 3899 Training Error: 105.17694 Validation Error: 105.180084\n",
            "Epoch: 3900 Training Error: 105.17694 Validation Error: 105.180084\n",
            "Epoch: 3901 Training Error: 105.17694 Validation Error: 105.18009\n",
            "Epoch: 3902 Training Error: 105.17694 Validation Error: 105.18012\n",
            "Epoch: 3903 Training Error: 105.17694 Validation Error: 105.18012\n",
            "Epoch: 3904 Training Error: 105.17694 Validation Error: 105.18012\n",
            "Epoch: 3905 Training Error: 105.17694 Validation Error: 105.18012\n",
            "Epoch: 3906 Training Error: 105.17694 Validation Error: 105.18013\n",
            "Epoch: 3907 Training Error: 105.176956 Validation Error: 105.180145\n",
            "Epoch: 3908 Training Error: 105.176956 Validation Error: 105.18017\n",
            "Epoch: 3909 Training Error: 105.17694 Validation Error: 105.18015\n",
            "Epoch: 3910 Training Error: 105.17693 Validation Error: 105.18012\n",
            "Epoch: 3911 Training Error: 105.17693 Validation Error: 105.18011\n",
            "Epoch: 3912 Training Error: 105.17692 Validation Error: 105.18009\n",
            "Epoch: 3913 Training Error: 105.17692 Validation Error: 105.18011\n",
            "Epoch: 3914 Training Error: 105.17693 Validation Error: 105.18012\n",
            "Epoch: 3915 Training Error: 105.17693 Validation Error: 105.18013\n",
            "Epoch: 3916 Training Error: 105.17693 Validation Error: 105.180145\n",
            "Epoch: 3917 Training Error: 105.17694 Validation Error: 105.18017\n",
            "Epoch: 3918 Training Error: 105.176956 Validation Error: 105.18019\n",
            "Epoch: 3919 Training Error: 105.176956 Validation Error: 105.18019\n",
            "Epoch: 3920 Training Error: 105.17697 Validation Error: 105.18021\n",
            "Epoch: 3921 Training Error: 105.176994 Validation Error: 105.18027\n",
            "Epoch: 3922 Training Error: 105.17702 Validation Error: 105.180305\n",
            "Epoch: 3923 Training Error: 105.17704 Validation Error: 105.18033\n",
            "Epoch: 3924 Training Error: 105.177055 Validation Error: 105.18036\n",
            "Epoch: 3925 Training Error: 105.177055 Validation Error: 105.18036\n",
            "Epoch: 3926 Training Error: 105.17703 Validation Error: 105.18033\n",
            "Epoch: 3927 Training Error: 105.17702 Validation Error: 105.180305\n",
            "Epoch: 3928 Training Error: 105.17702 Validation Error: 105.180305\n",
            "Epoch: 3929 Training Error: 105.17703 Validation Error: 105.18033\n",
            "Epoch: 3930 Training Error: 105.17707 Validation Error: 105.18038\n",
            "Epoch: 3931 Training Error: 105.17711 Validation Error: 105.18043\n",
            "Epoch: 3932 Training Error: 105.17709 Validation Error: 105.18042\n",
            "Epoch: 3933 Training Error: 105.17708 Validation Error: 105.18039\n",
            "Epoch: 3934 Training Error: 105.17708 Validation Error: 105.18039\n",
            "Epoch: 3935 Training Error: 105.17707 Validation Error: 105.18038\n",
            "Epoch: 3936 Training Error: 105.17704 Validation Error: 105.18034\n",
            "Epoch: 3937 Training Error: 105.17703 Validation Error: 105.18032\n",
            "Epoch: 3938 Training Error: 105.17701 Validation Error: 105.18029\n",
            "Epoch: 3939 Training Error: 105.17701 Validation Error: 105.18029\n",
            "Epoch: 3940 Training Error: 105.17698 Validation Error: 105.180244\n",
            "Epoch: 3941 Training Error: 105.17694 Validation Error: 105.18019\n",
            "Epoch: 3942 Training Error: 105.17694 Validation Error: 105.18018\n",
            "Epoch: 3943 Training Error: 105.17692 Validation Error: 105.18013\n",
            "Epoch: 3944 Training Error: 105.1769 Validation Error: 105.18011\n",
            "Epoch: 3945 Training Error: 105.17688 Validation Error: 105.180084\n",
            "Epoch: 3946 Training Error: 105.17687 Validation Error: 105.18005\n",
            "Epoch: 3947 Training Error: 105.17687 Validation Error: 105.180046\n",
            "Epoch: 3948 Training Error: 105.17687 Validation Error: 105.18005\n",
            "Epoch: 3949 Training Error: 105.17687 Validation Error: 105.18007\n",
            "Epoch: 3950 Training Error: 105.17688 Validation Error: 105.180084\n",
            "Epoch: 3951 Training Error: 105.17686 Validation Error: 105.18003\n",
            "Epoch: 3952 Training Error: 105.176834 Validation Error: 105.179985\n",
            "Epoch: 3953 Training Error: 105.17684 Validation Error: 105.17999\n",
            "Epoch: 3954 Training Error: 105.176834 Validation Error: 105.17997\n",
            "Epoch: 3955 Training Error: 105.17682 Validation Error: 105.179955\n",
            "Epoch: 3956 Training Error: 105.1768 Validation Error: 105.17995\n",
            "Epoch: 3957 Training Error: 105.1768 Validation Error: 105.17992\n",
            "Epoch: 3958 Training Error: 105.176796 Validation Error: 105.17991\n",
            "Epoch: 3959 Training Error: 105.176796 Validation Error: 105.17991\n",
            "Epoch: 3960 Training Error: 105.176796 Validation Error: 105.17991\n",
            "Epoch: 3961 Training Error: 105.176796 Validation Error: 105.17992\n",
            "Epoch: 3962 Training Error: 105.1768 Validation Error: 105.17993\n",
            "Epoch: 3963 Training Error: 105.1768 Validation Error: 105.179955\n",
            "Epoch: 3964 Training Error: 105.176796 Validation Error: 105.17992\n",
            "Epoch: 3965 Training Error: 105.17678 Validation Error: 105.17991\n",
            "Epoch: 3966 Training Error: 105.17678 Validation Error: 105.17989\n",
            "Epoch: 3967 Training Error: 105.17678 Validation Error: 105.179886\n",
            "Epoch: 3968 Training Error: 105.17677 Validation Error: 105.17987\n",
            "Epoch: 3969 Training Error: 105.17677 Validation Error: 105.179855\n",
            "Epoch: 3970 Training Error: 105.17677 Validation Error: 105.17985\n",
            "Epoch: 3971 Training Error: 105.17677 Validation Error: 105.179855\n",
            "Epoch: 3972 Training Error: 105.17677 Validation Error: 105.17987\n",
            "Epoch: 3973 Training Error: 105.17677 Validation Error: 105.179886\n",
            "Epoch: 3974 Training Error: 105.17677 Validation Error: 105.179886\n",
            "Epoch: 3975 Training Error: 105.17677 Validation Error: 105.179886\n",
            "Epoch: 3976 Training Error: 105.17676 Validation Error: 105.179855\n",
            "Epoch: 3977 Training Error: 105.17676 Validation Error: 105.17985\n",
            "Epoch: 3978 Training Error: 105.17674 Validation Error: 105.17983\n",
            "Epoch: 3979 Training Error: 105.17674 Validation Error: 105.17983\n",
            "Epoch: 3980 Training Error: 105.17674 Validation Error: 105.17982\n",
            "Epoch: 3981 Training Error: 105.176735 Validation Error: 105.17981\n",
            "Epoch: 3982 Training Error: 105.176735 Validation Error: 105.17979\n",
            "Epoch: 3983 Training Error: 105.17672 Validation Error: 105.179756\n",
            "Epoch: 3984 Training Error: 105.17672 Validation Error: 105.17973\n",
            "Epoch: 3985 Training Error: 105.17672 Validation Error: 105.17973\n",
            "Epoch: 3986 Training Error: 105.17672 Validation Error: 105.17973\n",
            "Epoch: 3987 Training Error: 105.17672 Validation Error: 105.17973\n",
            "Epoch: 3988 Training Error: 105.17672 Validation Error: 105.17972\n",
            "Epoch: 3989 Training Error: 105.176704 Validation Error: 105.17972\n",
            "Epoch: 3990 Training Error: 105.176704 Validation Error: 105.17972\n",
            "Epoch: 3991 Training Error: 105.1767 Validation Error: 105.17972\n",
            "Epoch: 3992 Training Error: 105.1767 Validation Error: 105.17972\n",
            "Epoch: 3993 Training Error: 105.1767 Validation Error: 105.17971\n",
            "Epoch: 3994 Training Error: 105.1767 Validation Error: 105.179695\n",
            "Epoch: 3995 Training Error: 105.1767 Validation Error: 105.179695\n",
            "Epoch: 3996 Training Error: 105.1767 Validation Error: 105.17968\n",
            "Epoch: 3997 Training Error: 105.1767 Validation Error: 105.17967\n",
            "Epoch: 3998 Training Error: 105.17668 Validation Error: 105.17968\n",
            "Epoch: 3999 Training Error: 105.17668 Validation Error: 105.17967\n",
            "Epoch: 4000 Training Error: 105.17668 Validation Error: 105.17968\n",
            "Epoch: 4001 Training Error: 105.17668 Validation Error: 105.17967\n",
            "Epoch: 4002 Training Error: 105.17667 Validation Error: 105.17967\n",
            "Epoch: 4003 Training Error: 105.17667 Validation Error: 105.17967\n",
            "Epoch: 4004 Training Error: 105.17667 Validation Error: 105.17967\n",
            "Epoch: 4005 Training Error: 105.17667 Validation Error: 105.17967\n",
            "Epoch: 4006 Training Error: 105.17667 Validation Error: 105.17967\n",
            "Epoch: 4007 Training Error: 105.17667 Validation Error: 105.17965\n",
            "Epoch: 4008 Training Error: 105.17667 Validation Error: 105.17965\n",
            "Epoch: 4009 Training Error: 105.17667 Validation Error: 105.17962\n",
            "Epoch: 4010 Training Error: 105.17667 Validation Error: 105.17962\n",
            "Epoch: 4011 Training Error: 105.17668 Validation Error: 105.17962\n",
            "Epoch: 4012 Training Error: 105.17668 Validation Error: 105.17962\n",
            "Epoch: 4013 Training Error: 105.17667 Validation Error: 105.17961\n",
            "Epoch: 4014 Training Error: 105.17668 Validation Error: 105.17961\n",
            "Epoch: 4015 Training Error: 105.1767 Validation Error: 105.179596\n",
            "Epoch: 4016 Training Error: 105.17672 Validation Error: 105.179596\n",
            "Epoch: 4017 Training Error: 105.176704 Validation Error: 105.179596\n",
            "Epoch: 4018 Training Error: 105.1767 Validation Error: 105.17958\n",
            "Epoch: 4019 Training Error: 105.17667 Validation Error: 105.17958\n",
            "Epoch: 4020 Training Error: 105.17667 Validation Error: 105.17957\n",
            "Epoch: 4021 Training Error: 105.17666 Validation Error: 105.17957\n",
            "Epoch: 4022 Training Error: 105.17666 Validation Error: 105.17957\n",
            "Epoch: 4023 Training Error: 105.17664 Validation Error: 105.17956\n",
            "Epoch: 4024 Training Error: 105.17664 Validation Error: 105.17956\n",
            "Epoch: 4025 Training Error: 105.176636 Validation Error: 105.17956\n",
            "Epoch: 4026 Training Error: 105.17662 Validation Error: 105.17956\n",
            "Epoch: 4027 Training Error: 105.17662 Validation Error: 105.17956\n",
            "Epoch: 4028 Training Error: 105.17662 Validation Error: 105.17956\n",
            "Epoch: 4029 Training Error: 105.176605 Validation Error: 105.17956\n",
            "Epoch: 4030 Training Error: 105.1766 Validation Error: 105.17957\n",
            "Epoch: 4031 Training Error: 105.1766 Validation Error: 105.17957\n",
            "Epoch: 4032 Training Error: 105.17658 Validation Error: 105.17957\n",
            "Epoch: 4033 Training Error: 105.17658 Validation Error: 105.17956\n",
            "Epoch: 4034 Training Error: 105.17658 Validation Error: 105.17956\n",
            "Epoch: 4035 Training Error: 105.17658 Validation Error: 105.17956\n",
            "Epoch: 4036 Training Error: 105.17658 Validation Error: 105.17956\n",
            "Epoch: 4037 Training Error: 105.17658 Validation Error: 105.17956\n",
            "Epoch: 4038 Training Error: 105.17657 Validation Error: 105.17957\n",
            "Epoch: 4039 Training Error: 105.17657 Validation Error: 105.17957\n",
            "Epoch: 4040 Training Error: 105.17657 Validation Error: 105.17956\n",
            "Epoch: 4041 Training Error: 105.17657 Validation Error: 105.17955\n",
            "Epoch: 4042 Training Error: 105.17657 Validation Error: 105.179535\n",
            "Epoch: 4043 Training Error: 105.17656 Validation Error: 105.17955\n",
            "Epoch: 4044 Training Error: 105.17656 Validation Error: 105.179535\n",
            "Epoch: 4045 Training Error: 105.17656 Validation Error: 105.17955\n",
            "Epoch: 4046 Training Error: 105.176544 Validation Error: 105.17952\n",
            "Epoch: 4047 Training Error: 105.176544 Validation Error: 105.17952\n",
            "Epoch: 4048 Training Error: 105.176544 Validation Error: 105.17952\n",
            "Epoch: 4049 Training Error: 105.176544 Validation Error: 105.17951\n",
            "Epoch: 4050 Training Error: 105.176544 Validation Error: 105.1795\n",
            "Epoch: 4051 Training Error: 105.176544 Validation Error: 105.1795\n",
            "Epoch: 4052 Training Error: 105.17654 Validation Error: 105.17951\n",
            "Epoch: 4053 Training Error: 105.17654 Validation Error: 105.1795\n",
            "Epoch: 4054 Training Error: 105.17654 Validation Error: 105.17951\n",
            "Epoch: 4055 Training Error: 105.17654 Validation Error: 105.17951\n",
            "Epoch: 4056 Training Error: 105.17654 Validation Error: 105.17951\n",
            "Epoch: 4057 Training Error: 105.17652 Validation Error: 105.17951\n",
            "Epoch: 4058 Training Error: 105.17652 Validation Error: 105.1795\n",
            "Epoch: 4059 Training Error: 105.17652 Validation Error: 105.17951\n",
            "Epoch: 4060 Training Error: 105.17652 Validation Error: 105.1795\n",
            "Epoch: 4061 Training Error: 105.176506 Validation Error: 105.17948\n",
            "Epoch: 4062 Training Error: 105.176506 Validation Error: 105.17948\n",
            "Epoch: 4063 Training Error: 105.176506 Validation Error: 105.1795\n",
            "Epoch: 4064 Training Error: 105.176506 Validation Error: 105.17948\n",
            "Epoch: 4065 Training Error: 105.176506 Validation Error: 105.17948\n",
            "Epoch: 4066 Training Error: 105.176506 Validation Error: 105.1795\n",
            "Epoch: 4067 Training Error: 105.1765 Validation Error: 105.1795\n",
            "Epoch: 4068 Training Error: 105.1765 Validation Error: 105.1795\n",
            "Epoch: 4069 Training Error: 105.1765 Validation Error: 105.1795\n",
            "Epoch: 4070 Training Error: 105.1765 Validation Error: 105.1795\n",
            "Epoch: 4071 Training Error: 105.1765 Validation Error: 105.1795\n",
            "Epoch: 4072 Training Error: 105.17648 Validation Error: 105.17948\n",
            "Epoch: 4073 Training Error: 105.17648 Validation Error: 105.179474\n",
            "Epoch: 4074 Training Error: 105.17647 Validation Error: 105.17946\n",
            "Epoch: 4075 Training Error: 105.17647 Validation Error: 105.17946\n",
            "Epoch: 4076 Training Error: 105.17647 Validation Error: 105.17946\n",
            "Epoch: 4077 Training Error: 105.17647 Validation Error: 105.17944\n",
            "Epoch: 4078 Training Error: 105.17646 Validation Error: 105.17944\n",
            "Epoch: 4079 Training Error: 105.17647 Validation Error: 105.179474\n",
            "Epoch: 4080 Training Error: 105.17648 Validation Error: 105.179474\n",
            "Epoch: 4081 Training Error: 105.17647 Validation Error: 105.179474\n",
            "Epoch: 4082 Training Error: 105.17647 Validation Error: 105.179474\n",
            "Epoch: 4083 Training Error: 105.17647 Validation Error: 105.17946\n",
            "Epoch: 4084 Training Error: 105.17646 Validation Error: 105.17946\n",
            "Epoch: 4085 Training Error: 105.17646 Validation Error: 105.17944\n",
            "Epoch: 4086 Training Error: 105.17646 Validation Error: 105.17944\n",
            "Epoch: 4087 Training Error: 105.17646 Validation Error: 105.17944\n",
            "Epoch: 4088 Training Error: 105.176445 Validation Error: 105.179436\n",
            "Epoch: 4089 Training Error: 105.176445 Validation Error: 105.17942\n",
            "Epoch: 4090 Training Error: 105.176445 Validation Error: 105.17942\n",
            "Epoch: 4091 Training Error: 105.176445 Validation Error: 105.17942\n",
            "Epoch: 4092 Training Error: 105.17643 Validation Error: 105.17942\n",
            "Epoch: 4093 Training Error: 105.17643 Validation Error: 105.17941\n",
            "Epoch: 4094 Training Error: 105.17643 Validation Error: 105.17941\n",
            "Epoch: 4095 Training Error: 105.17642 Validation Error: 105.17938\n",
            "Epoch: 4096 Training Error: 105.17642 Validation Error: 105.179375\n",
            "Epoch: 4097 Training Error: 105.17641 Validation Error: 105.179375\n",
            "Epoch: 4098 Training Error: 105.17641 Validation Error: 105.17936\n",
            "Epoch: 4099 Training Error: 105.17641 Validation Error: 105.179344\n",
            "Epoch: 4100 Training Error: 105.17641 Validation Error: 105.179344\n",
            "Epoch: 4101 Training Error: 105.1764 Validation Error: 105.17936\n",
            "Epoch: 4102 Training Error: 105.17641 Validation Error: 105.179375\n",
            "Epoch: 4103 Training Error: 105.17641 Validation Error: 105.179375\n",
            "Epoch: 4104 Training Error: 105.17641 Validation Error: 105.179375\n",
            "Epoch: 4105 Training Error: 105.1764 Validation Error: 105.179344\n",
            "Epoch: 4106 Training Error: 105.1764 Validation Error: 105.17934\n",
            "Epoch: 4107 Training Error: 105.1764 Validation Error: 105.17934\n",
            "Epoch: 4108 Training Error: 105.1764 Validation Error: 105.179344\n",
            "Epoch: 4109 Training Error: 105.1764 Validation Error: 105.179344\n",
            "Epoch: 4110 Training Error: 105.176384 Validation Error: 105.17934\n",
            "Epoch: 4111 Training Error: 105.176384 Validation Error: 105.17934\n",
            "Epoch: 4112 Training Error: 105.176384 Validation Error: 105.17934\n",
            "Epoch: 4113 Training Error: 105.176384 Validation Error: 105.17934\n",
            "Epoch: 4114 Training Error: 105.176384 Validation Error: 105.17932\n",
            "Epoch: 4115 Training Error: 105.17637 Validation Error: 105.179306\n",
            "Epoch: 4116 Training Error: 105.176384 Validation Error: 105.17934\n",
            "Epoch: 4117 Training Error: 105.17637 Validation Error: 105.179344\n",
            "Epoch: 4118 Training Error: 105.17637 Validation Error: 105.179344\n",
            "Epoch: 4119 Training Error: 105.176384 Validation Error: 105.17936\n",
            "Epoch: 4120 Training Error: 105.176384 Validation Error: 105.179375\n",
            "Epoch: 4121 Training Error: 105.1764 Validation Error: 105.17938\n",
            "Epoch: 4122 Training Error: 105.1764 Validation Error: 105.17938\n",
            "Epoch: 4123 Training Error: 105.1764 Validation Error: 105.1794\n",
            "Epoch: 4124 Training Error: 105.176384 Validation Error: 105.179375\n",
            "Epoch: 4125 Training Error: 105.176384 Validation Error: 105.17936\n",
            "Epoch: 4126 Training Error: 105.176384 Validation Error: 105.179375\n",
            "Epoch: 4127 Training Error: 105.17637 Validation Error: 105.17936\n",
            "Epoch: 4128 Training Error: 105.17637 Validation Error: 105.17936\n",
            "Epoch: 4129 Training Error: 105.17637 Validation Error: 105.179344\n",
            "Epoch: 4130 Training Error: 105.17637 Validation Error: 105.17936\n",
            "Epoch: 4131 Training Error: 105.17637 Validation Error: 105.17936\n",
            "Epoch: 4132 Training Error: 105.17637 Validation Error: 105.179375\n",
            "Epoch: 4133 Training Error: 105.17636 Validation Error: 105.179344\n",
            "Epoch: 4134 Training Error: 105.17636 Validation Error: 105.17934\n",
            "Epoch: 4135 Training Error: 105.176346 Validation Error: 105.17932\n",
            "Epoch: 4136 Training Error: 105.176346 Validation Error: 105.17932\n",
            "Epoch: 4137 Training Error: 105.176346 Validation Error: 105.17932\n",
            "Epoch: 4138 Training Error: 105.176346 Validation Error: 105.179306\n",
            "Epoch: 4139 Training Error: 105.17632 Validation Error: 105.179276\n",
            "Epoch: 4140 Training Error: 105.17631 Validation Error: 105.17926\n",
            "Epoch: 4141 Training Error: 105.17632 Validation Error: 105.17928\n",
            "Epoch: 4142 Training Error: 105.176346 Validation Error: 105.17934\n",
            "Epoch: 4143 Training Error: 105.176346 Validation Error: 105.17934\n",
            "Epoch: 4144 Training Error: 105.176346 Validation Error: 105.17934\n",
            "Epoch: 4145 Training Error: 105.17636 Validation Error: 105.17936\n",
            "Epoch: 4146 Training Error: 105.17636 Validation Error: 105.17936\n",
            "Epoch: 4147 Training Error: 105.176346 Validation Error: 105.17934\n",
            "Epoch: 4148 Training Error: 105.17633 Validation Error: 105.17932\n",
            "Epoch: 4149 Training Error: 105.17631 Validation Error: 105.17928\n",
            "Epoch: 4150 Training Error: 105.17631 Validation Error: 105.179276\n",
            "Epoch: 4151 Training Error: 105.17631 Validation Error: 105.179276\n",
            "Epoch: 4152 Training Error: 105.17632 Validation Error: 105.17928\n",
            "Epoch: 4153 Training Error: 105.17631 Validation Error: 105.17928\n",
            "Epoch: 4154 Training Error: 105.17631 Validation Error: 105.179276\n",
            "Epoch: 4155 Training Error: 105.1763 Validation Error: 105.17926\n",
            "Epoch: 4156 Training Error: 105.1763 Validation Error: 105.17926\n",
            "Epoch: 4157 Training Error: 105.17631 Validation Error: 105.17928\n",
            "Epoch: 4158 Training Error: 105.17631 Validation Error: 105.1793\n",
            "Epoch: 4159 Training Error: 105.1763 Validation Error: 105.179276\n",
            "Epoch: 4160 Training Error: 105.1763 Validation Error: 105.17926\n",
            "Epoch: 4161 Training Error: 105.1763 Validation Error: 105.179276\n",
            "Epoch: 4162 Training Error: 105.17631 Validation Error: 105.17928\n",
            "Epoch: 4163 Training Error: 105.1763 Validation Error: 105.17926\n",
            "Epoch: 4164 Training Error: 105.176285 Validation Error: 105.179245\n",
            "Epoch: 4165 Training Error: 105.176285 Validation Error: 105.179245\n",
            "Epoch: 4166 Training Error: 105.176285 Validation Error: 105.179245\n",
            "Epoch: 4167 Training Error: 105.17626 Validation Error: 105.17922\n",
            "Epoch: 4168 Training Error: 105.17626 Validation Error: 105.1792\n",
            "Epoch: 4169 Training Error: 105.17626 Validation Error: 105.17921\n",
            "Epoch: 4170 Training Error: 105.17626 Validation Error: 105.17921\n",
            "Epoch: 4171 Training Error: 105.17626 Validation Error: 105.17921\n",
            "Epoch: 4172 Training Error: 105.17626 Validation Error: 105.17921\n",
            "Epoch: 4173 Training Error: 105.17626 Validation Error: 105.1792\n",
            "Epoch: 4174 Training Error: 105.17626 Validation Error: 105.17921\n",
            "Epoch: 4175 Training Error: 105.17627 Validation Error: 105.17924\n",
            "Epoch: 4176 Training Error: 105.17626 Validation Error: 105.17924\n",
            "Epoch: 4177 Training Error: 105.17627 Validation Error: 105.17924\n",
            "Epoch: 4178 Training Error: 105.17626 Validation Error: 105.17922\n",
            "Epoch: 4179 Training Error: 105.17627 Validation Error: 105.179245\n",
            "Epoch: 4180 Training Error: 105.176285 Validation Error: 105.179276\n",
            "Epoch: 4181 Training Error: 105.1763 Validation Error: 105.17928\n",
            "Epoch: 4182 Training Error: 105.176285 Validation Error: 105.17926\n",
            "Epoch: 4183 Training Error: 105.176285 Validation Error: 105.17926\n",
            "Epoch: 4184 Training Error: 105.1763 Validation Error: 105.17928\n",
            "Epoch: 4185 Training Error: 105.176285 Validation Error: 105.179276\n",
            "Epoch: 4186 Training Error: 105.17627 Validation Error: 105.179245\n",
            "Epoch: 4187 Training Error: 105.17626 Validation Error: 105.17924\n",
            "Epoch: 4188 Training Error: 105.17625 Validation Error: 105.17921\n",
            "Epoch: 4189 Training Error: 105.17625 Validation Error: 105.1792\n",
            "Epoch: 4190 Training Error: 105.17622 Validation Error: 105.17918\n",
            "Epoch: 4191 Training Error: 105.17623 Validation Error: 105.1792\n",
            "Epoch: 4192 Training Error: 105.17622 Validation Error: 105.17918\n",
            "Epoch: 4193 Training Error: 105.17622 Validation Error: 105.17916\n",
            "Epoch: 4194 Training Error: 105.17621 Validation Error: 105.17914\n",
            "Epoch: 4195 Training Error: 105.17619 Validation Error: 105.17914\n",
            "Epoch: 4196 Training Error: 105.17619 Validation Error: 105.17912\n",
            "Epoch: 4197 Training Error: 105.17617 Validation Error: 105.179085\n",
            "Epoch: 4198 Training Error: 105.176186 Validation Error: 105.1791\n",
            "Epoch: 4199 Training Error: 105.17617 Validation Error: 105.1791\n",
            "Epoch: 4200 Training Error: 105.176186 Validation Error: 105.17911\n",
            "Epoch: 4201 Training Error: 105.17619 Validation Error: 105.179146\n",
            "Epoch: 4202 Training Error: 105.17621 Validation Error: 105.179146\n",
            "Epoch: 4203 Training Error: 105.17621 Validation Error: 105.17918\n",
            "Epoch: 4204 Training Error: 105.17622 Validation Error: 105.17918\n",
            "Epoch: 4205 Training Error: 105.17622 Validation Error: 105.17918\n",
            "Epoch: 4206 Training Error: 105.17623 Validation Error: 105.1792\n",
            "Epoch: 4207 Training Error: 105.17622 Validation Error: 105.179184\n",
            "Epoch: 4208 Training Error: 105.17622 Validation Error: 105.179184\n",
            "Epoch: 4209 Training Error: 105.17625 Validation Error: 105.17922\n",
            "Epoch: 4210 Training Error: 105.17625 Validation Error: 105.17922\n",
            "Epoch: 4211 Training Error: 105.17625 Validation Error: 105.17921\n",
            "Epoch: 4212 Training Error: 105.17627 Validation Error: 105.179245\n",
            "Epoch: 4213 Training Error: 105.17622 Validation Error: 105.1792\n",
            "Epoch: 4214 Training Error: 105.17622 Validation Error: 105.179184\n",
            "Epoch: 4215 Training Error: 105.17619 Validation Error: 105.17914\n",
            "Epoch: 4216 Training Error: 105.176186 Validation Error: 105.17912\n",
            "Epoch: 4217 Training Error: 105.17617 Validation Error: 105.1791\n",
            "Epoch: 4218 Training Error: 105.17616 Validation Error: 105.179085\n",
            "Epoch: 4219 Training Error: 105.17616 Validation Error: 105.179085\n",
            "Epoch: 4220 Training Error: 105.17616 Validation Error: 105.179085\n",
            "Epoch: 4221 Training Error: 105.17615 Validation Error: 105.17905\n",
            "Epoch: 4222 Training Error: 105.17611 Validation Error: 105.179\n",
            "Epoch: 4223 Training Error: 105.176094 Validation Error: 105.17897\n",
            "Epoch: 4224 Training Error: 105.17609 Validation Error: 105.17895\n",
            "Epoch: 4225 Training Error: 105.17607 Validation Error: 105.178925\n",
            "Epoch: 4226 Training Error: 105.17607 Validation Error: 105.17889\n",
            "Epoch: 4227 Training Error: 105.17606 Validation Error: 105.17887\n",
            "Epoch: 4228 Training Error: 105.17606 Validation Error: 105.17886\n",
            "Epoch: 4229 Training Error: 105.17606 Validation Error: 105.17886\n",
            "Epoch: 4230 Training Error: 105.17606 Validation Error: 105.17885\n",
            "Epoch: 4231 Training Error: 105.17605 Validation Error: 105.17885\n",
            "Epoch: 4232 Training Error: 105.17605 Validation Error: 105.17885\n",
            "Epoch: 4233 Training Error: 105.17605 Validation Error: 105.17886\n",
            "Epoch: 4234 Training Error: 105.17605 Validation Error: 105.17886\n",
            "Epoch: 4235 Training Error: 105.17605 Validation Error: 105.17883\n",
            "Epoch: 4236 Training Error: 105.17603 Validation Error: 105.178825\n",
            "Epoch: 4237 Training Error: 105.17603 Validation Error: 105.1788\n",
            "Epoch: 4238 Training Error: 105.17605 Validation Error: 105.17879\n",
            "Epoch: 4239 Training Error: 105.17605 Validation Error: 105.17877\n",
            "Epoch: 4240 Training Error: 105.17605 Validation Error: 105.17877\n",
            "Epoch: 4241 Training Error: 105.17606 Validation Error: 105.17877\n",
            "Epoch: 4242 Training Error: 105.17606 Validation Error: 105.17877\n",
            "Epoch: 4243 Training Error: 105.17607 Validation Error: 105.17877\n",
            "Epoch: 4244 Training Error: 105.17609 Validation Error: 105.178764\n",
            "Epoch: 4245 Training Error: 105.17606 Validation Error: 105.178764\n",
            "Epoch: 4246 Training Error: 105.17606 Validation Error: 105.178764\n",
            "Epoch: 4247 Training Error: 105.17606 Validation Error: 105.178764\n",
            "Epoch: 4248 Training Error: 105.17603 Validation Error: 105.17875\n",
            "Epoch: 4249 Training Error: 105.17603 Validation Error: 105.17875\n",
            "Epoch: 4250 Training Error: 105.176025 Validation Error: 105.17875\n",
            "Epoch: 4251 Training Error: 105.17601 Validation Error: 105.178764\n",
            "Epoch: 4252 Training Error: 105.17601 Validation Error: 105.178764\n",
            "Epoch: 4253 Training Error: 105.175995 Validation Error: 105.17879\n",
            "Epoch: 4254 Training Error: 105.17601 Validation Error: 105.1788\n",
            "Epoch: 4255 Training Error: 105.175995 Validation Error: 105.1788\n",
            "Epoch: 4256 Training Error: 105.175995 Validation Error: 105.17881\n",
            "Epoch: 4257 Training Error: 105.17601 Validation Error: 105.17883\n",
            "Epoch: 4258 Training Error: 105.176025 Validation Error: 105.17886\n",
            "Epoch: 4259 Training Error: 105.176025 Validation Error: 105.17886\n",
            "Epoch: 4260 Training Error: 105.17601 Validation Error: 105.17886\n",
            "Epoch: 4261 Training Error: 105.176025 Validation Error: 105.17887\n",
            "Epoch: 4262 Training Error: 105.176025 Validation Error: 105.17889\n",
            "Epoch: 4263 Training Error: 105.176025 Validation Error: 105.17889\n",
            "Epoch: 4264 Training Error: 105.176025 Validation Error: 105.17887\n",
            "Epoch: 4265 Training Error: 105.176025 Validation Error: 105.17887\n",
            "Epoch: 4266 Training Error: 105.17601 Validation Error: 105.17886\n",
            "Epoch: 4267 Training Error: 105.17601 Validation Error: 105.17885\n",
            "Epoch: 4268 Training Error: 105.17601 Validation Error: 105.17886\n",
            "Epoch: 4269 Training Error: 105.175995 Validation Error: 105.17883\n",
            "Epoch: 4270 Training Error: 105.17599 Validation Error: 105.178825\n",
            "Epoch: 4271 Training Error: 105.17599 Validation Error: 105.178825\n",
            "Epoch: 4272 Training Error: 105.17597 Validation Error: 105.17879\n",
            "Epoch: 4273 Training Error: 105.17597 Validation Error: 105.17879\n",
            "Epoch: 4274 Training Error: 105.17596 Validation Error: 105.17877\n",
            "Epoch: 4275 Training Error: 105.17596 Validation Error: 105.17877\n",
            "Epoch: 4276 Training Error: 105.17597 Validation Error: 105.17879\n",
            "Epoch: 4277 Training Error: 105.17597 Validation Error: 105.1788\n",
            "Epoch: 4278 Training Error: 105.17597 Validation Error: 105.1788\n",
            "Epoch: 4279 Training Error: 105.17596 Validation Error: 105.17879\n",
            "Epoch: 4280 Training Error: 105.17596 Validation Error: 105.1788\n",
            "Epoch: 4281 Training Error: 105.17596 Validation Error: 105.1788\n",
            "Epoch: 4282 Training Error: 105.17596 Validation Error: 105.17877\n",
            "Epoch: 4283 Training Error: 105.17596 Validation Error: 105.17877\n",
            "Epoch: 4284 Training Error: 105.17596 Validation Error: 105.17879\n",
            "Epoch: 4285 Training Error: 105.17595 Validation Error: 105.17877\n",
            "Epoch: 4286 Training Error: 105.17596 Validation Error: 105.17879\n",
            "Epoch: 4287 Training Error: 105.17596 Validation Error: 105.17879\n",
            "Epoch: 4288 Training Error: 105.175934 Validation Error: 105.17875\n",
            "Epoch: 4289 Training Error: 105.17593 Validation Error: 105.17873\n",
            "Epoch: 4290 Training Error: 105.17591 Validation Error: 105.17871\n",
            "Epoch: 4291 Training Error: 105.17591 Validation Error: 105.1787\n",
            "Epoch: 4292 Training Error: 105.17591 Validation Error: 105.1787\n",
            "Epoch: 4293 Training Error: 105.175896 Validation Error: 105.17867\n",
            "Epoch: 4294 Training Error: 105.175896 Validation Error: 105.17869\n",
            "Epoch: 4295 Training Error: 105.175896 Validation Error: 105.17867\n",
            "Epoch: 4296 Training Error: 105.17589 Validation Error: 105.178665\n",
            "Epoch: 4297 Training Error: 105.17589 Validation Error: 105.178635\n",
            "Epoch: 4298 Training Error: 105.17587 Validation Error: 105.178635\n",
            "Epoch: 4299 Training Error: 105.17587 Validation Error: 105.17861\n",
            "Epoch: 4300 Training Error: 105.17587 Validation Error: 105.1786\n",
            "Epoch: 4301 Training Error: 105.17587 Validation Error: 105.17859\n",
            "Epoch: 4302 Training Error: 105.17587 Validation Error: 105.17859\n",
            "Epoch: 4303 Training Error: 105.17587 Validation Error: 105.17857\n",
            "Epoch: 4304 Training Error: 105.17587 Validation Error: 105.17857\n",
            "Epoch: 4305 Training Error: 105.17587 Validation Error: 105.17857\n",
            "Epoch: 4306 Training Error: 105.17587 Validation Error: 105.178566\n",
            "Epoch: 4307 Training Error: 105.17586 Validation Error: 105.178566\n",
            "Epoch: 4308 Training Error: 105.17586 Validation Error: 105.178566\n",
            "Epoch: 4309 Training Error: 105.17586 Validation Error: 105.178566\n",
            "Epoch: 4310 Training Error: 105.17586 Validation Error: 105.17855\n",
            "Epoch: 4311 Training Error: 105.17586 Validation Error: 105.178535\n",
            "Epoch: 4312 Training Error: 105.17585 Validation Error: 105.17855\n",
            "Epoch: 4313 Training Error: 105.175835 Validation Error: 105.178535\n",
            "Epoch: 4314 Training Error: 105.175835 Validation Error: 105.17855\n",
            "Epoch: 4315 Training Error: 105.175835 Validation Error: 105.178566\n",
            "Epoch: 4316 Training Error: 105.175835 Validation Error: 105.178566\n",
            "Epoch: 4317 Training Error: 105.17583 Validation Error: 105.178535\n",
            "Epoch: 4318 Training Error: 105.175835 Validation Error: 105.178535\n",
            "Epoch: 4319 Training Error: 105.175835 Validation Error: 105.17853\n",
            "Epoch: 4320 Training Error: 105.175835 Validation Error: 105.17851\n",
            "Epoch: 4321 Training Error: 105.175835 Validation Error: 105.17851\n",
            "Epoch: 4322 Training Error: 105.17583 Validation Error: 105.17851\n",
            "Epoch: 4323 Training Error: 105.17583 Validation Error: 105.17851\n",
            "Epoch: 4324 Training Error: 105.17581 Validation Error: 105.17851\n",
            "Epoch: 4325 Training Error: 105.17581 Validation Error: 105.17851\n",
            "Epoch: 4326 Training Error: 105.1758 Validation Error: 105.17853\n",
            "Epoch: 4327 Training Error: 105.1758 Validation Error: 105.17853\n",
            "Epoch: 4328 Training Error: 105.1758 Validation Error: 105.17853\n",
            "Epoch: 4329 Training Error: 105.1758 Validation Error: 105.17853\n",
            "Epoch: 4330 Training Error: 105.1758 Validation Error: 105.17853\n",
            "Epoch: 4331 Training Error: 105.17579 Validation Error: 105.17853\n",
            "Epoch: 4332 Training Error: 105.17579 Validation Error: 105.17851\n",
            "Epoch: 4333 Training Error: 105.17579 Validation Error: 105.1785\n",
            "Epoch: 4334 Training Error: 105.17579 Validation Error: 105.17849\n",
            "Epoch: 4335 Training Error: 105.17579 Validation Error: 105.1785\n",
            "Epoch: 4336 Training Error: 105.17577 Validation Error: 105.1785\n",
            "Epoch: 4337 Training Error: 105.17577 Validation Error: 105.17849\n",
            "Epoch: 4338 Training Error: 105.17577 Validation Error: 105.17849\n",
            "Epoch: 4339 Training Error: 105.17577 Validation Error: 105.178474\n",
            "Epoch: 4340 Training Error: 105.17576 Validation Error: 105.1785\n",
            "Epoch: 4341 Training Error: 105.17577 Validation Error: 105.1785\n",
            "Epoch: 4342 Training Error: 105.17577 Validation Error: 105.17851\n",
            "Epoch: 4343 Training Error: 105.17576 Validation Error: 105.17851\n",
            "Epoch: 4344 Training Error: 105.17575 Validation Error: 105.1785\n",
            "Epoch: 4345 Training Error: 105.17575 Validation Error: 105.17849\n",
            "Epoch: 4346 Training Error: 105.17575 Validation Error: 105.1785\n",
            "Epoch: 4347 Training Error: 105.17575 Validation Error: 105.1785\n",
            "Epoch: 4348 Training Error: 105.17575 Validation Error: 105.17849\n",
            "Epoch: 4349 Training Error: 105.17575 Validation Error: 105.1785\n",
            "Epoch: 4350 Training Error: 105.17575 Validation Error: 105.17851\n",
            "Epoch: 4351 Training Error: 105.175735 Validation Error: 105.17849\n",
            "Epoch: 4352 Training Error: 105.175735 Validation Error: 105.17849\n",
            "Epoch: 4353 Training Error: 105.175735 Validation Error: 105.178474\n",
            "Epoch: 4354 Training Error: 105.175735 Validation Error: 105.1785\n",
            "Epoch: 4355 Training Error: 105.17575 Validation Error: 105.17851\n",
            "Epoch: 4356 Training Error: 105.17575 Validation Error: 105.17851\n",
            "Epoch: 4357 Training Error: 105.175735 Validation Error: 105.1785\n",
            "Epoch: 4358 Training Error: 105.175735 Validation Error: 105.17849\n",
            "Epoch: 4359 Training Error: 105.17572 Validation Error: 105.17847\n",
            "Epoch: 4360 Training Error: 105.17571 Validation Error: 105.17844\n",
            "Epoch: 4361 Training Error: 105.17571 Validation Error: 105.17844\n",
            "Epoch: 4362 Training Error: 105.17571 Validation Error: 105.17844\n",
            "Epoch: 4363 Training Error: 105.17571 Validation Error: 105.17844\n",
            "Epoch: 4364 Training Error: 105.17571 Validation Error: 105.17844\n",
            "Epoch: 4365 Training Error: 105.1757 Validation Error: 105.17844\n",
            "Epoch: 4366 Training Error: 105.17571 Validation Error: 105.17847\n",
            "Epoch: 4367 Training Error: 105.17571 Validation Error: 105.178474\n",
            "Epoch: 4368 Training Error: 105.17571 Validation Error: 105.178474\n",
            "Epoch: 4369 Training Error: 105.17571 Validation Error: 105.178474\n",
            "Epoch: 4370 Training Error: 105.17571 Validation Error: 105.178474\n",
            "Epoch: 4371 Training Error: 105.17572 Validation Error: 105.17849\n",
            "Epoch: 4372 Training Error: 105.17571 Validation Error: 105.178474\n",
            "Epoch: 4373 Training Error: 105.1757 Validation Error: 105.17847\n",
            "Epoch: 4374 Training Error: 105.1757 Validation Error: 105.17845\n",
            "Epoch: 4375 Training Error: 105.1757 Validation Error: 105.17844\n",
            "Epoch: 4376 Training Error: 105.1757 Validation Error: 105.17847\n",
            "Epoch: 4377 Training Error: 105.17571 Validation Error: 105.178474\n",
            "Epoch: 4378 Training Error: 105.1757 Validation Error: 105.17845\n",
            "Epoch: 4379 Training Error: 105.17569 Validation Error: 105.17843\n",
            "Epoch: 4380 Training Error: 105.175674 Validation Error: 105.17843\n",
            "Epoch: 4381 Training Error: 105.175674 Validation Error: 105.1784\n",
            "Epoch: 4382 Training Error: 105.17565 Validation Error: 105.178375\n",
            "Epoch: 4383 Training Error: 105.17566 Validation Error: 105.178375\n",
            "Epoch: 4384 Training Error: 105.17565 Validation Error: 105.17835\n",
            "Epoch: 4385 Training Error: 105.17564 Validation Error: 105.17833\n",
            "Epoch: 4386 Training Error: 105.17564 Validation Error: 105.178314\n",
            "Epoch: 4387 Training Error: 105.17565 Validation Error: 105.178314\n",
            "Epoch: 4388 Training Error: 105.17564 Validation Error: 105.178314\n",
            "Epoch: 4389 Training Error: 105.17564 Validation Error: 105.178314\n",
            "Epoch: 4390 Training Error: 105.17564 Validation Error: 105.1783\n",
            "Epoch: 4391 Training Error: 105.17564 Validation Error: 105.1783\n",
            "Epoch: 4392 Training Error: 105.17564 Validation Error: 105.1783\n",
            "Epoch: 4393 Training Error: 105.17564 Validation Error: 105.17829\n",
            "Epoch: 4394 Training Error: 105.17562 Validation Error: 105.17829\n",
            "Epoch: 4395 Training Error: 105.17564 Validation Error: 105.178276\n",
            "Epoch: 4396 Training Error: 105.17564 Validation Error: 105.178276\n",
            "Epoch: 4397 Training Error: 105.17562 Validation Error: 105.17826\n",
            "Epoch: 4398 Training Error: 105.17562 Validation Error: 105.17826\n",
            "Epoch: 4399 Training Error: 105.17561 Validation Error: 105.178276\n",
            "Epoch: 4400 Training Error: 105.17561 Validation Error: 105.178276\n",
            "Epoch: 4401 Training Error: 105.17561 Validation Error: 105.17826\n",
            "Epoch: 4402 Training Error: 105.1756 Validation Error: 105.178276\n",
            "Epoch: 4403 Training Error: 105.1756 Validation Error: 105.178276\n",
            "Epoch: 4404 Training Error: 105.1756 Validation Error: 105.178276\n",
            "Epoch: 4405 Training Error: 105.1756 Validation Error: 105.178276\n",
            "Epoch: 4406 Training Error: 105.17558 Validation Error: 105.178276\n",
            "Epoch: 4407 Training Error: 105.17558 Validation Error: 105.178276\n",
            "Epoch: 4408 Training Error: 105.17558 Validation Error: 105.17826\n",
            "Epoch: 4409 Training Error: 105.17558 Validation Error: 105.17826\n",
            "Epoch: 4410 Training Error: 105.175575 Validation Error: 105.17825\n",
            "Epoch: 4411 Training Error: 105.175575 Validation Error: 105.17824\n",
            "Epoch: 4412 Training Error: 105.17558 Validation Error: 105.178215\n",
            "Epoch: 4413 Training Error: 105.17558 Validation Error: 105.178215\n",
            "Epoch: 4414 Training Error: 105.1756 Validation Error: 105.1782\n",
            "Epoch: 4415 Training Error: 105.1756 Validation Error: 105.1782\n",
            "Epoch: 4416 Training Error: 105.1756 Validation Error: 105.1782\n",
            "Epoch: 4417 Training Error: 105.1756 Validation Error: 105.17819\n",
            "Epoch: 4418 Training Error: 105.1756 Validation Error: 105.17819\n",
            "Epoch: 4419 Training Error: 105.17558 Validation Error: 105.17819\n",
            "Epoch: 4420 Training Error: 105.17558 Validation Error: 105.17819\n",
            "Epoch: 4421 Training Error: 105.17558 Validation Error: 105.17818\n",
            "Epoch: 4422 Training Error: 105.175575 Validation Error: 105.17818\n",
            "Epoch: 4423 Training Error: 105.17556 Validation Error: 105.17818\n",
            "Epoch: 4424 Training Error: 105.17556 Validation Error: 105.17818\n",
            "Epoch: 4425 Training Error: 105.17555 Validation Error: 105.17816\n",
            "Epoch: 4426 Training Error: 105.17555 Validation Error: 105.17816\n",
            "Epoch: 4427 Training Error: 105.17555 Validation Error: 105.17816\n",
            "Epoch: 4428 Training Error: 105.17555 Validation Error: 105.17816\n",
            "Epoch: 4429 Training Error: 105.17554 Validation Error: 105.17816\n",
            "Epoch: 4430 Training Error: 105.17554 Validation Error: 105.17816\n",
            "Epoch: 4431 Training Error: 105.17554 Validation Error: 105.178154\n",
            "Epoch: 4432 Training Error: 105.17554 Validation Error: 105.178154\n",
            "Epoch: 4433 Training Error: 105.17554 Validation Error: 105.178154\n",
            "Epoch: 4434 Training Error: 105.17552 Validation Error: 105.17814\n",
            "Epoch: 4435 Training Error: 105.17552 Validation Error: 105.178154\n",
            "Epoch: 4436 Training Error: 105.175514 Validation Error: 105.178154\n",
            "Epoch: 4437 Training Error: 105.175514 Validation Error: 105.178154\n",
            "Epoch: 4438 Training Error: 105.175514 Validation Error: 105.178154\n",
            "Epoch: 4439 Training Error: 105.175514 Validation Error: 105.17814\n",
            "Epoch: 4440 Training Error: 105.1755 Validation Error: 105.17814\n",
            "Epoch: 4441 Training Error: 105.1755 Validation Error: 105.17812\n",
            "Epoch: 4442 Training Error: 105.1755 Validation Error: 105.17812\n",
            "Epoch: 4443 Training Error: 105.1755 Validation Error: 105.178116\n",
            "Epoch: 4444 Training Error: 105.1755 Validation Error: 105.178116\n",
            "Epoch: 4445 Training Error: 105.1755 Validation Error: 105.1781\n",
            "Epoch: 4446 Training Error: 105.175514 Validation Error: 105.1781\n",
            "Epoch: 4447 Training Error: 105.17552 Validation Error: 105.17809\n",
            "Epoch: 4448 Training Error: 105.175514 Validation Error: 105.17809\n",
            "Epoch: 4449 Training Error: 105.17554 Validation Error: 105.17809\n",
            "Epoch: 4450 Training Error: 105.17554 Validation Error: 105.17809\n",
            "Epoch: 4451 Training Error: 105.17552 Validation Error: 105.17809\n",
            "Epoch: 4452 Training Error: 105.17552 Validation Error: 105.17809\n",
            "Epoch: 4453 Training Error: 105.175514 Validation Error: 105.17808\n",
            "Epoch: 4454 Training Error: 105.17552 Validation Error: 105.17808\n",
            "Epoch: 4455 Training Error: 105.17554 Validation Error: 105.17808\n",
            "Epoch: 4456 Training Error: 105.17555 Validation Error: 105.17808\n",
            "Epoch: 4457 Training Error: 105.17555 Validation Error: 105.17808\n",
            "Epoch: 4458 Training Error: 105.17556 Validation Error: 105.17808\n",
            "Epoch: 4459 Training Error: 105.17554 Validation Error: 105.17806\n",
            "Epoch: 4460 Training Error: 105.175514 Validation Error: 105.17806\n",
            "Epoch: 4461 Training Error: 105.175514 Validation Error: 105.178055\n",
            "Epoch: 4462 Training Error: 105.1755 Validation Error: 105.178055\n",
            "Epoch: 4463 Training Error: 105.1755 Validation Error: 105.178055\n",
            "Epoch: 4464 Training Error: 105.1755 Validation Error: 105.178055\n",
            "Epoch: 4465 Training Error: 105.1755 Validation Error: 105.178055\n",
            "Epoch: 4466 Training Error: 105.1755 Validation Error: 105.17804\n",
            "Epoch: 4467 Training Error: 105.17548 Validation Error: 105.17804\n",
            "Epoch: 4468 Training Error: 105.17548 Validation Error: 105.17804\n",
            "Epoch: 4469 Training Error: 105.175476 Validation Error: 105.17804\n",
            "Epoch: 4470 Training Error: 105.175476 Validation Error: 105.17804\n",
            "Epoch: 4471 Training Error: 105.175476 Validation Error: 105.178024\n",
            "Epoch: 4472 Training Error: 105.175476 Validation Error: 105.178024\n",
            "Epoch: 4473 Training Error: 105.17548 Validation Error: 105.178024\n",
            "Epoch: 4474 Training Error: 105.1755 Validation Error: 105.178024\n",
            "Epoch: 4475 Training Error: 105.17548 Validation Error: 105.178024\n",
            "Epoch: 4476 Training Error: 105.175476 Validation Error: 105.17802\n",
            "Epoch: 4477 Training Error: 105.17546 Validation Error: 105.17802\n",
            "Epoch: 4478 Training Error: 105.17546 Validation Error: 105.17802\n",
            "Epoch: 4479 Training Error: 105.17546 Validation Error: 105.178\n",
            "Epoch: 4480 Training Error: 105.17545 Validation Error: 105.178\n",
            "Epoch: 4481 Training Error: 105.17544 Validation Error: 105.178\n",
            "Epoch: 4482 Training Error: 105.17542 Validation Error: 105.178\n",
            "Epoch: 4483 Training Error: 105.175415 Validation Error: 105.178\n",
            "Epoch: 4484 Training Error: 105.175415 Validation Error: 105.178\n",
            "Epoch: 4485 Training Error: 105.1754 Validation Error: 105.17802\n",
            "Epoch: 4486 Training Error: 105.1754 Validation Error: 105.17802\n",
            "Epoch: 4487 Training Error: 105.1754 Validation Error: 105.178024\n",
            "Epoch: 4488 Training Error: 105.1754 Validation Error: 105.17804\n",
            "Epoch: 4489 Training Error: 105.1754 Validation Error: 105.17804\n",
            "Epoch: 4490 Training Error: 105.175385 Validation Error: 105.17804\n",
            "Epoch: 4491 Training Error: 105.175385 Validation Error: 105.17802\n",
            "Epoch: 4492 Training Error: 105.175385 Validation Error: 105.17802\n",
            "Epoch: 4493 Training Error: 105.175385 Validation Error: 105.17802\n",
            "Epoch: 4494 Training Error: 105.175385 Validation Error: 105.178024\n",
            "Epoch: 4495 Training Error: 105.175385 Validation Error: 105.17802\n",
            "Epoch: 4496 Training Error: 105.175385 Validation Error: 105.178024\n",
            "Epoch: 4497 Training Error: 105.175385 Validation Error: 105.17802\n",
            "Epoch: 4498 Training Error: 105.175385 Validation Error: 105.178\n",
            "Epoch: 4499 Training Error: 105.17538 Validation Error: 105.177986\n",
            "Epoch: 4500 Training Error: 105.17538 Validation Error: 105.178\n",
            "Epoch: 4501 Training Error: 105.17538 Validation Error: 105.178\n",
            "Epoch: 4502 Training Error: 105.17538 Validation Error: 105.178\n",
            "Epoch: 4503 Training Error: 105.17536 Validation Error: 105.177986\n",
            "Epoch: 4504 Training Error: 105.17536 Validation Error: 105.178\n",
            "Epoch: 4505 Training Error: 105.17536 Validation Error: 105.177986\n",
            "Epoch: 4506 Training Error: 105.17536 Validation Error: 105.177986\n",
            "Epoch: 4507 Training Error: 105.17536 Validation Error: 105.177986\n",
            "Epoch: 4508 Training Error: 105.17535 Validation Error: 105.177986\n",
            "Epoch: 4509 Training Error: 105.17535 Validation Error: 105.177986\n",
            "Epoch: 4510 Training Error: 105.17536 Validation Error: 105.178\n",
            "Epoch: 4511 Training Error: 105.17535 Validation Error: 105.177986\n",
            "Epoch: 4512 Training Error: 105.17534 Validation Error: 105.17796\n",
            "Epoch: 4513 Training Error: 105.17534 Validation Error: 105.177956\n",
            "Epoch: 4514 Training Error: 105.17534 Validation Error: 105.177956\n",
            "Epoch: 4515 Training Error: 105.17534 Validation Error: 105.177956\n",
            "Epoch: 4516 Training Error: 105.17534 Validation Error: 105.177925\n",
            "Epoch: 4517 Training Error: 105.17534 Validation Error: 105.177925\n",
            "Epoch: 4518 Training Error: 105.17532 Validation Error: 105.17792\n",
            "Epoch: 4519 Training Error: 105.17532 Validation Error: 105.1779\n",
            "Epoch: 4520 Training Error: 105.17534 Validation Error: 105.17789\n",
            "Epoch: 4521 Training Error: 105.17532 Validation Error: 105.17789\n",
            "Epoch: 4522 Training Error: 105.17534 Validation Error: 105.17788\n",
            "Epoch: 4523 Training Error: 105.17535 Validation Error: 105.17788\n",
            "Epoch: 4524 Training Error: 105.17535 Validation Error: 105.17788\n",
            "Epoch: 4525 Training Error: 105.17535 Validation Error: 105.177864\n",
            "Epoch: 4526 Training Error: 105.17535 Validation Error: 105.177864\n",
            "Epoch: 4527 Training Error: 105.17535 Validation Error: 105.17786\n",
            "Epoch: 4528 Training Error: 105.17535 Validation Error: 105.17786\n",
            "Epoch: 4529 Training Error: 105.17535 Validation Error: 105.17786\n",
            "Epoch: 4530 Training Error: 105.17534 Validation Error: 105.17786\n",
            "Epoch: 4531 Training Error: 105.17532 Validation Error: 105.17786\n",
            "Epoch: 4532 Training Error: 105.175316 Validation Error: 105.17786\n",
            "Epoch: 4533 Training Error: 105.175316 Validation Error: 105.17786\n",
            "Epoch: 4534 Training Error: 105.1753 Validation Error: 105.17786\n",
            "Epoch: 4535 Training Error: 105.1753 Validation Error: 105.17786\n",
            "Epoch: 4536 Training Error: 105.1753 Validation Error: 105.17786\n",
            "Epoch: 4537 Training Error: 105.1753 Validation Error: 105.177864\n",
            "Epoch: 4538 Training Error: 105.175285 Validation Error: 105.17788\n",
            "Epoch: 4539 Training Error: 105.175285 Validation Error: 105.177864\n",
            "Epoch: 4540 Training Error: 105.175285 Validation Error: 105.17788\n",
            "Epoch: 4541 Training Error: 105.17528 Validation Error: 105.17786\n",
            "Epoch: 4542 Training Error: 105.17528 Validation Error: 105.17784\n",
            "Epoch: 4543 Training Error: 105.17528 Validation Error: 105.17784\n",
            "Epoch: 4544 Training Error: 105.17528 Validation Error: 105.177826\n",
            "Epoch: 4545 Training Error: 105.17528 Validation Error: 105.177826\n",
            "Epoch: 4546 Training Error: 105.17528 Validation Error: 105.177826\n",
            "Epoch: 4547 Training Error: 105.17528 Validation Error: 105.177826\n",
            "Epoch: 4548 Training Error: 105.17528 Validation Error: 105.177826\n",
            "Epoch: 4549 Training Error: 105.17526 Validation Error: 105.17782\n",
            "Epoch: 4550 Training Error: 105.17526 Validation Error: 105.177826\n",
            "Epoch: 4551 Training Error: 105.17526 Validation Error: 105.17782\n",
            "Epoch: 4552 Training Error: 105.17526 Validation Error: 105.17782\n",
            "Epoch: 4553 Training Error: 105.17526 Validation Error: 105.1778\n",
            "Epoch: 4554 Training Error: 105.17526 Validation Error: 105.1778\n",
            "Epoch: 4555 Training Error: 105.17528 Validation Error: 105.17779\n",
            "Epoch: 4556 Training Error: 105.17526 Validation Error: 105.17779\n",
            "Epoch: 4557 Training Error: 105.17526 Validation Error: 105.17779\n",
            "Epoch: 4558 Training Error: 105.17526 Validation Error: 105.17778\n",
            "Epoch: 4559 Training Error: 105.17526 Validation Error: 105.17778\n",
            "Epoch: 4560 Training Error: 105.17526 Validation Error: 105.17778\n",
            "Epoch: 4561 Training Error: 105.17526 Validation Error: 105.17778\n",
            "Epoch: 4562 Training Error: 105.17526 Validation Error: 105.17778\n",
            "Epoch: 4563 Training Error: 105.17526 Validation Error: 105.177765\n",
            "Epoch: 4564 Training Error: 105.17526 Validation Error: 105.177765\n",
            "Epoch: 4565 Training Error: 105.17525 Validation Error: 105.177765\n",
            "Epoch: 4566 Training Error: 105.17524 Validation Error: 105.177765\n",
            "Epoch: 4567 Training Error: 105.17524 Validation Error: 105.177765\n",
            "Epoch: 4568 Training Error: 105.175224 Validation Error: 105.177765\n",
            "Epoch: 4569 Training Error: 105.175224 Validation Error: 105.177765\n",
            "Epoch: 4570 Training Error: 105.175224 Validation Error: 105.177765\n",
            "Epoch: 4571 Training Error: 105.175224 Validation Error: 105.17775\n",
            "Epoch: 4572 Training Error: 105.17522 Validation Error: 105.17775\n",
            "Epoch: 4573 Training Error: 105.17522 Validation Error: 105.17775\n",
            "Epoch: 4574 Training Error: 105.17522 Validation Error: 105.17775\n",
            "Epoch: 4575 Training Error: 105.17522 Validation Error: 105.177765\n",
            "Epoch: 4576 Training Error: 105.1752 Validation Error: 105.17775\n",
            "Epoch: 4577 Training Error: 105.1752 Validation Error: 105.17775\n",
            "Epoch: 4578 Training Error: 105.1752 Validation Error: 105.17775\n",
            "Epoch: 4579 Training Error: 105.1752 Validation Error: 105.17775\n",
            "Epoch: 4580 Training Error: 105.1752 Validation Error: 105.177765\n",
            "Epoch: 4581 Training Error: 105.1752 Validation Error: 105.177765\n",
            "Epoch: 4582 Training Error: 105.175186 Validation Error: 105.17775\n",
            "Epoch: 4583 Training Error: 105.175186 Validation Error: 105.17775\n",
            "Epoch: 4584 Training Error: 105.17518 Validation Error: 105.17775\n",
            "Epoch: 4585 Training Error: 105.17518 Validation Error: 105.17775\n",
            "Epoch: 4586 Training Error: 105.17518 Validation Error: 105.17775\n",
            "Epoch: 4587 Training Error: 105.17518 Validation Error: 105.17774\n",
            "Epoch: 4588 Training Error: 105.17518 Validation Error: 105.17774\n",
            "Epoch: 4589 Training Error: 105.17516 Validation Error: 105.17774\n",
            "Epoch: 4590 Training Error: 105.17518 Validation Error: 105.17774\n",
            "Epoch: 4591 Training Error: 105.17516 Validation Error: 105.17775\n",
            "Epoch: 4592 Training Error: 105.17516 Validation Error: 105.17774\n",
            "Epoch: 4593 Training Error: 105.17516 Validation Error: 105.17774\n",
            "Epoch: 4594 Training Error: 105.17516 Validation Error: 105.17773\n",
            "Epoch: 4595 Training Error: 105.17516 Validation Error: 105.17773\n",
            "Epoch: 4596 Training Error: 105.17515 Validation Error: 105.17774\n",
            "Epoch: 4597 Training Error: 105.17516 Validation Error: 105.17773\n",
            "Epoch: 4598 Training Error: 105.17515 Validation Error: 105.17773\n",
            "Epoch: 4599 Training Error: 105.17515 Validation Error: 105.17772\n",
            "Epoch: 4600 Training Error: 105.17515 Validation Error: 105.177704\n",
            "Epoch: 4601 Training Error: 105.17514 Validation Error: 105.177704\n",
            "Epoch: 4602 Training Error: 105.17514 Validation Error: 105.177704\n",
            "Epoch: 4603 Training Error: 105.17514 Validation Error: 105.17769\n",
            "Epoch: 4604 Training Error: 105.17514 Validation Error: 105.17769\n",
            "Epoch: 4605 Training Error: 105.17514 Validation Error: 105.17769\n",
            "Epoch: 4606 Training Error: 105.175125 Validation Error: 105.17768\n",
            "Epoch: 4607 Training Error: 105.175125 Validation Error: 105.17768\n",
            "Epoch: 4608 Training Error: 105.17514 Validation Error: 105.17765\n",
            "Epoch: 4609 Training Error: 105.175125 Validation Error: 105.17765\n",
            "Epoch: 4610 Training Error: 105.175125 Validation Error: 105.17764\n",
            "Epoch: 4611 Training Error: 105.175125 Validation Error: 105.17764\n",
            "Epoch: 4612 Training Error: 105.175125 Validation Error: 105.17763\n",
            "Epoch: 4613 Training Error: 105.175125 Validation Error: 105.17763\n",
            "Epoch: 4614 Training Error: 105.175125 Validation Error: 105.17763\n",
            "Epoch: 4615 Training Error: 105.175125 Validation Error: 105.17763\n",
            "Epoch: 4616 Training Error: 105.175125 Validation Error: 105.17763\n",
            "Epoch: 4617 Training Error: 105.175125 Validation Error: 105.17762\n",
            "Epoch: 4618 Training Error: 105.175125 Validation Error: 105.17762\n",
            "Epoch: 4619 Training Error: 105.175125 Validation Error: 105.17762\n",
            "Epoch: 4620 Training Error: 105.175125 Validation Error: 105.177605\n",
            "Epoch: 4621 Training Error: 105.175125 Validation Error: 105.177605\n",
            "Epoch: 4622 Training Error: 105.175125 Validation Error: 105.177605\n",
            "Epoch: 4623 Training Error: 105.17511 Validation Error: 105.177605\n",
            "Epoch: 4624 Training Error: 105.17511 Validation Error: 105.177605\n",
            "Epoch: 4625 Training Error: 105.1751 Validation Error: 105.17762\n",
            "Epoch: 4626 Training Error: 105.1751 Validation Error: 105.177605\n",
            "Epoch: 4627 Training Error: 105.1751 Validation Error: 105.17759\n",
            "Epoch: 4628 Training Error: 105.1751 Validation Error: 105.17759\n",
            "Epoch: 4629 Training Error: 105.1751 Validation Error: 105.17758\n",
            "Epoch: 4630 Training Error: 105.17509 Validation Error: 105.17759\n",
            "Epoch: 4631 Training Error: 105.17509 Validation Error: 105.17759\n",
            "Epoch: 4632 Training Error: 105.17509 Validation Error: 105.17759\n",
            "Epoch: 4633 Training Error: 105.17508 Validation Error: 105.17759\n",
            "Epoch: 4634 Training Error: 105.17508 Validation Error: 105.17762\n",
            "Epoch: 4635 Training Error: 105.17508 Validation Error: 105.17762\n",
            "Epoch: 4636 Training Error: 105.17509 Validation Error: 105.17765\n",
            "Epoch: 4637 Training Error: 105.1751 Validation Error: 105.17769\n",
            "Epoch: 4638 Training Error: 105.1751 Validation Error: 105.17769\n",
            "Epoch: 4639 Training Error: 105.1751 Validation Error: 105.177704\n",
            "Epoch: 4640 Training Error: 105.175125 Validation Error: 105.17774\n",
            "Epoch: 4641 Training Error: 105.175125 Validation Error: 105.17774\n",
            "Epoch: 4642 Training Error: 105.175125 Validation Error: 105.17775\n",
            "Epoch: 4643 Training Error: 105.17514 Validation Error: 105.17778\n",
            "Epoch: 4644 Training Error: 105.17515 Validation Error: 105.17779\n",
            "Epoch: 4645 Training Error: 105.17515 Validation Error: 105.17779\n",
            "Epoch: 4646 Training Error: 105.17516 Validation Error: 105.1778\n",
            "Epoch: 4647 Training Error: 105.17515 Validation Error: 105.1778\n",
            "Epoch: 4648 Training Error: 105.17516 Validation Error: 105.1778\n",
            "Epoch: 4649 Training Error: 105.17516 Validation Error: 105.17782\n",
            "Epoch: 4650 Training Error: 105.175186 Validation Error: 105.17784\n",
            "Epoch: 4651 Training Error: 105.17518 Validation Error: 105.177826\n",
            "Epoch: 4652 Training Error: 105.17518 Validation Error: 105.177826\n",
            "Epoch: 4653 Training Error: 105.17515 Validation Error: 105.1778\n",
            "Epoch: 4654 Training Error: 105.17515 Validation Error: 105.17779\n",
            "Epoch: 4655 Training Error: 105.17511 Validation Error: 105.17775\n",
            "Epoch: 4656 Training Error: 105.17511 Validation Error: 105.17773\n",
            "Epoch: 4657 Training Error: 105.17511 Validation Error: 105.17772\n",
            "Epoch: 4658 Training Error: 105.1751 Validation Error: 105.17772\n",
            "Epoch: 4659 Training Error: 105.1751 Validation Error: 105.17772\n",
            "Epoch: 4660 Training Error: 105.1751 Validation Error: 105.177704\n",
            "Epoch: 4661 Training Error: 105.1751 Validation Error: 105.17772\n",
            "Epoch: 4662 Training Error: 105.17509 Validation Error: 105.17769\n",
            "Epoch: 4663 Training Error: 105.17509 Validation Error: 105.177704\n",
            "Epoch: 4664 Training Error: 105.1751 Validation Error: 105.17772\n",
            "Epoch: 4665 Training Error: 105.17511 Validation Error: 105.17773\n",
            "Epoch: 4666 Training Error: 105.17508 Validation Error: 105.17768\n",
            "Epoch: 4667 Training Error: 105.175064 Validation Error: 105.17765\n",
            "Epoch: 4668 Training Error: 105.17505 Validation Error: 105.17763\n",
            "Epoch: 4669 Training Error: 105.17504 Validation Error: 105.17762\n",
            "Epoch: 4670 Training Error: 105.175026 Validation Error: 105.17759\n",
            "Epoch: 4671 Training Error: 105.17501 Validation Error: 105.17757\n",
            "Epoch: 4672 Training Error: 105.17501 Validation Error: 105.17757\n",
            "Epoch: 4673 Training Error: 105.175026 Validation Error: 105.17758\n",
            "Epoch: 4674 Training Error: 105.17501 Validation Error: 105.17757\n",
            "Epoch: 4675 Training Error: 105.17501 Validation Error: 105.17757\n",
            "Epoch: 4676 Training Error: 105.17501 Validation Error: 105.17757\n",
            "Epoch: 4677 Training Error: 105.17501 Validation Error: 105.17758\n",
            "Epoch: 4678 Training Error: 105.17501 Validation Error: 105.17757\n",
            "Epoch: 4679 Training Error: 105.175 Validation Error: 105.17754\n",
            "Epoch: 4680 Training Error: 105.17499 Validation Error: 105.17753\n",
            "Epoch: 4681 Training Error: 105.17499 Validation Error: 105.17753\n",
            "Epoch: 4682 Training Error: 105.17498 Validation Error: 105.17749\n",
            "Epoch: 4683 Training Error: 105.174965 Validation Error: 105.17748\n",
            "Epoch: 4684 Training Error: 105.174965 Validation Error: 105.17748\n",
            "Epoch: 4685 Training Error: 105.174965 Validation Error: 105.17749\n",
            "Epoch: 4686 Training Error: 105.174965 Validation Error: 105.17748\n",
            "Epoch: 4687 Training Error: 105.174965 Validation Error: 105.17748\n",
            "Epoch: 4688 Training Error: 105.174965 Validation Error: 105.17748\n",
            "Epoch: 4689 Training Error: 105.174965 Validation Error: 105.17747\n",
            "Epoch: 4690 Training Error: 105.17495 Validation Error: 105.17747\n",
            "Epoch: 4691 Training Error: 105.17495 Validation Error: 105.17745\n",
            "Epoch: 4692 Training Error: 105.17494 Validation Error: 105.177444\n",
            "Epoch: 4693 Training Error: 105.17495 Validation Error: 105.17745\n",
            "Epoch: 4694 Training Error: 105.17494 Validation Error: 105.17745\n",
            "Epoch: 4695 Training Error: 105.17495 Validation Error: 105.17747\n",
            "Epoch: 4696 Training Error: 105.17495 Validation Error: 105.17748\n",
            "Epoch: 4697 Training Error: 105.17495 Validation Error: 105.17747\n",
            "Epoch: 4698 Training Error: 105.17495 Validation Error: 105.17747\n",
            "Epoch: 4699 Training Error: 105.17494 Validation Error: 105.17747\n",
            "Epoch: 4700 Training Error: 105.17494 Validation Error: 105.177444\n",
            "Epoch: 4701 Training Error: 105.17493 Validation Error: 105.17743\n",
            "Epoch: 4702 Training Error: 105.17493 Validation Error: 105.177414\n",
            "Epoch: 4703 Training Error: 105.17493 Validation Error: 105.17741\n",
            "Epoch: 4704 Training Error: 105.17491 Validation Error: 105.17739\n",
            "Epoch: 4705 Training Error: 105.17491 Validation Error: 105.17738\n",
            "Epoch: 4706 Training Error: 105.17493 Validation Error: 105.17737\n",
            "Epoch: 4707 Training Error: 105.17493 Validation Error: 105.17735\n",
            "Epoch: 4708 Training Error: 105.17494 Validation Error: 105.17735\n",
            "Epoch: 4709 Training Error: 105.17494 Validation Error: 105.17735\n",
            "Epoch: 4710 Training Error: 105.17493 Validation Error: 105.177345\n",
            "Epoch: 4711 Training Error: 105.17494 Validation Error: 105.177345\n",
            "Epoch: 4712 Training Error: 105.17491 Validation Error: 105.177345\n",
            "Epoch: 4713 Training Error: 105.17493 Validation Error: 105.17733\n",
            "Epoch: 4714 Training Error: 105.17491 Validation Error: 105.17733\n",
            "Epoch: 4715 Training Error: 105.17491 Validation Error: 105.17733\n",
            "Epoch: 4716 Training Error: 105.174904 Validation Error: 105.17733\n",
            "Epoch: 4717 Training Error: 105.174904 Validation Error: 105.17733\n",
            "Epoch: 4718 Training Error: 105.174904 Validation Error: 105.17733\n",
            "Epoch: 4719 Training Error: 105.17489 Validation Error: 105.17733\n",
            "Epoch: 4720 Training Error: 105.17489 Validation Error: 105.17733\n",
            "Epoch: 4721 Training Error: 105.17489 Validation Error: 105.17733\n",
            "Epoch: 4722 Training Error: 105.17487 Validation Error: 105.17733\n",
            "Epoch: 4723 Training Error: 105.17487 Validation Error: 105.17733\n",
            "Epoch: 4724 Training Error: 105.17487 Validation Error: 105.177315\n",
            "Epoch: 4725 Training Error: 105.17487 Validation Error: 105.177315\n",
            "Epoch: 4726 Training Error: 105.174866 Validation Error: 105.177315\n",
            "Epoch: 4727 Training Error: 105.174866 Validation Error: 105.177315\n",
            "Epoch: 4728 Training Error: 105.174866 Validation Error: 105.17733\n",
            "Epoch: 4729 Training Error: 105.174866 Validation Error: 105.17733\n",
            "Epoch: 4730 Training Error: 105.174866 Validation Error: 105.177345\n",
            "Epoch: 4731 Training Error: 105.174866 Validation Error: 105.177345\n",
            "Epoch: 4732 Training Error: 105.174866 Validation Error: 105.17735\n",
            "Epoch: 4733 Training Error: 105.174866 Validation Error: 105.17735\n",
            "Epoch: 4734 Training Error: 105.174866 Validation Error: 105.17737\n",
            "Epoch: 4735 Training Error: 105.17487 Validation Error: 105.17739\n",
            "Epoch: 4736 Training Error: 105.17487 Validation Error: 105.17738\n",
            "Epoch: 4737 Training Error: 105.17487 Validation Error: 105.17741\n",
            "Epoch: 4738 Training Error: 105.17487 Validation Error: 105.17741\n",
            "Epoch: 4739 Training Error: 105.17489 Validation Error: 105.177414\n",
            "Epoch: 4740 Training Error: 105.17487 Validation Error: 105.177414\n",
            "Epoch: 4741 Training Error: 105.174904 Validation Error: 105.177444\n",
            "Epoch: 4742 Training Error: 105.17489 Validation Error: 105.17743\n",
            "Epoch: 4743 Training Error: 105.17489 Validation Error: 105.17743\n",
            "Epoch: 4744 Training Error: 105.17489 Validation Error: 105.17743\n",
            "Epoch: 4745 Training Error: 105.17487 Validation Error: 105.17739\n",
            "Epoch: 4746 Training Error: 105.17485 Validation Error: 105.17737\n",
            "Epoch: 4747 Training Error: 105.17485 Validation Error: 105.17735\n",
            "Epoch: 4748 Training Error: 105.17484 Validation Error: 105.17735\n",
            "Epoch: 4749 Training Error: 105.17484 Validation Error: 105.17733\n",
            "Epoch: 4750 Training Error: 105.17483 Validation Error: 105.177315\n",
            "Epoch: 4751 Training Error: 105.17483 Validation Error: 105.177315\n",
            "Epoch: 4752 Training Error: 105.17483 Validation Error: 105.17733\n",
            "Epoch: 4753 Training Error: 105.17483 Validation Error: 105.17733\n",
            "Epoch: 4754 Training Error: 105.17483 Validation Error: 105.177315\n",
            "Epoch: 4755 Training Error: 105.17483 Validation Error: 105.177315\n",
            "Epoch: 4756 Training Error: 105.17484 Validation Error: 105.17735\n",
            "Epoch: 4757 Training Error: 105.17484 Validation Error: 105.17735\n",
            "Epoch: 4758 Training Error: 105.17484 Validation Error: 105.17735\n",
            "Epoch: 4759 Training Error: 105.17484 Validation Error: 105.17735\n",
            "Epoch: 4760 Training Error: 105.17484 Validation Error: 105.17737\n",
            "Epoch: 4761 Training Error: 105.17484 Validation Error: 105.17737\n",
            "Epoch: 4762 Training Error: 105.17485 Validation Error: 105.17738\n",
            "Epoch: 4763 Training Error: 105.17485 Validation Error: 105.17741\n",
            "Epoch: 4764 Training Error: 105.174866 Validation Error: 105.17741\n",
            "Epoch: 4765 Training Error: 105.174866 Validation Error: 105.177414\n",
            "Epoch: 4766 Training Error: 105.174866 Validation Error: 105.177414\n",
            "Epoch: 4767 Training Error: 105.17487 Validation Error: 105.177444\n",
            "Epoch: 4768 Training Error: 105.17487 Validation Error: 105.177444\n",
            "Epoch: 4769 Training Error: 105.17489 Validation Error: 105.177444\n",
            "Epoch: 4770 Training Error: 105.17489 Validation Error: 105.177444\n",
            "Epoch: 4771 Training Error: 105.174866 Validation Error: 105.17743\n",
            "Epoch: 4772 Training Error: 105.17487 Validation Error: 105.17743\n",
            "Epoch: 4773 Training Error: 105.174866 Validation Error: 105.177414\n",
            "Epoch: 4774 Training Error: 105.17485 Validation Error: 105.17739\n",
            "Epoch: 4775 Training Error: 105.17485 Validation Error: 105.17741\n",
            "Epoch: 4776 Training Error: 105.17487 Validation Error: 105.177414\n",
            "Epoch: 4777 Training Error: 105.17487 Validation Error: 105.177444\n",
            "Epoch: 4778 Training Error: 105.174866 Validation Error: 105.177414\n",
            "Epoch: 4779 Training Error: 105.17484 Validation Error: 105.17738\n",
            "Epoch: 4780 Training Error: 105.17484 Validation Error: 105.17738\n",
            "Epoch: 4781 Training Error: 105.17483 Validation Error: 105.17737\n",
            "Epoch: 4782 Training Error: 105.17483 Validation Error: 105.17735\n",
            "Epoch: 4783 Training Error: 105.17483 Validation Error: 105.17737\n",
            "Epoch: 4784 Training Error: 105.17481 Validation Error: 105.177345\n",
            "Epoch: 4785 Training Error: 105.174805 Validation Error: 105.177345\n",
            "Epoch: 4786 Training Error: 105.17483 Validation Error: 105.17735\n",
            "Epoch: 4787 Training Error: 105.17484 Validation Error: 105.17738\n",
            "Epoch: 4788 Training Error: 105.17481 Validation Error: 105.17735\n",
            "Epoch: 4789 Training Error: 105.17479 Validation Error: 105.177315\n",
            "Epoch: 4790 Training Error: 105.17477 Validation Error: 105.17727\n",
            "Epoch: 4791 Training Error: 105.17477 Validation Error: 105.17727\n",
            "Epoch: 4792 Training Error: 105.17477 Validation Error: 105.17727\n",
            "Epoch: 4793 Training Error: 105.17477 Validation Error: 105.17725\n",
            "Epoch: 4794 Training Error: 105.17475 Validation Error: 105.177246\n",
            "Epoch: 4795 Training Error: 105.17475 Validation Error: 105.17723\n",
            "Epoch: 4796 Training Error: 105.17475 Validation Error: 105.177246\n",
            "Epoch: 4797 Training Error: 105.17474 Validation Error: 105.177216\n",
            "Epoch: 4798 Training Error: 105.17473 Validation Error: 105.17718\n",
            "Epoch: 4799 Training Error: 105.17471 Validation Error: 105.17717\n",
            "Epoch: 4800 Training Error: 105.174706 Validation Error: 105.17715\n",
            "Epoch: 4801 Training Error: 105.17471 Validation Error: 105.17712\n",
            "Epoch: 4802 Training Error: 105.174706 Validation Error: 105.17711\n",
            "Epoch: 4803 Training Error: 105.174706 Validation Error: 105.17711\n",
            "Epoch: 4804 Training Error: 105.174706 Validation Error: 105.17709\n",
            "Epoch: 4805 Training Error: 105.17473 Validation Error: 105.17709\n",
            "Epoch: 4806 Training Error: 105.17474 Validation Error: 105.17709\n",
            "Epoch: 4807 Training Error: 105.17475 Validation Error: 105.17709\n",
            "Epoch: 4808 Training Error: 105.17475 Validation Error: 105.17708\n",
            "Epoch: 4809 Training Error: 105.17474 Validation Error: 105.17708\n",
            "Epoch: 4810 Training Error: 105.17474 Validation Error: 105.17707\n",
            "Epoch: 4811 Training Error: 105.17474 Validation Error: 105.17707\n",
            "Epoch: 4812 Training Error: 105.17473 Validation Error: 105.17707\n",
            "Epoch: 4813 Training Error: 105.17473 Validation Error: 105.17707\n",
            "Epoch: 4814 Training Error: 105.17473 Validation Error: 105.177055\n",
            "Epoch: 4815 Training Error: 105.17471 Validation Error: 105.177055\n",
            "Epoch: 4816 Training Error: 105.17473 Validation Error: 105.177055\n",
            "Epoch: 4817 Training Error: 105.17471 Validation Error: 105.177055\n",
            "Epoch: 4818 Training Error: 105.174706 Validation Error: 105.177055\n",
            "Epoch: 4819 Training Error: 105.174706 Validation Error: 105.17704\n",
            "Epoch: 4820 Training Error: 105.174706 Validation Error: 105.17704\n",
            "Epoch: 4821 Training Error: 105.17469 Validation Error: 105.17704\n",
            "Epoch: 4822 Training Error: 105.17469 Validation Error: 105.17704\n",
            "Epoch: 4823 Training Error: 105.174675 Validation Error: 105.17704\n",
            "Epoch: 4824 Training Error: 105.174675 Validation Error: 105.17703\n",
            "Epoch: 4825 Training Error: 105.17467 Validation Error: 105.17703\n",
            "Epoch: 4826 Training Error: 105.17465 Validation Error: 105.17704\n",
            "Epoch: 4827 Training Error: 105.17465 Validation Error: 105.17703\n",
            "Epoch: 4828 Training Error: 105.17465 Validation Error: 105.17704\n",
            "Epoch: 4829 Training Error: 105.17465 Validation Error: 105.17703\n",
            "Epoch: 4830 Training Error: 105.17464 Validation Error: 105.17703\n",
            "Epoch: 4831 Training Error: 105.17464 Validation Error: 105.17703\n",
            "Epoch: 4832 Training Error: 105.17464 Validation Error: 105.17703\n",
            "Epoch: 4833 Training Error: 105.17464 Validation Error: 105.17703\n",
            "Epoch: 4834 Training Error: 105.17464 Validation Error: 105.17702\n",
            "Epoch: 4835 Training Error: 105.17464 Validation Error: 105.17701\n",
            "Epoch: 4836 Training Error: 105.17465 Validation Error: 105.17701\n",
            "Epoch: 4837 Training Error: 105.17465 Validation Error: 105.17701\n",
            "Epoch: 4838 Training Error: 105.17464 Validation Error: 105.176994\n",
            "Epoch: 4839 Training Error: 105.17464 Validation Error: 105.176994\n",
            "Epoch: 4840 Training Error: 105.17465 Validation Error: 105.176994\n",
            "Epoch: 4841 Training Error: 105.17465 Validation Error: 105.176994\n",
            "Epoch: 4842 Training Error: 105.17465 Validation Error: 105.176994\n",
            "Epoch: 4843 Training Error: 105.17467 Validation Error: 105.17698\n",
            "Epoch: 4844 Training Error: 105.17467 Validation Error: 105.17698\n",
            "Epoch: 4845 Training Error: 105.174675 Validation Error: 105.176994\n",
            "Epoch: 4846 Training Error: 105.174675 Validation Error: 105.17698\n",
            "Epoch: 4847 Training Error: 105.17467 Validation Error: 105.17698\n",
            "Epoch: 4848 Training Error: 105.174675 Validation Error: 105.17698\n",
            "Epoch: 4849 Training Error: 105.17469 Validation Error: 105.17698\n",
            "Epoch: 4850 Training Error: 105.174706 Validation Error: 105.17698\n",
            "Epoch: 4851 Training Error: 105.17471 Validation Error: 105.17698\n",
            "Epoch: 4852 Training Error: 105.174706 Validation Error: 105.17698\n",
            "Epoch: 4853 Training Error: 105.174675 Validation Error: 105.17697\n",
            "Epoch: 4854 Training Error: 105.17469 Validation Error: 105.17697\n",
            "Epoch: 4855 Training Error: 105.174675 Validation Error: 105.17697\n",
            "Epoch: 4856 Training Error: 105.17465 Validation Error: 105.176956\n",
            "Epoch: 4857 Training Error: 105.17464 Validation Error: 105.176956\n",
            "Epoch: 4858 Training Error: 105.17464 Validation Error: 105.17694\n",
            "Epoch: 4859 Training Error: 105.17464 Validation Error: 105.17694\n",
            "Epoch: 4860 Training Error: 105.17464 Validation Error: 105.17694\n",
            "Epoch: 4861 Training Error: 105.17465 Validation Error: 105.17694\n",
            "Epoch: 4862 Training Error: 105.17464 Validation Error: 105.17694\n",
            "Epoch: 4863 Training Error: 105.17464 Validation Error: 105.17693\n",
            "Epoch: 4864 Training Error: 105.17464 Validation Error: 105.17693\n",
            "Epoch: 4865 Training Error: 105.17464 Validation Error: 105.17693\n",
            "Epoch: 4866 Training Error: 105.17464 Validation Error: 105.17693\n",
            "Epoch: 4867 Training Error: 105.17464 Validation Error: 105.17693\n",
            "Epoch: 4868 Training Error: 105.17465 Validation Error: 105.17693\n",
            "Epoch: 4869 Training Error: 105.17464 Validation Error: 105.17693\n",
            "Epoch: 4870 Training Error: 105.17464 Validation Error: 105.17692\n",
            "Epoch: 4871 Training Error: 105.174614 Validation Error: 105.17692\n",
            "Epoch: 4872 Training Error: 105.17459 Validation Error: 105.17692\n",
            "Epoch: 4873 Training Error: 105.174576 Validation Error: 105.17692\n",
            "Epoch: 4874 Training Error: 105.174576 Validation Error: 105.1769\n",
            "Epoch: 4875 Training Error: 105.174576 Validation Error: 105.1769\n",
            "Epoch: 4876 Training Error: 105.17457 Validation Error: 105.1769\n",
            "Epoch: 4877 Training Error: 105.174576 Validation Error: 105.1769\n",
            "Epoch: 4878 Training Error: 105.17457 Validation Error: 105.176895\n",
            "Epoch: 4879 Training Error: 105.174576 Validation Error: 105.176895\n",
            "Epoch: 4880 Training Error: 105.17455 Validation Error: 105.176895\n",
            "Epoch: 4881 Training Error: 105.17455 Validation Error: 105.176895\n",
            "Epoch: 4882 Training Error: 105.17454 Validation Error: 105.176895\n",
            "Epoch: 4883 Training Error: 105.17454 Validation Error: 105.176895\n",
            "Epoch: 4884 Training Error: 105.17454 Validation Error: 105.176895\n",
            "Epoch: 4885 Training Error: 105.17454 Validation Error: 105.17688\n",
            "Epoch: 4886 Training Error: 105.17454 Validation Error: 105.17688\n",
            "Epoch: 4887 Training Error: 105.17453 Validation Error: 105.17688\n",
            "Epoch: 4888 Training Error: 105.17453 Validation Error: 105.17688\n",
            "Epoch: 4889 Training Error: 105.17453 Validation Error: 105.17688\n",
            "Epoch: 4890 Training Error: 105.17453 Validation Error: 105.17687\n",
            "Epoch: 4891 Training Error: 105.17453 Validation Error: 105.17687\n",
            "Epoch: 4892 Training Error: 105.17453 Validation Error: 105.17686\n",
            "Epoch: 4893 Training Error: 105.17453 Validation Error: 105.17686\n",
            "Epoch: 4894 Training Error: 105.17454 Validation Error: 105.17686\n",
            "Epoch: 4895 Training Error: 105.17453 Validation Error: 105.17686\n",
            "Epoch: 4896 Training Error: 105.174515 Validation Error: 105.17684\n",
            "Epoch: 4897 Training Error: 105.174515 Validation Error: 105.17684\n",
            "Epoch: 4898 Training Error: 105.174515 Validation Error: 105.17684\n",
            "Epoch: 4899 Training Error: 105.1745 Validation Error: 105.17684\n",
            "Epoch: 4900 Training Error: 105.1745 Validation Error: 105.17684\n",
            "Epoch: 4901 Training Error: 105.1745 Validation Error: 105.17684\n",
            "Epoch: 4902 Training Error: 105.1745 Validation Error: 105.17684\n",
            "Epoch: 4903 Training Error: 105.17449 Validation Error: 105.17684\n",
            "Epoch: 4904 Training Error: 105.1745 Validation Error: 105.176834\n",
            "Epoch: 4905 Training Error: 105.1745 Validation Error: 105.176834\n",
            "Epoch: 4906 Training Error: 105.1745 Validation Error: 105.17682\n",
            "Epoch: 4907 Training Error: 105.1745 Validation Error: 105.17682\n",
            "Epoch: 4908 Training Error: 105.1745 Validation Error: 105.17682\n",
            "Epoch: 4909 Training Error: 105.1745 Validation Error: 105.17682\n",
            "Epoch: 4910 Training Error: 105.17449 Validation Error: 105.17682\n",
            "Epoch: 4911 Training Error: 105.17449 Validation Error: 105.17682\n",
            "Epoch: 4912 Training Error: 105.17448 Validation Error: 105.17682\n",
            "Epoch: 4913 Training Error: 105.17448 Validation Error: 105.1768\n",
            "Epoch: 4914 Training Error: 105.17447 Validation Error: 105.17682\n",
            "Epoch: 4915 Training Error: 105.17447 Validation Error: 105.1768\n",
            "Epoch: 4916 Training Error: 105.17447 Validation Error: 105.1768\n",
            "Epoch: 4917 Training Error: 105.17447 Validation Error: 105.1768\n",
            "Epoch: 4918 Training Error: 105.17447 Validation Error: 105.1768\n",
            "Epoch: 4919 Training Error: 105.17445 Validation Error: 105.1768\n",
            "Epoch: 4920 Training Error: 105.17445 Validation Error: 105.1768\n",
            "Epoch: 4921 Training Error: 105.17445 Validation Error: 105.176796\n",
            "Epoch: 4922 Training Error: 105.17445 Validation Error: 105.176796\n",
            "Epoch: 4923 Training Error: 105.17445 Validation Error: 105.176796\n",
            "Epoch: 4924 Training Error: 105.17445 Validation Error: 105.176796\n",
            "Epoch: 4925 Training Error: 105.17445 Validation Error: 105.17678\n",
            "Epoch: 4926 Training Error: 105.17445 Validation Error: 105.17678\n",
            "Epoch: 4927 Training Error: 105.17444 Validation Error: 105.17678\n",
            "Epoch: 4928 Training Error: 105.17444 Validation Error: 105.17678\n",
            "Epoch: 4929 Training Error: 105.17444 Validation Error: 105.17678\n",
            "Epoch: 4930 Training Error: 105.17444 Validation Error: 105.17677\n",
            "Epoch: 4931 Training Error: 105.17444 Validation Error: 105.17677\n",
            "Epoch: 4932 Training Error: 105.17444 Validation Error: 105.17677\n",
            "Epoch: 4933 Training Error: 105.17443 Validation Error: 105.17677\n",
            "Epoch: 4934 Training Error: 105.17443 Validation Error: 105.17676\n",
            "Epoch: 4935 Training Error: 105.17443 Validation Error: 105.17676\n",
            "Epoch: 4936 Training Error: 105.17443 Validation Error: 105.17676\n",
            "Epoch: 4937 Training Error: 105.174416 Validation Error: 105.17676\n",
            "Epoch: 4938 Training Error: 105.174416 Validation Error: 105.17677\n",
            "Epoch: 4939 Training Error: 105.174416 Validation Error: 105.17677\n",
            "Epoch: 4940 Training Error: 105.174416 Validation Error: 105.17676\n",
            "Epoch: 4941 Training Error: 105.174416 Validation Error: 105.17676\n",
            "Epoch: 4942 Training Error: 105.1744 Validation Error: 105.17674\n",
            "Epoch: 4943 Training Error: 105.1744 Validation Error: 105.17674\n",
            "Epoch: 4944 Training Error: 105.1744 Validation Error: 105.176735\n",
            "Epoch: 4945 Training Error: 105.1744 Validation Error: 105.176735\n",
            "Epoch: 4946 Training Error: 105.1744 Validation Error: 105.176735\n",
            "Epoch: 4947 Training Error: 105.1744 Validation Error: 105.176735\n",
            "Epoch: 4948 Training Error: 105.1744 Validation Error: 105.176735\n",
            "Epoch: 4949 Training Error: 105.17439 Validation Error: 105.17674\n",
            "Epoch: 4950 Training Error: 105.17439 Validation Error: 105.17674\n",
            "Epoch: 4951 Training Error: 105.17439 Validation Error: 105.17674\n",
            "Epoch: 4952 Training Error: 105.17439 Validation Error: 105.17674\n",
            "Epoch: 4953 Training Error: 105.17439 Validation Error: 105.17674\n",
            "Epoch: 4954 Training Error: 105.17439 Validation Error: 105.17674\n",
            "Epoch: 4955 Training Error: 105.17438 Validation Error: 105.17674\n",
            "Epoch: 4956 Training Error: 105.17439 Validation Error: 105.17676\n",
            "Epoch: 4957 Training Error: 105.17439 Validation Error: 105.17676\n",
            "Epoch: 4958 Training Error: 105.17438 Validation Error: 105.17674\n",
            "Epoch: 4959 Training Error: 105.17438 Validation Error: 105.17674\n",
            "Epoch: 4960 Training Error: 105.17438 Validation Error: 105.176735\n",
            "Epoch: 4961 Training Error: 105.17438 Validation Error: 105.17672\n",
            "Epoch: 4962 Training Error: 105.17437 Validation Error: 105.176735\n",
            "Epoch: 4963 Training Error: 105.17438 Validation Error: 105.176735\n",
            "Epoch: 4964 Training Error: 105.17437 Validation Error: 105.176735\n",
            "Epoch: 4965 Training Error: 105.17437 Validation Error: 105.176735\n",
            "Epoch: 4966 Training Error: 105.17437 Validation Error: 105.176735\n",
            "Epoch: 4967 Training Error: 105.17437 Validation Error: 105.176704\n",
            "Epoch: 4968 Training Error: 105.17437 Validation Error: 105.176704\n",
            "Epoch: 4969 Training Error: 105.174355 Validation Error: 105.1767\n",
            "Epoch: 4970 Training Error: 105.174355 Validation Error: 105.176704\n",
            "Epoch: 4971 Training Error: 105.174355 Validation Error: 105.17672\n",
            "Epoch: 4972 Training Error: 105.17437 Validation Error: 105.17672\n",
            "Epoch: 4973 Training Error: 105.17437 Validation Error: 105.176735\n",
            "Epoch: 4974 Training Error: 105.174355 Validation Error: 105.176735\n",
            "Epoch: 4975 Training Error: 105.17437 Validation Error: 105.17674\n",
            "Epoch: 4976 Training Error: 105.17437 Validation Error: 105.17674\n",
            "Epoch: 4977 Training Error: 105.174355 Validation Error: 105.176735\n",
            "Epoch: 4978 Training Error: 105.174355 Validation Error: 105.17672\n",
            "Epoch: 4979 Training Error: 105.17434 Validation Error: 105.176704\n",
            "Epoch: 4980 Training Error: 105.174355 Validation Error: 105.176735\n",
            "Epoch: 4981 Training Error: 105.174355 Validation Error: 105.17674\n",
            "Epoch: 4982 Training Error: 105.174355 Validation Error: 105.17672\n",
            "Epoch: 4983 Training Error: 105.17434 Validation Error: 105.17672\n",
            "Epoch: 4984 Training Error: 105.17434 Validation Error: 105.176704\n",
            "Epoch: 4985 Training Error: 105.17433 Validation Error: 105.1767\n",
            "Epoch: 4986 Training Error: 105.17433 Validation Error: 105.1767\n",
            "Epoch: 4987 Training Error: 105.17433 Validation Error: 105.17668\n",
            "Epoch: 4988 Training Error: 105.17433 Validation Error: 105.176704\n",
            "Epoch: 4989 Training Error: 105.17434 Validation Error: 105.176704\n",
            "Epoch: 4990 Training Error: 105.17433 Validation Error: 105.176704\n",
            "Epoch: 4991 Training Error: 105.17434 Validation Error: 105.17672\n",
            "Epoch: 4992 Training Error: 105.17434 Validation Error: 105.17672\n",
            "Epoch: 4993 Training Error: 105.17433 Validation Error: 105.176704\n",
            "Epoch: 4994 Training Error: 105.17433 Validation Error: 105.176704\n",
            "Epoch: 4995 Training Error: 105.17433 Validation Error: 105.176704\n",
            "Epoch: 4996 Training Error: 105.17433 Validation Error: 105.17672\n",
            "Epoch: 4997 Training Error: 105.174355 Validation Error: 105.176735\n",
            "Epoch: 4998 Training Error: 105.17434 Validation Error: 105.176735\n",
            "Epoch: 4999 Training Error: 105.174355 Validation Error: 105.17674\n",
            "Average MinSqLoss w Training Set: tf.Tensor(105.30995, shape=(), dtype=float32)\n",
            "Average MinSqLoss w Validation Set: tf.Tensor(105.323654, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "trainingErrorSum = 0\n",
        "validationErrorSum = 0\n",
        "allLossesTrain=[]\n",
        "allLossesValid=[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    shuffled = np.arange(len(Y))\n",
        "    np.random.shuffle(shuffled)\n",
        "    for batch_num in range(batches_per_epoch):\n",
        "        start = batch_num*batch_size\n",
        "        batch_xs = tf.constant(X[shuffled[start:start+batch_size],:].astype(np.float32))\n",
        "        batch_ys = tf.constant(Y[shuffled[start:start+batch_size]].astype(np.float32))\n",
        "        gradients,variables = grad(batch_xs, batch_ys, variables)\n",
        "        optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    ys_Pred_Train = predict(tf.constant(X.astype(np.float32)))\n",
        "    ys_Pred_Val = predict(tf.constant(valid_X.astype(np.float32)))\n",
        "\n",
        "    lossTrain = loss(tf.constant(ys_Pred_Train),tf.constant(Y.astype(np.float32)))**0.5*stds[0]\n",
        "    lossVal = loss(tf.constant(ys_Pred_Val),tf.constant(Y.astype(np.float32)))**0.5*stds[0]\n",
        "\n",
        "    print(\"Epoch: \" +str(epoch) +\" Training Error: \" + str(lossTrain.numpy()) + \" Validation Error: \" + str(lossVal.numpy()))\n",
        "\n",
        "    with writer.as_default():\n",
        "        tf.summary.scalar(\"Train loss\", lossTrain, step=epoch)\n",
        "        tf.summary.scalar(\"Val loss\", lossVal, step=epoch)\n",
        "\n",
        "    allLossesTrain.append(lossTrain)\n",
        "    allLossesValid.append(lossVal)\n",
        "    trainingErrorSum = (trainingErrorSum + lossTrain)\n",
        "    validationErrorSum = (validationErrorSum + lossVal)\n",
        "writer.close()\n",
        "\n",
        "trainingErrorAvg = (trainingErrorSum / epoch)\n",
        "validationErrorAvg = (validationErrorSum / epoch)\n",
        "\n",
        "\n",
        "print(\"Average MinSqLoss w Training Set: \" + str(trainingErrorAvg))\n",
        "print(\"Average MinSqLoss w Validation Set: \" + str(validationErrorAvg))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(range(1,epochs+1), allLossesTrain, 'b', label='Training set')\n",
        "plt.plot(range(1,epochs+1), allLossesValid, 'r', label='Validation set')\n",
        "plt.title('Losses (Training and Validation)')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "8Z8poGNJ6pXE",
        "outputId": "7ff7d4e6-e314-4b4b-903a-ac32a653850f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análise do gráfico\n",
        "Como podemos ver pelo gráfico acima, o modelo parece ter feito um modelo que fez **fit aos dados apropriadamente**, isto é, o erro de Treino diminuiu mas o de validação também, provando assim que não houve overfit ao conjunto de treino. Outro aspeto que se podia revelar neste gráfico seria a **escolha da Learning Rate**. Caso tivesse sido muito alto, iríamos ver muitas oscilações e *jitter* na curva de treino pelo modelo dar sempre passos demasiado grandes e não conseguir convergir apropriadamente para nada. No entanto, como vemos, **a curva é suave** o que demonstra que a Learning Rate usada foi correta.\n",
        "Olhando para o modelo feito, percebemos que existem muitos parâmetros que podem ser tuned e escolhidos de forma diferente como é o caso da learning rate, de usarmos momentum ou não, do tamanho dos batches, da escolha do optimizer, do número de camadas e neurónios... \n",
        "\n",
        "Em deep learning, por ser algo exigente computacionalmente e demorar bastante a treinar um modelo uma vez, **não seria exequível fazermos por exemplo cross-validation** que iria treinar o modelo k vezes para escolher os melhores parâmetros. Assim, neste tipo de problemas a melhor abordagem é mesmo experimentar vários parâmetros e fazer diferentes escolhas para melhorarmos a performance, ressalvando que depois da escolha destes parâmetros, teríamos de testar o nosso modelo com um outro dataset (de treino) que nunca tenha sido visto antes pelo modelo para as previsões não serem enviesadas.\n",
        "\n",
        "Um aparte é o de ter decidido fazer este gráfico diretamente no *python* ao invés de no TensorBoard pois não era muito intuitiva a maneira de juntar ambas as losses no mesmo gráfico."
      ],
      "metadata": {
        "id": "652I73ww8JTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keras sequencial\n",
        "O keras dá-nos uma API mais high-level que nos permite criar e fazer operações sobre redes neuronais muito mais facilmente que anteriormente. Durante as aulas falámos de 2 tipos de maneiras de criar um modelo no Keras: sequencialmente e funcionalmente. O **sequencial** é bastante direto e definimos **layer a layer** o que cada uma será. Os passos para criarmos e treinarmos um modelo sequencial do keras serão\n",
        "\n",
        "\n",
        "1.   Criar a rede em si (layer a layer)\n",
        "2.   Compilar o modelo\n",
        "3.   Fazer fit do modelo\n",
        "4.   Calcular métricas do modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "349Hzn68BvYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para percebermos como definir a camada de input relativamente ao **número de inputs**, iremos verificar quantos são (por termos de usar este valor na definição da camada com o keras)."
      ],
      "metadata": {
        "id": "Gz7sV1fhEDrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape[1]\n",
        "#Temos 8 atributos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjF-fBfREUet",
        "outputId": "28798049-4996-4e54-e026-29ea890170f4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definir o modelo\n",
        "Criaremos então agora o modelo!\n",
        "Este terá 2 camadas **densamente conectadas** (com 4 neurónios) e uma camada de output que retorna um **único valor contínuo** (com 1 neurónio)."
      ],
      "metadata": {
        "id": "t_cgCV4zEkn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization,Conv2D,MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense\n",
        "from tensorflow import keras\n",
        "\n",
        "def create_model():\n",
        "    #se aplicarmos a batch normalization antes do relu, o relu vai po los nao standardizado\n",
        "    model = Sequential()\n",
        "    model.add(Dense(4, input_shape = (8,)))\n",
        "    model.add(Activation(\"leaky_relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(4, input_shape = (8,)))\n",
        "    model.add(Activation(\"leaky_relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    model.add(Dense(1))\n",
        "    return model"
      ],
      "metadata": {
        "id": "VYN1NKxPEuUc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compilar o modelo\n",
        "Agora, como dito anteriormente, precisaremos de **compilar o modelo**. Isto é, especificar o tipo de loss function que irá ser utilizada, o tipo de optimizer e algumas métricas que podem ser calculadas para posterior verificação da qualidade do modelo. Os parâmetros e funções usadas (optimizer, loss, learning rate, número de épocas, batch size) serão análogos ao feito no modelo com o tensorflow vanilla."
      ],
      "metadata": {
        "id": "1Y772yplHska"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INIT_LR = 0.001\n",
        "NUM_EPOCHS = 5000\n",
        "BS = 128\n",
        "\n",
        "opt = SGD(lr = INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)\n",
        "model = create_model()\n",
        "model.compile(loss= tf.keras.losses.MeanSquaredError(), optimizer=opt,metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B-EkKiMH8_m",
        "outputId": "7300f7f7-9664-46af-a52e-9ba035ba2f9c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 4)                 36        \n",
            "                                                                 \n",
            " activation (Activation)     (None, 4)                 0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 4)                16        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 20        \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 4)                16        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93\n",
            "Trainable params: 77\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit do modelo aos dados\n",
        "Como dito anteriormente, precisamos agora de fazer o **fit do modelo aos nossos dados** usando a função `fit()` sobre o objecto `model`. Para isto precisamos de passar os nossos dados como argumento (bem como as *labels*) e os restantes parâmetros semelhantes à fase de compilação."
      ],
      "metadata": {
        "id": "8H6bmwXfJWOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, Y, validation_data=(valid_X, valid_Y),\n",
        "                  batch_size=BS, epochs=NUM_EPOCHS)"
      ],
      "metadata": {
        "id": "N-ILOYT6JzSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e1620f8-89df-4416-8369-b747f9165b67"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1907 - accuracy: 0.0000e+00 - val_loss: 0.2054 - val_accuracy: 0.0000e+00\n",
            "Epoch 2502/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1863 - accuracy: 0.0000e+00 - val_loss: 0.2049 - val_accuracy: 0.0000e+00\n",
            "Epoch 2503/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2017 - accuracy: 0.0000e+00 - val_loss: 0.2053 - val_accuracy: 0.0000e+00\n",
            "Epoch 2504/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1985 - accuracy: 0.0000e+00 - val_loss: 0.2057 - val_accuracy: 0.0000e+00\n",
            "Epoch 2505/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1998 - accuracy: 0.0000e+00 - val_loss: 0.2059 - val_accuracy: 0.0000e+00\n",
            "Epoch 2506/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1932 - accuracy: 0.0000e+00 - val_loss: 0.2057 - val_accuracy: 0.0000e+00\n",
            "Epoch 2507/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1964 - accuracy: 0.0000e+00 - val_loss: 0.2053 - val_accuracy: 0.0000e+00\n",
            "Epoch 2508/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1911 - accuracy: 0.0000e+00 - val_loss: 0.2049 - val_accuracy: 0.0000e+00\n",
            "Epoch 2509/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1879 - accuracy: 0.0000e+00 - val_loss: 0.2048 - val_accuracy: 0.0000e+00\n",
            "Epoch 2510/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1996 - accuracy: 0.0000e+00 - val_loss: 0.2049 - val_accuracy: 0.0000e+00\n",
            "Epoch 2511/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2021 - accuracy: 0.0000e+00 - val_loss: 0.2056 - val_accuracy: 0.0000e+00\n",
            "Epoch 2512/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1945 - accuracy: 0.0000e+00 - val_loss: 0.2059 - val_accuracy: 0.0000e+00\n",
            "Epoch 2513/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2004 - accuracy: 0.0000e+00 - val_loss: 0.2052 - val_accuracy: 0.0000e+00\n",
            "Epoch 2514/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1939 - accuracy: 0.0000e+00 - val_loss: 0.2043 - val_accuracy: 0.0000e+00\n",
            "Epoch 2515/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1962 - accuracy: 0.0000e+00 - val_loss: 0.2048 - val_accuracy: 0.0000e+00\n",
            "Epoch 2516/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2314 - accuracy: 0.0000e+00 - val_loss: 0.2049 - val_accuracy: 0.0000e+00\n",
            "Epoch 2517/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2003 - accuracy: 0.0000e+00 - val_loss: 0.2045 - val_accuracy: 0.0000e+00\n",
            "Epoch 2518/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2023 - accuracy: 0.0000e+00 - val_loss: 0.2045 - val_accuracy: 0.0000e+00\n",
            "Epoch 2519/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2014 - accuracy: 0.0000e+00 - val_loss: 0.2043 - val_accuracy: 0.0000e+00\n",
            "Epoch 2520/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2146 - accuracy: 0.0000e+00 - val_loss: 0.2052 - val_accuracy: 0.0000e+00\n",
            "Epoch 2521/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1996 - accuracy: 0.0000e+00 - val_loss: 0.2052 - val_accuracy: 0.0000e+00\n",
            "Epoch 2522/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1965 - accuracy: 0.0000e+00 - val_loss: 0.2047 - val_accuracy: 0.0000e+00\n",
            "Epoch 2523/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2040 - accuracy: 0.0000e+00 - val_loss: 0.2042 - val_accuracy: 0.0000e+00\n",
            "Epoch 2524/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1912 - accuracy: 0.0000e+00 - val_loss: 0.2036 - val_accuracy: 0.0000e+00\n",
            "Epoch 2525/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1923 - accuracy: 0.0000e+00 - val_loss: 0.2042 - val_accuracy: 0.0000e+00\n",
            "Epoch 2526/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1998 - accuracy: 0.0000e+00 - val_loss: 0.2043 - val_accuracy: 0.0000e+00\n",
            "Epoch 2527/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1977 - accuracy: 0.0000e+00 - val_loss: 0.2038 - val_accuracy: 0.0000e+00\n",
            "Epoch 2528/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1932 - accuracy: 0.0000e+00 - val_loss: 0.2038 - val_accuracy: 0.0000e+00\n",
            "Epoch 2529/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1938 - accuracy: 0.0000e+00 - val_loss: 0.2043 - val_accuracy: 0.0000e+00\n",
            "Epoch 2530/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1946 - accuracy: 0.0000e+00 - val_loss: 0.2046 - val_accuracy: 0.0000e+00\n",
            "Epoch 2531/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2103 - accuracy: 0.0000e+00 - val_loss: 0.2048 - val_accuracy: 0.0000e+00\n",
            "Epoch 2532/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1887 - accuracy: 0.0000e+00 - val_loss: 0.2057 - val_accuracy: 0.0000e+00\n",
            "Epoch 2533/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1958 - accuracy: 0.0000e+00 - val_loss: 0.2057 - val_accuracy: 0.0000e+00\n",
            "Epoch 2534/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2103 - accuracy: 0.0000e+00 - val_loss: 0.2051 - val_accuracy: 0.0000e+00\n",
            "Epoch 2535/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2008 - accuracy: 0.0000e+00 - val_loss: 0.2048 - val_accuracy: 0.0000e+00\n",
            "Epoch 2536/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1988 - accuracy: 0.0000e+00 - val_loss: 0.2054 - val_accuracy: 0.0000e+00\n",
            "Epoch 2537/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1972 - accuracy: 0.0000e+00 - val_loss: 0.2056 - val_accuracy: 0.0000e+00\n",
            "Epoch 2538/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1890 - accuracy: 0.0000e+00 - val_loss: 0.2053 - val_accuracy: 0.0000e+00\n",
            "Epoch 2539/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1905 - accuracy: 0.0000e+00 - val_loss: 0.2052 - val_accuracy: 0.0000e+00\n",
            "Epoch 2540/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2026 - accuracy: 0.0000e+00 - val_loss: 0.2053 - val_accuracy: 0.0000e+00\n",
            "Epoch 2541/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2037 - accuracy: 0.0000e+00 - val_loss: 0.2050 - val_accuracy: 0.0000e+00\n",
            "Epoch 2542/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2053 - accuracy: 0.0000e+00 - val_loss: 0.2058 - val_accuracy: 0.0000e+00\n",
            "Epoch 2543/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1954 - accuracy: 0.0000e+00 - val_loss: 0.2062 - val_accuracy: 0.0000e+00\n",
            "Epoch 2544/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1996 - accuracy: 0.0000e+00 - val_loss: 0.2065 - val_accuracy: 0.0000e+00\n",
            "Epoch 2545/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2050 - accuracy: 0.0000e+00 - val_loss: 0.2056 - val_accuracy: 0.0000e+00\n",
            "Epoch 2546/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1877 - accuracy: 0.0000e+00 - val_loss: 0.2055 - val_accuracy: 0.0000e+00\n",
            "Epoch 2547/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2081 - accuracy: 0.0000e+00 - val_loss: 0.2051 - val_accuracy: 0.0000e+00\n",
            "Epoch 2548/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1908 - accuracy: 0.0000e+00 - val_loss: 0.2042 - val_accuracy: 0.0000e+00\n",
            "Epoch 2549/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2142 - accuracy: 0.0000e+00 - val_loss: 0.2035 - val_accuracy: 0.0000e+00\n",
            "Epoch 2550/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1851 - accuracy: 0.0000e+00 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 2551/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1965 - accuracy: 0.0000e+00 - val_loss: 0.2041 - val_accuracy: 0.0000e+00\n",
            "Epoch 2552/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1969 - accuracy: 0.0000e+00 - val_loss: 0.2055 - val_accuracy: 0.0000e+00\n",
            "Epoch 2553/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1889 - accuracy: 0.0000e+00 - val_loss: 0.2046 - val_accuracy: 0.0000e+00\n",
            "Epoch 2554/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2093 - accuracy: 0.0000e+00 - val_loss: 0.2043 - val_accuracy: 0.0000e+00\n",
            "Epoch 2555/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1945 - accuracy: 0.0000e+00 - val_loss: 0.2041 - val_accuracy: 0.0000e+00\n",
            "Epoch 2556/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1917 - accuracy: 0.0000e+00 - val_loss: 0.2044 - val_accuracy: 0.0000e+00\n",
            "Epoch 2557/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2040 - accuracy: 0.0000e+00 - val_loss: 0.2039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2558/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1896 - accuracy: 0.0000e+00 - val_loss: 0.2033 - val_accuracy: 0.0000e+00\n",
            "Epoch 2559/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1986 - accuracy: 0.0000e+00 - val_loss: 0.2036 - val_accuracy: 0.0000e+00\n",
            "Epoch 2560/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1979 - accuracy: 0.0000e+00 - val_loss: 0.2038 - val_accuracy: 0.0000e+00\n",
            "Epoch 2561/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2064 - accuracy: 0.0000e+00 - val_loss: 0.2042 - val_accuracy: 0.0000e+00\n",
            "Epoch 2562/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2054 - accuracy: 0.0000e+00 - val_loss: 0.2035 - val_accuracy: 0.0000e+00\n",
            "Epoch 2563/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1975 - accuracy: 0.0000e+00 - val_loss: 0.2036 - val_accuracy: 0.0000e+00\n",
            "Epoch 2564/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1967 - accuracy: 0.0000e+00 - val_loss: 0.2041 - val_accuracy: 0.0000e+00\n",
            "Epoch 2565/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1907 - accuracy: 0.0000e+00 - val_loss: 0.2042 - val_accuracy: 0.0000e+00\n",
            "Epoch 2566/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1910 - accuracy: 0.0000e+00 - val_loss: 0.2042 - val_accuracy: 0.0000e+00\n",
            "Epoch 2567/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2028 - accuracy: 0.0000e+00 - val_loss: 0.2050 - val_accuracy: 0.0000e+00\n",
            "Epoch 2568/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1895 - accuracy: 0.0000e+00 - val_loss: 0.2043 - val_accuracy: 0.0000e+00\n",
            "Epoch 2569/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2000 - accuracy: 0.0000e+00 - val_loss: 0.2037 - val_accuracy: 0.0000e+00\n",
            "Epoch 2570/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1868 - accuracy: 0.0000e+00 - val_loss: 0.2043 - val_accuracy: 0.0000e+00\n",
            "Epoch 2571/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1931 - accuracy: 0.0000e+00 - val_loss: 0.2046 - val_accuracy: 0.0000e+00\n",
            "Epoch 2572/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1904 - accuracy: 0.0000e+00 - val_loss: 0.2048 - val_accuracy: 0.0000e+00\n",
            "Epoch 2573/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2017 - accuracy: 0.0000e+00 - val_loss: 0.2048 - val_accuracy: 0.0000e+00\n",
            "Epoch 2574/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1970 - accuracy: 0.0000e+00 - val_loss: 0.2056 - val_accuracy: 0.0000e+00\n",
            "Epoch 2575/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1905 - accuracy: 0.0000e+00 - val_loss: 0.2041 - val_accuracy: 0.0000e+00\n",
            "Epoch 2576/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1908 - accuracy: 0.0000e+00 - val_loss: 0.2035 - val_accuracy: 0.0000e+00\n",
            "Epoch 2577/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1936 - accuracy: 0.0000e+00 - val_loss: 0.2036 - val_accuracy: 0.0000e+00\n",
            "Epoch 2578/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1967 - accuracy: 0.0000e+00 - val_loss: 0.2032 - val_accuracy: 0.0000e+00\n",
            "Epoch 2579/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2011 - accuracy: 0.0000e+00 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2580/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1882 - accuracy: 0.0000e+00 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 2581/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1991 - accuracy: 0.0000e+00 - val_loss: 0.2043 - val_accuracy: 0.0000e+00\n",
            "Epoch 2582/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2085 - accuracy: 0.0000e+00 - val_loss: 0.2048 - val_accuracy: 0.0000e+00\n",
            "Epoch 2583/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1953 - accuracy: 0.0000e+00 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 2584/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2000 - accuracy: 0.0000e+00 - val_loss: 0.2038 - val_accuracy: 0.0000e+00\n",
            "Epoch 2585/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1937 - accuracy: 0.0000e+00 - val_loss: 0.2036 - val_accuracy: 0.0000e+00\n",
            "Epoch 2586/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1910 - accuracy: 0.0000e+00 - val_loss: 0.2037 - val_accuracy: 0.0000e+00\n",
            "Epoch 2587/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2008 - accuracy: 0.0000e+00 - val_loss: 0.2036 - val_accuracy: 0.0000e+00\n",
            "Epoch 2588/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1988 - accuracy: 0.0000e+00 - val_loss: 0.2038 - val_accuracy: 0.0000e+00\n",
            "Epoch 2589/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1901 - accuracy: 0.0000e+00 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 2590/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1952 - accuracy: 0.0000e+00 - val_loss: 0.2039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2591/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1913 - accuracy: 0.0000e+00 - val_loss: 0.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 2592/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2093 - accuracy: 0.0000e+00 - val_loss: 0.2035 - val_accuracy: 0.0000e+00\n",
            "Epoch 2593/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1982 - accuracy: 0.0000e+00 - val_loss: 0.2035 - val_accuracy: 0.0000e+00\n",
            "Epoch 2594/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1950 - accuracy: 0.0000e+00 - val_loss: 0.2029 - val_accuracy: 0.0000e+00\n",
            "Epoch 2595/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1917 - accuracy: 0.0000e+00 - val_loss: 0.2027 - val_accuracy: 0.0000e+00\n",
            "Epoch 2596/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1936 - accuracy: 0.0000e+00 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 2597/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1957 - accuracy: 0.0000e+00 - val_loss: 0.2048 - val_accuracy: 0.0000e+00\n",
            "Epoch 2598/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1970 - accuracy: 0.0000e+00 - val_loss: 0.2050 - val_accuracy: 0.0000e+00\n",
            "Epoch 2599/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1961 - accuracy: 0.0000e+00 - val_loss: 0.2043 - val_accuracy: 0.0000e+00\n",
            "Epoch 2600/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1863 - accuracy: 0.0000e+00 - val_loss: 0.2038 - val_accuracy: 0.0000e+00\n",
            "Epoch 2601/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1845 - accuracy: 0.0000e+00 - val_loss: 0.2037 - val_accuracy: 0.0000e+00\n",
            "Epoch 2602/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2038 - accuracy: 0.0000e+00 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 2603/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2079 - accuracy: 0.0000e+00 - val_loss: 0.2036 - val_accuracy: 0.0000e+00\n",
            "Epoch 2604/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1859 - accuracy: 0.0000e+00 - val_loss: 0.2032 - val_accuracy: 0.0000e+00\n",
            "Epoch 2605/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1923 - accuracy: 0.0000e+00 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2606/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1906 - accuracy: 0.0000e+00 - val_loss: 0.2033 - val_accuracy: 0.0000e+00\n",
            "Epoch 2607/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2047 - accuracy: 0.0000e+00 - val_loss: 0.2039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2608/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1906 - accuracy: 0.0000e+00 - val_loss: 0.2044 - val_accuracy: 0.0000e+00\n",
            "Epoch 2609/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1968 - accuracy: 0.0000e+00 - val_loss: 0.2044 - val_accuracy: 0.0000e+00\n",
            "Epoch 2610/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2102 - accuracy: 0.0000e+00 - val_loss: 0.2043 - val_accuracy: 0.0000e+00\n",
            "Epoch 2611/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2001 - accuracy: 0.0000e+00 - val_loss: 0.2043 - val_accuracy: 0.0000e+00\n",
            "Epoch 2612/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1965 - accuracy: 0.0000e+00 - val_loss: 0.2043 - val_accuracy: 0.0000e+00\n",
            "Epoch 2613/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2012 - accuracy: 0.0000e+00 - val_loss: 0.2036 - val_accuracy: 0.0000e+00\n",
            "Epoch 2614/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1957 - accuracy: 0.0000e+00 - val_loss: 0.2037 - val_accuracy: 0.0000e+00\n",
            "Epoch 2615/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1957 - accuracy: 0.0000e+00 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 2616/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1905 - accuracy: 0.0000e+00 - val_loss: 0.2049 - val_accuracy: 0.0000e+00\n",
            "Epoch 2617/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1951 - accuracy: 0.0000e+00 - val_loss: 0.2049 - val_accuracy: 0.0000e+00\n",
            "Epoch 2618/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1869 - accuracy: 0.0000e+00 - val_loss: 0.2041 - val_accuracy: 0.0000e+00\n",
            "Epoch 2619/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1974 - accuracy: 0.0000e+00 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 2620/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1976 - accuracy: 0.0000e+00 - val_loss: 0.2037 - val_accuracy: 0.0000e+00\n",
            "Epoch 2621/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2072 - accuracy: 0.0000e+00 - val_loss: 0.2052 - val_accuracy: 0.0000e+00\n",
            "Epoch 2622/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1923 - accuracy: 0.0000e+00 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 2623/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1988 - accuracy: 0.0000e+00 - val_loss: 0.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 2624/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1954 - accuracy: 0.0000e+00 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2625/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1908 - accuracy: 0.0000e+00 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2626/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2042 - accuracy: 0.0000e+00 - val_loss: 0.2032 - val_accuracy: 0.0000e+00\n",
            "Epoch 2627/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2016 - accuracy: 0.0000e+00 - val_loss: 0.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 2628/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1989 - accuracy: 0.0000e+00 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
            "Epoch 2629/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2009 - accuracy: 0.0000e+00 - val_loss: 0.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 2630/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1884 - accuracy: 0.0000e+00 - val_loss: 0.2026 - val_accuracy: 0.0000e+00\n",
            "Epoch 2631/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1886 - accuracy: 0.0000e+00 - val_loss: 0.2024 - val_accuracy: 0.0000e+00\n",
            "Epoch 2632/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2097 - accuracy: 0.0000e+00 - val_loss: 0.2021 - val_accuracy: 0.0000e+00\n",
            "Epoch 2633/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1894 - accuracy: 0.0000e+00 - val_loss: 0.2026 - val_accuracy: 0.0000e+00\n",
            "Epoch 2634/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1965 - accuracy: 0.0000e+00 - val_loss: 0.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 2635/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1857 - accuracy: 0.0000e+00 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
            "Epoch 2636/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2035 - accuracy: 0.0000e+00 - val_loss: 0.2029 - val_accuracy: 0.0000e+00\n",
            "Epoch 2637/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1916 - accuracy: 0.0000e+00 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
            "Epoch 2638/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1878 - accuracy: 0.0000e+00 - val_loss: 0.2025 - val_accuracy: 0.0000e+00\n",
            "Epoch 2639/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1966 - accuracy: 0.0000e+00 - val_loss: 0.2024 - val_accuracy: 0.0000e+00\n",
            "Epoch 2640/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1931 - accuracy: 0.0000e+00 - val_loss: 0.2026 - val_accuracy: 0.0000e+00\n",
            "Epoch 2641/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1875 - accuracy: 0.0000e+00 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2642/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1955 - accuracy: 0.0000e+00 - val_loss: 0.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 2643/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2033 - accuracy: 0.0000e+00 - val_loss: 0.2033 - val_accuracy: 0.0000e+00\n",
            "Epoch 2644/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1934 - accuracy: 0.0000e+00 - val_loss: 0.2035 - val_accuracy: 0.0000e+00\n",
            "Epoch 2645/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2101 - accuracy: 0.0000e+00 - val_loss: 0.2037 - val_accuracy: 0.0000e+00\n",
            "Epoch 2646/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1927 - accuracy: 0.0000e+00 - val_loss: 0.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 2647/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1867 - accuracy: 0.0000e+00 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
            "Epoch 2648/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2030 - accuracy: 0.0000e+00 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 2649/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2014 - accuracy: 0.0000e+00 - val_loss: 0.2038 - val_accuracy: 0.0000e+00\n",
            "Epoch 2650/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1973 - accuracy: 0.0000e+00 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2651/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1874 - accuracy: 0.0000e+00 - val_loss: 0.2025 - val_accuracy: 0.0000e+00\n",
            "Epoch 2652/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1946 - accuracy: 0.0000e+00 - val_loss: 0.2022 - val_accuracy: 0.0000e+00\n",
            "Epoch 2653/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1979 - accuracy: 0.0000e+00 - val_loss: 0.2025 - val_accuracy: 0.0000e+00\n",
            "Epoch 2654/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1975 - accuracy: 0.0000e+00 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 2655/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1925 - accuracy: 0.0000e+00 - val_loss: 0.2035 - val_accuracy: 0.0000e+00\n",
            "Epoch 2656/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1883 - accuracy: 0.0000e+00 - val_loss: 0.2036 - val_accuracy: 0.0000e+00\n",
            "Epoch 2657/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1882 - accuracy: 0.0000e+00 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2658/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1856 - accuracy: 0.0000e+00 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
            "Epoch 2659/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1899 - accuracy: 0.0000e+00 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
            "Epoch 2660/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1999 - accuracy: 0.0000e+00 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 2661/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1871 - accuracy: 0.0000e+00 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 2662/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1927 - accuracy: 0.0000e+00 - val_loss: 0.2035 - val_accuracy: 0.0000e+00\n",
            "Epoch 2663/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2020 - accuracy: 0.0000e+00 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 2664/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1898 - accuracy: 0.0000e+00 - val_loss: 0.2047 - val_accuracy: 0.0000e+00\n",
            "Epoch 2665/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1852 - accuracy: 0.0000e+00 - val_loss: 0.2049 - val_accuracy: 0.0000e+00\n",
            "Epoch 2666/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1892 - accuracy: 0.0000e+00 - val_loss: 0.2053 - val_accuracy: 0.0000e+00\n",
            "Epoch 2667/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1821 - accuracy: 0.0000e+00 - val_loss: 0.2045 - val_accuracy: 0.0000e+00\n",
            "Epoch 2668/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1940 - accuracy: 0.0000e+00 - val_loss: 0.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 2669/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1927 - accuracy: 0.0000e+00 - val_loss: 0.2033 - val_accuracy: 0.0000e+00\n",
            "Epoch 2670/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2024 - accuracy: 0.0000e+00 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 2671/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1937 - accuracy: 0.0000e+00 - val_loss: 0.2032 - val_accuracy: 0.0000e+00\n",
            "Epoch 2672/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1956 - accuracy: 0.0000e+00 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
            "Epoch 2673/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1871 - accuracy: 0.0000e+00 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
            "Epoch 2674/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1861 - accuracy: 0.0000e+00 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2675/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1859 - accuracy: 0.0000e+00 - val_loss: 0.2039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2676/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1786 - accuracy: 0.0000e+00 - val_loss: 0.2038 - val_accuracy: 0.0000e+00\n",
            "Epoch 2677/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1875 - accuracy: 0.0000e+00 - val_loss: 0.2037 - val_accuracy: 0.0000e+00\n",
            "Epoch 2678/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2078 - accuracy: 0.0000e+00 - val_loss: 0.2033 - val_accuracy: 0.0000e+00\n",
            "Epoch 2679/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2051 - accuracy: 0.0000e+00 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
            "Epoch 2680/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2037 - accuracy: 0.0000e+00 - val_loss: 0.2026 - val_accuracy: 0.0000e+00\n",
            "Epoch 2681/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1880 - accuracy: 0.0000e+00 - val_loss: 0.2026 - val_accuracy: 0.0000e+00\n",
            "Epoch 2682/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1913 - accuracy: 0.0000e+00 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
            "Epoch 2683/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1919 - accuracy: 0.0000e+00 - val_loss: 0.2027 - val_accuracy: 0.0000e+00\n",
            "Epoch 2684/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1947 - accuracy: 0.0000e+00 - val_loss: 0.2025 - val_accuracy: 0.0000e+00\n",
            "Epoch 2685/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1930 - accuracy: 0.0000e+00 - val_loss: 0.2029 - val_accuracy: 0.0000e+00\n",
            "Epoch 2686/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1826 - accuracy: 0.0000e+00 - val_loss: 0.2037 - val_accuracy: 0.0000e+00\n",
            "Epoch 2687/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1846 - accuracy: 0.0000e+00 - val_loss: 0.2039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2688/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1986 - accuracy: 0.0000e+00 - val_loss: 0.2042 - val_accuracy: 0.0000e+00\n",
            "Epoch 2689/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1944 - accuracy: 0.0000e+00 - val_loss: 0.2035 - val_accuracy: 0.0000e+00\n",
            "Epoch 2690/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1947 - accuracy: 0.0000e+00 - val_loss: 0.2032 - val_accuracy: 0.0000e+00\n",
            "Epoch 2691/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1850 - accuracy: 0.0000e+00 - val_loss: 0.2033 - val_accuracy: 0.0000e+00\n",
            "Epoch 2692/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1822 - accuracy: 0.0000e+00 - val_loss: 0.2033 - val_accuracy: 0.0000e+00\n",
            "Epoch 2693/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1862 - accuracy: 0.0000e+00 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 2694/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1898 - accuracy: 0.0000e+00 - val_loss: 0.2027 - val_accuracy: 0.0000e+00\n",
            "Epoch 2695/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1960 - accuracy: 0.0000e+00 - val_loss: 0.2024 - val_accuracy: 0.0000e+00\n",
            "Epoch 2696/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1861 - accuracy: 0.0000e+00 - val_loss: 0.2027 - val_accuracy: 0.0000e+00\n",
            "Epoch 2697/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1808 - accuracy: 0.0000e+00 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
            "Epoch 2698/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1960 - accuracy: 0.0000e+00 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2699/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1843 - accuracy: 0.0000e+00 - val_loss: 0.2027 - val_accuracy: 0.0000e+00\n",
            "Epoch 2700/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1837 - accuracy: 0.0000e+00 - val_loss: 0.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 2701/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1828 - accuracy: 0.0000e+00 - val_loss: 0.2032 - val_accuracy: 0.0000e+00\n",
            "Epoch 2702/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1850 - accuracy: 0.0000e+00 - val_loss: 0.2038 - val_accuracy: 0.0000e+00\n",
            "Epoch 2703/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1874 - accuracy: 0.0000e+00 - val_loss: 0.2041 - val_accuracy: 0.0000e+00\n",
            "Epoch 2704/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1823 - accuracy: 0.0000e+00 - val_loss: 0.2037 - val_accuracy: 0.0000e+00\n",
            "Epoch 2705/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2011 - accuracy: 0.0000e+00 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 2706/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1907 - accuracy: 0.0000e+00 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 2707/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1932 - accuracy: 0.0000e+00 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 2708/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1893 - accuracy: 0.0000e+00 - val_loss: 0.2041 - val_accuracy: 0.0000e+00\n",
            "Epoch 2709/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1895 - accuracy: 0.0000e+00 - val_loss: 0.2036 - val_accuracy: 0.0000e+00\n",
            "Epoch 2710/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1990 - accuracy: 0.0000e+00 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
            "Epoch 2711/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2093 - accuracy: 0.0000e+00 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 2712/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1928 - accuracy: 0.0000e+00 - val_loss: 0.2048 - val_accuracy: 0.0000e+00\n",
            "Epoch 2713/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1977 - accuracy: 0.0000e+00 - val_loss: 0.2039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2714/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1916 - accuracy: 0.0000e+00 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 2715/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1828 - accuracy: 0.0000e+00 - val_loss: 0.2033 - val_accuracy: 0.0000e+00\n",
            "Epoch 2716/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1854 - accuracy: 0.0000e+00 - val_loss: 0.2037 - val_accuracy: 0.0000e+00\n",
            "Epoch 2717/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1810 - accuracy: 0.0000e+00 - val_loss: 0.2038 - val_accuracy: 0.0000e+00\n",
            "Epoch 2718/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1771 - accuracy: 0.0000e+00 - val_loss: 0.2039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2719/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1957 - accuracy: 0.0000e+00 - val_loss: 0.2035 - val_accuracy: 0.0000e+00\n",
            "Epoch 2720/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2000 - accuracy: 0.0000e+00 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2721/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1908 - accuracy: 0.0000e+00 - val_loss: 0.2029 - val_accuracy: 0.0000e+00\n",
            "Epoch 2722/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1972 - accuracy: 0.0000e+00 - val_loss: 0.2025 - val_accuracy: 0.0000e+00\n",
            "Epoch 2723/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1816 - accuracy: 0.0000e+00 - val_loss: 0.2025 - val_accuracy: 0.0000e+00\n",
            "Epoch 2724/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1959 - accuracy: 0.0000e+00 - val_loss: 0.2029 - val_accuracy: 0.0000e+00\n",
            "Epoch 2725/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1843 - accuracy: 0.0000e+00 - val_loss: 0.2033 - val_accuracy: 0.0000e+00\n",
            "Epoch 2726/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1941 - accuracy: 0.0000e+00 - val_loss: 0.2038 - val_accuracy: 0.0000e+00\n",
            "Epoch 2727/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1875 - accuracy: 0.0000e+00 - val_loss: 0.2038 - val_accuracy: 0.0000e+00\n",
            "Epoch 2728/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2001 - accuracy: 0.0000e+00 - val_loss: 0.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 2729/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1871 - accuracy: 0.0000e+00 - val_loss: 0.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 2730/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1995 - accuracy: 0.0000e+00 - val_loss: 0.2029 - val_accuracy: 0.0000e+00\n",
            "Epoch 2731/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1950 - accuracy: 0.0000e+00 - val_loss: 0.2023 - val_accuracy: 0.0000e+00\n",
            "Epoch 2732/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1912 - accuracy: 0.0000e+00 - val_loss: 0.2020 - val_accuracy: 0.0000e+00\n",
            "Epoch 2733/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1913 - accuracy: 0.0000e+00 - val_loss: 0.2025 - val_accuracy: 0.0000e+00\n",
            "Epoch 2734/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1970 - accuracy: 0.0000e+00 - val_loss: 0.2025 - val_accuracy: 0.0000e+00\n",
            "Epoch 2735/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1855 - accuracy: 0.0000e+00 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2736/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1938 - accuracy: 0.0000e+00 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2737/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1824 - accuracy: 0.0000e+00 - val_loss: 0.2033 - val_accuracy: 0.0000e+00\n",
            "Epoch 2738/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1897 - accuracy: 0.0000e+00 - val_loss: 0.2038 - val_accuracy: 0.0000e+00\n",
            "Epoch 2739/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1833 - accuracy: 0.0000e+00 - val_loss: 0.2042 - val_accuracy: 0.0000e+00\n",
            "Epoch 2740/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1874 - accuracy: 0.0000e+00 - val_loss: 0.2047 - val_accuracy: 0.0000e+00\n",
            "Epoch 2741/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1796 - accuracy: 0.0000e+00 - val_loss: 0.2039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2742/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1875 - accuracy: 0.0000e+00 - val_loss: 0.2033 - val_accuracy: 0.0000e+00\n",
            "Epoch 2743/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1808 - accuracy: 0.0000e+00 - val_loss: 0.2027 - val_accuracy: 0.0000e+00\n",
            "Epoch 2744/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1857 - accuracy: 0.0000e+00 - val_loss: 0.2025 - val_accuracy: 0.0000e+00\n",
            "Epoch 2745/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1842 - accuracy: 0.0000e+00 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2746/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1873 - accuracy: 0.0000e+00 - val_loss: 0.2039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2747/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1822 - accuracy: 0.0000e+00 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 2748/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1830 - accuracy: 0.0000e+00 - val_loss: 0.2037 - val_accuracy: 0.0000e+00\n",
            "Epoch 2749/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1904 - accuracy: 0.0000e+00 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
            "Epoch 2750/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1875 - accuracy: 0.0000e+00 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2751/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1838 - accuracy: 0.0000e+00 - val_loss: 0.2033 - val_accuracy: 0.0000e+00\n",
            "Epoch 2752/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1839 - accuracy: 0.0000e+00 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 2753/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1954 - accuracy: 0.0000e+00 - val_loss: 0.2033 - val_accuracy: 0.0000e+00\n",
            "Epoch 2754/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1917 - accuracy: 0.0000e+00 - val_loss: 0.2025 - val_accuracy: 0.0000e+00\n",
            "Epoch 2755/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1797 - accuracy: 0.0000e+00 - val_loss: 0.2019 - val_accuracy: 0.0000e+00\n",
            "Epoch 2756/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1960 - accuracy: 0.0000e+00 - val_loss: 0.2017 - val_accuracy: 0.0000e+00\n",
            "Epoch 2757/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1817 - accuracy: 0.0000e+00 - val_loss: 0.2019 - val_accuracy: 0.0000e+00\n",
            "Epoch 2758/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1932 - accuracy: 0.0000e+00 - val_loss: 0.2024 - val_accuracy: 0.0000e+00\n",
            "Epoch 2759/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1824 - accuracy: 0.0000e+00 - val_loss: 0.2024 - val_accuracy: 0.0000e+00\n",
            "Epoch 2760/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1873 - accuracy: 0.0000e+00 - val_loss: 0.2027 - val_accuracy: 0.0000e+00\n",
            "Epoch 2761/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1878 - accuracy: 0.0000e+00 - val_loss: 0.2024 - val_accuracy: 0.0000e+00\n",
            "Epoch 2762/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1795 - accuracy: 0.0000e+00 - val_loss: 0.2024 - val_accuracy: 0.0000e+00\n",
            "Epoch 2763/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1854 - accuracy: 0.0000e+00 - val_loss: 0.2027 - val_accuracy: 0.0000e+00\n",
            "Epoch 2764/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1852 - accuracy: 0.0000e+00 - val_loss: 0.2022 - val_accuracy: 0.0000e+00\n",
            "Epoch 2765/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1883 - accuracy: 0.0000e+00 - val_loss: 0.2025 - val_accuracy: 0.0000e+00\n",
            "Epoch 2766/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1781 - accuracy: 0.0000e+00 - val_loss: 0.2027 - val_accuracy: 0.0000e+00\n",
            "Epoch 2767/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1826 - accuracy: 0.0000e+00 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2768/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1951 - accuracy: 0.0000e+00 - val_loss: 0.2026 - val_accuracy: 0.0000e+00\n",
            "Epoch 2769/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1998 - accuracy: 0.0000e+00 - val_loss: 0.2025 - val_accuracy: 0.0000e+00\n",
            "Epoch 2770/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1856 - accuracy: 0.0000e+00 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2771/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1825 - accuracy: 0.0000e+00 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 2772/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1941 - accuracy: 0.0000e+00 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 2773/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1815 - accuracy: 0.0000e+00 - val_loss: 0.2038 - val_accuracy: 0.0000e+00\n",
            "Epoch 2774/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1910 - accuracy: 0.0000e+00 - val_loss: 0.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 2775/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1878 - accuracy: 0.0000e+00 - val_loss: 0.2032 - val_accuracy: 0.0000e+00\n",
            "Epoch 2776/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1930 - accuracy: 0.0000e+00 - val_loss: 0.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 2777/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1882 - accuracy: 0.0000e+00 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 2778/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1941 - accuracy: 0.0000e+00 - val_loss: 0.2042 - val_accuracy: 0.0000e+00\n",
            "Epoch 2779/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1799 - accuracy: 0.0000e+00 - val_loss: 0.2046 - val_accuracy: 0.0000e+00\n",
            "Epoch 2780/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1929 - accuracy: 0.0000e+00 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 2781/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1860 - accuracy: 0.0000e+00 - val_loss: 0.2023 - val_accuracy: 0.0000e+00\n",
            "Epoch 2782/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1880 - accuracy: 0.0000e+00 - val_loss: 0.2017 - val_accuracy: 0.0000e+00\n",
            "Epoch 2783/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1800 - accuracy: 0.0000e+00 - val_loss: 0.2018 - val_accuracy: 0.0000e+00\n",
            "Epoch 2784/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1923 - accuracy: 0.0000e+00 - val_loss: 0.2024 - val_accuracy: 0.0000e+00\n",
            "Epoch 2785/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1839 - accuracy: 0.0000e+00 - val_loss: 0.2033 - val_accuracy: 0.0000e+00\n",
            "Epoch 2786/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1766 - accuracy: 0.0000e+00 - val_loss: 0.2026 - val_accuracy: 0.0000e+00\n",
            "Epoch 2787/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1978 - accuracy: 0.0000e+00 - val_loss: 0.2020 - val_accuracy: 0.0000e+00\n",
            "Epoch 2788/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1798 - accuracy: 0.0000e+00 - val_loss: 0.2026 - val_accuracy: 0.0000e+00\n",
            "Epoch 2789/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1718 - accuracy: 0.0000e+00 - val_loss: 0.2020 - val_accuracy: 0.0000e+00\n",
            "Epoch 2790/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1860 - accuracy: 0.0000e+00 - val_loss: 0.2022 - val_accuracy: 0.0000e+00\n",
            "Epoch 2791/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1847 - accuracy: 0.0000e+00 - val_loss: 0.2024 - val_accuracy: 0.0000e+00\n",
            "Epoch 2792/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1867 - accuracy: 0.0000e+00 - val_loss: 0.2026 - val_accuracy: 0.0000e+00\n",
            "Epoch 2793/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1824 - accuracy: 0.0000e+00 - val_loss: 0.2026 - val_accuracy: 0.0000e+00\n",
            "Epoch 2794/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1840 - accuracy: 0.0000e+00 - val_loss: 0.2017 - val_accuracy: 0.0000e+00\n",
            "Epoch 2795/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1830 - accuracy: 0.0000e+00 - val_loss: 0.2010 - val_accuracy: 0.0000e+00\n",
            "Epoch 2796/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1746 - accuracy: 0.0000e+00 - val_loss: 0.2011 - val_accuracy: 0.0000e+00\n",
            "Epoch 2797/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1995 - accuracy: 0.0000e+00 - val_loss: 0.2008 - val_accuracy: 0.0000e+00\n",
            "Epoch 2798/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1730 - accuracy: 0.0000e+00 - val_loss: 0.2002 - val_accuracy: 0.0000e+00\n",
            "Epoch 2799/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1790 - accuracy: 0.0000e+00 - val_loss: 0.2003 - val_accuracy: 0.0000e+00\n",
            "Epoch 2800/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1852 - accuracy: 0.0000e+00 - val_loss: 0.2008 - val_accuracy: 0.0000e+00\n",
            "Epoch 2801/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1734 - accuracy: 0.0000e+00 - val_loss: 0.2007 - val_accuracy: 0.0000e+00\n",
            "Epoch 2802/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1823 - accuracy: 0.0000e+00 - val_loss: 0.2011 - val_accuracy: 0.0000e+00\n",
            "Epoch 2803/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1836 - accuracy: 0.0000e+00 - val_loss: 0.2012 - val_accuracy: 0.0000e+00\n",
            "Epoch 2804/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1824 - accuracy: 0.0000e+00 - val_loss: 0.2005 - val_accuracy: 0.0000e+00\n",
            "Epoch 2805/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1913 - accuracy: 0.0000e+00 - val_loss: 0.2005 - val_accuracy: 0.0000e+00\n",
            "Epoch 2806/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1789 - accuracy: 0.0000e+00 - val_loss: 0.2002 - val_accuracy: 0.0000e+00\n",
            "Epoch 2807/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1837 - accuracy: 0.0000e+00 - val_loss: 0.2012 - val_accuracy: 0.0000e+00\n",
            "Epoch 2808/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1889 - accuracy: 0.0000e+00 - val_loss: 0.2010 - val_accuracy: 0.0000e+00\n",
            "Epoch 2809/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2003 - accuracy: 0.0000e+00 - val_loss: 0.2000 - val_accuracy: 0.0000e+00\n",
            "Epoch 2810/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1768 - accuracy: 0.0000e+00 - val_loss: 0.1987 - val_accuracy: 0.0000e+00\n",
            "Epoch 2811/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1945 - accuracy: 0.0000e+00 - val_loss: 0.1985 - val_accuracy: 0.0000e+00\n",
            "Epoch 2812/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1767 - accuracy: 0.0000e+00 - val_loss: 0.1982 - val_accuracy: 0.0000e+00\n",
            "Epoch 2813/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1843 - accuracy: 0.0000e+00 - val_loss: 0.1975 - val_accuracy: 0.0000e+00\n",
            "Epoch 2814/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1847 - accuracy: 0.0000e+00 - val_loss: 0.1985 - val_accuracy: 0.0000e+00\n",
            "Epoch 2815/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1921 - accuracy: 0.0000e+00 - val_loss: 0.1980 - val_accuracy: 0.0000e+00\n",
            "Epoch 2816/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1760 - accuracy: 0.0000e+00 - val_loss: 0.1970 - val_accuracy: 0.0000e+00\n",
            "Epoch 2817/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1770 - accuracy: 0.0000e+00 - val_loss: 0.1968 - val_accuracy: 0.0000e+00\n",
            "Epoch 2818/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1760 - accuracy: 0.0000e+00 - val_loss: 0.1961 - val_accuracy: 0.0000e+00\n",
            "Epoch 2819/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1810 - accuracy: 0.0000e+00 - val_loss: 0.1956 - val_accuracy: 0.0000e+00\n",
            "Epoch 2820/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1819 - accuracy: 0.0000e+00 - val_loss: 0.1957 - val_accuracy: 0.0000e+00\n",
            "Epoch 2821/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1882 - accuracy: 0.0000e+00 - val_loss: 0.1969 - val_accuracy: 0.0000e+00\n",
            "Epoch 2822/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1773 - accuracy: 0.0000e+00 - val_loss: 0.1960 - val_accuracy: 0.0000e+00\n",
            "Epoch 2823/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1872 - accuracy: 0.0000e+00 - val_loss: 0.1957 - val_accuracy: 0.0000e+00\n",
            "Epoch 2824/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1919 - accuracy: 0.0000e+00 - val_loss: 0.1956 - val_accuracy: 0.0000e+00\n",
            "Epoch 2825/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1825 - accuracy: 0.0000e+00 - val_loss: 0.1957 - val_accuracy: 0.0000e+00\n",
            "Epoch 2826/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1734 - accuracy: 0.0000e+00 - val_loss: 0.1954 - val_accuracy: 0.0000e+00\n",
            "Epoch 2827/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1787 - accuracy: 0.0000e+00 - val_loss: 0.1957 - val_accuracy: 0.0000e+00\n",
            "Epoch 2828/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1846 - accuracy: 0.0000e+00 - val_loss: 0.1958 - val_accuracy: 0.0000e+00\n",
            "Epoch 2829/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1704 - accuracy: 0.0000e+00 - val_loss: 0.1946 - val_accuracy: 0.0000e+00\n",
            "Epoch 2830/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1741 - accuracy: 0.0000e+00 - val_loss: 0.1942 - val_accuracy: 0.0000e+00\n",
            "Epoch 2831/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1695 - accuracy: 0.0000e+00 - val_loss: 0.1939 - val_accuracy: 0.0000e+00\n",
            "Epoch 2832/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1757 - accuracy: 0.0000e+00 - val_loss: 0.1939 - val_accuracy: 0.0000e+00\n",
            "Epoch 2833/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1835 - accuracy: 0.0000e+00 - val_loss: 0.1941 - val_accuracy: 0.0000e+00\n",
            "Epoch 2834/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1682 - accuracy: 0.0000e+00 - val_loss: 0.1948 - val_accuracy: 0.0000e+00\n",
            "Epoch 2835/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1860 - accuracy: 0.0000e+00 - val_loss: 0.1944 - val_accuracy: 0.0000e+00\n",
            "Epoch 2836/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1707 - accuracy: 0.0000e+00 - val_loss: 0.1941 - val_accuracy: 0.0000e+00\n",
            "Epoch 2837/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1877 - accuracy: 0.0000e+00 - val_loss: 0.1931 - val_accuracy: 0.0000e+00\n",
            "Epoch 2838/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1777 - accuracy: 0.0000e+00 - val_loss: 0.1923 - val_accuracy: 0.0000e+00\n",
            "Epoch 2839/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1700 - accuracy: 0.0000e+00 - val_loss: 0.1925 - val_accuracy: 0.0000e+00\n",
            "Epoch 2840/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1736 - accuracy: 0.0000e+00 - val_loss: 0.1923 - val_accuracy: 0.0000e+00\n",
            "Epoch 2841/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1686 - accuracy: 0.0000e+00 - val_loss: 0.1927 - val_accuracy: 0.0000e+00\n",
            "Epoch 2842/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1729 - accuracy: 0.0000e+00 - val_loss: 0.1924 - val_accuracy: 0.0000e+00\n",
            "Epoch 2843/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1796 - accuracy: 0.0000e+00 - val_loss: 0.1921 - val_accuracy: 0.0000e+00\n",
            "Epoch 2844/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1792 - accuracy: 0.0000e+00 - val_loss: 0.1918 - val_accuracy: 0.0000e+00\n",
            "Epoch 2845/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1787 - accuracy: 0.0000e+00 - val_loss: 0.1913 - val_accuracy: 0.0000e+00\n",
            "Epoch 2846/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1709 - accuracy: 0.0000e+00 - val_loss: 0.1903 - val_accuracy: 0.0000e+00\n",
            "Epoch 2847/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1637 - accuracy: 0.0000e+00 - val_loss: 0.1901 - val_accuracy: 0.0000e+00\n",
            "Epoch 2848/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1776 - accuracy: 0.0000e+00 - val_loss: 0.1902 - val_accuracy: 0.0000e+00\n",
            "Epoch 2849/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1773 - accuracy: 0.0000e+00 - val_loss: 0.1901 - val_accuracy: 0.0000e+00\n",
            "Epoch 2850/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1804 - accuracy: 0.0000e+00 - val_loss: 0.1897 - val_accuracy: 0.0000e+00\n",
            "Epoch 2851/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1802 - accuracy: 0.0000e+00 - val_loss: 0.1926 - val_accuracy: 0.0000e+00\n",
            "Epoch 2852/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1706 - accuracy: 0.0000e+00 - val_loss: 0.1921 - val_accuracy: 0.0000e+00\n",
            "Epoch 2853/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1689 - accuracy: 0.0000e+00 - val_loss: 0.1906 - val_accuracy: 0.0000e+00\n",
            "Epoch 2854/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1763 - accuracy: 0.0000e+00 - val_loss: 0.1900 - val_accuracy: 0.0000e+00\n",
            "Epoch 2855/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1738 - accuracy: 0.0000e+00 - val_loss: 0.1898 - val_accuracy: 0.0000e+00\n",
            "Epoch 2856/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1751 - accuracy: 0.0000e+00 - val_loss: 0.1898 - val_accuracy: 0.0000e+00\n",
            "Epoch 2857/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1775 - accuracy: 0.0000e+00 - val_loss: 0.1897 - val_accuracy: 0.0000e+00\n",
            "Epoch 2858/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1751 - accuracy: 0.0000e+00 - val_loss: 0.1893 - val_accuracy: 0.0000e+00\n",
            "Epoch 2859/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1780 - accuracy: 0.0000e+00 - val_loss: 0.1885 - val_accuracy: 0.0000e+00\n",
            "Epoch 2860/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1701 - accuracy: 0.0000e+00 - val_loss: 0.1881 - val_accuracy: 0.0000e+00\n",
            "Epoch 2861/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1642 - accuracy: 0.0000e+00 - val_loss: 0.1874 - val_accuracy: 0.0000e+00\n",
            "Epoch 2862/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1660 - accuracy: 0.0000e+00 - val_loss: 0.1868 - val_accuracy: 0.0000e+00\n",
            "Epoch 2863/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1627 - accuracy: 0.0000e+00 - val_loss: 0.1863 - val_accuracy: 0.0000e+00\n",
            "Epoch 2864/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1819 - accuracy: 0.0000e+00 - val_loss: 0.1860 - val_accuracy: 0.0000e+00\n",
            "Epoch 2865/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1734 - accuracy: 0.0000e+00 - val_loss: 0.1862 - val_accuracy: 0.0000e+00\n",
            "Epoch 2866/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1766 - accuracy: 0.0000e+00 - val_loss: 0.1865 - val_accuracy: 0.0000e+00\n",
            "Epoch 2867/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1768 - accuracy: 0.0000e+00 - val_loss: 0.1865 - val_accuracy: 0.0000e+00\n",
            "Epoch 2868/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1851 - accuracy: 0.0000e+00 - val_loss: 0.1867 - val_accuracy: 0.0000e+00\n",
            "Epoch 2869/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1683 - accuracy: 0.0000e+00 - val_loss: 0.1860 - val_accuracy: 0.0000e+00\n",
            "Epoch 2870/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1723 - accuracy: 0.0000e+00 - val_loss: 0.1859 - val_accuracy: 0.0000e+00\n",
            "Epoch 2871/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1801 - accuracy: 0.0000e+00 - val_loss: 0.1863 - val_accuracy: 0.0000e+00\n",
            "Epoch 2872/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1726 - accuracy: 0.0000e+00 - val_loss: 0.1861 - val_accuracy: 0.0000e+00\n",
            "Epoch 2873/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1849 - accuracy: 0.0000e+00 - val_loss: 0.1855 - val_accuracy: 0.0000e+00\n",
            "Epoch 2874/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1749 - accuracy: 0.0000e+00 - val_loss: 0.1853 - val_accuracy: 0.0000e+00\n",
            "Epoch 2875/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1728 - accuracy: 0.0000e+00 - val_loss: 0.1858 - val_accuracy: 0.0000e+00\n",
            "Epoch 2876/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1693 - accuracy: 0.0000e+00 - val_loss: 0.1852 - val_accuracy: 0.0000e+00\n",
            "Epoch 2877/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1702 - accuracy: 0.0000e+00 - val_loss: 0.1855 - val_accuracy: 0.0000e+00\n",
            "Epoch 2878/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1682 - accuracy: 0.0000e+00 - val_loss: 0.1850 - val_accuracy: 0.0000e+00\n",
            "Epoch 2879/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1842 - accuracy: 0.0000e+00 - val_loss: 0.1850 - val_accuracy: 0.0000e+00\n",
            "Epoch 2880/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1716 - accuracy: 0.0000e+00 - val_loss: 0.1854 - val_accuracy: 0.0000e+00\n",
            "Epoch 2881/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1707 - accuracy: 0.0000e+00 - val_loss: 0.1849 - val_accuracy: 0.0000e+00\n",
            "Epoch 2882/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1656 - accuracy: 0.0000e+00 - val_loss: 0.1847 - val_accuracy: 0.0000e+00\n",
            "Epoch 2883/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1633 - accuracy: 0.0000e+00 - val_loss: 0.1846 - val_accuracy: 0.0000e+00\n",
            "Epoch 2884/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1767 - accuracy: 0.0000e+00 - val_loss: 0.1841 - val_accuracy: 0.0000e+00\n",
            "Epoch 2885/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1772 - accuracy: 0.0000e+00 - val_loss: 0.1837 - val_accuracy: 0.0000e+00\n",
            "Epoch 2886/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1810 - accuracy: 0.0000e+00 - val_loss: 0.1832 - val_accuracy: 0.0000e+00\n",
            "Epoch 2887/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1689 - accuracy: 0.0000e+00 - val_loss: 0.1832 - val_accuracy: 0.0000e+00\n",
            "Epoch 2888/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1685 - accuracy: 0.0000e+00 - val_loss: 0.1836 - val_accuracy: 0.0000e+00\n",
            "Epoch 2889/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1768 - accuracy: 0.0000e+00 - val_loss: 0.1840 - val_accuracy: 0.0000e+00\n",
            "Epoch 2890/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1757 - accuracy: 0.0000e+00 - val_loss: 0.1837 - val_accuracy: 0.0000e+00\n",
            "Epoch 2891/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1631 - accuracy: 0.0000e+00 - val_loss: 0.1833 - val_accuracy: 0.0000e+00\n",
            "Epoch 2892/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1615 - accuracy: 0.0000e+00 - val_loss: 0.1826 - val_accuracy: 0.0000e+00\n",
            "Epoch 2893/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1764 - accuracy: 0.0000e+00 - val_loss: 0.1823 - val_accuracy: 0.0000e+00\n",
            "Epoch 2894/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1769 - accuracy: 0.0000e+00 - val_loss: 0.1823 - val_accuracy: 0.0000e+00\n",
            "Epoch 2895/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1836 - accuracy: 0.0000e+00 - val_loss: 0.1829 - val_accuracy: 0.0000e+00\n",
            "Epoch 2896/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1667 - accuracy: 0.0000e+00 - val_loss: 0.1838 - val_accuracy: 0.0000e+00\n",
            "Epoch 2897/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1721 - accuracy: 0.0000e+00 - val_loss: 0.1842 - val_accuracy: 0.0000e+00\n",
            "Epoch 2898/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1738 - accuracy: 0.0000e+00 - val_loss: 0.1838 - val_accuracy: 0.0000e+00\n",
            "Epoch 2899/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1851 - accuracy: 0.0000e+00 - val_loss: 0.1830 - val_accuracy: 0.0000e+00\n",
            "Epoch 2900/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1819 - accuracy: 0.0000e+00 - val_loss: 0.1827 - val_accuracy: 0.0000e+00\n",
            "Epoch 2901/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1886 - accuracy: 0.0000e+00 - val_loss: 0.1816 - val_accuracy: 0.0000e+00\n",
            "Epoch 2902/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1645 - accuracy: 0.0000e+00 - val_loss: 0.1813 - val_accuracy: 0.0000e+00\n",
            "Epoch 2903/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1690 - accuracy: 0.0000e+00 - val_loss: 0.1811 - val_accuracy: 0.0000e+00\n",
            "Epoch 2904/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1764 - accuracy: 0.0000e+00 - val_loss: 0.1812 - val_accuracy: 0.0000e+00\n",
            "Epoch 2905/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1736 - accuracy: 0.0000e+00 - val_loss: 0.1814 - val_accuracy: 0.0000e+00\n",
            "Epoch 2906/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1731 - accuracy: 0.0000e+00 - val_loss: 0.1812 - val_accuracy: 0.0000e+00\n",
            "Epoch 2907/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1659 - accuracy: 0.0000e+00 - val_loss: 0.1809 - val_accuracy: 0.0000e+00\n",
            "Epoch 2908/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1678 - accuracy: 0.0000e+00 - val_loss: 0.1810 - val_accuracy: 0.0000e+00\n",
            "Epoch 2909/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1708 - accuracy: 0.0000e+00 - val_loss: 0.1810 - val_accuracy: 0.0000e+00\n",
            "Epoch 2910/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1670 - accuracy: 0.0000e+00 - val_loss: 0.1810 - val_accuracy: 0.0000e+00\n",
            "Epoch 2911/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1589 - accuracy: 0.0000e+00 - val_loss: 0.1811 - val_accuracy: 0.0000e+00\n",
            "Epoch 2912/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1903 - accuracy: 0.0000e+00 - val_loss: 0.1806 - val_accuracy: 0.0000e+00\n",
            "Epoch 2913/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1701 - accuracy: 0.0000e+00 - val_loss: 0.1807 - val_accuracy: 0.0000e+00\n",
            "Epoch 2914/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1693 - accuracy: 0.0000e+00 - val_loss: 0.1804 - val_accuracy: 0.0000e+00\n",
            "Epoch 2915/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1642 - accuracy: 0.0000e+00 - val_loss: 0.1795 - val_accuracy: 0.0000e+00\n",
            "Epoch 2916/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1688 - accuracy: 0.0000e+00 - val_loss: 0.1796 - val_accuracy: 0.0000e+00\n",
            "Epoch 2917/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1741 - accuracy: 0.0000e+00 - val_loss: 0.1803 - val_accuracy: 0.0000e+00\n",
            "Epoch 2918/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1623 - accuracy: 0.0000e+00 - val_loss: 0.1799 - val_accuracy: 0.0000e+00\n",
            "Epoch 2919/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1826 - accuracy: 0.0000e+00 - val_loss: 0.1801 - val_accuracy: 0.0000e+00\n",
            "Epoch 2920/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1682 - accuracy: 0.0000e+00 - val_loss: 0.1799 - val_accuracy: 0.0000e+00\n",
            "Epoch 2921/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1770 - accuracy: 0.0000e+00 - val_loss: 0.1797 - val_accuracy: 0.0000e+00\n",
            "Epoch 2922/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1741 - accuracy: 0.0000e+00 - val_loss: 0.1798 - val_accuracy: 0.0000e+00\n",
            "Epoch 2923/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1703 - accuracy: 0.0000e+00 - val_loss: 0.1802 - val_accuracy: 0.0000e+00\n",
            "Epoch 2924/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1707 - accuracy: 0.0000e+00 - val_loss: 0.1804 - val_accuracy: 0.0000e+00\n",
            "Epoch 2925/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1608 - accuracy: 0.0000e+00 - val_loss: 0.1813 - val_accuracy: 0.0000e+00\n",
            "Epoch 2926/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1820 - accuracy: 0.0000e+00 - val_loss: 0.1802 - val_accuracy: 0.0000e+00\n",
            "Epoch 2927/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1705 - accuracy: 0.0000e+00 - val_loss: 0.1797 - val_accuracy: 0.0000e+00\n",
            "Epoch 2928/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1794 - accuracy: 0.0000e+00 - val_loss: 0.1789 - val_accuracy: 0.0000e+00\n",
            "Epoch 2929/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1676 - accuracy: 0.0000e+00 - val_loss: 0.1784 - val_accuracy: 0.0000e+00\n",
            "Epoch 2930/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1598 - accuracy: 0.0000e+00 - val_loss: 0.1782 - val_accuracy: 0.0000e+00\n",
            "Epoch 2931/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1823 - accuracy: 0.0000e+00 - val_loss: 0.1781 - val_accuracy: 0.0000e+00\n",
            "Epoch 2932/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1807 - accuracy: 0.0000e+00 - val_loss: 0.1788 - val_accuracy: 0.0000e+00\n",
            "Epoch 2933/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1643 - accuracy: 0.0000e+00 - val_loss: 0.1791 - val_accuracy: 0.0000e+00\n",
            "Epoch 2934/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1721 - accuracy: 0.0000e+00 - val_loss: 0.1789 - val_accuracy: 0.0000e+00\n",
            "Epoch 2935/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1635 - accuracy: 0.0000e+00 - val_loss: 0.1786 - val_accuracy: 0.0000e+00\n",
            "Epoch 2936/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1633 - accuracy: 0.0000e+00 - val_loss: 0.1783 - val_accuracy: 0.0000e+00\n",
            "Epoch 2937/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1763 - accuracy: 0.0000e+00 - val_loss: 0.1781 - val_accuracy: 0.0000e+00\n",
            "Epoch 2938/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1725 - accuracy: 0.0000e+00 - val_loss: 0.1775 - val_accuracy: 0.0000e+00\n",
            "Epoch 2939/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1660 - accuracy: 0.0000e+00 - val_loss: 0.1772 - val_accuracy: 0.0000e+00\n",
            "Epoch 2940/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1608 - accuracy: 0.0000e+00 - val_loss: 0.1777 - val_accuracy: 0.0000e+00\n",
            "Epoch 2941/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1672 - accuracy: 0.0000e+00 - val_loss: 0.1773 - val_accuracy: 0.0000e+00\n",
            "Epoch 2942/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1620 - accuracy: 0.0000e+00 - val_loss: 0.1767 - val_accuracy: 0.0000e+00\n",
            "Epoch 2943/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1574 - accuracy: 0.0000e+00 - val_loss: 0.1767 - val_accuracy: 0.0000e+00\n",
            "Epoch 2944/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1666 - accuracy: 0.0000e+00 - val_loss: 0.1763 - val_accuracy: 0.0000e+00\n",
            "Epoch 2945/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1590 - accuracy: 0.0000e+00 - val_loss: 0.1767 - val_accuracy: 0.0000e+00\n",
            "Epoch 2946/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1696 - accuracy: 0.0000e+00 - val_loss: 0.1769 - val_accuracy: 0.0000e+00\n",
            "Epoch 2947/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1580 - accuracy: 0.0000e+00 - val_loss: 0.1769 - val_accuracy: 0.0000e+00\n",
            "Epoch 2948/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1771 - accuracy: 0.0000e+00 - val_loss: 0.1766 - val_accuracy: 0.0000e+00\n",
            "Epoch 2949/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1636 - accuracy: 0.0000e+00 - val_loss: 0.1769 - val_accuracy: 0.0000e+00\n",
            "Epoch 2950/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1695 - accuracy: 0.0000e+00 - val_loss: 0.1778 - val_accuracy: 0.0000e+00\n",
            "Epoch 2951/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1744 - accuracy: 0.0000e+00 - val_loss: 0.1768 - val_accuracy: 0.0000e+00\n",
            "Epoch 2952/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1651 - accuracy: 0.0000e+00 - val_loss: 0.1765 - val_accuracy: 0.0000e+00\n",
            "Epoch 2953/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1583 - accuracy: 0.0000e+00 - val_loss: 0.1763 - val_accuracy: 0.0000e+00\n",
            "Epoch 2954/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1701 - accuracy: 0.0000e+00 - val_loss: 0.1763 - val_accuracy: 0.0000e+00\n",
            "Epoch 2955/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1586 - accuracy: 0.0000e+00 - val_loss: 0.1762 - val_accuracy: 0.0000e+00\n",
            "Epoch 2956/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1665 - accuracy: 0.0000e+00 - val_loss: 0.1757 - val_accuracy: 0.0000e+00\n",
            "Epoch 2957/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1712 - accuracy: 0.0000e+00 - val_loss: 0.1757 - val_accuracy: 0.0000e+00\n",
            "Epoch 2958/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1643 - accuracy: 0.0000e+00 - val_loss: 0.1755 - val_accuracy: 0.0000e+00\n",
            "Epoch 2959/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1619 - accuracy: 0.0000e+00 - val_loss: 0.1755 - val_accuracy: 0.0000e+00\n",
            "Epoch 2960/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1724 - accuracy: 0.0000e+00 - val_loss: 0.1756 - val_accuracy: 0.0000e+00\n",
            "Epoch 2961/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1666 - accuracy: 0.0000e+00 - val_loss: 0.1750 - val_accuracy: 0.0000e+00\n",
            "Epoch 2962/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1842 - accuracy: 0.0000e+00 - val_loss: 0.1750 - val_accuracy: 0.0000e+00\n",
            "Epoch 2963/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1689 - accuracy: 0.0000e+00 - val_loss: 0.1752 - val_accuracy: 0.0000e+00\n",
            "Epoch 2964/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1585 - accuracy: 0.0000e+00 - val_loss: 0.1754 - val_accuracy: 0.0000e+00\n",
            "Epoch 2965/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1590 - accuracy: 0.0000e+00 - val_loss: 0.1755 - val_accuracy: 0.0000e+00\n",
            "Epoch 2966/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1647 - accuracy: 0.0000e+00 - val_loss: 0.1749 - val_accuracy: 0.0000e+00\n",
            "Epoch 2967/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1656 - accuracy: 0.0000e+00 - val_loss: 0.1744 - val_accuracy: 0.0000e+00\n",
            "Epoch 2968/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1632 - accuracy: 0.0000e+00 - val_loss: 0.1739 - val_accuracy: 0.0000e+00\n",
            "Epoch 2969/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1674 - accuracy: 0.0000e+00 - val_loss: 0.1739 - val_accuracy: 0.0000e+00\n",
            "Epoch 2970/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1684 - accuracy: 0.0000e+00 - val_loss: 0.1741 - val_accuracy: 0.0000e+00\n",
            "Epoch 2971/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1618 - accuracy: 0.0000e+00 - val_loss: 0.1739 - val_accuracy: 0.0000e+00\n",
            "Epoch 2972/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1686 - accuracy: 0.0000e+00 - val_loss: 0.1740 - val_accuracy: 0.0000e+00\n",
            "Epoch 2973/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1661 - accuracy: 0.0000e+00 - val_loss: 0.1744 - val_accuracy: 0.0000e+00\n",
            "Epoch 2974/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1580 - accuracy: 0.0000e+00 - val_loss: 0.1740 - val_accuracy: 0.0000e+00\n",
            "Epoch 2975/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1591 - accuracy: 0.0000e+00 - val_loss: 0.1734 - val_accuracy: 0.0000e+00\n",
            "Epoch 2976/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1685 - accuracy: 0.0000e+00 - val_loss: 0.1733 - val_accuracy: 0.0000e+00\n",
            "Epoch 2977/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1659 - accuracy: 0.0000e+00 - val_loss: 0.1735 - val_accuracy: 0.0000e+00\n",
            "Epoch 2978/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1682 - accuracy: 0.0000e+00 - val_loss: 0.1738 - val_accuracy: 0.0000e+00\n",
            "Epoch 2979/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1559 - accuracy: 0.0000e+00 - val_loss: 0.1742 - val_accuracy: 0.0000e+00\n",
            "Epoch 2980/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1656 - accuracy: 0.0000e+00 - val_loss: 0.1744 - val_accuracy: 0.0000e+00\n",
            "Epoch 2981/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1709 - accuracy: 0.0000e+00 - val_loss: 0.1743 - val_accuracy: 0.0000e+00\n",
            "Epoch 2982/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1559 - accuracy: 0.0000e+00 - val_loss: 0.1734 - val_accuracy: 0.0000e+00\n",
            "Epoch 2983/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1662 - accuracy: 0.0000e+00 - val_loss: 0.1736 - val_accuracy: 0.0000e+00\n",
            "Epoch 2984/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1642 - accuracy: 0.0000e+00 - val_loss: 0.1735 - val_accuracy: 0.0000e+00\n",
            "Epoch 2985/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1785 - accuracy: 0.0000e+00 - val_loss: 0.1733 - val_accuracy: 0.0000e+00\n",
            "Epoch 2986/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1646 - accuracy: 0.0000e+00 - val_loss: 0.1740 - val_accuracy: 0.0000e+00\n",
            "Epoch 2987/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1726 - accuracy: 0.0000e+00 - val_loss: 0.1738 - val_accuracy: 0.0000e+00\n",
            "Epoch 2988/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1586 - accuracy: 0.0000e+00 - val_loss: 0.1732 - val_accuracy: 0.0000e+00\n",
            "Epoch 2989/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1654 - accuracy: 0.0000e+00 - val_loss: 0.1725 - val_accuracy: 0.0000e+00\n",
            "Epoch 2990/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1628 - accuracy: 0.0000e+00 - val_loss: 0.1723 - val_accuracy: 0.0000e+00\n",
            "Epoch 2991/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1654 - accuracy: 0.0000e+00 - val_loss: 0.1716 - val_accuracy: 0.0000e+00\n",
            "Epoch 2992/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1556 - accuracy: 0.0000e+00 - val_loss: 0.1714 - val_accuracy: 0.0000e+00\n",
            "Epoch 2993/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1765 - accuracy: 0.0000e+00 - val_loss: 0.1709 - val_accuracy: 0.0000e+00\n",
            "Epoch 2994/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1633 - accuracy: 0.0000e+00 - val_loss: 0.1703 - val_accuracy: 0.0000e+00\n",
            "Epoch 2995/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1585 - accuracy: 0.0000e+00 - val_loss: 0.1698 - val_accuracy: 0.0000e+00\n",
            "Epoch 2996/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1632 - accuracy: 0.0000e+00 - val_loss: 0.1701 - val_accuracy: 0.0000e+00\n",
            "Epoch 2997/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1651 - accuracy: 0.0000e+00 - val_loss: 0.1707 - val_accuracy: 0.0000e+00\n",
            "Epoch 2998/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1674 - accuracy: 0.0000e+00 - val_loss: 0.1706 - val_accuracy: 0.0000e+00\n",
            "Epoch 2999/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1615 - accuracy: 0.0000e+00 - val_loss: 0.1706 - val_accuracy: 0.0000e+00\n",
            "Epoch 3000/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1599 - accuracy: 0.0000e+00 - val_loss: 0.1702 - val_accuracy: 0.0000e+00\n",
            "Epoch 3001/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1640 - accuracy: 0.0000e+00 - val_loss: 0.1698 - val_accuracy: 0.0000e+00\n",
            "Epoch 3002/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1651 - accuracy: 0.0000e+00 - val_loss: 0.1691 - val_accuracy: 0.0000e+00\n",
            "Epoch 3003/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1564 - accuracy: 0.0000e+00 - val_loss: 0.1691 - val_accuracy: 0.0000e+00\n",
            "Epoch 3004/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1717 - accuracy: 0.0000e+00 - val_loss: 0.1689 - val_accuracy: 0.0000e+00\n",
            "Epoch 3005/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1666 - accuracy: 0.0000e+00 - val_loss: 0.1692 - val_accuracy: 0.0000e+00\n",
            "Epoch 3006/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1518 - accuracy: 0.0000e+00 - val_loss: 0.1692 - val_accuracy: 0.0000e+00\n",
            "Epoch 3007/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1682 - accuracy: 0.0000e+00 - val_loss: 0.1691 - val_accuracy: 0.0000e+00\n",
            "Epoch 3008/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1613 - accuracy: 0.0000e+00 - val_loss: 0.1698 - val_accuracy: 0.0000e+00\n",
            "Epoch 3009/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1575 - accuracy: 0.0000e+00 - val_loss: 0.1695 - val_accuracy: 0.0000e+00\n",
            "Epoch 3010/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1645 - accuracy: 0.0000e+00 - val_loss: 0.1697 - val_accuracy: 0.0000e+00\n",
            "Epoch 3011/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1670 - accuracy: 0.0000e+00 - val_loss: 0.1689 - val_accuracy: 0.0000e+00\n",
            "Epoch 3012/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1596 - accuracy: 0.0000e+00 - val_loss: 0.1689 - val_accuracy: 0.0000e+00\n",
            "Epoch 3013/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1574 - accuracy: 0.0000e+00 - val_loss: 0.1681 - val_accuracy: 0.0000e+00\n",
            "Epoch 3014/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1795 - accuracy: 0.0000e+00 - val_loss: 0.1680 - val_accuracy: 0.0000e+00\n",
            "Epoch 3015/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1579 - accuracy: 0.0000e+00 - val_loss: 0.1685 - val_accuracy: 0.0000e+00\n",
            "Epoch 3016/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1577 - accuracy: 0.0000e+00 - val_loss: 0.1683 - val_accuracy: 0.0000e+00\n",
            "Epoch 3017/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1650 - accuracy: 0.0000e+00 - val_loss: 0.1681 - val_accuracy: 0.0000e+00\n",
            "Epoch 3018/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1818 - accuracy: 0.0000e+00 - val_loss: 0.1687 - val_accuracy: 0.0000e+00\n",
            "Epoch 3019/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1715 - accuracy: 0.0000e+00 - val_loss: 0.1681 - val_accuracy: 0.0000e+00\n",
            "Epoch 3020/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1620 - accuracy: 0.0000e+00 - val_loss: 0.1675 - val_accuracy: 0.0000e+00\n",
            "Epoch 3021/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1645 - accuracy: 0.0000e+00 - val_loss: 0.1673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3022/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1537 - accuracy: 0.0000e+00 - val_loss: 0.1673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3023/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1616 - accuracy: 0.0000e+00 - val_loss: 0.1669 - val_accuracy: 0.0000e+00\n",
            "Epoch 3024/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1657 - accuracy: 0.0000e+00 - val_loss: 0.1673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3025/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1638 - accuracy: 0.0000e+00 - val_loss: 0.1677 - val_accuracy: 0.0000e+00\n",
            "Epoch 3026/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1797 - accuracy: 0.0000e+00 - val_loss: 0.1673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3027/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1566 - accuracy: 0.0000e+00 - val_loss: 0.1671 - val_accuracy: 0.0000e+00\n",
            "Epoch 3028/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1655 - accuracy: 0.0000e+00 - val_loss: 0.1665 - val_accuracy: 0.0000e+00\n",
            "Epoch 3029/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1679 - accuracy: 0.0000e+00 - val_loss: 0.1663 - val_accuracy: 0.0000e+00\n",
            "Epoch 3030/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1586 - accuracy: 0.0000e+00 - val_loss: 0.1667 - val_accuracy: 0.0000e+00\n",
            "Epoch 3031/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1571 - accuracy: 0.0000e+00 - val_loss: 0.1664 - val_accuracy: 0.0000e+00\n",
            "Epoch 3032/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1708 - accuracy: 0.0000e+00 - val_loss: 0.1663 - val_accuracy: 0.0000e+00\n",
            "Epoch 3033/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1583 - accuracy: 0.0000e+00 - val_loss: 0.1664 - val_accuracy: 0.0000e+00\n",
            "Epoch 3034/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1518 - accuracy: 0.0000e+00 - val_loss: 0.1660 - val_accuracy: 0.0000e+00\n",
            "Epoch 3035/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1508 - accuracy: 0.0000e+00 - val_loss: 0.1659 - val_accuracy: 0.0000e+00\n",
            "Epoch 3036/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1702 - accuracy: 0.0000e+00 - val_loss: 0.1662 - val_accuracy: 0.0000e+00\n",
            "Epoch 3037/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1600 - accuracy: 0.0000e+00 - val_loss: 0.1664 - val_accuracy: 0.0000e+00\n",
            "Epoch 3038/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1686 - accuracy: 0.0000e+00 - val_loss: 0.1655 - val_accuracy: 0.0000e+00\n",
            "Epoch 3039/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1679 - accuracy: 0.0000e+00 - val_loss: 0.1653 - val_accuracy: 0.0000e+00\n",
            "Epoch 3040/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1600 - accuracy: 0.0000e+00 - val_loss: 0.1660 - val_accuracy: 0.0000e+00\n",
            "Epoch 3041/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1615 - accuracy: 0.0000e+00 - val_loss: 0.1667 - val_accuracy: 0.0000e+00\n",
            "Epoch 3042/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1519 - accuracy: 0.0000e+00 - val_loss: 0.1660 - val_accuracy: 0.0000e+00\n",
            "Epoch 3043/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1655 - accuracy: 0.0000e+00 - val_loss: 0.1656 - val_accuracy: 0.0000e+00\n",
            "Epoch 3044/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1659 - accuracy: 0.0000e+00 - val_loss: 0.1655 - val_accuracy: 0.0000e+00\n",
            "Epoch 3045/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1687 - accuracy: 0.0000e+00 - val_loss: 0.1646 - val_accuracy: 0.0000e+00\n",
            "Epoch 3046/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1557 - accuracy: 0.0000e+00 - val_loss: 0.1637 - val_accuracy: 0.0000e+00\n",
            "Epoch 3047/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1522 - accuracy: 0.0000e+00 - val_loss: 0.1634 - val_accuracy: 0.0000e+00\n",
            "Epoch 3048/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1552 - accuracy: 0.0000e+00 - val_loss: 0.1639 - val_accuracy: 0.0000e+00\n",
            "Epoch 3049/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1629 - accuracy: 0.0000e+00 - val_loss: 0.1643 - val_accuracy: 0.0000e+00\n",
            "Epoch 3050/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1628 - accuracy: 0.0000e+00 - val_loss: 0.1645 - val_accuracy: 0.0000e+00\n",
            "Epoch 3051/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1563 - accuracy: 0.0000e+00 - val_loss: 0.1638 - val_accuracy: 0.0000e+00\n",
            "Epoch 3052/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1550 - accuracy: 0.0000e+00 - val_loss: 0.1635 - val_accuracy: 0.0000e+00\n",
            "Epoch 3053/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1538 - accuracy: 0.0000e+00 - val_loss: 0.1633 - val_accuracy: 0.0000e+00\n",
            "Epoch 3054/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1543 - accuracy: 0.0000e+00 - val_loss: 0.1638 - val_accuracy: 0.0000e+00\n",
            "Epoch 3055/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1589 - accuracy: 0.0000e+00 - val_loss: 0.1631 - val_accuracy: 0.0000e+00\n",
            "Epoch 3056/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1584 - accuracy: 0.0000e+00 - val_loss: 0.1623 - val_accuracy: 0.0000e+00\n",
            "Epoch 3057/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1645 - accuracy: 0.0000e+00 - val_loss: 0.1631 - val_accuracy: 0.0000e+00\n",
            "Epoch 3058/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1539 - accuracy: 0.0000e+00 - val_loss: 0.1627 - val_accuracy: 0.0000e+00\n",
            "Epoch 3059/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1592 - accuracy: 0.0000e+00 - val_loss: 0.1626 - val_accuracy: 0.0000e+00\n",
            "Epoch 3060/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1581 - accuracy: 0.0000e+00 - val_loss: 0.1623 - val_accuracy: 0.0000e+00\n",
            "Epoch 3061/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1673 - accuracy: 0.0000e+00 - val_loss: 0.1629 - val_accuracy: 0.0000e+00\n",
            "Epoch 3062/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1642 - accuracy: 0.0000e+00 - val_loss: 0.1633 - val_accuracy: 0.0000e+00\n",
            "Epoch 3063/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1594 - accuracy: 0.0000e+00 - val_loss: 0.1639 - val_accuracy: 0.0000e+00\n",
            "Epoch 3064/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1605 - accuracy: 0.0000e+00 - val_loss: 0.1634 - val_accuracy: 0.0000e+00\n",
            "Epoch 3065/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1595 - accuracy: 0.0000e+00 - val_loss: 0.1634 - val_accuracy: 0.0000e+00\n",
            "Epoch 3066/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1764 - accuracy: 0.0000e+00 - val_loss: 0.1622 - val_accuracy: 0.0000e+00\n",
            "Epoch 3067/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1586 - accuracy: 0.0000e+00 - val_loss: 0.1616 - val_accuracy: 0.0000e+00\n",
            "Epoch 3068/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1727 - accuracy: 0.0000e+00 - val_loss: 0.1609 - val_accuracy: 0.0000e+00\n",
            "Epoch 3069/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1537 - accuracy: 0.0000e+00 - val_loss: 0.1610 - val_accuracy: 0.0000e+00\n",
            "Epoch 3070/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1507 - accuracy: 0.0000e+00 - val_loss: 0.1609 - val_accuracy: 0.0000e+00\n",
            "Epoch 3071/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1615 - accuracy: 0.0000e+00 - val_loss: 0.1609 - val_accuracy: 0.0000e+00\n",
            "Epoch 3072/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1630 - accuracy: 0.0000e+00 - val_loss: 0.1610 - val_accuracy: 0.0000e+00\n",
            "Epoch 3073/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1589 - accuracy: 0.0000e+00 - val_loss: 0.1610 - val_accuracy: 0.0000e+00\n",
            "Epoch 3074/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1503 - accuracy: 0.0000e+00 - val_loss: 0.1609 - val_accuracy: 0.0000e+00\n",
            "Epoch 3075/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1525 - accuracy: 0.0000e+00 - val_loss: 0.1612 - val_accuracy: 0.0000e+00\n",
            "Epoch 3076/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1605 - accuracy: 0.0000e+00 - val_loss: 0.1616 - val_accuracy: 0.0000e+00\n",
            "Epoch 3077/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1606 - accuracy: 0.0000e+00 - val_loss: 0.1614 - val_accuracy: 0.0000e+00\n",
            "Epoch 3078/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1569 - accuracy: 0.0000e+00 - val_loss: 0.1609 - val_accuracy: 0.0000e+00\n",
            "Epoch 3079/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1606 - accuracy: 0.0000e+00 - val_loss: 0.1608 - val_accuracy: 0.0000e+00\n",
            "Epoch 3080/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1650 - accuracy: 0.0000e+00 - val_loss: 0.1612 - val_accuracy: 0.0000e+00\n",
            "Epoch 3081/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1489 - accuracy: 0.0000e+00 - val_loss: 0.1611 - val_accuracy: 0.0000e+00\n",
            "Epoch 3082/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1486 - accuracy: 0.0000e+00 - val_loss: 0.1609 - val_accuracy: 0.0000e+00\n",
            "Epoch 3083/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1576 - accuracy: 0.0000e+00 - val_loss: 0.1602 - val_accuracy: 0.0000e+00\n",
            "Epoch 3084/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1678 - accuracy: 0.0000e+00 - val_loss: 0.1598 - val_accuracy: 0.0000e+00\n",
            "Epoch 3085/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1511 - accuracy: 0.0000e+00 - val_loss: 0.1595 - val_accuracy: 0.0000e+00\n",
            "Epoch 3086/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1530 - accuracy: 0.0000e+00 - val_loss: 0.1592 - val_accuracy: 0.0000e+00\n",
            "Epoch 3087/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1560 - accuracy: 0.0000e+00 - val_loss: 0.1595 - val_accuracy: 0.0000e+00\n",
            "Epoch 3088/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1566 - accuracy: 0.0000e+00 - val_loss: 0.1594 - val_accuracy: 0.0000e+00\n",
            "Epoch 3089/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1447 - accuracy: 0.0000e+00 - val_loss: 0.1595 - val_accuracy: 0.0000e+00\n",
            "Epoch 3090/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1552 - accuracy: 0.0000e+00 - val_loss: 0.1591 - val_accuracy: 0.0000e+00\n",
            "Epoch 3091/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1610 - accuracy: 0.0000e+00 - val_loss: 0.1589 - val_accuracy: 0.0000e+00\n",
            "Epoch 3092/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1547 - accuracy: 0.0000e+00 - val_loss: 0.1589 - val_accuracy: 0.0000e+00\n",
            "Epoch 3093/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1731 - accuracy: 0.0000e+00 - val_loss: 0.1588 - val_accuracy: 0.0000e+00\n",
            "Epoch 3094/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1530 - accuracy: 0.0000e+00 - val_loss: 0.1590 - val_accuracy: 0.0000e+00\n",
            "Epoch 3095/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1582 - accuracy: 0.0000e+00 - val_loss: 0.1586 - val_accuracy: 0.0000e+00\n",
            "Epoch 3096/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1607 - accuracy: 0.0000e+00 - val_loss: 0.1582 - val_accuracy: 0.0000e+00\n",
            "Epoch 3097/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1472 - accuracy: 0.0000e+00 - val_loss: 0.1580 - val_accuracy: 0.0000e+00\n",
            "Epoch 3098/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1596 - accuracy: 0.0000e+00 - val_loss: 0.1576 - val_accuracy: 0.0000e+00\n",
            "Epoch 3099/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1626 - accuracy: 0.0000e+00 - val_loss: 0.1575 - val_accuracy: 0.0000e+00\n",
            "Epoch 3100/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1622 - accuracy: 0.0000e+00 - val_loss: 0.1573 - val_accuracy: 0.0000e+00\n",
            "Epoch 3101/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1477 - accuracy: 0.0000e+00 - val_loss: 0.1573 - val_accuracy: 0.0000e+00\n",
            "Epoch 3102/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1481 - accuracy: 0.0000e+00 - val_loss: 0.1576 - val_accuracy: 0.0000e+00\n",
            "Epoch 3103/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1496 - accuracy: 0.0000e+00 - val_loss: 0.1581 - val_accuracy: 0.0000e+00\n",
            "Epoch 3104/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1585 - accuracy: 0.0000e+00 - val_loss: 0.1582 - val_accuracy: 0.0000e+00\n",
            "Epoch 3105/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1592 - accuracy: 0.0000e+00 - val_loss: 0.1576 - val_accuracy: 0.0000e+00\n",
            "Epoch 3106/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1553 - accuracy: 0.0000e+00 - val_loss: 0.1572 - val_accuracy: 0.0000e+00\n",
            "Epoch 3107/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1585 - accuracy: 0.0000e+00 - val_loss: 0.1571 - val_accuracy: 0.0000e+00\n",
            "Epoch 3108/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1456 - accuracy: 0.0000e+00 - val_loss: 0.1568 - val_accuracy: 0.0000e+00\n",
            "Epoch 3109/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1508 - accuracy: 0.0000e+00 - val_loss: 0.1563 - val_accuracy: 0.0000e+00\n",
            "Epoch 3110/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1573 - accuracy: 0.0000e+00 - val_loss: 0.1561 - val_accuracy: 0.0000e+00\n",
            "Epoch 3111/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1564 - accuracy: 0.0000e+00 - val_loss: 0.1564 - val_accuracy: 0.0000e+00\n",
            "Epoch 3112/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1612 - accuracy: 0.0000e+00 - val_loss: 0.1563 - val_accuracy: 0.0000e+00\n",
            "Epoch 3113/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1582 - accuracy: 0.0000e+00 - val_loss: 0.1559 - val_accuracy: 0.0000e+00\n",
            "Epoch 3114/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1455 - accuracy: 0.0000e+00 - val_loss: 0.1562 - val_accuracy: 0.0000e+00\n",
            "Epoch 3115/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1549 - accuracy: 0.0000e+00 - val_loss: 0.1562 - val_accuracy: 0.0000e+00\n",
            "Epoch 3116/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1512 - accuracy: 0.0000e+00 - val_loss: 0.1560 - val_accuracy: 0.0000e+00\n",
            "Epoch 3117/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1610 - accuracy: 0.0000e+00 - val_loss: 0.1561 - val_accuracy: 0.0000e+00\n",
            "Epoch 3118/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1503 - accuracy: 0.0000e+00 - val_loss: 0.1562 - val_accuracy: 0.0000e+00\n",
            "Epoch 3119/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1588 - accuracy: 0.0000e+00 - val_loss: 0.1561 - val_accuracy: 0.0000e+00\n",
            "Epoch 3120/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1576 - accuracy: 0.0000e+00 - val_loss: 0.1560 - val_accuracy: 0.0000e+00\n",
            "Epoch 3121/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1537 - accuracy: 0.0000e+00 - val_loss: 0.1556 - val_accuracy: 0.0000e+00\n",
            "Epoch 3122/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1506 - accuracy: 0.0000e+00 - val_loss: 0.1555 - val_accuracy: 0.0000e+00\n",
            "Epoch 3123/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1532 - accuracy: 0.0000e+00 - val_loss: 0.1550 - val_accuracy: 0.0000e+00\n",
            "Epoch 3124/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1492 - accuracy: 0.0000e+00 - val_loss: 0.1550 - val_accuracy: 0.0000e+00\n",
            "Epoch 3125/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1570 - accuracy: 0.0000e+00 - val_loss: 0.1550 - val_accuracy: 0.0000e+00\n",
            "Epoch 3126/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1602 - accuracy: 0.0000e+00 - val_loss: 0.1546 - val_accuracy: 0.0000e+00\n",
            "Epoch 3127/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1558 - accuracy: 0.0000e+00 - val_loss: 0.1547 - val_accuracy: 0.0000e+00\n",
            "Epoch 3128/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1640 - accuracy: 0.0000e+00 - val_loss: 0.1551 - val_accuracy: 0.0000e+00\n",
            "Epoch 3129/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1462 - accuracy: 0.0000e+00 - val_loss: 0.1553 - val_accuracy: 0.0000e+00\n",
            "Epoch 3130/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1485 - accuracy: 0.0000e+00 - val_loss: 0.1553 - val_accuracy: 0.0000e+00\n",
            "Epoch 3131/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1476 - accuracy: 0.0000e+00 - val_loss: 0.1549 - val_accuracy: 0.0000e+00\n",
            "Epoch 3132/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1450 - accuracy: 0.0000e+00 - val_loss: 0.1542 - val_accuracy: 0.0000e+00\n",
            "Epoch 3133/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1520 - accuracy: 0.0000e+00 - val_loss: 0.1545 - val_accuracy: 0.0000e+00\n",
            "Epoch 3134/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1578 - accuracy: 0.0000e+00 - val_loss: 0.1540 - val_accuracy: 0.0000e+00\n",
            "Epoch 3135/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1645 - accuracy: 0.0000e+00 - val_loss: 0.1541 - val_accuracy: 0.0000e+00\n",
            "Epoch 3136/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1554 - accuracy: 0.0000e+00 - val_loss: 0.1546 - val_accuracy: 0.0000e+00\n",
            "Epoch 3137/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1581 - accuracy: 0.0000e+00 - val_loss: 0.1544 - val_accuracy: 0.0000e+00\n",
            "Epoch 3138/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1531 - accuracy: 0.0000e+00 - val_loss: 0.1542 - val_accuracy: 0.0000e+00\n",
            "Epoch 3139/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1569 - accuracy: 0.0000e+00 - val_loss: 0.1536 - val_accuracy: 0.0000e+00\n",
            "Epoch 3140/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1520 - accuracy: 0.0000e+00 - val_loss: 0.1532 - val_accuracy: 0.0000e+00\n",
            "Epoch 3141/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1466 - accuracy: 0.0000e+00 - val_loss: 0.1527 - val_accuracy: 0.0000e+00\n",
            "Epoch 3142/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1631 - accuracy: 0.0000e+00 - val_loss: 0.1528 - val_accuracy: 0.0000e+00\n",
            "Epoch 3143/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1537 - accuracy: 0.0000e+00 - val_loss: 0.1531 - val_accuracy: 0.0000e+00\n",
            "Epoch 3144/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1694 - accuracy: 0.0000e+00 - val_loss: 0.1533 - val_accuracy: 0.0000e+00\n",
            "Epoch 3145/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1563 - accuracy: 0.0000e+00 - val_loss: 0.1532 - val_accuracy: 0.0000e+00\n",
            "Epoch 3146/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1566 - accuracy: 0.0000e+00 - val_loss: 0.1533 - val_accuracy: 0.0000e+00\n",
            "Epoch 3147/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1557 - accuracy: 0.0000e+00 - val_loss: 0.1535 - val_accuracy: 0.0000e+00\n",
            "Epoch 3148/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1434 - accuracy: 0.0000e+00 - val_loss: 0.1533 - val_accuracy: 0.0000e+00\n",
            "Epoch 3149/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1580 - accuracy: 0.0000e+00 - val_loss: 0.1533 - val_accuracy: 0.0000e+00\n",
            "Epoch 3150/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1727 - accuracy: 0.0000e+00 - val_loss: 0.1531 - val_accuracy: 0.0000e+00\n",
            "Epoch 3151/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1506 - accuracy: 0.0000e+00 - val_loss: 0.1535 - val_accuracy: 0.0000e+00\n",
            "Epoch 3152/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1482 - accuracy: 0.0000e+00 - val_loss: 0.1532 - val_accuracy: 0.0000e+00\n",
            "Epoch 3153/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1550 - accuracy: 0.0000e+00 - val_loss: 0.1533 - val_accuracy: 0.0000e+00\n",
            "Epoch 3154/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1554 - accuracy: 0.0000e+00 - val_loss: 0.1529 - val_accuracy: 0.0000e+00\n",
            "Epoch 3155/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1607 - accuracy: 0.0000e+00 - val_loss: 0.1528 - val_accuracy: 0.0000e+00\n",
            "Epoch 3156/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1538 - accuracy: 0.0000e+00 - val_loss: 0.1527 - val_accuracy: 0.0000e+00\n",
            "Epoch 3157/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1578 - accuracy: 0.0000e+00 - val_loss: 0.1525 - val_accuracy: 0.0000e+00\n",
            "Epoch 3158/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1514 - accuracy: 0.0000e+00 - val_loss: 0.1526 - val_accuracy: 0.0000e+00\n",
            "Epoch 3159/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1449 - accuracy: 0.0000e+00 - val_loss: 0.1527 - val_accuracy: 0.0000e+00\n",
            "Epoch 3160/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1548 - accuracy: 0.0000e+00 - val_loss: 0.1527 - val_accuracy: 0.0000e+00\n",
            "Epoch 3161/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1542 - accuracy: 0.0000e+00 - val_loss: 0.1527 - val_accuracy: 0.0000e+00\n",
            "Epoch 3162/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1546 - accuracy: 0.0000e+00 - val_loss: 0.1522 - val_accuracy: 0.0000e+00\n",
            "Epoch 3163/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1526 - accuracy: 0.0000e+00 - val_loss: 0.1524 - val_accuracy: 0.0000e+00\n",
            "Epoch 3164/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1540 - accuracy: 0.0000e+00 - val_loss: 0.1531 - val_accuracy: 0.0000e+00\n",
            "Epoch 3165/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1573 - accuracy: 0.0000e+00 - val_loss: 0.1526 - val_accuracy: 0.0000e+00\n",
            "Epoch 3166/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1609 - accuracy: 0.0000e+00 - val_loss: 0.1521 - val_accuracy: 0.0000e+00\n",
            "Epoch 3167/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1594 - accuracy: 0.0000e+00 - val_loss: 0.1518 - val_accuracy: 0.0000e+00\n",
            "Epoch 3168/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1515 - accuracy: 0.0000e+00 - val_loss: 0.1517 - val_accuracy: 0.0000e+00\n",
            "Epoch 3169/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1529 - accuracy: 0.0000e+00 - val_loss: 0.1515 - val_accuracy: 0.0000e+00\n",
            "Epoch 3170/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1651 - accuracy: 0.0000e+00 - val_loss: 0.1517 - val_accuracy: 0.0000e+00\n",
            "Epoch 3171/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1542 - accuracy: 0.0000e+00 - val_loss: 0.1518 - val_accuracy: 0.0000e+00\n",
            "Epoch 3172/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1602 - accuracy: 0.0000e+00 - val_loss: 0.1518 - val_accuracy: 0.0000e+00\n",
            "Epoch 3173/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1522 - accuracy: 0.0000e+00 - val_loss: 0.1517 - val_accuracy: 0.0000e+00\n",
            "Epoch 3174/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1589 - accuracy: 0.0000e+00 - val_loss: 0.1515 - val_accuracy: 0.0000e+00\n",
            "Epoch 3175/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1452 - accuracy: 0.0000e+00 - val_loss: 0.1513 - val_accuracy: 0.0000e+00\n",
            "Epoch 3176/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1477 - accuracy: 0.0000e+00 - val_loss: 0.1514 - val_accuracy: 0.0000e+00\n",
            "Epoch 3177/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1562 - accuracy: 0.0000e+00 - val_loss: 0.1517 - val_accuracy: 0.0000e+00\n",
            "Epoch 3178/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1502 - accuracy: 0.0000e+00 - val_loss: 0.1519 - val_accuracy: 0.0000e+00\n",
            "Epoch 3179/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1506 - accuracy: 0.0000e+00 - val_loss: 0.1519 - val_accuracy: 0.0000e+00\n",
            "Epoch 3180/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1483 - accuracy: 0.0000e+00 - val_loss: 0.1517 - val_accuracy: 0.0000e+00\n",
            "Epoch 3181/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1463 - accuracy: 0.0000e+00 - val_loss: 0.1514 - val_accuracy: 0.0000e+00\n",
            "Epoch 3182/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1425 - accuracy: 0.0000e+00 - val_loss: 0.1509 - val_accuracy: 0.0000e+00\n",
            "Epoch 3183/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1538 - accuracy: 0.0000e+00 - val_loss: 0.1507 - val_accuracy: 0.0000e+00\n",
            "Epoch 3184/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1585 - accuracy: 0.0000e+00 - val_loss: 0.1509 - val_accuracy: 0.0000e+00\n",
            "Epoch 3185/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1520 - accuracy: 0.0000e+00 - val_loss: 0.1505 - val_accuracy: 0.0000e+00\n",
            "Epoch 3186/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1525 - accuracy: 0.0000e+00 - val_loss: 0.1504 - val_accuracy: 0.0000e+00\n",
            "Epoch 3187/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1496 - accuracy: 0.0000e+00 - val_loss: 0.1503 - val_accuracy: 0.0000e+00\n",
            "Epoch 3188/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1453 - accuracy: 0.0000e+00 - val_loss: 0.1505 - val_accuracy: 0.0000e+00\n",
            "Epoch 3189/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1611 - accuracy: 0.0000e+00 - val_loss: 0.1506 - val_accuracy: 0.0000e+00\n",
            "Epoch 3190/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1624 - accuracy: 0.0000e+00 - val_loss: 0.1507 - val_accuracy: 0.0000e+00\n",
            "Epoch 3191/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1570 - accuracy: 0.0000e+00 - val_loss: 0.1514 - val_accuracy: 0.0000e+00\n",
            "Epoch 3192/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1538 - accuracy: 0.0000e+00 - val_loss: 0.1505 - val_accuracy: 0.0000e+00\n",
            "Epoch 3193/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1637 - accuracy: 0.0000e+00 - val_loss: 0.1501 - val_accuracy: 0.0000e+00\n",
            "Epoch 3194/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1479 - accuracy: 0.0000e+00 - val_loss: 0.1503 - val_accuracy: 0.0000e+00\n",
            "Epoch 3195/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1525 - accuracy: 0.0000e+00 - val_loss: 0.1505 - val_accuracy: 0.0000e+00\n",
            "Epoch 3196/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1582 - accuracy: 0.0000e+00 - val_loss: 0.1502 - val_accuracy: 0.0000e+00\n",
            "Epoch 3197/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1515 - accuracy: 0.0000e+00 - val_loss: 0.1496 - val_accuracy: 0.0000e+00\n",
            "Epoch 3198/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1506 - accuracy: 0.0000e+00 - val_loss: 0.1494 - val_accuracy: 0.0000e+00\n",
            "Epoch 3199/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1440 - accuracy: 0.0000e+00 - val_loss: 0.1493 - val_accuracy: 0.0000e+00\n",
            "Epoch 3200/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1409 - accuracy: 0.0000e+00 - val_loss: 0.1497 - val_accuracy: 0.0000e+00\n",
            "Epoch 3201/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1547 - accuracy: 0.0000e+00 - val_loss: 0.1496 - val_accuracy: 0.0000e+00\n",
            "Epoch 3202/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1454 - accuracy: 0.0000e+00 - val_loss: 0.1494 - val_accuracy: 0.0000e+00\n",
            "Epoch 3203/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1473 - accuracy: 0.0000e+00 - val_loss: 0.1492 - val_accuracy: 0.0000e+00\n",
            "Epoch 3204/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1560 - accuracy: 0.0000e+00 - val_loss: 0.1492 - val_accuracy: 0.0000e+00\n",
            "Epoch 3205/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1588 - accuracy: 0.0000e+00 - val_loss: 0.1493 - val_accuracy: 0.0000e+00\n",
            "Epoch 3206/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1477 - accuracy: 0.0000e+00 - val_loss: 0.1499 - val_accuracy: 0.0000e+00\n",
            "Epoch 3207/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1540 - accuracy: 0.0000e+00 - val_loss: 0.1500 - val_accuracy: 0.0000e+00\n",
            "Epoch 3208/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1515 - accuracy: 0.0000e+00 - val_loss: 0.1497 - val_accuracy: 0.0000e+00\n",
            "Epoch 3209/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1441 - accuracy: 0.0000e+00 - val_loss: 0.1492 - val_accuracy: 0.0000e+00\n",
            "Epoch 3210/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1535 - accuracy: 0.0000e+00 - val_loss: 0.1492 - val_accuracy: 0.0000e+00\n",
            "Epoch 3211/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1507 - accuracy: 0.0000e+00 - val_loss: 0.1489 - val_accuracy: 0.0000e+00\n",
            "Epoch 3212/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1553 - accuracy: 0.0000e+00 - val_loss: 0.1491 - val_accuracy: 0.0000e+00\n",
            "Epoch 3213/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1496 - accuracy: 0.0000e+00 - val_loss: 0.1489 - val_accuracy: 0.0000e+00\n",
            "Epoch 3214/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1482 - accuracy: 0.0000e+00 - val_loss: 0.1488 - val_accuracy: 0.0000e+00\n",
            "Epoch 3215/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1446 - accuracy: 0.0000e+00 - val_loss: 0.1484 - val_accuracy: 0.0000e+00\n",
            "Epoch 3216/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1614 - accuracy: 0.0000e+00 - val_loss: 0.1483 - val_accuracy: 0.0000e+00\n",
            "Epoch 3217/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1577 - accuracy: 0.0000e+00 - val_loss: 0.1488 - val_accuracy: 0.0000e+00\n",
            "Epoch 3218/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1570 - accuracy: 0.0000e+00 - val_loss: 0.1490 - val_accuracy: 0.0000e+00\n",
            "Epoch 3219/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1597 - accuracy: 0.0000e+00 - val_loss: 0.1494 - val_accuracy: 0.0000e+00\n",
            "Epoch 3220/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1476 - accuracy: 0.0000e+00 - val_loss: 0.1490 - val_accuracy: 0.0000e+00\n",
            "Epoch 3221/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1575 - accuracy: 0.0000e+00 - val_loss: 0.1485 - val_accuracy: 0.0000e+00\n",
            "Epoch 3222/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1452 - accuracy: 0.0000e+00 - val_loss: 0.1485 - val_accuracy: 0.0000e+00\n",
            "Epoch 3223/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1552 - accuracy: 0.0000e+00 - val_loss: 0.1488 - val_accuracy: 0.0000e+00\n",
            "Epoch 3224/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1548 - accuracy: 0.0000e+00 - val_loss: 0.1486 - val_accuracy: 0.0000e+00\n",
            "Epoch 3225/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1566 - accuracy: 0.0000e+00 - val_loss: 0.1480 - val_accuracy: 0.0000e+00\n",
            "Epoch 3226/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1493 - accuracy: 0.0000e+00 - val_loss: 0.1485 - val_accuracy: 0.0000e+00\n",
            "Epoch 3227/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1587 - accuracy: 0.0000e+00 - val_loss: 0.1487 - val_accuracy: 0.0000e+00\n",
            "Epoch 3228/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1462 - accuracy: 0.0000e+00 - val_loss: 0.1485 - val_accuracy: 0.0000e+00\n",
            "Epoch 3229/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1574 - accuracy: 0.0000e+00 - val_loss: 0.1483 - val_accuracy: 0.0000e+00\n",
            "Epoch 3230/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1426 - accuracy: 0.0000e+00 - val_loss: 0.1482 - val_accuracy: 0.0000e+00\n",
            "Epoch 3231/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1754 - accuracy: 0.0000e+00 - val_loss: 0.1481 - val_accuracy: 0.0000e+00\n",
            "Epoch 3232/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1464 - accuracy: 0.0000e+00 - val_loss: 0.1482 - val_accuracy: 0.0000e+00\n",
            "Epoch 3233/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1516 - accuracy: 0.0000e+00 - val_loss: 0.1477 - val_accuracy: 0.0000e+00\n",
            "Epoch 3234/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1477 - accuracy: 0.0000e+00 - val_loss: 0.1476 - val_accuracy: 0.0000e+00\n",
            "Epoch 3235/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1455 - accuracy: 0.0000e+00 - val_loss: 0.1472 - val_accuracy: 0.0000e+00\n",
            "Epoch 3236/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1412 - accuracy: 0.0000e+00 - val_loss: 0.1469 - val_accuracy: 0.0000e+00\n",
            "Epoch 3237/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1546 - accuracy: 0.0000e+00 - val_loss: 0.1467 - val_accuracy: 0.0000e+00\n",
            "Epoch 3238/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1584 - accuracy: 0.0000e+00 - val_loss: 0.1465 - val_accuracy: 0.0000e+00\n",
            "Epoch 3239/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1526 - accuracy: 0.0000e+00 - val_loss: 0.1465 - val_accuracy: 0.0000e+00\n",
            "Epoch 3240/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1562 - accuracy: 0.0000e+00 - val_loss: 0.1465 - val_accuracy: 0.0000e+00\n",
            "Epoch 3241/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1576 - accuracy: 0.0000e+00 - val_loss: 0.1470 - val_accuracy: 0.0000e+00\n",
            "Epoch 3242/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1512 - accuracy: 0.0000e+00 - val_loss: 0.1474 - val_accuracy: 0.0000e+00\n",
            "Epoch 3243/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1421 - accuracy: 0.0000e+00 - val_loss: 0.1471 - val_accuracy: 0.0000e+00\n",
            "Epoch 3244/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1559 - accuracy: 0.0000e+00 - val_loss: 0.1471 - val_accuracy: 0.0000e+00\n",
            "Epoch 3245/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1482 - accuracy: 0.0000e+00 - val_loss: 0.1469 - val_accuracy: 0.0000e+00\n",
            "Epoch 3246/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1508 - accuracy: 0.0000e+00 - val_loss: 0.1465 - val_accuracy: 0.0000e+00\n",
            "Epoch 3247/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1577 - accuracy: 0.0000e+00 - val_loss: 0.1476 - val_accuracy: 0.0000e+00\n",
            "Epoch 3248/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1466 - accuracy: 0.0000e+00 - val_loss: 0.1469 - val_accuracy: 0.0000e+00\n",
            "Epoch 3249/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1545 - accuracy: 0.0000e+00 - val_loss: 0.1474 - val_accuracy: 0.0000e+00\n",
            "Epoch 3250/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1442 - accuracy: 0.0000e+00 - val_loss: 0.1470 - val_accuracy: 0.0000e+00\n",
            "Epoch 3251/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1511 - accuracy: 0.0000e+00 - val_loss: 0.1470 - val_accuracy: 0.0000e+00\n",
            "Epoch 3252/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1504 - accuracy: 0.0000e+00 - val_loss: 0.1468 - val_accuracy: 0.0000e+00\n",
            "Epoch 3253/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1647 - accuracy: 0.0000e+00 - val_loss: 0.1466 - val_accuracy: 0.0000e+00\n",
            "Epoch 3254/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1437 - accuracy: 0.0000e+00 - val_loss: 0.1460 - val_accuracy: 0.0000e+00\n",
            "Epoch 3255/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1453 - accuracy: 0.0000e+00 - val_loss: 0.1459 - val_accuracy: 0.0000e+00\n",
            "Epoch 3256/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1583 - accuracy: 0.0000e+00 - val_loss: 0.1462 - val_accuracy: 0.0000e+00\n",
            "Epoch 3257/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1480 - accuracy: 0.0000e+00 - val_loss: 0.1467 - val_accuracy: 0.0000e+00\n",
            "Epoch 3258/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1635 - accuracy: 0.0000e+00 - val_loss: 0.1467 - val_accuracy: 0.0000e+00\n",
            "Epoch 3259/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1502 - accuracy: 0.0000e+00 - val_loss: 0.1466 - val_accuracy: 0.0000e+00\n",
            "Epoch 3260/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1492 - accuracy: 0.0000e+00 - val_loss: 0.1460 - val_accuracy: 0.0000e+00\n",
            "Epoch 3261/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1542 - accuracy: 0.0000e+00 - val_loss: 0.1462 - val_accuracy: 0.0000e+00\n",
            "Epoch 3262/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1601 - accuracy: 0.0000e+00 - val_loss: 0.1468 - val_accuracy: 0.0000e+00\n",
            "Epoch 3263/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1553 - accuracy: 0.0000e+00 - val_loss: 0.1478 - val_accuracy: 0.0000e+00\n",
            "Epoch 3264/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1614 - accuracy: 0.0000e+00 - val_loss: 0.1471 - val_accuracy: 0.0000e+00\n",
            "Epoch 3265/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1427 - accuracy: 0.0000e+00 - val_loss: 0.1470 - val_accuracy: 0.0000e+00\n",
            "Epoch 3266/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1473 - accuracy: 0.0000e+00 - val_loss: 0.1462 - val_accuracy: 0.0000e+00\n",
            "Epoch 3267/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1457 - accuracy: 0.0000e+00 - val_loss: 0.1461 - val_accuracy: 0.0000e+00\n",
            "Epoch 3268/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1564 - accuracy: 0.0000e+00 - val_loss: 0.1460 - val_accuracy: 0.0000e+00\n",
            "Epoch 3269/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1513 - accuracy: 0.0000e+00 - val_loss: 0.1462 - val_accuracy: 0.0000e+00\n",
            "Epoch 3270/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1448 - accuracy: 0.0000e+00 - val_loss: 0.1461 - val_accuracy: 0.0000e+00\n",
            "Epoch 3271/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1415 - accuracy: 0.0000e+00 - val_loss: 0.1459 - val_accuracy: 0.0000e+00\n",
            "Epoch 3272/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1487 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 3273/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1428 - accuracy: 0.0000e+00 - val_loss: 0.1459 - val_accuracy: 0.0000e+00\n",
            "Epoch 3274/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1583 - accuracy: 0.0000e+00 - val_loss: 0.1471 - val_accuracy: 0.0000e+00\n",
            "Epoch 3275/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1487 - accuracy: 0.0000e+00 - val_loss: 0.1471 - val_accuracy: 0.0000e+00\n",
            "Epoch 3276/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1554 - accuracy: 0.0000e+00 - val_loss: 0.1464 - val_accuracy: 0.0000e+00\n",
            "Epoch 3277/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1490 - accuracy: 0.0000e+00 - val_loss: 0.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 3278/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1422 - accuracy: 0.0000e+00 - val_loss: 0.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 3279/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1435 - accuracy: 0.0000e+00 - val_loss: 0.1453 - val_accuracy: 0.0000e+00\n",
            "Epoch 3280/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1591 - accuracy: 0.0000e+00 - val_loss: 0.1453 - val_accuracy: 0.0000e+00\n",
            "Epoch 3281/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1429 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 3282/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1506 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 3283/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1463 - accuracy: 0.0000e+00 - val_loss: 0.1460 - val_accuracy: 0.0000e+00\n",
            "Epoch 3284/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1530 - accuracy: 0.0000e+00 - val_loss: 0.1460 - val_accuracy: 0.0000e+00\n",
            "Epoch 3285/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1488 - accuracy: 0.0000e+00 - val_loss: 0.1463 - val_accuracy: 0.0000e+00\n",
            "Epoch 3286/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1487 - accuracy: 0.0000e+00 - val_loss: 0.1457 - val_accuracy: 0.0000e+00\n",
            "Epoch 3287/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1480 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 3288/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1470 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 3289/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1513 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 3290/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1486 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 3291/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1443 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 3292/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1554 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 3293/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1539 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 3294/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1470 - accuracy: 0.0000e+00 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 3295/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1566 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 3296/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1478 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 3297/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1477 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 3298/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1519 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 3299/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1441 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 3300/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1480 - accuracy: 0.0000e+00 - val_loss: 0.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 3301/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1471 - accuracy: 0.0000e+00 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 3302/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1405 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 3303/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1496 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 3304/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1508 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 3305/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1452 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 3306/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1440 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 3307/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1519 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 3308/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1490 - accuracy: 0.0000e+00 - val_loss: 0.1452 - val_accuracy: 0.0000e+00\n",
            "Epoch 3309/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1509 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 3310/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1435 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 3311/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1470 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 3312/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1492 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 3313/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1525 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 3314/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1474 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 3315/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1525 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 3316/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1467 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 3317/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1407 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 3318/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1566 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 3319/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1505 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 3320/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1437 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 3321/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1670 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 3322/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1543 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 3323/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1522 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 3324/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1436 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 3325/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1553 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 3326/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1501 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 3327/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1503 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 3328/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1521 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 3329/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1472 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 3330/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1526 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 3331/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1492 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 3332/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1484 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 3333/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1461 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 3334/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1489 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 3335/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1544 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 3336/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1513 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 3337/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1480 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 3338/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1583 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 3339/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1466 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 3340/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1449 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 3341/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1407 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 3342/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1578 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 3343/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1512 - accuracy: 0.0000e+00 - val_loss: 0.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 3344/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1452 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 3345/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1526 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 3346/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1454 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 3347/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1450 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 3348/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1588 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 3349/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1432 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 3350/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1536 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 3351/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1457 - accuracy: 0.0000e+00 - val_loss: 0.1457 - val_accuracy: 0.0000e+00\n",
            "Epoch 3352/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1527 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 3353/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1515 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 3354/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1579 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 3355/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1433 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 3356/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1531 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 3357/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1562 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 3358/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1424 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 3359/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1499 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 3360/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1499 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 3361/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1626 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 3362/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1428 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 3363/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1526 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 3364/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1412 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 3365/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1443 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 3366/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1496 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 3367/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1525 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 3368/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1497 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 3369/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1485 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 3370/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1503 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 3371/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1691 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 3372/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1635 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 3373/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1498 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 3374/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1547 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 3375/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1590 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 3376/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1533 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 3377/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1441 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 3378/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1388 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 3379/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1541 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 3380/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1456 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 3381/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1549 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 3382/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1454 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 3383/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1582 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 3384/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1571 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 3385/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1480 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 3386/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1478 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 3387/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1534 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 3388/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1477 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 3389/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1432 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 3390/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1552 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 3391/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1464 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 3392/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1650 - accuracy: 0.0000e+00 - val_loss: 0.1452 - val_accuracy: 0.0000e+00\n",
            "Epoch 3393/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1453 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 3394/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1395 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 3395/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1526 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 3396/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1479 - accuracy: 0.0000e+00 - val_loss: 0.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 3397/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1533 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 3398/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1511 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 3399/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1485 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 3400/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1548 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 3401/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1495 - accuracy: 0.0000e+00 - val_loss: 0.1429 - val_accuracy: 0.0000e+00\n",
            "Epoch 3402/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 3403/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1413 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 3404/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1442 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 3405/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1454 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 3406/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1474 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 3407/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1452 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 3408/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1552 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 3409/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1542 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 3410/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1676 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 3411/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1485 - accuracy: 0.0000e+00 - val_loss: 0.1429 - val_accuracy: 0.0000e+00\n",
            "Epoch 3412/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1441 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 3413/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1413 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 3414/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1495 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 3415/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1493 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 3416/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1530 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 3417/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1571 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 3418/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1453 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 3419/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1473 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 3420/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1522 - accuracy: 0.0000e+00 - val_loss: 0.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 3421/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1588 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 3422/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 3423/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1548 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 3424/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1484 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 3425/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1462 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 3426/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1515 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 3427/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1378 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 3428/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1455 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 3429/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1500 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 3430/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1469 - accuracy: 0.0000e+00 - val_loss: 0.1426 - val_accuracy: 0.0000e+00\n",
            "Epoch 3431/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1523 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 3432/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1461 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 3433/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1553 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 3434/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1381 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 3435/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1603 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 3436/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1509 - accuracy: 0.0000e+00 - val_loss: 0.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 3437/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 3438/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1400 - accuracy: 0.0000e+00 - val_loss: 0.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 3439/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1455 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 3440/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1584 - accuracy: 0.0000e+00 - val_loss: 0.1429 - val_accuracy: 0.0000e+00\n",
            "Epoch 3441/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1496 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 3442/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1540 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 3443/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1474 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 3444/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1481 - accuracy: 0.0000e+00 - val_loss: 0.1426 - val_accuracy: 0.0000e+00\n",
            "Epoch 3445/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1520 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 3446/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1452 - accuracy: 0.0000e+00 - val_loss: 0.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 3447/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1444 - accuracy: 0.0000e+00 - val_loss: 0.1424 - val_accuracy: 0.0000e+00\n",
            "Epoch 3448/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1429 - accuracy: 0.0000e+00 - val_loss: 0.1424 - val_accuracy: 0.0000e+00\n",
            "Epoch 3449/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1508 - accuracy: 0.0000e+00 - val_loss: 0.1424 - val_accuracy: 0.0000e+00\n",
            "Epoch 3450/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1469 - accuracy: 0.0000e+00 - val_loss: 0.1421 - val_accuracy: 0.0000e+00\n",
            "Epoch 3451/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1439 - accuracy: 0.0000e+00 - val_loss: 0.1421 - val_accuracy: 0.0000e+00\n",
            "Epoch 3452/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1484 - accuracy: 0.0000e+00 - val_loss: 0.1421 - val_accuracy: 0.0000e+00\n",
            "Epoch 3453/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1407 - accuracy: 0.0000e+00 - val_loss: 0.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 3454/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1446 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 3455/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1533 - accuracy: 0.0000e+00 - val_loss: 0.1418 - val_accuracy: 0.0000e+00\n",
            "Epoch 3456/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1569 - accuracy: 0.0000e+00 - val_loss: 0.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 3457/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1465 - accuracy: 0.0000e+00 - val_loss: 0.1424 - val_accuracy: 0.0000e+00\n",
            "Epoch 3458/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1468 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 3459/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1430 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 3460/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1444 - accuracy: 0.0000e+00 - val_loss: 0.1426 - val_accuracy: 0.0000e+00\n",
            "Epoch 3461/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1525 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 3462/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1434 - accuracy: 0.0000e+00 - val_loss: 0.1429 - val_accuracy: 0.0000e+00\n",
            "Epoch 3463/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1443 - accuracy: 0.0000e+00 - val_loss: 0.1426 - val_accuracy: 0.0000e+00\n",
            "Epoch 3464/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1549 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 3465/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1575 - accuracy: 0.0000e+00 - val_loss: 0.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 3466/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1568 - accuracy: 0.0000e+00 - val_loss: 0.1424 - val_accuracy: 0.0000e+00\n",
            "Epoch 3467/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1507 - accuracy: 0.0000e+00 - val_loss: 0.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 3468/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1429 - val_accuracy: 0.0000e+00\n",
            "Epoch 3469/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1534 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 3470/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1485 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 3471/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1419 - accuracy: 0.0000e+00 - val_loss: 0.1426 - val_accuracy: 0.0000e+00\n",
            "Epoch 3472/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1491 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 3473/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1493 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 3474/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1504 - accuracy: 0.0000e+00 - val_loss: 0.1424 - val_accuracy: 0.0000e+00\n",
            "Epoch 3475/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1450 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 3476/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1508 - accuracy: 0.0000e+00 - val_loss: 0.1418 - val_accuracy: 0.0000e+00\n",
            "Epoch 3477/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1497 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 3478/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1470 - accuracy: 0.0000e+00 - val_loss: 0.1414 - val_accuracy: 0.0000e+00\n",
            "Epoch 3479/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1403 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 3480/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1480 - accuracy: 0.0000e+00 - val_loss: 0.1414 - val_accuracy: 0.0000e+00\n",
            "Epoch 3481/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1469 - accuracy: 0.0000e+00 - val_loss: 0.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 3482/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1440 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 3483/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1409 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 3484/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1444 - accuracy: 0.0000e+00 - val_loss: 0.1419 - val_accuracy: 0.0000e+00\n",
            "Epoch 3485/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1480 - accuracy: 0.0000e+00 - val_loss: 0.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 3486/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1427 - accuracy: 0.0000e+00 - val_loss: 0.1419 - val_accuracy: 0.0000e+00\n",
            "Epoch 3487/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1527 - accuracy: 0.0000e+00 - val_loss: 0.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 3488/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1561 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 3489/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1457 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 3490/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1611 - accuracy: 0.0000e+00 - val_loss: 0.1415 - val_accuracy: 0.0000e+00\n",
            "Epoch 3491/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1408 - accuracy: 0.0000e+00 - val_loss: 0.1414 - val_accuracy: 0.0000e+00\n",
            "Epoch 3492/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1614 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 3493/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1446 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 3494/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1423 - accuracy: 0.0000e+00 - val_loss: 0.1419 - val_accuracy: 0.0000e+00\n",
            "Epoch 3495/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1495 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 3496/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1478 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 3497/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1430 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 3498/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1471 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 3499/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1411 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 3500/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1488 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 3501/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1612 - accuracy: 0.0000e+00 - val_loss: 0.1418 - val_accuracy: 0.0000e+00\n",
            "Epoch 3502/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1535 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 3503/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1426 - val_accuracy: 0.0000e+00\n",
            "Epoch 3504/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1402 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 3505/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1492 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 3506/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1446 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 3507/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1507 - accuracy: 0.0000e+00 - val_loss: 0.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 3508/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1511 - accuracy: 0.0000e+00 - val_loss: 0.1418 - val_accuracy: 0.0000e+00\n",
            "Epoch 3509/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1490 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 3510/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1491 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 3511/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1421 - accuracy: 0.0000e+00 - val_loss: 0.1414 - val_accuracy: 0.0000e+00\n",
            "Epoch 3512/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1397 - accuracy: 0.0000e+00 - val_loss: 0.1414 - val_accuracy: 0.0000e+00\n",
            "Epoch 3513/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1666 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 3514/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1469 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 3515/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1444 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 3516/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1474 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 3517/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1471 - accuracy: 0.0000e+00 - val_loss: 0.1417 - val_accuracy: 0.0000e+00\n",
            "Epoch 3518/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1558 - accuracy: 0.0000e+00 - val_loss: 0.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 3519/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1387 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 3520/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 3521/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1476 - accuracy: 0.0000e+00 - val_loss: 0.1419 - val_accuracy: 0.0000e+00\n",
            "Epoch 3522/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1449 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 3523/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1488 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 3524/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1492 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 3525/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1539 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 3526/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1428 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 3527/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1420 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 3528/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 3529/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1543 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 3530/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1441 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 3531/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1450 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 3532/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1494 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 3533/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1571 - accuracy: 0.0000e+00 - val_loss: 0.1415 - val_accuracy: 0.0000e+00\n",
            "Epoch 3534/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1536 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 3535/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1625 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 3536/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1468 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 3537/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1378 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 3538/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1378 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 3539/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1441 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 3540/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1468 - accuracy: 0.0000e+00 - val_loss: 0.1414 - val_accuracy: 0.0000e+00\n",
            "Epoch 3541/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1427 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 3542/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1444 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 3543/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1540 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 3544/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1438 - accuracy: 0.0000e+00 - val_loss: 0.1401 - val_accuracy: 0.0000e+00\n",
            "Epoch 3545/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1376 - accuracy: 0.0000e+00 - val_loss: 0.1405 - val_accuracy: 0.0000e+00\n",
            "Epoch 3546/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1498 - accuracy: 0.0000e+00 - val_loss: 0.1403 - val_accuracy: 0.0000e+00\n",
            "Epoch 3547/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1501 - accuracy: 0.0000e+00 - val_loss: 0.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 3548/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1497 - accuracy: 0.0000e+00 - val_loss: 0.1418 - val_accuracy: 0.0000e+00\n",
            "Epoch 3549/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1468 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 3550/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1577 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 3551/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1537 - accuracy: 0.0000e+00 - val_loss: 0.1417 - val_accuracy: 0.0000e+00\n",
            "Epoch 3552/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1435 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 3553/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1417 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 3554/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1535 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 3555/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1444 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 3556/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1495 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 3557/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1459 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 3558/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1384 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 3559/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 3560/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1405 - val_accuracy: 0.0000e+00\n",
            "Epoch 3561/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1434 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 3562/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1404 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 3563/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1503 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 3564/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1532 - accuracy: 0.0000e+00 - val_loss: 0.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 3565/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1477 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 3566/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1531 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 3567/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1504 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 3568/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1565 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 3569/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1427 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 3570/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1467 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 3571/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1514 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 3572/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1595 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 3573/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1544 - accuracy: 0.0000e+00 - val_loss: 0.1405 - val_accuracy: 0.0000e+00\n",
            "Epoch 3574/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1489 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 3575/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1480 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 3576/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1511 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 3577/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1468 - accuracy: 0.0000e+00 - val_loss: 0.1415 - val_accuracy: 0.0000e+00\n",
            "Epoch 3578/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1574 - accuracy: 0.0000e+00 - val_loss: 0.1421 - val_accuracy: 0.0000e+00\n",
            "Epoch 3579/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1451 - accuracy: 0.0000e+00 - val_loss: 0.1421 - val_accuracy: 0.0000e+00\n",
            "Epoch 3580/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1435 - accuracy: 0.0000e+00 - val_loss: 0.1418 - val_accuracy: 0.0000e+00\n",
            "Epoch 3581/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1442 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 3582/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1474 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 3583/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1543 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 3584/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1490 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 3585/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1554 - accuracy: 0.0000e+00 - val_loss: 0.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 3586/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1469 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 3587/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1454 - accuracy: 0.0000e+00 - val_loss: 0.1417 - val_accuracy: 0.0000e+00\n",
            "Epoch 3588/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1582 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 3589/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1438 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 3590/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1389 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 3591/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1556 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 3592/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1401 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 3593/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1503 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 3594/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1478 - accuracy: 0.0000e+00 - val_loss: 0.1424 - val_accuracy: 0.0000e+00\n",
            "Epoch 3595/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1461 - accuracy: 0.0000e+00 - val_loss: 0.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 3596/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1369 - accuracy: 0.0000e+00 - val_loss: 0.1421 - val_accuracy: 0.0000e+00\n",
            "Epoch 3597/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1448 - accuracy: 0.0000e+00 - val_loss: 0.1415 - val_accuracy: 0.0000e+00\n",
            "Epoch 3598/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1687 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 3599/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1454 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 3600/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1411 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 3601/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1595 - accuracy: 0.0000e+00 - val_loss: 0.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 3602/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1557 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 3603/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1556 - accuracy: 0.0000e+00 - val_loss: 0.1405 - val_accuracy: 0.0000e+00\n",
            "Epoch 3604/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1512 - accuracy: 0.0000e+00 - val_loss: 0.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 3605/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1548 - accuracy: 0.0000e+00 - val_loss: 0.1405 - val_accuracy: 0.0000e+00\n",
            "Epoch 3606/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1435 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 3607/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1446 - accuracy: 0.0000e+00 - val_loss: 0.1414 - val_accuracy: 0.0000e+00\n",
            "Epoch 3608/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1482 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 3609/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1526 - accuracy: 0.0000e+00 - val_loss: 0.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 3610/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1527 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 3611/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1395 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 3612/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1575 - accuracy: 0.0000e+00 - val_loss: 0.1421 - val_accuracy: 0.0000e+00\n",
            "Epoch 3613/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1472 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 3614/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1385 - accuracy: 0.0000e+00 - val_loss: 0.1419 - val_accuracy: 0.0000e+00\n",
            "Epoch 3615/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1455 - accuracy: 0.0000e+00 - val_loss: 0.1417 - val_accuracy: 0.0000e+00\n",
            "Epoch 3616/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1475 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 3617/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1462 - accuracy: 0.0000e+00 - val_loss: 0.1415 - val_accuracy: 0.0000e+00\n",
            "Epoch 3618/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1390 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 3619/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1442 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 3620/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1538 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 3621/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1576 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 3622/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1464 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 3623/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1439 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 3624/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1528 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 3625/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1439 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 3626/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1462 - accuracy: 0.0000e+00 - val_loss: 0.1415 - val_accuracy: 0.0000e+00\n",
            "Epoch 3627/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1501 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 3628/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1552 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 3629/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1469 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 3630/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1550 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 3631/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1493 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 3632/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1586 - accuracy: 0.0000e+00 - val_loss: 0.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 3633/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1401 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 3634/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1418 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 3635/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1549 - accuracy: 0.0000e+00 - val_loss: 0.1414 - val_accuracy: 0.0000e+00\n",
            "Epoch 3636/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1442 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 3637/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1465 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 3638/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1422 - accuracy: 0.0000e+00 - val_loss: 0.1414 - val_accuracy: 0.0000e+00\n",
            "Epoch 3639/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1414 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 3640/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1514 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 3641/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1490 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 3642/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1413 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 3643/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1493 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 3644/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1443 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 3645/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1452 - accuracy: 0.0000e+00 - val_loss: 0.1403 - val_accuracy: 0.0000e+00\n",
            "Epoch 3646/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1470 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 3647/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1466 - accuracy: 0.0000e+00 - val_loss: 0.1419 - val_accuracy: 0.0000e+00\n",
            "Epoch 3648/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1448 - accuracy: 0.0000e+00 - val_loss: 0.1418 - val_accuracy: 0.0000e+00\n",
            "Epoch 3649/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1428 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 3650/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1547 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 3651/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1435 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 3652/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1574 - accuracy: 0.0000e+00 - val_loss: 0.1403 - val_accuracy: 0.0000e+00\n",
            "Epoch 3653/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1454 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 3654/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1418 - accuracy: 0.0000e+00 - val_loss: 0.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 3655/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1502 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 3656/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1410 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 3657/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1485 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 3658/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1495 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 3659/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1609 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 3660/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1522 - accuracy: 0.0000e+00 - val_loss: 0.1405 - val_accuracy: 0.0000e+00\n",
            "Epoch 3661/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1464 - accuracy: 0.0000e+00 - val_loss: 0.1401 - val_accuracy: 0.0000e+00\n",
            "Epoch 3662/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
            "Epoch 3663/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1511 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 3664/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1483 - accuracy: 0.0000e+00 - val_loss: 0.1398 - val_accuracy: 0.0000e+00\n",
            "Epoch 3665/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1496 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 3666/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1402 - accuracy: 0.0000e+00 - val_loss: 0.1401 - val_accuracy: 0.0000e+00\n",
            "Epoch 3667/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1450 - accuracy: 0.0000e+00 - val_loss: 0.1405 - val_accuracy: 0.0000e+00\n",
            "Epoch 3668/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1504 - accuracy: 0.0000e+00 - val_loss: 0.1405 - val_accuracy: 0.0000e+00\n",
            "Epoch 3669/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1517 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 3670/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1462 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 3671/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1532 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 3672/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1536 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 3673/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1477 - accuracy: 0.0000e+00 - val_loss: 0.1399 - val_accuracy: 0.0000e+00\n",
            "Epoch 3674/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1442 - accuracy: 0.0000e+00 - val_loss: 0.1397 - val_accuracy: 0.0000e+00\n",
            "Epoch 3675/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1468 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 3676/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1542 - accuracy: 0.0000e+00 - val_loss: 0.1401 - val_accuracy: 0.0000e+00\n",
            "Epoch 3677/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1447 - accuracy: 0.0000e+00 - val_loss: 0.1399 - val_accuracy: 0.0000e+00\n",
            "Epoch 3678/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1454 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 3679/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1569 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
            "Epoch 3680/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1541 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 3681/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1496 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3682/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1429 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3683/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1538 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3684/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1464 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3685/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1441 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 3686/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1473 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 3687/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1430 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 3688/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1570 - accuracy: 0.0000e+00 - val_loss: 0.1397 - val_accuracy: 0.0000e+00\n",
            "Epoch 3689/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1468 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 3690/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1531 - accuracy: 0.0000e+00 - val_loss: 0.1401 - val_accuracy: 0.0000e+00\n",
            "Epoch 3691/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 3692/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1479 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 3693/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1344 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 3694/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1512 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
            "Epoch 3695/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1474 - accuracy: 0.0000e+00 - val_loss: 0.1399 - val_accuracy: 0.0000e+00\n",
            "Epoch 3696/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1515 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 3697/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1540 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3698/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1611 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 3699/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1572 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 3700/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1482 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 3701/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1442 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 3702/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1433 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 3703/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1487 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 3704/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1522 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 3705/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1430 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 3706/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1438 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
            "Epoch 3707/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1602 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 3708/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1519 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 3709/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1505 - accuracy: 0.0000e+00 - val_loss: 0.1401 - val_accuracy: 0.0000e+00\n",
            "Epoch 3710/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1389 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 3711/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1462 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 3712/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1471 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 3713/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1439 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3714/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1425 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 3715/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1455 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 3716/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1398 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 3717/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1508 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 3718/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1389 - accuracy: 0.0000e+00 - val_loss: 0.1397 - val_accuracy: 0.0000e+00\n",
            "Epoch 3719/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1515 - accuracy: 0.0000e+00 - val_loss: 0.1397 - val_accuracy: 0.0000e+00\n",
            "Epoch 3720/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1492 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 3721/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1442 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 3722/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1469 - accuracy: 0.0000e+00 - val_loss: 0.1399 - val_accuracy: 0.0000e+00\n",
            "Epoch 3723/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1430 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 3724/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1442 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 3725/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1559 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 3726/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1398 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3727/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1431 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 3728/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1413 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 3729/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1429 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 3730/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1390 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3731/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1393 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 3732/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1626 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 3733/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1539 - accuracy: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
            "Epoch 3734/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1382 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 3735/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1489 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 3736/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1488 - accuracy: 0.0000e+00 - val_loss: 0.1401 - val_accuracy: 0.0000e+00\n",
            "Epoch 3737/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1528 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 3738/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1469 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 3739/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1467 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 3740/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1373 - accuracy: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
            "Epoch 3741/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1363 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 3742/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1481 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 3743/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1440 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 3744/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1381 - accuracy: 0.0000e+00 - val_loss: 0.1398 - val_accuracy: 0.0000e+00\n",
            "Epoch 3745/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1533 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 3746/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1635 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 3747/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1507 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 3748/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1544 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 3749/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1513 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 3750/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1471 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 3751/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1416 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 3752/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1411 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 3753/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1472 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 3754/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1408 - accuracy: 0.0000e+00 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
            "Epoch 3755/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1520 - accuracy: 0.0000e+00 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
            "Epoch 3756/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1370 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 3757/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1410 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 3758/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1516 - accuracy: 0.0000e+00 - val_loss: 0.1398 - val_accuracy: 0.0000e+00\n",
            "Epoch 3759/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1548 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 3760/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1507 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 3761/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1513 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
            "Epoch 3762/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1421 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 3763/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1446 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 3764/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1384 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 3765/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1432 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 3766/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1462 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 3767/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1380 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3768/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1425 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 3769/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1542 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 3770/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1424 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3771/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1381 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3772/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1508 - accuracy: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
            "Epoch 3773/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1373 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3774/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1428 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3775/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1410 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 3776/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1409 - accuracy: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
            "Epoch 3777/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1444 - accuracy: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
            "Epoch 3778/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1465 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 3779/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1424 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3780/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1419 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 3781/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1454 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 3782/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1618 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 3783/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1630 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 3784/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1470 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3785/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1414 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 3786/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1490 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3787/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1530 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3788/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1367 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 3789/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1434 - accuracy: 0.0000e+00 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
            "Epoch 3790/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1466 - accuracy: 0.0000e+00 - val_loss: 0.1371 - val_accuracy: 0.0000e+00\n",
            "Epoch 3791/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1467 - accuracy: 0.0000e+00 - val_loss: 0.1367 - val_accuracy: 0.0000e+00\n",
            "Epoch 3792/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1462 - accuracy: 0.0000e+00 - val_loss: 0.1370 - val_accuracy: 0.0000e+00\n",
            "Epoch 3793/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1357 - accuracy: 0.0000e+00 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
            "Epoch 3794/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1508 - accuracy: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
            "Epoch 3795/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1477 - accuracy: 0.0000e+00 - val_loss: 0.1398 - val_accuracy: 0.0000e+00\n",
            "Epoch 3796/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1481 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 3797/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1447 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 3798/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1396 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3799/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1468 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 3800/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1450 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 3801/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1426 - accuracy: 0.0000e+00 - val_loss: 0.1374 - val_accuracy: 0.0000e+00\n",
            "Epoch 3802/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1455 - accuracy: 0.0000e+00 - val_loss: 0.1375 - val_accuracy: 0.0000e+00\n",
            "Epoch 3803/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1497 - accuracy: 0.0000e+00 - val_loss: 0.1373 - val_accuracy: 0.0000e+00\n",
            "Epoch 3804/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1375 - val_accuracy: 0.0000e+00\n",
            "Epoch 3805/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1455 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 3806/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1540 - accuracy: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
            "Epoch 3807/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1575 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 3808/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1468 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 3809/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1419 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3810/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1411 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 3811/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1472 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 3812/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1480 - accuracy: 0.0000e+00 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
            "Epoch 3813/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1508 - accuracy: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
            "Epoch 3814/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1446 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 3815/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1410 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 3816/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1499 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 3817/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1437 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 3818/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1366 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 3819/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1500 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 3820/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1411 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 3821/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1468 - accuracy: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
            "Epoch 3822/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1421 - accuracy: 0.0000e+00 - val_loss: 0.1371 - val_accuracy: 0.0000e+00\n",
            "Epoch 3823/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1475 - accuracy: 0.0000e+00 - val_loss: 0.1370 - val_accuracy: 0.0000e+00\n",
            "Epoch 3824/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1508 - accuracy: 0.0000e+00 - val_loss: 0.1372 - val_accuracy: 0.0000e+00\n",
            "Epoch 3825/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1546 - accuracy: 0.0000e+00 - val_loss: 0.1369 - val_accuracy: 0.0000e+00\n",
            "Epoch 3826/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1435 - accuracy: 0.0000e+00 - val_loss: 0.1370 - val_accuracy: 0.0000e+00\n",
            "Epoch 3827/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1449 - accuracy: 0.0000e+00 - val_loss: 0.1365 - val_accuracy: 0.0000e+00\n",
            "Epoch 3828/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1434 - accuracy: 0.0000e+00 - val_loss: 0.1372 - val_accuracy: 0.0000e+00\n",
            "Epoch 3829/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1360 - accuracy: 0.0000e+00 - val_loss: 0.1375 - val_accuracy: 0.0000e+00\n",
            "Epoch 3830/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1474 - accuracy: 0.0000e+00 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
            "Epoch 3831/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1578 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 3832/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1416 - accuracy: 0.0000e+00 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
            "Epoch 3833/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1407 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3834/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1380 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 3835/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1423 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 3836/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1377 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 3837/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1372 - accuracy: 0.0000e+00 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
            "Epoch 3838/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1398 - accuracy: 0.0000e+00 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
            "Epoch 3839/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1490 - accuracy: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
            "Epoch 3840/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1500 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3841/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1491 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 3842/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1383 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 3843/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1391 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 3844/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1399 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3845/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1585 - accuracy: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
            "Epoch 3846/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1497 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 3847/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1429 - accuracy: 0.0000e+00 - val_loss: 0.1371 - val_accuracy: 0.0000e+00\n",
            "Epoch 3848/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1429 - accuracy: 0.0000e+00 - val_loss: 0.1374 - val_accuracy: 0.0000e+00\n",
            "Epoch 3849/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1448 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 3850/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1392 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
            "Epoch 3851/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1389 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 3852/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1440 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3853/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1420 - accuracy: 0.0000e+00 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
            "Epoch 3854/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1462 - accuracy: 0.0000e+00 - val_loss: 0.1373 - val_accuracy: 0.0000e+00\n",
            "Epoch 3855/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1426 - accuracy: 0.0000e+00 - val_loss: 0.1372 - val_accuracy: 0.0000e+00\n",
            "Epoch 3856/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1554 - accuracy: 0.0000e+00 - val_loss: 0.1370 - val_accuracy: 0.0000e+00\n",
            "Epoch 3857/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1401 - accuracy: 0.0000e+00 - val_loss: 0.1373 - val_accuracy: 0.0000e+00\n",
            "Epoch 3858/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1386 - accuracy: 0.0000e+00 - val_loss: 0.1371 - val_accuracy: 0.0000e+00\n",
            "Epoch 3859/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1566 - accuracy: 0.0000e+00 - val_loss: 0.1371 - val_accuracy: 0.0000e+00\n",
            "Epoch 3860/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1503 - accuracy: 0.0000e+00 - val_loss: 0.1375 - val_accuracy: 0.0000e+00\n",
            "Epoch 3861/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1428 - accuracy: 0.0000e+00 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
            "Epoch 3862/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1378 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3863/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1425 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 3864/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1618 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 3865/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1484 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 3866/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1485 - accuracy: 0.0000e+00 - val_loss: 0.1372 - val_accuracy: 0.0000e+00\n",
            "Epoch 3867/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1402 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 3868/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1532 - accuracy: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
            "Epoch 3869/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1432 - accuracy: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
            "Epoch 3870/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1395 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3871/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1390 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 3872/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1671 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 3873/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1422 - accuracy: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
            "Epoch 3874/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1381 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 3875/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1501 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 3876/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1404 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 3877/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1530 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 3878/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1380 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3879/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1388 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 3880/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1491 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 3881/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1469 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 3882/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1364 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 3883/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1600 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 3884/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1470 - accuracy: 0.0000e+00 - val_loss: 0.1375 - val_accuracy: 0.0000e+00\n",
            "Epoch 3885/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1441 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 3886/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1416 - accuracy: 0.0000e+00 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
            "Epoch 3887/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1402 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 3888/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1423 - accuracy: 0.0000e+00 - val_loss: 0.1370 - val_accuracy: 0.0000e+00\n",
            "Epoch 3889/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1412 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 3890/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1362 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 3891/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1414 - accuracy: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
            "Epoch 3892/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1418 - accuracy: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
            "Epoch 3893/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1334 - accuracy: 0.0000e+00 - val_loss: 0.1373 - val_accuracy: 0.0000e+00\n",
            "Epoch 3894/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1476 - accuracy: 0.0000e+00 - val_loss: 0.1371 - val_accuracy: 0.0000e+00\n",
            "Epoch 3895/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1490 - accuracy: 0.0000e+00 - val_loss: 0.1370 - val_accuracy: 0.0000e+00\n",
            "Epoch 3896/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1363 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 3897/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1426 - accuracy: 0.0000e+00 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
            "Epoch 3898/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
            "Epoch 3899/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1425 - accuracy: 0.0000e+00 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
            "Epoch 3900/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1455 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 3901/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1428 - accuracy: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
            "Epoch 3902/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1403 - accuracy: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
            "Epoch 3903/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1624 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 3904/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1425 - accuracy: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
            "Epoch 3905/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1541 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 3906/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1455 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3907/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1421 - accuracy: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
            "Epoch 3908/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1589 - accuracy: 0.0000e+00 - val_loss: 0.1375 - val_accuracy: 0.0000e+00\n",
            "Epoch 3909/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 3910/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1399 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3911/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1359 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 3912/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1391 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3913/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1589 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3914/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1449 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 3915/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1470 - accuracy: 0.0000e+00 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
            "Epoch 3916/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1394 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 3917/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1381 - accuracy: 0.0000e+00 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
            "Epoch 3918/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1401 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 3919/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3920/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 3921/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1410 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3922/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1410 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3923/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1427 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3924/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1468 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 3925/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1401 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 3926/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1514 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3927/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1523 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 3928/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1486 - accuracy: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
            "Epoch 3929/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1411 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 3930/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1493 - accuracy: 0.0000e+00 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
            "Epoch 3931/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1430 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 3932/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1498 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 3933/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1353 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 3934/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1338 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3935/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1466 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 3936/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1396 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 3937/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1677 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3938/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1368 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 3939/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1413 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3940/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1449 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3941/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1419 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3942/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1446 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 3943/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1493 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3944/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1481 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3945/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1484 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 3946/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1515 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 3947/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1500 - accuracy: 0.0000e+00 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
            "Epoch 3948/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1364 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 3949/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1452 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 3950/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1434 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3951/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1374 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 3952/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1345 - accuracy: 0.0000e+00 - val_loss: 0.1399 - val_accuracy: 0.0000e+00\n",
            "Epoch 3953/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1457 - accuracy: 0.0000e+00 - val_loss: 0.1401 - val_accuracy: 0.0000e+00\n",
            "Epoch 3954/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1426 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 3955/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1385 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 3956/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1433 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 3957/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1362 - accuracy: 0.0000e+00 - val_loss: 0.1397 - val_accuracy: 0.0000e+00\n",
            "Epoch 3958/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1415 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 3959/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1478 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3960/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1490 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3961/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1449 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3962/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1529 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3963/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1537 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 3964/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1497 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3965/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1384 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 3966/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1457 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 3967/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1675 - accuracy: 0.0000e+00 - val_loss: 0.1401 - val_accuracy: 0.0000e+00\n",
            "Epoch 3968/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1622 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 3969/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1394 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 3970/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1386 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 3971/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1355 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 3972/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1459 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3973/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1380 - accuracy: 0.0000e+00 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
            "Epoch 3974/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1392 - accuracy: 0.0000e+00 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
            "Epoch 3975/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1418 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3976/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1355 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 3977/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1468 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 3978/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1485 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 3979/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1432 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 3980/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1513 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 3981/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1358 - accuracy: 0.0000e+00 - val_loss: 0.1397 - val_accuracy: 0.0000e+00\n",
            "Epoch 3982/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1448 - accuracy: 0.0000e+00 - val_loss: 0.1397 - val_accuracy: 0.0000e+00\n",
            "Epoch 3983/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1427 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 3984/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1485 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 3985/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1364 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3986/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1402 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 3987/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1335 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3988/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1417 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 3989/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1620 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 3990/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1397 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 3991/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1417 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 3992/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 3993/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1392 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 3994/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1444 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 3995/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1551 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 3996/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1314 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 3997/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1490 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 3998/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1385 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 3999/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1377 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 4000/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1401 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 4001/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1550 - accuracy: 0.0000e+00 - val_loss: 0.1401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4002/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1421 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4003/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1567 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4004/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1487 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 4005/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1377 - accuracy: 0.0000e+00 - val_loss: 0.1372 - val_accuracy: 0.0000e+00\n",
            "Epoch 4006/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1455 - accuracy: 0.0000e+00 - val_loss: 0.1374 - val_accuracy: 0.0000e+00\n",
            "Epoch 4007/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1484 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 4008/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1341 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4009/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1425 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4010/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1442 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 4011/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1447 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4012/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1369 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4013/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1417 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 4014/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1452 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4015/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1433 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4016/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1430 - accuracy: 0.0000e+00 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
            "Epoch 4017/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1484 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 4018/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1441 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 4019/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1573 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 4020/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1522 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4021/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1423 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 4022/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1414 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 4023/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1456 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 4024/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1515 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 4025/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1388 - accuracy: 0.0000e+00 - val_loss: 0.1398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4026/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 4027/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1380 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 4028/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1631 - accuracy: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
            "Epoch 4029/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1392 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4030/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1373 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4031/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1397 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4032/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1384 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4033/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1475 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 4034/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1561 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 4035/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1446 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 4036/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1392 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 4037/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1387 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4038/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1511 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 4039/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1444 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 4040/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1385 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 4041/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1466 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4042/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1397 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4043/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1490 - accuracy: 0.0000e+00 - val_loss: 0.1401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4044/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1342 - accuracy: 0.0000e+00 - val_loss: 0.1403 - val_accuracy: 0.0000e+00\n",
            "Epoch 4045/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1355 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 4046/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1438 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 4047/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1378 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4048/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1352 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 4049/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1431 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4050/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1414 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4051/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1427 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 4052/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1454 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 4053/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1394 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4054/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1423 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4055/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1441 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 4056/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1394 - accuracy: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
            "Epoch 4057/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1390 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 4058/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1461 - accuracy: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
            "Epoch 4059/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1342 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 4060/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1547 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 4061/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1465 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 4062/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1349 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 4063/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1474 - accuracy: 0.0000e+00 - val_loss: 0.1374 - val_accuracy: 0.0000e+00\n",
            "Epoch 4064/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1418 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4065/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1366 - accuracy: 0.0000e+00 - val_loss: 0.1401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4066/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1416 - accuracy: 0.0000e+00 - val_loss: 0.1399 - val_accuracy: 0.0000e+00\n",
            "Epoch 4067/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1431 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 4068/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1384 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 4069/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1493 - accuracy: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
            "Epoch 4070/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1469 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 4071/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1439 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 4072/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1485 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 4073/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1432 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 4074/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1471 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 4075/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1456 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 4076/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1399 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4077/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4078/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1448 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 4079/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1488 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 4080/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1392 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 4081/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1382 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4082/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1410 - accuracy: 0.0000e+00 - val_loss: 0.1397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4083/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1534 - accuracy: 0.0000e+00 - val_loss: 0.1398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4084/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1475 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 4085/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1352 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4086/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1369 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4087/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1455 - accuracy: 0.0000e+00 - val_loss: 0.1401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4088/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1474 - accuracy: 0.0000e+00 - val_loss: 0.1398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4089/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1420 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 4090/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1449 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4091/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1354 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 4092/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1394 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 4093/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1379 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 4094/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1416 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4095/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1438 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 4096/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1348 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 4097/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1498 - accuracy: 0.0000e+00 - val_loss: 0.1397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4098/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1375 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4099/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1432 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 4100/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1502 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 4101/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1473 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4102/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1428 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 4103/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1448 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4104/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 4105/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1339 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 4106/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1618 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 4107/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1426 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4108/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1381 - accuracy: 0.0000e+00 - val_loss: 0.1403 - val_accuracy: 0.0000e+00\n",
            "Epoch 4109/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1365 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4110/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1573 - accuracy: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
            "Epoch 4111/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1509 - accuracy: 0.0000e+00 - val_loss: 0.1375 - val_accuracy: 0.0000e+00\n",
            "Epoch 4112/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1381 - accuracy: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
            "Epoch 4113/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1498 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 4114/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1419 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 4115/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1429 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 4116/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1461 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 4117/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1412 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4118/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1375 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4119/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1506 - accuracy: 0.0000e+00 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
            "Epoch 4120/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1400 - accuracy: 0.0000e+00 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 4121/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1399 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4122/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1418 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 4123/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1385 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4124/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1448 - accuracy: 0.0000e+00 - val_loss: 0.1385 - val_accuracy: 0.0000e+00\n",
            "Epoch 4125/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4126/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1379 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4127/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1391 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4128/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1486 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 4129/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1465 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 4130/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 4131/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1525 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 4132/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1399 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 4133/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1484 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4134/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1443 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 4135/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1566 - accuracy: 0.0000e+00 - val_loss: 0.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4136/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1394 - accuracy: 0.0000e+00 - val_loss: 0.1386 - val_accuracy: 0.0000e+00\n",
            "Epoch 4137/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1343 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 4138/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1497 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 4139/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1432 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4140/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1475 - accuracy: 0.0000e+00 - val_loss: 0.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 4141/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1414 - accuracy: 0.0000e+00 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
            "Epoch 4142/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1415 - accuracy: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
            "Epoch 4143/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1349 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 4144/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1527 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 4145/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1351 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 4146/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1439 - accuracy: 0.0000e+00 - val_loss: 0.1376 - val_accuracy: 0.0000e+00\n",
            "Epoch 4147/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1421 - accuracy: 0.0000e+00 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
            "Epoch 4148/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1512 - accuracy: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.0000e+00\n",
            "Epoch 4149/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1394 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4150/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1380 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4151/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1413 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4152/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1405 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 4153/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1351 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4154/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1356 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4155/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1347 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 4156/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1413 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4157/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1543 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
            "Epoch 4158/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1449 - accuracy: 0.0000e+00 - val_loss: 0.1380 - val_accuracy: 0.0000e+00\n",
            "Epoch 4159/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1384 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4160/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1336 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 4161/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1592 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4162/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1370 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4163/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1350 - accuracy: 0.0000e+00 - val_loss: 0.1399 - val_accuracy: 0.0000e+00\n",
            "Epoch 4164/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1448 - accuracy: 0.0000e+00 - val_loss: 0.1398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4165/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1490 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 4166/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1418 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 4167/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1517 - accuracy: 0.0000e+00 - val_loss: 0.1397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4168/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1452 - accuracy: 0.0000e+00 - val_loss: 0.1401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4169/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4170/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1304 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4171/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1377 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4172/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1486 - accuracy: 0.0000e+00 - val_loss: 0.1387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4173/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1397 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4174/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1474 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4175/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1387 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4176/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1390 - accuracy: 0.0000e+00 - val_loss: 0.1405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4177/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1431 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 4178/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1375 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 4179/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1430 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 4180/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1452 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 4181/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1471 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
            "Epoch 4182/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1450 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4183/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1439 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4184/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1393 - accuracy: 0.0000e+00 - val_loss: 0.1393 - val_accuracy: 0.0000e+00\n",
            "Epoch 4185/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1420 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 4186/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1337 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 4187/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1357 - accuracy: 0.0000e+00 - val_loss: 0.1405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4188/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1359 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 4189/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1377 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 4190/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1382 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 4191/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1559 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 4192/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1636 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 4193/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1465 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 4194/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1499 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 4195/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1340 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4196/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1480 - accuracy: 0.0000e+00 - val_loss: 0.1403 - val_accuracy: 0.0000e+00\n",
            "Epoch 4197/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1395 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 4198/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1459 - accuracy: 0.0000e+00 - val_loss: 0.1399 - val_accuracy: 0.0000e+00\n",
            "Epoch 4199/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1387 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 4200/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1415 - accuracy: 0.0000e+00 - val_loss: 0.1392 - val_accuracy: 0.0000e+00\n",
            "Epoch 4201/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1364 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 4202/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1391 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 4203/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1447 - accuracy: 0.0000e+00 - val_loss: 0.1399 - val_accuracy: 0.0000e+00\n",
            "Epoch 4204/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1335 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4205/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1438 - accuracy: 0.0000e+00 - val_loss: 0.1397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4206/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1405 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4207/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1400 - accuracy: 0.0000e+00 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 4208/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1367 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4209/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1383 - accuracy: 0.0000e+00 - val_loss: 0.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4210/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1415 - accuracy: 0.0000e+00 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n",
            "Epoch 4211/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1334 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4212/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1379 - accuracy: 0.0000e+00 - val_loss: 0.1398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4213/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1405 - accuracy: 0.0000e+00 - val_loss: 0.1398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4214/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1320 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4215/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1319 - accuracy: 0.0000e+00 - val_loss: 0.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 4216/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1413 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 4217/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1425 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4218/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1359 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 4219/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1345 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 4220/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1307 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 4221/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1350 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 4222/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1420 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4223/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1455 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 4224/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1413 - accuracy: 0.0000e+00 - val_loss: 0.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 4225/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1374 - accuracy: 0.0000e+00 - val_loss: 0.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 4226/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1391 - accuracy: 0.0000e+00 - val_loss: 0.1401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4227/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1335 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 4228/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1426 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 4229/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1407 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 4230/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1389 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 4231/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1326 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 4232/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1363 - accuracy: 0.0000e+00 - val_loss: 0.1397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4233/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1454 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4234/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1405 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4235/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1420 - accuracy: 0.0000e+00 - val_loss: 0.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 4236/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1408 - accuracy: 0.0000e+00 - val_loss: 0.1414 - val_accuracy: 0.0000e+00\n",
            "Epoch 4237/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1404 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 4238/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1431 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 4239/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1351 - accuracy: 0.0000e+00 - val_loss: 0.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 4240/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1552 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 4241/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1373 - accuracy: 0.0000e+00 - val_loss: 0.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 4242/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1563 - accuracy: 0.0000e+00 - val_loss: 0.1426 - val_accuracy: 0.0000e+00\n",
            "Epoch 4243/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1420 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4244/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1419 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 4245/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1417 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 4246/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1478 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 4247/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1421 - val_accuracy: 0.0000e+00\n",
            "Epoch 4248/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1381 - accuracy: 0.0000e+00 - val_loss: 0.1424 - val_accuracy: 0.0000e+00\n",
            "Epoch 4249/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1414 - val_accuracy: 0.0000e+00\n",
            "Epoch 4250/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1394 - accuracy: 0.0000e+00 - val_loss: 0.1403 - val_accuracy: 0.0000e+00\n",
            "Epoch 4251/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1561 - accuracy: 0.0000e+00 - val_loss: 0.1403 - val_accuracy: 0.0000e+00\n",
            "Epoch 4252/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1363 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 4253/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1401 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 4254/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1328 - accuracy: 0.0000e+00 - val_loss: 0.1414 - val_accuracy: 0.0000e+00\n",
            "Epoch 4255/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1436 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 4256/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1381 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 4257/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1478 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 4258/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1621 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 4259/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1420 - accuracy: 0.0000e+00 - val_loss: 0.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 4260/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1368 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4261/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1522 - accuracy: 0.0000e+00 - val_loss: 0.1417 - val_accuracy: 0.0000e+00\n",
            "Epoch 4262/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1377 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 4263/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1404 - accuracy: 0.0000e+00 - val_loss: 0.1418 - val_accuracy: 0.0000e+00\n",
            "Epoch 4264/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1480 - accuracy: 0.0000e+00 - val_loss: 0.1424 - val_accuracy: 0.0000e+00\n",
            "Epoch 4265/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1400 - accuracy: 0.0000e+00 - val_loss: 0.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 4266/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1390 - accuracy: 0.0000e+00 - val_loss: 0.1421 - val_accuracy: 0.0000e+00\n",
            "Epoch 4267/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1470 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 4268/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1351 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4269/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1313 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4270/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1340 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4271/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1378 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 4272/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1416 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 4273/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1421 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4274/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1380 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 4275/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1450 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 4276/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1400 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 4277/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1360 - accuracy: 0.0000e+00 - val_loss: 0.1405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4278/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1378 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 4279/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1433 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 4280/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1398 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 4281/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1428 - accuracy: 0.0000e+00 - val_loss: 0.1418 - val_accuracy: 0.0000e+00\n",
            "Epoch 4282/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1430 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4283/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1320 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 4284/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1328 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 4285/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1442 - accuracy: 0.0000e+00 - val_loss: 0.1417 - val_accuracy: 0.0000e+00\n",
            "Epoch 4286/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1500 - accuracy: 0.0000e+00 - val_loss: 0.1417 - val_accuracy: 0.0000e+00\n",
            "Epoch 4287/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1325 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 4288/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1387 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4289/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1464 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 4290/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1380 - accuracy: 0.0000e+00 - val_loss: 0.1417 - val_accuracy: 0.0000e+00\n",
            "Epoch 4291/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1465 - accuracy: 0.0000e+00 - val_loss: 0.1415 - val_accuracy: 0.0000e+00\n",
            "Epoch 4292/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1364 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 4293/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1514 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 4294/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1471 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 4295/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1370 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 4296/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1369 - accuracy: 0.0000e+00 - val_loss: 0.1419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4297/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1424 - val_accuracy: 0.0000e+00\n",
            "Epoch 4298/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1551 - accuracy: 0.0000e+00 - val_loss: 0.1419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4299/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1358 - accuracy: 0.0000e+00 - val_loss: 0.1424 - val_accuracy: 0.0000e+00\n",
            "Epoch 4300/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1377 - accuracy: 0.0000e+00 - val_loss: 0.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 4301/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1412 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 4302/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1343 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 4303/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1411 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4304/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1331 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 4305/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1433 - accuracy: 0.0000e+00 - val_loss: 0.1400 - val_accuracy: 0.0000e+00\n",
            "Epoch 4306/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1438 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 4307/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1376 - accuracy: 0.0000e+00 - val_loss: 0.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 4308/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1343 - accuracy: 0.0000e+00 - val_loss: 0.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 4309/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1571 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4310/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1343 - accuracy: 0.0000e+00 - val_loss: 0.1397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4311/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1363 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 4312/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1395 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 4313/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1349 - accuracy: 0.0000e+00 - val_loss: 0.1417 - val_accuracy: 0.0000e+00\n",
            "Epoch 4314/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1419 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 4315/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1329 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 4316/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1416 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 4317/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1362 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
            "Epoch 4318/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1334 - accuracy: 0.0000e+00 - val_loss: 0.1414 - val_accuracy: 0.0000e+00\n",
            "Epoch 4319/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1495 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 4320/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1354 - accuracy: 0.0000e+00 - val_loss: 0.1410 - val_accuracy: 0.0000e+00\n",
            "Epoch 4321/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1397 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 4322/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1452 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 4323/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1449 - accuracy: 0.0000e+00 - val_loss: 0.1426 - val_accuracy: 0.0000e+00\n",
            "Epoch 4324/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1354 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4325/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1473 - accuracy: 0.0000e+00 - val_loss: 0.1417 - val_accuracy: 0.0000e+00\n",
            "Epoch 4326/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1358 - accuracy: 0.0000e+00 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 4327/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1347 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 4328/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1548 - accuracy: 0.0000e+00 - val_loss: 0.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4329/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1427 - accuracy: 0.0000e+00 - val_loss: 0.1405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4330/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1442 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 4331/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1464 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4332/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4333/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1374 - accuracy: 0.0000e+00 - val_loss: 0.1415 - val_accuracy: 0.0000e+00\n",
            "Epoch 4334/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1485 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4335/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1589 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4336/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1449 - accuracy: 0.0000e+00 - val_loss: 0.1426 - val_accuracy: 0.0000e+00\n",
            "Epoch 4337/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1365 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4338/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1437 - accuracy: 0.0000e+00 - val_loss: 0.1426 - val_accuracy: 0.0000e+00\n",
            "Epoch 4339/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1347 - accuracy: 0.0000e+00 - val_loss: 0.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 4340/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1410 - accuracy: 0.0000e+00 - val_loss: 0.1424 - val_accuracy: 0.0000e+00\n",
            "Epoch 4341/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1486 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4342/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1344 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4343/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1321 - accuracy: 0.0000e+00 - val_loss: 0.1424 - val_accuracy: 0.0000e+00\n",
            "Epoch 4344/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1417 - accuracy: 0.0000e+00 - val_loss: 0.1419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4345/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1400 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4346/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1340 - accuracy: 0.0000e+00 - val_loss: 0.1419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4347/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1306 - accuracy: 0.0000e+00 - val_loss: 0.1419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4348/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1373 - accuracy: 0.0000e+00 - val_loss: 0.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 4349/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1311 - accuracy: 0.0000e+00 - val_loss: 0.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 4350/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1375 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4351/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1343 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 4352/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1476 - accuracy: 0.0000e+00 - val_loss: 0.1415 - val_accuracy: 0.0000e+00\n",
            "Epoch 4353/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1348 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 4354/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1287 - accuracy: 0.0000e+00 - val_loss: 0.1419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4355/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1433 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 4356/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1291 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 4357/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1401 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4358/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1387 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 4359/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1353 - accuracy: 0.0000e+00 - val_loss: 0.1426 - val_accuracy: 0.0000e+00\n",
            "Epoch 4360/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1379 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 4361/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1305 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 4362/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1314 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4363/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1466 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 4364/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1354 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4365/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1398 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4366/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1414 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4367/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1493 - accuracy: 0.0000e+00 - val_loss: 0.1429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4368/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1275 - accuracy: 0.0000e+00 - val_loss: 0.1419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4369/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1387 - accuracy: 0.0000e+00 - val_loss: 0.1417 - val_accuracy: 0.0000e+00\n",
            "Epoch 4370/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1486 - accuracy: 0.0000e+00 - val_loss: 0.1426 - val_accuracy: 0.0000e+00\n",
            "Epoch 4371/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1439 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4372/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1630 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4373/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1396 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 4374/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1418 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4375/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1332 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4376/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1358 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4377/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1475 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4378/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1425 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4379/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1311 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4380/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1443 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4381/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1394 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4382/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1339 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4383/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1419 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 4384/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1392 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4385/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1393 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4386/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1363 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4387/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1380 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4388/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1412 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4389/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1371 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4390/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1385 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 4391/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1435 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4392/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1326 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4393/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1390 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4394/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1362 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4395/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1317 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4396/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1375 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4397/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1411 - accuracy: 0.0000e+00 - val_loss: 0.1453 - val_accuracy: 0.0000e+00\n",
            "Epoch 4398/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1470 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4399/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1408 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4400/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1334 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4401/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1356 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4402/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1493 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4403/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1343 - accuracy: 0.0000e+00 - val_loss: 0.1421 - val_accuracy: 0.0000e+00\n",
            "Epoch 4404/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1393 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4405/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1364 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4406/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1370 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4407/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1433 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4408/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1357 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4409/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1494 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 4410/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1431 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 4411/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1402 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4412/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1351 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4413/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1313 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4414/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1467 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4415/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1423 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4416/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1330 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4417/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1351 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4418/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1328 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4419/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1303 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 4420/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1412 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4421/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1358 - accuracy: 0.0000e+00 - val_loss: 0.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 4422/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1296 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 4423/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1409 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4424/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1291 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4425/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1362 - accuracy: 0.0000e+00 - val_loss: 0.1452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4426/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1392 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 4427/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1393 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4428/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1374 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4429/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1366 - accuracy: 0.0000e+00 - val_loss: 0.1429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4430/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1522 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 4431/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1361 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4432/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1364 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4433/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1390 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4434/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1542 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4435/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1384 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4436/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1383 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4437/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1324 - accuracy: 0.0000e+00 - val_loss: 0.1457 - val_accuracy: 0.0000e+00\n",
            "Epoch 4438/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1375 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4439/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1414 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4440/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1319 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 4441/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1369 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4442/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1411 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4443/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1327 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 4444/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1351 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4445/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1391 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4446/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1327 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 4447/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1319 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4448/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1410 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4449/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1424 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4450/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1428 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4451/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1431 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 4452/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1385 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4453/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1424 - accuracy: 0.0000e+00 - val_loss: 0.1423 - val_accuracy: 0.0000e+00\n",
            "Epoch 4454/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1340 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4455/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1369 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4456/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1435 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4457/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1322 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4458/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1313 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4459/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1380 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4460/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1363 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4461/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1378 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4462/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1327 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4463/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1292 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4464/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1509 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4465/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1402 - accuracy: 0.0000e+00 - val_loss: 0.1458 - val_accuracy: 0.0000e+00\n",
            "Epoch 4466/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1394 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4467/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1374 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4468/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1475 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4469/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1374 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4470/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1324 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4471/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1434 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4472/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1376 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4473/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1373 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4474/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1525 - accuracy: 0.0000e+00 - val_loss: 0.1462 - val_accuracy: 0.0000e+00\n",
            "Epoch 4475/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1369 - accuracy: 0.0000e+00 - val_loss: 0.1461 - val_accuracy: 0.0000e+00\n",
            "Epoch 4476/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1384 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 4477/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1369 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4478/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1375 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4479/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1391 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4480/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1413 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4481/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1360 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4482/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1506 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4483/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1366 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4484/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1314 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4485/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1404 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4486/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1459 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4487/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1285 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4488/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1346 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4489/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1396 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4490/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1285 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4491/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1361 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4492/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1474 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4493/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1341 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 4494/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1276 - accuracy: 0.0000e+00 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4495/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1294 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4496/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1382 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4497/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1447 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4498/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1397 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4499/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1414 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4500/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1430 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4501/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1360 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4502/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1407 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4503/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1431 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4504/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1316 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4505/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1346 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4506/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1366 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4507/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1301 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4508/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1389 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4509/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1387 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4510/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1520 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4511/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1344 - accuracy: 0.0000e+00 - val_loss: 0.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 4512/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1337 - accuracy: 0.0000e+00 - val_loss: 0.1453 - val_accuracy: 0.0000e+00\n",
            "Epoch 4513/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1320 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4514/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1381 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4515/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1408 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4516/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1443 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4517/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1346 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4518/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1387 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4519/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1374 - accuracy: 0.0000e+00 - val_loss: 0.1452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4520/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1407 - accuracy: 0.0000e+00 - val_loss: 0.1458 - val_accuracy: 0.0000e+00\n",
            "Epoch 4521/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1369 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4522/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1389 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4523/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1417 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4524/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1439 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4525/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1267 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4526/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1376 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4527/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1456 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4528/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1403 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4529/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1336 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4530/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1304 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4531/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1331 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4532/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 4533/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1323 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4534/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1294 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4535/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1394 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4536/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1348 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4537/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1422 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4538/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1313 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4539/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1460 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4540/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1348 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4541/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1400 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4542/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1382 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4543/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1499 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4544/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1319 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4545/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1329 - accuracy: 0.0000e+00 - val_loss: 0.1452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4546/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1349 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4547/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1390 - accuracy: 0.0000e+00 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4548/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1359 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4549/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1323 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4550/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1360 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4551/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1397 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4552/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1245 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4553/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1375 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4554/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1424 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4555/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1334 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4556/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1363 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4557/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1353 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4558/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1350 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4559/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1401 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4560/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1318 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4561/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1342 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4562/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1385 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4563/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1368 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4564/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1327 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4565/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1377 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4566/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1294 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4567/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1354 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4568/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1370 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4569/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1320 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4570/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1311 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4571/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1409 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4572/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1486 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4573/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1517 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4574/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1381 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4575/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1402 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4576/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1478 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4577/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1364 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4578/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1449 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4579/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1411 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4580/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1346 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 4581/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1332 - accuracy: 0.0000e+00 - val_loss: 0.1429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4582/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1317 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4583/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1329 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4584/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1479 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4585/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1446 - accuracy: 0.0000e+00 - val_loss: 0.1470 - val_accuracy: 0.0000e+00\n",
            "Epoch 4586/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1331 - accuracy: 0.0000e+00 - val_loss: 0.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 4587/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1440 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4588/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1427 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4589/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1316 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4590/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1476 - accuracy: 0.0000e+00 - val_loss: 0.1424 - val_accuracy: 0.0000e+00\n",
            "Epoch 4591/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1311 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 4592/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1342 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4593/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1466 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4594/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1415 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4595/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1370 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4596/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1370 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4597/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1362 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4598/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1412 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 4599/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1339 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4600/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1498 - accuracy: 0.0000e+00 - val_loss: 0.1429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4601/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1365 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4602/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1308 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 4603/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1358 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4604/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1360 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4605/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1369 - accuracy: 0.0000e+00 - val_loss: 0.1461 - val_accuracy: 0.0000e+00\n",
            "Epoch 4606/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1375 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4607/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1471 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4608/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1480 - accuracy: 0.0000e+00 - val_loss: 0.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 4609/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1416 - accuracy: 0.0000e+00 - val_loss: 0.1429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4610/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1532 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4611/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1363 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4612/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1353 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4613/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4614/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1357 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4615/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1368 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 4616/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1505 - accuracy: 0.0000e+00 - val_loss: 0.1452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4617/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1377 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4618/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1361 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4619/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1366 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4620/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1444 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4621/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1334 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4622/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1365 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4623/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1375 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4624/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1375 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4625/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1376 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4626/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1331 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4627/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4628/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1430 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4629/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1497 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4630/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1380 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4631/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1466 - accuracy: 0.0000e+00 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4632/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1371 - accuracy: 0.0000e+00 - val_loss: 0.1452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4633/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1405 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4634/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1385 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4635/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1394 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4636/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1401 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4637/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1457 - accuracy: 0.0000e+00 - val_loss: 0.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4638/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1369 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4639/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1404 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4640/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1379 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4641/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1353 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4642/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1338 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4643/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1435 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4644/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1340 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4645/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1324 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 4646/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1404 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4647/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1386 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4648/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1433 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4649/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1399 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4650/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1383 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4651/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1336 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4652/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1371 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4653/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1451 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4654/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1366 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4655/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1393 - accuracy: 0.0000e+00 - val_loss: 0.1453 - val_accuracy: 0.0000e+00\n",
            "Epoch 4656/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1331 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4657/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1353 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4658/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1393 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4659/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1539 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4660/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1306 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4661/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1369 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4662/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1363 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4663/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1354 - accuracy: 0.0000e+00 - val_loss: 0.1459 - val_accuracy: 0.0000e+00\n",
            "Epoch 4664/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1531 - accuracy: 0.0000e+00 - val_loss: 0.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 4665/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1381 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4666/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1392 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4667/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1343 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4668/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1327 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4669/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1319 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4670/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1343 - accuracy: 0.0000e+00 - val_loss: 0.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 4671/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1409 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4672/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1365 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4673/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1358 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4674/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1460 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4675/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1364 - accuracy: 0.0000e+00 - val_loss: 0.1463 - val_accuracy: 0.0000e+00\n",
            "Epoch 4676/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1389 - accuracy: 0.0000e+00 - val_loss: 0.1460 - val_accuracy: 0.0000e+00\n",
            "Epoch 4677/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4678/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1344 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4679/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1371 - accuracy: 0.0000e+00 - val_loss: 0.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 4680/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1381 - accuracy: 0.0000e+00 - val_loss: 0.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 4681/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1529 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4682/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1367 - accuracy: 0.0000e+00 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4683/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1450 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4684/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1365 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4685/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1279 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4686/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1433 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4687/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1361 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4688/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1392 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4689/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1308 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4690/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1328 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4691/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1415 - accuracy: 0.0000e+00 - val_loss: 0.1452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4692/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1475 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4693/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1528 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4694/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1368 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4695/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1339 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4696/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1301 - accuracy: 0.0000e+00 - val_loss: 0.1458 - val_accuracy: 0.0000e+00\n",
            "Epoch 4697/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1408 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4698/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1286 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4699/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1277 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4700/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1433 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4701/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1439 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4702/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1318 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4703/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1345 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4704/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1384 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4705/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1487 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4706/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1503 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 4707/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1334 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4708/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1370 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4709/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1386 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4710/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1436 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4711/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1438 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 4712/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1328 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4713/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1322 - accuracy: 0.0000e+00 - val_loss: 0.1452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4714/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1285 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 4715/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1419 - accuracy: 0.0000e+00 - val_loss: 0.1460 - val_accuracy: 0.0000e+00\n",
            "Epoch 4716/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1339 - accuracy: 0.0000e+00 - val_loss: 0.1457 - val_accuracy: 0.0000e+00\n",
            "Epoch 4717/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1383 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4718/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1401 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4719/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1336 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4720/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1401 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4721/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1355 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4722/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1440 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4723/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1391 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4724/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1405 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4725/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1331 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4726/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1328 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4727/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1411 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4728/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1273 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4729/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1468 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4730/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1425 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4731/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1344 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4732/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1473 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4733/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1443 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4734/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1358 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4735/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1353 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4736/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1270 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4737/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1316 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4738/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1315 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4739/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1403 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4740/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1348 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4741/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1351 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4742/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1470 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4743/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1361 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4744/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1356 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4745/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1435 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4746/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1522 - accuracy: 0.0000e+00 - val_loss: 0.1429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4747/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1361 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4748/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1343 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4749/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1329 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4750/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1357 - accuracy: 0.0000e+00 - val_loss: 0.1453 - val_accuracy: 0.0000e+00\n",
            "Epoch 4751/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1582 - accuracy: 0.0000e+00 - val_loss: 0.1467 - val_accuracy: 0.0000e+00\n",
            "Epoch 4752/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1331 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4753/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1452 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4754/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1451 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4755/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1355 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4756/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1430 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4757/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1388 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4758/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1420 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4759/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1363 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4760/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1367 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4761/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1331 - accuracy: 0.0000e+00 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4762/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1480 - accuracy: 0.0000e+00 - val_loss: 0.1459 - val_accuracy: 0.0000e+00\n",
            "Epoch 4763/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1423 - accuracy: 0.0000e+00 - val_loss: 0.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 4764/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1359 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4765/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1284 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4766/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1363 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4767/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1325 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4768/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1472 - accuracy: 0.0000e+00 - val_loss: 0.1453 - val_accuracy: 0.0000e+00\n",
            "Epoch 4769/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1387 - accuracy: 0.0000e+00 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4770/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1437 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4771/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1292 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4772/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1344 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4773/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1359 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4774/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1357 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4775/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1369 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4776/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1442 - accuracy: 0.0000e+00 - val_loss: 0.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 4777/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1284 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 4778/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1362 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4779/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1369 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4780/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1463 - accuracy: 0.0000e+00 - val_loss: 0.1461 - val_accuracy: 0.0000e+00\n",
            "Epoch 4781/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1314 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4782/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1388 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4783/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1386 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4784/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1388 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4785/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1390 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4786/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1346 - accuracy: 0.0000e+00 - val_loss: 0.1464 - val_accuracy: 0.0000e+00\n",
            "Epoch 4787/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1318 - accuracy: 0.0000e+00 - val_loss: 0.1460 - val_accuracy: 0.0000e+00\n",
            "Epoch 4788/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1344 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4789/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1447 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4790/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1377 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4791/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1445 - accuracy: 0.0000e+00 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4792/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1407 - accuracy: 0.0000e+00 - val_loss: 0.1457 - val_accuracy: 0.0000e+00\n",
            "Epoch 4793/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1319 - accuracy: 0.0000e+00 - val_loss: 0.1459 - val_accuracy: 0.0000e+00\n",
            "Epoch 4794/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1364 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4795/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1324 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4796/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1428 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4797/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1377 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4798/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1345 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4799/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1322 - accuracy: 0.0000e+00 - val_loss: 0.1458 - val_accuracy: 0.0000e+00\n",
            "Epoch 4800/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1408 - accuracy: 0.0000e+00 - val_loss: 0.1474 - val_accuracy: 0.0000e+00\n",
            "Epoch 4801/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1291 - accuracy: 0.0000e+00 - val_loss: 0.1453 - val_accuracy: 0.0000e+00\n",
            "Epoch 4802/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1336 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4803/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1412 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4804/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1322 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4805/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1287 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4806/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1358 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4807/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1328 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4808/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1368 - accuracy: 0.0000e+00 - val_loss: 0.1462 - val_accuracy: 0.0000e+00\n",
            "Epoch 4809/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1322 - accuracy: 0.0000e+00 - val_loss: 0.1466 - val_accuracy: 0.0000e+00\n",
            "Epoch 4810/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1365 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 4811/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1325 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4812/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1422 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4813/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1533 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4814/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1346 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4815/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1292 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4816/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1315 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 4817/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1395 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4818/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1488 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4819/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1403 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4820/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1332 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4821/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1379 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4822/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1302 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4823/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1371 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4824/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1355 - accuracy: 0.0000e+00 - val_loss: 0.1457 - val_accuracy: 0.0000e+00\n",
            "Epoch 4825/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1656 - accuracy: 0.0000e+00 - val_loss: 0.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 4826/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1427 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4827/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1443 - accuracy: 0.0000e+00 - val_loss: 0.1432 - val_accuracy: 0.0000e+00\n",
            "Epoch 4828/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1412 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4829/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1478 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4830/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1377 - accuracy: 0.0000e+00 - val_loss: 0.1453 - val_accuracy: 0.0000e+00\n",
            "Epoch 4831/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1351 - accuracy: 0.0000e+00 - val_loss: 0.1465 - val_accuracy: 0.0000e+00\n",
            "Epoch 4832/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1361 - accuracy: 0.0000e+00 - val_loss: 0.1458 - val_accuracy: 0.0000e+00\n",
            "Epoch 4833/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1454 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4834/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1352 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4835/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1350 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4836/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1391 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4837/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1328 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4838/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1479 - accuracy: 0.0000e+00 - val_loss: 0.1459 - val_accuracy: 0.0000e+00\n",
            "Epoch 4839/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1360 - accuracy: 0.0000e+00 - val_loss: 0.1460 - val_accuracy: 0.0000e+00\n",
            "Epoch 4840/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1295 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4841/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1365 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4842/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1297 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4843/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1505 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4844/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1314 - accuracy: 0.0000e+00 - val_loss: 0.1457 - val_accuracy: 0.0000e+00\n",
            "Epoch 4845/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1270 - accuracy: 0.0000e+00 - val_loss: 0.1457 - val_accuracy: 0.0000e+00\n",
            "Epoch 4846/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1435 - accuracy: 0.0000e+00 - val_loss: 0.1460 - val_accuracy: 0.0000e+00\n",
            "Epoch 4847/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1465 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4848/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1368 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4849/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1381 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4850/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1318 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 4851/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1321 - accuracy: 0.0000e+00 - val_loss: 0.1458 - val_accuracy: 0.0000e+00\n",
            "Epoch 4852/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1470 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 4853/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1363 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4854/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1262 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4855/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1345 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4856/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1440 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4857/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4858/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1485 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4859/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1376 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4860/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1316 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4861/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1366 - accuracy: 0.0000e+00 - val_loss: 0.1452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4862/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1322 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4863/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1352 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4864/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1416 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4865/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1356 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4866/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1325 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4867/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1349 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4868/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1519 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4869/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1353 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4870/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1354 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4871/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1316 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4872/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1327 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4873/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1460 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4874/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1368 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4875/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1351 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4876/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1603 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4877/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1279 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4878/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1394 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4879/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1418 - accuracy: 0.0000e+00 - val_loss: 0.1469 - val_accuracy: 0.0000e+00\n",
            "Epoch 4880/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1350 - accuracy: 0.0000e+00 - val_loss: 0.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 4881/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1306 - accuracy: 0.0000e+00 - val_loss: 0.1458 - val_accuracy: 0.0000e+00\n",
            "Epoch 4882/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1534 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4883/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1428 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4884/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1386 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4885/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1358 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4886/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1409 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4887/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1344 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4888/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1332 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4889/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1398 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4890/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1321 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4891/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1404 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4892/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1379 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 4893/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1329 - accuracy: 0.0000e+00 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4894/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1382 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4895/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1401 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4896/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1397 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4897/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4898/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1355 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4899/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1395 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4900/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1306 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4901/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1302 - accuracy: 0.0000e+00 - val_loss: 0.1452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4902/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1350 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4903/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1458 - accuracy: 0.0000e+00 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4904/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1310 - accuracy: 0.0000e+00 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 4905/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1400 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4906/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1419 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4907/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1350 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4908/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1491 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4909/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1384 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4910/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1463 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4911/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1317 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4912/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1472 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4913/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1352 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4914/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1369 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4915/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1360 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4916/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1306 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4917/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1382 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4918/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1343 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4919/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1440 - accuracy: 0.0000e+00 - val_loss: 0.1458 - val_accuracy: 0.0000e+00\n",
            "Epoch 4920/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1346 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 4921/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1413 - accuracy: 0.0000e+00 - val_loss: 0.1435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4922/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1417 - accuracy: 0.0000e+00 - val_loss: 0.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4923/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1568 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4924/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1367 - accuracy: 0.0000e+00 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4925/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1313 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4926/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1362 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4927/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1292 - accuracy: 0.0000e+00 - val_loss: 0.1429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4928/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1348 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4929/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1444 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4930/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1383 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4931/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1437 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4932/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1320 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4933/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1380 - accuracy: 0.0000e+00 - val_loss: 0.1460 - val_accuracy: 0.0000e+00\n",
            "Epoch 4934/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1395 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4935/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1305 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4936/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1481 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4937/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1364 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4938/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1331 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4939/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1371 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4940/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1310 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4941/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1271 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4942/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1379 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4943/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1362 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4944/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1309 - accuracy: 0.0000e+00 - val_loss: 0.1444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4945/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1386 - accuracy: 0.0000e+00 - val_loss: 0.1459 - val_accuracy: 0.0000e+00\n",
            "Epoch 4946/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1444 - accuracy: 0.0000e+00 - val_loss: 0.1459 - val_accuracy: 0.0000e+00\n",
            "Epoch 4947/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1511 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4948/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1372 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4949/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1343 - accuracy: 0.0000e+00 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4950/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1345 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4951/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1358 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4952/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1594 - accuracy: 0.0000e+00 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4953/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1326 - accuracy: 0.0000e+00 - val_loss: 0.1453 - val_accuracy: 0.0000e+00\n",
            "Epoch 4954/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1250 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4955/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1392 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4956/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1437 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4957/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1372 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 4958/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1346 - accuracy: 0.0000e+00 - val_loss: 0.1471 - val_accuracy: 0.0000e+00\n",
            "Epoch 4959/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1376 - accuracy: 0.0000e+00 - val_loss: 0.1475 - val_accuracy: 0.0000e+00\n",
            "Epoch 4960/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1352 - accuracy: 0.0000e+00 - val_loss: 0.1467 - val_accuracy: 0.0000e+00\n",
            "Epoch 4961/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1338 - accuracy: 0.0000e+00 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4962/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1344 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4963/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1458 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4964/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1559 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4965/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1487 - accuracy: 0.0000e+00 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4966/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1339 - accuracy: 0.0000e+00 - val_loss: 0.1452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4967/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1380 - accuracy: 0.0000e+00 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4968/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1358 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4969/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1354 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4970/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1375 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4971/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1463 - accuracy: 0.0000e+00 - val_loss: 0.1462 - val_accuracy: 0.0000e+00\n",
            "Epoch 4972/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1457 - accuracy: 0.0000e+00 - val_loss: 0.1457 - val_accuracy: 0.0000e+00\n",
            "Epoch 4973/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1324 - accuracy: 0.0000e+00 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 4974/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1346 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4975/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1320 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4976/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1467 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4977/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1396 - accuracy: 0.0000e+00 - val_loss: 0.1448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4978/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1413 - accuracy: 0.0000e+00 - val_loss: 0.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 4979/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1493 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4980/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1352 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4981/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1373 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4982/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1378 - accuracy: 0.0000e+00 - val_loss: 0.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4983/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1400 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4984/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1302 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4985/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1467 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4986/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1592 - accuracy: 0.0000e+00 - val_loss: 0.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4987/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1362 - accuracy: 0.0000e+00 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4988/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1566 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4989/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1384 - accuracy: 0.0000e+00 - val_loss: 0.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 4990/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1499 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4991/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1265 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4992/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1375 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4993/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1319 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4994/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1420 - accuracy: 0.0000e+00 - val_loss: 0.1438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4995/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1335 - accuracy: 0.0000e+00 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4996/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1350 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4997/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1324 - accuracy: 0.0000e+00 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4998/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1281 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4999/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1368 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n",
            "Epoch 5000/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1277 - accuracy: 0.0000e+00 - val_loss: 0.1446 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance do keras sequencial\n",
        "Faremos agora a avaliação do modelo criado com o keras sequencial."
      ],
      "metadata": {
        "id": "GbGF3tBnLDD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "    x = range(1, len(history.history['loss']) + 1)\n",
        "    trainingLoss = history.history['loss']\n",
        "    validationLoss = history.history['val_loss']\n",
        "    plt.plot(x, trainingLoss, 'b', label='Training loss')\n",
        "    plt.plot(x, validationLoss, 'r', label='Validation loss')\n",
        "    plt.title('Losses (Training and validation)')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "    \n",
        "plot_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "jVqK-tfELaqm",
        "outputId": "aa53b605-e5ea-4ba6-a11b-4407abe65f5f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos ver pelo gráfico acima, **não houve overfit** por parte do modelo pela mesma explicação que no implementado com o tensorflow. Embora pareca que a curva de treino está jittery, mas no primeiro modelo tal não aconteceu. Ora, voltando a verificar qual fora o valor usado, percebemos que foi de 0.0001 (uma dimensão a menos que a que agora), e por isso explica a **ligeira quantidade de jitter** que desapareceria caso alterássemos para o mesmo valor."
      ],
      "metadata": {
        "id": "AoYC2jNxOmkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(valid_X, valid_Y)\n",
        "print('Validation Loss: ' +str(loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35YDN8NrNyZU",
        "outputId": "ba4489e5-235f-4dec-9116-1037e045d986"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.0000e+00\n",
            "Validation Loss: 0.14463722705841064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keras funcional\n",
        "Passemos agora do keras sequencial para o keras funcional. As vantagens deste comparativamente ao sequencial é o de podermos **criar modelos mais complexos** que não são possíveis com o outro. Como exemplo de rede complexa é uma que tenha camadas partilhadas e que possa **fugir à regra de uma camada apenas se poder conectar com a ultima camada**."
      ],
      "metadata": {
        "id": "FAZMgeskSxfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definir o modelo\n",
        "Definiremos de seguida então a topologia da rede. Esta será muito semelhante à anterior mas usando o keras funcional."
      ],
      "metadata": {
        "id": "rbb05l_k4lzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, BatchNormalization, Conv2D, Dense\n",
        "from tensorflow.keras.layers import MaxPooling2D, Activation, Flatten, Dropout\n",
        "\n",
        "inputs = Input(shape=(8, ),name='inputs')\n",
        "layer = Dense(4)(inputs)\n",
        "layer = Activation(LeakyReLU())(layer)\n",
        "layer = BatchNormalization(axis=-1)(layer)\n",
        "####\n",
        "layer = Dense(4)(layer)\n",
        "layer = Activation(LeakyReLU())(layer)\n",
        "layer = BatchNormalization(axis=-1)(layer)\n",
        "#####\n",
        "layer = Dense(1)(layer)"
      ],
      "metadata": {
        "id": "Kzg4BmytVruE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O nosso modelo terá como inputs o que nós passamos (que serão os dados com os 8 atributos iguais a anteriormente) e como output o final da ultima layer."
      ],
      "metadata": {
        "id": "GOCDgCehYWy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "functionalKerasModel = Model(inputs = inputs, outputs = layer)   \n",
        "functionalKerasModel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1dzpYFNV00R",
        "outputId": "00ecfd01-d02b-46e6-adb3-a79ada37e819"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 8)]               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 36        \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 4)                16        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4)                 20        \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 4)                16        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93\n",
            "Trainable params: 77\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compilar o modelo e fazer o fit\n",
        "Assim como no sequencial, agora precisaremos de **compilar** o nosso modelo e posteriormente fazer o **fit** ao mesmo com os nossos dados."
      ],
      "metadata": {
        "id": "u4wyEeqEY4U_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 5000\n",
        "BS= 128\n",
        "opt = SGD(lr=0.00001, momentum=0.9)\n",
        "\n",
        "functionalKerasModel.compile(loss=tf.keras.losses.MeanSquaredError(),optimizer=opt, metrics=[\"accuracy\"])\n",
        "functionalKerasModel.summary()\n",
        "fittedModel = functionalKerasModel.fit(X, Y,validation_data=(valid_X, valid_Y),batch_size=BS, epochs=NUM_EPOCHS)\n"
      ],
      "metadata": {
        "id": "8BEjEfPkY31_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b43d31-5115-4346-8d8b-a502c4f6a47d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 8)]               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 36        \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 4)                16        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4)                 20        \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 4)                16        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93\n",
            "Trainable params: 77\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "Epoch 1/5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3618 - accuracy: 0.0000e+00 - val_loss: 0.3982 - val_accuracy: 0.0000e+00\n",
            "Epoch 2502/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3886 - accuracy: 0.0000e+00 - val_loss: 0.3982 - val_accuracy: 0.0000e+00\n",
            "Epoch 2503/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3655 - accuracy: 0.0000e+00 - val_loss: 0.3982 - val_accuracy: 0.0000e+00\n",
            "Epoch 2504/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3679 - accuracy: 0.0000e+00 - val_loss: 0.3981 - val_accuracy: 0.0000e+00\n",
            "Epoch 2505/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3690 - accuracy: 0.0000e+00 - val_loss: 0.3981 - val_accuracy: 0.0000e+00\n",
            "Epoch 2506/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3648 - accuracy: 0.0000e+00 - val_loss: 0.3981 - val_accuracy: 0.0000e+00\n",
            "Epoch 2507/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3701 - accuracy: 0.0000e+00 - val_loss: 0.3981 - val_accuracy: 0.0000e+00\n",
            "Epoch 2508/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3810 - accuracy: 0.0000e+00 - val_loss: 0.3980 - val_accuracy: 0.0000e+00\n",
            "Epoch 2509/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3725 - accuracy: 0.0000e+00 - val_loss: 0.3981 - val_accuracy: 0.0000e+00\n",
            "Epoch 2510/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3633 - accuracy: 0.0000e+00 - val_loss: 0.3981 - val_accuracy: 0.0000e+00\n",
            "Epoch 2511/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3647 - accuracy: 0.0000e+00 - val_loss: 0.3981 - val_accuracy: 0.0000e+00\n",
            "Epoch 2512/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3777 - accuracy: 0.0000e+00 - val_loss: 0.3981 - val_accuracy: 0.0000e+00\n",
            "Epoch 2513/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3664 - accuracy: 0.0000e+00 - val_loss: 0.3980 - val_accuracy: 0.0000e+00\n",
            "Epoch 2514/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3685 - accuracy: 0.0000e+00 - val_loss: 0.3980 - val_accuracy: 0.0000e+00\n",
            "Epoch 2515/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3712 - accuracy: 0.0000e+00 - val_loss: 0.3979 - val_accuracy: 0.0000e+00\n",
            "Epoch 2516/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3633 - accuracy: 0.0000e+00 - val_loss: 0.3978 - val_accuracy: 0.0000e+00\n",
            "Epoch 2517/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3789 - accuracy: 0.0000e+00 - val_loss: 0.3978 - val_accuracy: 0.0000e+00\n",
            "Epoch 2518/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3678 - accuracy: 0.0000e+00 - val_loss: 0.3978 - val_accuracy: 0.0000e+00\n",
            "Epoch 2519/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3668 - accuracy: 0.0000e+00 - val_loss: 0.3978 - val_accuracy: 0.0000e+00\n",
            "Epoch 2520/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3681 - accuracy: 0.0000e+00 - val_loss: 0.3978 - val_accuracy: 0.0000e+00\n",
            "Epoch 2521/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3666 - accuracy: 0.0000e+00 - val_loss: 0.3978 - val_accuracy: 0.0000e+00\n",
            "Epoch 2522/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3630 - accuracy: 0.0000e+00 - val_loss: 0.3978 - val_accuracy: 0.0000e+00\n",
            "Epoch 2523/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3647 - accuracy: 0.0000e+00 - val_loss: 0.3977 - val_accuracy: 0.0000e+00\n",
            "Epoch 2524/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3683 - accuracy: 0.0000e+00 - val_loss: 0.3977 - val_accuracy: 0.0000e+00\n",
            "Epoch 2525/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3652 - accuracy: 0.0000e+00 - val_loss: 0.3976 - val_accuracy: 0.0000e+00\n",
            "Epoch 2526/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3702 - accuracy: 0.0000e+00 - val_loss: 0.3977 - val_accuracy: 0.0000e+00\n",
            "Epoch 2527/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3623 - accuracy: 0.0000e+00 - val_loss: 0.3976 - val_accuracy: 0.0000e+00\n",
            "Epoch 2528/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3634 - accuracy: 0.0000e+00 - val_loss: 0.3975 - val_accuracy: 0.0000e+00\n",
            "Epoch 2529/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3606 - accuracy: 0.0000e+00 - val_loss: 0.3975 - val_accuracy: 0.0000e+00\n",
            "Epoch 2530/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3571 - accuracy: 0.0000e+00 - val_loss: 0.3975 - val_accuracy: 0.0000e+00\n",
            "Epoch 2531/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3628 - accuracy: 0.0000e+00 - val_loss: 0.3975 - val_accuracy: 0.0000e+00\n",
            "Epoch 2532/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3659 - accuracy: 0.0000e+00 - val_loss: 0.3974 - val_accuracy: 0.0000e+00\n",
            "Epoch 2533/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3638 - accuracy: 0.0000e+00 - val_loss: 0.3974 - val_accuracy: 0.0000e+00\n",
            "Epoch 2534/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3634 - accuracy: 0.0000e+00 - val_loss: 0.3974 - val_accuracy: 0.0000e+00\n",
            "Epoch 2535/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3721 - accuracy: 0.0000e+00 - val_loss: 0.3974 - val_accuracy: 0.0000e+00\n",
            "Epoch 2536/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3630 - accuracy: 0.0000e+00 - val_loss: 0.3975 - val_accuracy: 0.0000e+00\n",
            "Epoch 2537/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3708 - accuracy: 0.0000e+00 - val_loss: 0.3977 - val_accuracy: 0.0000e+00\n",
            "Epoch 2538/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3672 - accuracy: 0.0000e+00 - val_loss: 0.3976 - val_accuracy: 0.0000e+00\n",
            "Epoch 2539/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3713 - accuracy: 0.0000e+00 - val_loss: 0.3974 - val_accuracy: 0.0000e+00\n",
            "Epoch 2540/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3758 - accuracy: 0.0000e+00 - val_loss: 0.3973 - val_accuracy: 0.0000e+00\n",
            "Epoch 2541/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3685 - accuracy: 0.0000e+00 - val_loss: 0.3973 - val_accuracy: 0.0000e+00\n",
            "Epoch 2542/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3717 - accuracy: 0.0000e+00 - val_loss: 0.3974 - val_accuracy: 0.0000e+00\n",
            "Epoch 2543/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3605 - accuracy: 0.0000e+00 - val_loss: 0.3973 - val_accuracy: 0.0000e+00\n",
            "Epoch 2544/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3616 - accuracy: 0.0000e+00 - val_loss: 0.3972 - val_accuracy: 0.0000e+00\n",
            "Epoch 2545/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3664 - accuracy: 0.0000e+00 - val_loss: 0.3972 - val_accuracy: 0.0000e+00\n",
            "Epoch 2546/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3667 - accuracy: 0.0000e+00 - val_loss: 0.3971 - val_accuracy: 0.0000e+00\n",
            "Epoch 2547/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3594 - accuracy: 0.0000e+00 - val_loss: 0.3971 - val_accuracy: 0.0000e+00\n",
            "Epoch 2548/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3721 - accuracy: 0.0000e+00 - val_loss: 0.3969 - val_accuracy: 0.0000e+00\n",
            "Epoch 2549/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3625 - accuracy: 0.0000e+00 - val_loss: 0.3969 - val_accuracy: 0.0000e+00\n",
            "Epoch 2550/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3781 - accuracy: 0.0000e+00 - val_loss: 0.3969 - val_accuracy: 0.0000e+00\n",
            "Epoch 2551/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3697 - accuracy: 0.0000e+00 - val_loss: 0.3968 - val_accuracy: 0.0000e+00\n",
            "Epoch 2552/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3616 - accuracy: 0.0000e+00 - val_loss: 0.3968 - val_accuracy: 0.0000e+00\n",
            "Epoch 2553/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3647 - accuracy: 0.0000e+00 - val_loss: 0.3968 - val_accuracy: 0.0000e+00\n",
            "Epoch 2554/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3660 - accuracy: 0.0000e+00 - val_loss: 0.3967 - val_accuracy: 0.0000e+00\n",
            "Epoch 2555/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3637 - accuracy: 0.0000e+00 - val_loss: 0.3966 - val_accuracy: 0.0000e+00\n",
            "Epoch 2556/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3657 - accuracy: 0.0000e+00 - val_loss: 0.3966 - val_accuracy: 0.0000e+00\n",
            "Epoch 2557/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3644 - accuracy: 0.0000e+00 - val_loss: 0.3965 - val_accuracy: 0.0000e+00\n",
            "Epoch 2558/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3647 - accuracy: 0.0000e+00 - val_loss: 0.3966 - val_accuracy: 0.0000e+00\n",
            "Epoch 2559/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3659 - accuracy: 0.0000e+00 - val_loss: 0.3966 - val_accuracy: 0.0000e+00\n",
            "Epoch 2560/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3735 - accuracy: 0.0000e+00 - val_loss: 0.3966 - val_accuracy: 0.0000e+00\n",
            "Epoch 2561/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3665 - accuracy: 0.0000e+00 - val_loss: 0.3966 - val_accuracy: 0.0000e+00\n",
            "Epoch 2562/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3649 - accuracy: 0.0000e+00 - val_loss: 0.3966 - val_accuracy: 0.0000e+00\n",
            "Epoch 2563/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3615 - accuracy: 0.0000e+00 - val_loss: 0.3965 - val_accuracy: 0.0000e+00\n",
            "Epoch 2564/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3714 - accuracy: 0.0000e+00 - val_loss: 0.3965 - val_accuracy: 0.0000e+00\n",
            "Epoch 2565/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3656 - accuracy: 0.0000e+00 - val_loss: 0.3964 - val_accuracy: 0.0000e+00\n",
            "Epoch 2566/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3769 - accuracy: 0.0000e+00 - val_loss: 0.3964 - val_accuracy: 0.0000e+00\n",
            "Epoch 2567/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3670 - accuracy: 0.0000e+00 - val_loss: 0.3964 - val_accuracy: 0.0000e+00\n",
            "Epoch 2568/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3655 - accuracy: 0.0000e+00 - val_loss: 0.3964 - val_accuracy: 0.0000e+00\n",
            "Epoch 2569/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3599 - accuracy: 0.0000e+00 - val_loss: 0.3964 - val_accuracy: 0.0000e+00\n",
            "Epoch 2570/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3708 - accuracy: 0.0000e+00 - val_loss: 0.3964 - val_accuracy: 0.0000e+00\n",
            "Epoch 2571/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3629 - accuracy: 0.0000e+00 - val_loss: 0.3963 - val_accuracy: 0.0000e+00\n",
            "Epoch 2572/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3638 - accuracy: 0.0000e+00 - val_loss: 0.3962 - val_accuracy: 0.0000e+00\n",
            "Epoch 2573/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3617 - accuracy: 0.0000e+00 - val_loss: 0.3962 - val_accuracy: 0.0000e+00\n",
            "Epoch 2574/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3642 - accuracy: 0.0000e+00 - val_loss: 0.3962 - val_accuracy: 0.0000e+00\n",
            "Epoch 2575/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3653 - accuracy: 0.0000e+00 - val_loss: 0.3961 - val_accuracy: 0.0000e+00\n",
            "Epoch 2576/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3678 - accuracy: 0.0000e+00 - val_loss: 0.3961 - val_accuracy: 0.0000e+00\n",
            "Epoch 2577/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3666 - accuracy: 0.0000e+00 - val_loss: 0.3961 - val_accuracy: 0.0000e+00\n",
            "Epoch 2578/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3645 - accuracy: 0.0000e+00 - val_loss: 0.3961 - val_accuracy: 0.0000e+00\n",
            "Epoch 2579/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3626 - accuracy: 0.0000e+00 - val_loss: 0.3960 - val_accuracy: 0.0000e+00\n",
            "Epoch 2580/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3682 - accuracy: 0.0000e+00 - val_loss: 0.3961 - val_accuracy: 0.0000e+00\n",
            "Epoch 2581/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3574 - accuracy: 0.0000e+00 - val_loss: 0.3961 - val_accuracy: 0.0000e+00\n",
            "Epoch 2582/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3619 - accuracy: 0.0000e+00 - val_loss: 0.3961 - val_accuracy: 0.0000e+00\n",
            "Epoch 2583/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3677 - accuracy: 0.0000e+00 - val_loss: 0.3961 - val_accuracy: 0.0000e+00\n",
            "Epoch 2584/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3667 - accuracy: 0.0000e+00 - val_loss: 0.3961 - val_accuracy: 0.0000e+00\n",
            "Epoch 2585/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3636 - accuracy: 0.0000e+00 - val_loss: 0.3960 - val_accuracy: 0.0000e+00\n",
            "Epoch 2586/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3641 - accuracy: 0.0000e+00 - val_loss: 0.3959 - val_accuracy: 0.0000e+00\n",
            "Epoch 2587/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3603 - accuracy: 0.0000e+00 - val_loss: 0.3960 - val_accuracy: 0.0000e+00\n",
            "Epoch 2588/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3714 - accuracy: 0.0000e+00 - val_loss: 0.3959 - val_accuracy: 0.0000e+00\n",
            "Epoch 2589/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3584 - accuracy: 0.0000e+00 - val_loss: 0.3959 - val_accuracy: 0.0000e+00\n",
            "Epoch 2590/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3728 - accuracy: 0.0000e+00 - val_loss: 0.3959 - val_accuracy: 0.0000e+00\n",
            "Epoch 2591/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3581 - accuracy: 0.0000e+00 - val_loss: 0.3958 - val_accuracy: 0.0000e+00\n",
            "Epoch 2592/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3704 - accuracy: 0.0000e+00 - val_loss: 0.3959 - val_accuracy: 0.0000e+00\n",
            "Epoch 2593/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3671 - accuracy: 0.0000e+00 - val_loss: 0.3959 - val_accuracy: 0.0000e+00\n",
            "Epoch 2594/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3649 - accuracy: 0.0000e+00 - val_loss: 0.3958 - val_accuracy: 0.0000e+00\n",
            "Epoch 2595/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3610 - accuracy: 0.0000e+00 - val_loss: 0.3958 - val_accuracy: 0.0000e+00\n",
            "Epoch 2596/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3747 - accuracy: 0.0000e+00 - val_loss: 0.3957 - val_accuracy: 0.0000e+00\n",
            "Epoch 2597/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3602 - accuracy: 0.0000e+00 - val_loss: 0.3957 - val_accuracy: 0.0000e+00\n",
            "Epoch 2598/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3625 - accuracy: 0.0000e+00 - val_loss: 0.3957 - val_accuracy: 0.0000e+00\n",
            "Epoch 2599/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3653 - accuracy: 0.0000e+00 - val_loss: 0.3957 - val_accuracy: 0.0000e+00\n",
            "Epoch 2600/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3604 - accuracy: 0.0000e+00 - val_loss: 0.3956 - val_accuracy: 0.0000e+00\n",
            "Epoch 2601/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3658 - accuracy: 0.0000e+00 - val_loss: 0.3956 - val_accuracy: 0.0000e+00\n",
            "Epoch 2602/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3606 - accuracy: 0.0000e+00 - val_loss: 0.3955 - val_accuracy: 0.0000e+00\n",
            "Epoch 2603/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3680 - accuracy: 0.0000e+00 - val_loss: 0.3955 - val_accuracy: 0.0000e+00\n",
            "Epoch 2604/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3700 - accuracy: 0.0000e+00 - val_loss: 0.3955 - val_accuracy: 0.0000e+00\n",
            "Epoch 2605/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3708 - accuracy: 0.0000e+00 - val_loss: 0.3954 - val_accuracy: 0.0000e+00\n",
            "Epoch 2606/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3701 - accuracy: 0.0000e+00 - val_loss: 0.3954 - val_accuracy: 0.0000e+00\n",
            "Epoch 2607/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3614 - accuracy: 0.0000e+00 - val_loss: 0.3954 - val_accuracy: 0.0000e+00\n",
            "Epoch 2608/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3727 - accuracy: 0.0000e+00 - val_loss: 0.3953 - val_accuracy: 0.0000e+00\n",
            "Epoch 2609/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3704 - accuracy: 0.0000e+00 - val_loss: 0.3953 - val_accuracy: 0.0000e+00\n",
            "Epoch 2610/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3759 - accuracy: 0.0000e+00 - val_loss: 0.3953 - val_accuracy: 0.0000e+00\n",
            "Epoch 2611/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3615 - accuracy: 0.0000e+00 - val_loss: 0.3953 - val_accuracy: 0.0000e+00\n",
            "Epoch 2612/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3686 - accuracy: 0.0000e+00 - val_loss: 0.3953 - val_accuracy: 0.0000e+00\n",
            "Epoch 2613/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3671 - accuracy: 0.0000e+00 - val_loss: 0.3953 - val_accuracy: 0.0000e+00\n",
            "Epoch 2614/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3589 - accuracy: 0.0000e+00 - val_loss: 0.3953 - val_accuracy: 0.0000e+00\n",
            "Epoch 2615/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3670 - accuracy: 0.0000e+00 - val_loss: 0.3953 - val_accuracy: 0.0000e+00\n",
            "Epoch 2616/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3629 - accuracy: 0.0000e+00 - val_loss: 0.3953 - val_accuracy: 0.0000e+00\n",
            "Epoch 2617/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3647 - accuracy: 0.0000e+00 - val_loss: 0.3952 - val_accuracy: 0.0000e+00\n",
            "Epoch 2618/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3651 - accuracy: 0.0000e+00 - val_loss: 0.3952 - val_accuracy: 0.0000e+00\n",
            "Epoch 2619/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3624 - accuracy: 0.0000e+00 - val_loss: 0.3951 - val_accuracy: 0.0000e+00\n",
            "Epoch 2620/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3635 - accuracy: 0.0000e+00 - val_loss: 0.3950 - val_accuracy: 0.0000e+00\n",
            "Epoch 2621/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3573 - accuracy: 0.0000e+00 - val_loss: 0.3950 - val_accuracy: 0.0000e+00\n",
            "Epoch 2622/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3611 - accuracy: 0.0000e+00 - val_loss: 0.3950 - val_accuracy: 0.0000e+00\n",
            "Epoch 2623/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3642 - accuracy: 0.0000e+00 - val_loss: 0.3950 - val_accuracy: 0.0000e+00\n",
            "Epoch 2624/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3657 - accuracy: 0.0000e+00 - val_loss: 0.3950 - val_accuracy: 0.0000e+00\n",
            "Epoch 2625/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3552 - accuracy: 0.0000e+00 - val_loss: 0.3950 - val_accuracy: 0.0000e+00\n",
            "Epoch 2626/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3626 - accuracy: 0.0000e+00 - val_loss: 0.3950 - val_accuracy: 0.0000e+00\n",
            "Epoch 2627/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3601 - accuracy: 0.0000e+00 - val_loss: 0.3950 - val_accuracy: 0.0000e+00\n",
            "Epoch 2628/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3688 - accuracy: 0.0000e+00 - val_loss: 0.3950 - val_accuracy: 0.0000e+00\n",
            "Epoch 2629/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3643 - accuracy: 0.0000e+00 - val_loss: 0.3950 - val_accuracy: 0.0000e+00\n",
            "Epoch 2630/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3587 - accuracy: 0.0000e+00 - val_loss: 0.3950 - val_accuracy: 0.0000e+00\n",
            "Epoch 2631/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3628 - accuracy: 0.0000e+00 - val_loss: 0.3949 - val_accuracy: 0.0000e+00\n",
            "Epoch 2632/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3712 - accuracy: 0.0000e+00 - val_loss: 0.3948 - val_accuracy: 0.0000e+00\n",
            "Epoch 2633/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3752 - accuracy: 0.0000e+00 - val_loss: 0.3948 - val_accuracy: 0.0000e+00\n",
            "Epoch 2634/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3601 - accuracy: 0.0000e+00 - val_loss: 0.3948 - val_accuracy: 0.0000e+00\n",
            "Epoch 2635/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3716 - accuracy: 0.0000e+00 - val_loss: 0.3947 - val_accuracy: 0.0000e+00\n",
            "Epoch 2636/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3593 - accuracy: 0.0000e+00 - val_loss: 0.3947 - val_accuracy: 0.0000e+00\n",
            "Epoch 2637/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3610 - accuracy: 0.0000e+00 - val_loss: 0.3946 - val_accuracy: 0.0000e+00\n",
            "Epoch 2638/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3802 - accuracy: 0.0000e+00 - val_loss: 0.3946 - val_accuracy: 0.0000e+00\n",
            "Epoch 2639/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3659 - accuracy: 0.0000e+00 - val_loss: 0.3945 - val_accuracy: 0.0000e+00\n",
            "Epoch 2640/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3611 - accuracy: 0.0000e+00 - val_loss: 0.3944 - val_accuracy: 0.0000e+00\n",
            "Epoch 2641/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3624 - accuracy: 0.0000e+00 - val_loss: 0.3944 - val_accuracy: 0.0000e+00\n",
            "Epoch 2642/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3642 - accuracy: 0.0000e+00 - val_loss: 0.3945 - val_accuracy: 0.0000e+00\n",
            "Epoch 2643/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3586 - accuracy: 0.0000e+00 - val_loss: 0.3944 - val_accuracy: 0.0000e+00\n",
            "Epoch 2644/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3694 - accuracy: 0.0000e+00 - val_loss: 0.3944 - val_accuracy: 0.0000e+00\n",
            "Epoch 2645/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3610 - accuracy: 0.0000e+00 - val_loss: 0.3944 - val_accuracy: 0.0000e+00\n",
            "Epoch 2646/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3605 - accuracy: 0.0000e+00 - val_loss: 0.3943 - val_accuracy: 0.0000e+00\n",
            "Epoch 2647/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3695 - accuracy: 0.0000e+00 - val_loss: 0.3944 - val_accuracy: 0.0000e+00\n",
            "Epoch 2648/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3586 - accuracy: 0.0000e+00 - val_loss: 0.3942 - val_accuracy: 0.0000e+00\n",
            "Epoch 2649/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3640 - accuracy: 0.0000e+00 - val_loss: 0.3941 - val_accuracy: 0.0000e+00\n",
            "Epoch 2650/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3745 - accuracy: 0.0000e+00 - val_loss: 0.3941 - val_accuracy: 0.0000e+00\n",
            "Epoch 2651/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3624 - accuracy: 0.0000e+00 - val_loss: 0.3940 - val_accuracy: 0.0000e+00\n",
            "Epoch 2652/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3554 - accuracy: 0.0000e+00 - val_loss: 0.3940 - val_accuracy: 0.0000e+00\n",
            "Epoch 2653/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3623 - accuracy: 0.0000e+00 - val_loss: 0.3940 - val_accuracy: 0.0000e+00\n",
            "Epoch 2654/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3669 - accuracy: 0.0000e+00 - val_loss: 0.3940 - val_accuracy: 0.0000e+00\n",
            "Epoch 2655/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3697 - accuracy: 0.0000e+00 - val_loss: 0.3940 - val_accuracy: 0.0000e+00\n",
            "Epoch 2656/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3647 - accuracy: 0.0000e+00 - val_loss: 0.3939 - val_accuracy: 0.0000e+00\n",
            "Epoch 2657/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3693 - accuracy: 0.0000e+00 - val_loss: 0.3939 - val_accuracy: 0.0000e+00\n",
            "Epoch 2658/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3619 - accuracy: 0.0000e+00 - val_loss: 0.3939 - val_accuracy: 0.0000e+00\n",
            "Epoch 2659/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3670 - accuracy: 0.0000e+00 - val_loss: 0.3939 - val_accuracy: 0.0000e+00\n",
            "Epoch 2660/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3649 - accuracy: 0.0000e+00 - val_loss: 0.3938 - val_accuracy: 0.0000e+00\n",
            "Epoch 2661/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3628 - accuracy: 0.0000e+00 - val_loss: 0.3938 - val_accuracy: 0.0000e+00\n",
            "Epoch 2662/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3583 - accuracy: 0.0000e+00 - val_loss: 0.3937 - val_accuracy: 0.0000e+00\n",
            "Epoch 2663/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3544 - accuracy: 0.0000e+00 - val_loss: 0.3937 - val_accuracy: 0.0000e+00\n",
            "Epoch 2664/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3579 - accuracy: 0.0000e+00 - val_loss: 0.3937 - val_accuracy: 0.0000e+00\n",
            "Epoch 2665/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3634 - accuracy: 0.0000e+00 - val_loss: 0.3936 - val_accuracy: 0.0000e+00\n",
            "Epoch 2666/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3664 - accuracy: 0.0000e+00 - val_loss: 0.3936 - val_accuracy: 0.0000e+00\n",
            "Epoch 2667/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3667 - accuracy: 0.0000e+00 - val_loss: 0.3936 - val_accuracy: 0.0000e+00\n",
            "Epoch 2668/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3601 - accuracy: 0.0000e+00 - val_loss: 0.3936 - val_accuracy: 0.0000e+00\n",
            "Epoch 2669/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3548 - accuracy: 0.0000e+00 - val_loss: 0.3936 - val_accuracy: 0.0000e+00\n",
            "Epoch 2670/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3571 - accuracy: 0.0000e+00 - val_loss: 0.3936 - val_accuracy: 0.0000e+00\n",
            "Epoch 2671/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3627 - accuracy: 0.0000e+00 - val_loss: 0.3936 - val_accuracy: 0.0000e+00\n",
            "Epoch 2672/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3613 - accuracy: 0.0000e+00 - val_loss: 0.3935 - val_accuracy: 0.0000e+00\n",
            "Epoch 2673/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3670 - accuracy: 0.0000e+00 - val_loss: 0.3936 - val_accuracy: 0.0000e+00\n",
            "Epoch 2674/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3610 - accuracy: 0.0000e+00 - val_loss: 0.3935 - val_accuracy: 0.0000e+00\n",
            "Epoch 2675/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3596 - accuracy: 0.0000e+00 - val_loss: 0.3934 - val_accuracy: 0.0000e+00\n",
            "Epoch 2676/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3683 - accuracy: 0.0000e+00 - val_loss: 0.3933 - val_accuracy: 0.0000e+00\n",
            "Epoch 2677/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3633 - accuracy: 0.0000e+00 - val_loss: 0.3933 - val_accuracy: 0.0000e+00\n",
            "Epoch 2678/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3656 - accuracy: 0.0000e+00 - val_loss: 0.3932 - val_accuracy: 0.0000e+00\n",
            "Epoch 2679/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3567 - accuracy: 0.0000e+00 - val_loss: 0.3931 - val_accuracy: 0.0000e+00\n",
            "Epoch 2680/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3592 - accuracy: 0.0000e+00 - val_loss: 0.3930 - val_accuracy: 0.0000e+00\n",
            "Epoch 2681/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3618 - accuracy: 0.0000e+00 - val_loss: 0.3930 - val_accuracy: 0.0000e+00\n",
            "Epoch 2682/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3544 - accuracy: 0.0000e+00 - val_loss: 0.3929 - val_accuracy: 0.0000e+00\n",
            "Epoch 2683/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3621 - accuracy: 0.0000e+00 - val_loss: 0.3930 - val_accuracy: 0.0000e+00\n",
            "Epoch 2684/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3683 - accuracy: 0.0000e+00 - val_loss: 0.3930 - val_accuracy: 0.0000e+00\n",
            "Epoch 2685/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3667 - accuracy: 0.0000e+00 - val_loss: 0.3931 - val_accuracy: 0.0000e+00\n",
            "Epoch 2686/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3589 - accuracy: 0.0000e+00 - val_loss: 0.3930 - val_accuracy: 0.0000e+00\n",
            "Epoch 2687/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3596 - accuracy: 0.0000e+00 - val_loss: 0.3929 - val_accuracy: 0.0000e+00\n",
            "Epoch 2688/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3619 - accuracy: 0.0000e+00 - val_loss: 0.3929 - val_accuracy: 0.0000e+00\n",
            "Epoch 2689/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3664 - accuracy: 0.0000e+00 - val_loss: 0.3929 - val_accuracy: 0.0000e+00\n",
            "Epoch 2690/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3656 - accuracy: 0.0000e+00 - val_loss: 0.3928 - val_accuracy: 0.0000e+00\n",
            "Epoch 2691/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3582 - accuracy: 0.0000e+00 - val_loss: 0.3928 - val_accuracy: 0.0000e+00\n",
            "Epoch 2692/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3764 - accuracy: 0.0000e+00 - val_loss: 0.3928 - val_accuracy: 0.0000e+00\n",
            "Epoch 2693/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3717 - accuracy: 0.0000e+00 - val_loss: 0.3928 - val_accuracy: 0.0000e+00\n",
            "Epoch 2694/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3578 - accuracy: 0.0000e+00 - val_loss: 0.3928 - val_accuracy: 0.0000e+00\n",
            "Epoch 2695/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3686 - accuracy: 0.0000e+00 - val_loss: 0.3928 - val_accuracy: 0.0000e+00\n",
            "Epoch 2696/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3601 - accuracy: 0.0000e+00 - val_loss: 0.3927 - val_accuracy: 0.0000e+00\n",
            "Epoch 2697/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3633 - accuracy: 0.0000e+00 - val_loss: 0.3927 - val_accuracy: 0.0000e+00\n",
            "Epoch 2698/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3629 - accuracy: 0.0000e+00 - val_loss: 0.3926 - val_accuracy: 0.0000e+00\n",
            "Epoch 2699/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3578 - accuracy: 0.0000e+00 - val_loss: 0.3926 - val_accuracy: 0.0000e+00\n",
            "Epoch 2700/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3636 - accuracy: 0.0000e+00 - val_loss: 0.3925 - val_accuracy: 0.0000e+00\n",
            "Epoch 2701/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3695 - accuracy: 0.0000e+00 - val_loss: 0.3925 - val_accuracy: 0.0000e+00\n",
            "Epoch 2702/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3557 - accuracy: 0.0000e+00 - val_loss: 0.3925 - val_accuracy: 0.0000e+00\n",
            "Epoch 2703/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3648 - accuracy: 0.0000e+00 - val_loss: 0.3924 - val_accuracy: 0.0000e+00\n",
            "Epoch 2704/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3516 - accuracy: 0.0000e+00 - val_loss: 0.3924 - val_accuracy: 0.0000e+00\n",
            "Epoch 2705/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3644 - accuracy: 0.0000e+00 - val_loss: 0.3924 - val_accuracy: 0.0000e+00\n",
            "Epoch 2706/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3589 - accuracy: 0.0000e+00 - val_loss: 0.3922 - val_accuracy: 0.0000e+00\n",
            "Epoch 2707/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3560 - accuracy: 0.0000e+00 - val_loss: 0.3922 - val_accuracy: 0.0000e+00\n",
            "Epoch 2708/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3614 - accuracy: 0.0000e+00 - val_loss: 0.3922 - val_accuracy: 0.0000e+00\n",
            "Epoch 2709/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3616 - accuracy: 0.0000e+00 - val_loss: 0.3922 - val_accuracy: 0.0000e+00\n",
            "Epoch 2710/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3664 - accuracy: 0.0000e+00 - val_loss: 0.3921 - val_accuracy: 0.0000e+00\n",
            "Epoch 2711/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3615 - accuracy: 0.0000e+00 - val_loss: 0.3921 - val_accuracy: 0.0000e+00\n",
            "Epoch 2712/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3638 - accuracy: 0.0000e+00 - val_loss: 0.3922 - val_accuracy: 0.0000e+00\n",
            "Epoch 2713/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3651 - accuracy: 0.0000e+00 - val_loss: 0.3921 - val_accuracy: 0.0000e+00\n",
            "Epoch 2714/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3657 - accuracy: 0.0000e+00 - val_loss: 0.3920 - val_accuracy: 0.0000e+00\n",
            "Epoch 2715/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3622 - accuracy: 0.0000e+00 - val_loss: 0.3920 - val_accuracy: 0.0000e+00\n",
            "Epoch 2716/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3598 - accuracy: 0.0000e+00 - val_loss: 0.3920 - val_accuracy: 0.0000e+00\n",
            "Epoch 2717/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3670 - accuracy: 0.0000e+00 - val_loss: 0.3920 - val_accuracy: 0.0000e+00\n",
            "Epoch 2718/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3580 - accuracy: 0.0000e+00 - val_loss: 0.3919 - val_accuracy: 0.0000e+00\n",
            "Epoch 2719/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3568 - accuracy: 0.0000e+00 - val_loss: 0.3918 - val_accuracy: 0.0000e+00\n",
            "Epoch 2720/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3601 - accuracy: 0.0000e+00 - val_loss: 0.3918 - val_accuracy: 0.0000e+00\n",
            "Epoch 2721/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3633 - accuracy: 0.0000e+00 - val_loss: 0.3917 - val_accuracy: 0.0000e+00\n",
            "Epoch 2722/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3579 - accuracy: 0.0000e+00 - val_loss: 0.3917 - val_accuracy: 0.0000e+00\n",
            "Epoch 2723/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3604 - accuracy: 0.0000e+00 - val_loss: 0.3915 - val_accuracy: 0.0000e+00\n",
            "Epoch 2724/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3592 - accuracy: 0.0000e+00 - val_loss: 0.3915 - val_accuracy: 0.0000e+00\n",
            "Epoch 2725/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3587 - accuracy: 0.0000e+00 - val_loss: 0.3914 - val_accuracy: 0.0000e+00\n",
            "Epoch 2726/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3633 - accuracy: 0.0000e+00 - val_loss: 0.3913 - val_accuracy: 0.0000e+00\n",
            "Epoch 2727/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3565 - accuracy: 0.0000e+00 - val_loss: 0.3913 - val_accuracy: 0.0000e+00\n",
            "Epoch 2728/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3585 - accuracy: 0.0000e+00 - val_loss: 0.3913 - val_accuracy: 0.0000e+00\n",
            "Epoch 2729/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3527 - accuracy: 0.0000e+00 - val_loss: 0.3912 - val_accuracy: 0.0000e+00\n",
            "Epoch 2730/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3580 - accuracy: 0.0000e+00 - val_loss: 0.3912 - val_accuracy: 0.0000e+00\n",
            "Epoch 2731/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3559 - accuracy: 0.0000e+00 - val_loss: 0.3912 - val_accuracy: 0.0000e+00\n",
            "Epoch 2732/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3629 - accuracy: 0.0000e+00 - val_loss: 0.3911 - val_accuracy: 0.0000e+00\n",
            "Epoch 2733/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3607 - accuracy: 0.0000e+00 - val_loss: 0.3911 - val_accuracy: 0.0000e+00\n",
            "Epoch 2734/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3623 - accuracy: 0.0000e+00 - val_loss: 0.3911 - val_accuracy: 0.0000e+00\n",
            "Epoch 2735/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3561 - accuracy: 0.0000e+00 - val_loss: 0.3911 - val_accuracy: 0.0000e+00\n",
            "Epoch 2736/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3562 - accuracy: 0.0000e+00 - val_loss: 0.3911 - val_accuracy: 0.0000e+00\n",
            "Epoch 2737/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3600 - accuracy: 0.0000e+00 - val_loss: 0.3912 - val_accuracy: 0.0000e+00\n",
            "Epoch 2738/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3579 - accuracy: 0.0000e+00 - val_loss: 0.3911 - val_accuracy: 0.0000e+00\n",
            "Epoch 2739/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3617 - accuracy: 0.0000e+00 - val_loss: 0.3910 - val_accuracy: 0.0000e+00\n",
            "Epoch 2740/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3560 - accuracy: 0.0000e+00 - val_loss: 0.3910 - val_accuracy: 0.0000e+00\n",
            "Epoch 2741/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3626 - accuracy: 0.0000e+00 - val_loss: 0.3910 - val_accuracy: 0.0000e+00\n",
            "Epoch 2742/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3503 - accuracy: 0.0000e+00 - val_loss: 0.3910 - val_accuracy: 0.0000e+00\n",
            "Epoch 2743/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3597 - accuracy: 0.0000e+00 - val_loss: 0.3908 - val_accuracy: 0.0000e+00\n",
            "Epoch 2744/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3534 - accuracy: 0.0000e+00 - val_loss: 0.3909 - val_accuracy: 0.0000e+00\n",
            "Epoch 2745/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3562 - accuracy: 0.0000e+00 - val_loss: 0.3909 - val_accuracy: 0.0000e+00\n",
            "Epoch 2746/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3599 - accuracy: 0.0000e+00 - val_loss: 0.3908 - val_accuracy: 0.0000e+00\n",
            "Epoch 2747/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3590 - accuracy: 0.0000e+00 - val_loss: 0.3908 - val_accuracy: 0.0000e+00\n",
            "Epoch 2748/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3583 - accuracy: 0.0000e+00 - val_loss: 0.3907 - val_accuracy: 0.0000e+00\n",
            "Epoch 2749/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3584 - accuracy: 0.0000e+00 - val_loss: 0.3906 - val_accuracy: 0.0000e+00\n",
            "Epoch 2750/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3639 - accuracy: 0.0000e+00 - val_loss: 0.3907 - val_accuracy: 0.0000e+00\n",
            "Epoch 2751/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3524 - accuracy: 0.0000e+00 - val_loss: 0.3906 - val_accuracy: 0.0000e+00\n",
            "Epoch 2752/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3558 - accuracy: 0.0000e+00 - val_loss: 0.3905 - val_accuracy: 0.0000e+00\n",
            "Epoch 2753/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3576 - accuracy: 0.0000e+00 - val_loss: 0.3905 - val_accuracy: 0.0000e+00\n",
            "Epoch 2754/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3567 - accuracy: 0.0000e+00 - val_loss: 0.3905 - val_accuracy: 0.0000e+00\n",
            "Epoch 2755/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3590 - accuracy: 0.0000e+00 - val_loss: 0.3905 - val_accuracy: 0.0000e+00\n",
            "Epoch 2756/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3594 - accuracy: 0.0000e+00 - val_loss: 0.3905 - val_accuracy: 0.0000e+00\n",
            "Epoch 2757/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3670 - accuracy: 0.0000e+00 - val_loss: 0.3905 - val_accuracy: 0.0000e+00\n",
            "Epoch 2758/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3571 - accuracy: 0.0000e+00 - val_loss: 0.3905 - val_accuracy: 0.0000e+00\n",
            "Epoch 2759/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3562 - accuracy: 0.0000e+00 - val_loss: 0.3904 - val_accuracy: 0.0000e+00\n",
            "Epoch 2760/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3627 - accuracy: 0.0000e+00 - val_loss: 0.3904 - val_accuracy: 0.0000e+00\n",
            "Epoch 2761/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3594 - accuracy: 0.0000e+00 - val_loss: 0.3904 - val_accuracy: 0.0000e+00\n",
            "Epoch 2762/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3629 - accuracy: 0.0000e+00 - val_loss: 0.3904 - val_accuracy: 0.0000e+00\n",
            "Epoch 2763/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3614 - accuracy: 0.0000e+00 - val_loss: 0.3903 - val_accuracy: 0.0000e+00\n",
            "Epoch 2764/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3555 - accuracy: 0.0000e+00 - val_loss: 0.3902 - val_accuracy: 0.0000e+00\n",
            "Epoch 2765/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3559 - accuracy: 0.0000e+00 - val_loss: 0.3901 - val_accuracy: 0.0000e+00\n",
            "Epoch 2766/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3524 - accuracy: 0.0000e+00 - val_loss: 0.3900 - val_accuracy: 0.0000e+00\n",
            "Epoch 2767/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3539 - accuracy: 0.0000e+00 - val_loss: 0.3900 - val_accuracy: 0.0000e+00\n",
            "Epoch 2768/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3577 - accuracy: 0.0000e+00 - val_loss: 0.3900 - val_accuracy: 0.0000e+00\n",
            "Epoch 2769/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3669 - accuracy: 0.0000e+00 - val_loss: 0.3900 - val_accuracy: 0.0000e+00\n",
            "Epoch 2770/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3685 - accuracy: 0.0000e+00 - val_loss: 0.3899 - val_accuracy: 0.0000e+00\n",
            "Epoch 2771/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3585 - accuracy: 0.0000e+00 - val_loss: 0.3899 - val_accuracy: 0.0000e+00\n",
            "Epoch 2772/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3529 - accuracy: 0.0000e+00 - val_loss: 0.3898 - val_accuracy: 0.0000e+00\n",
            "Epoch 2773/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3606 - accuracy: 0.0000e+00 - val_loss: 0.3899 - val_accuracy: 0.0000e+00\n",
            "Epoch 2774/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3704 - accuracy: 0.0000e+00 - val_loss: 0.3898 - val_accuracy: 0.0000e+00\n",
            "Epoch 2775/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3618 - accuracy: 0.0000e+00 - val_loss: 0.3898 - val_accuracy: 0.0000e+00\n",
            "Epoch 2776/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3586 - accuracy: 0.0000e+00 - val_loss: 0.3898 - val_accuracy: 0.0000e+00\n",
            "Epoch 2777/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3614 - accuracy: 0.0000e+00 - val_loss: 0.3897 - val_accuracy: 0.0000e+00\n",
            "Epoch 2778/5000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3630 - accuracy: 0.0000e+00 - val_loss: 0.3897 - val_accuracy: 0.0000e+00\n",
            "Epoch 2779/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3626 - accuracy: 0.0000e+00 - val_loss: 0.3897 - val_accuracy: 0.0000e+00\n",
            "Epoch 2780/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3569 - accuracy: 0.0000e+00 - val_loss: 0.3896 - val_accuracy: 0.0000e+00\n",
            "Epoch 2781/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3620 - accuracy: 0.0000e+00 - val_loss: 0.3896 - val_accuracy: 0.0000e+00\n",
            "Epoch 2782/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3552 - accuracy: 0.0000e+00 - val_loss: 0.3895 - val_accuracy: 0.0000e+00\n",
            "Epoch 2783/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3626 - accuracy: 0.0000e+00 - val_loss: 0.3894 - val_accuracy: 0.0000e+00\n",
            "Epoch 2784/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3519 - accuracy: 0.0000e+00 - val_loss: 0.3893 - val_accuracy: 0.0000e+00\n",
            "Epoch 2785/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3561 - accuracy: 0.0000e+00 - val_loss: 0.3893 - val_accuracy: 0.0000e+00\n",
            "Epoch 2786/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3543 - accuracy: 0.0000e+00 - val_loss: 0.3892 - val_accuracy: 0.0000e+00\n",
            "Epoch 2787/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3603 - accuracy: 0.0000e+00 - val_loss: 0.3892 - val_accuracy: 0.0000e+00\n",
            "Epoch 2788/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3580 - accuracy: 0.0000e+00 - val_loss: 0.3892 - val_accuracy: 0.0000e+00\n",
            "Epoch 2789/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3627 - accuracy: 0.0000e+00 - val_loss: 0.3891 - val_accuracy: 0.0000e+00\n",
            "Epoch 2790/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3569 - accuracy: 0.0000e+00 - val_loss: 0.3891 - val_accuracy: 0.0000e+00\n",
            "Epoch 2791/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3572 - accuracy: 0.0000e+00 - val_loss: 0.3891 - val_accuracy: 0.0000e+00\n",
            "Epoch 2792/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3618 - accuracy: 0.0000e+00 - val_loss: 0.3892 - val_accuracy: 0.0000e+00\n",
            "Epoch 2793/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3577 - accuracy: 0.0000e+00 - val_loss: 0.3892 - val_accuracy: 0.0000e+00\n",
            "Epoch 2794/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3557 - accuracy: 0.0000e+00 - val_loss: 0.3891 - val_accuracy: 0.0000e+00\n",
            "Epoch 2795/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3482 - accuracy: 0.0000e+00 - val_loss: 0.3891 - val_accuracy: 0.0000e+00\n",
            "Epoch 2796/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3543 - accuracy: 0.0000e+00 - val_loss: 0.3890 - val_accuracy: 0.0000e+00\n",
            "Epoch 2797/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3559 - accuracy: 0.0000e+00 - val_loss: 0.3890 - val_accuracy: 0.0000e+00\n",
            "Epoch 2798/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3553 - accuracy: 0.0000e+00 - val_loss: 0.3890 - val_accuracy: 0.0000e+00\n",
            "Epoch 2799/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3542 - accuracy: 0.0000e+00 - val_loss: 0.3890 - val_accuracy: 0.0000e+00\n",
            "Epoch 2800/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3664 - accuracy: 0.0000e+00 - val_loss: 0.3889 - val_accuracy: 0.0000e+00\n",
            "Epoch 2801/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3569 - accuracy: 0.0000e+00 - val_loss: 0.3889 - val_accuracy: 0.0000e+00\n",
            "Epoch 2802/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3587 - accuracy: 0.0000e+00 - val_loss: 0.3888 - val_accuracy: 0.0000e+00\n",
            "Epoch 2803/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3597 - accuracy: 0.0000e+00 - val_loss: 0.3887 - val_accuracy: 0.0000e+00\n",
            "Epoch 2804/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3639 - accuracy: 0.0000e+00 - val_loss: 0.3888 - val_accuracy: 0.0000e+00\n",
            "Epoch 2805/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3573 - accuracy: 0.0000e+00 - val_loss: 0.3886 - val_accuracy: 0.0000e+00\n",
            "Epoch 2806/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3615 - accuracy: 0.0000e+00 - val_loss: 0.3887 - val_accuracy: 0.0000e+00\n",
            "Epoch 2807/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3536 - accuracy: 0.0000e+00 - val_loss: 0.3886 - val_accuracy: 0.0000e+00\n",
            "Epoch 2808/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3568 - accuracy: 0.0000e+00 - val_loss: 0.3885 - val_accuracy: 0.0000e+00\n",
            "Epoch 2809/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3600 - accuracy: 0.0000e+00 - val_loss: 0.3884 - val_accuracy: 0.0000e+00\n",
            "Epoch 2810/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3621 - accuracy: 0.0000e+00 - val_loss: 0.3884 - val_accuracy: 0.0000e+00\n",
            "Epoch 2811/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3611 - accuracy: 0.0000e+00 - val_loss: 0.3884 - val_accuracy: 0.0000e+00\n",
            "Epoch 2812/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3584 - accuracy: 0.0000e+00 - val_loss: 0.3883 - val_accuracy: 0.0000e+00\n",
            "Epoch 2813/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3513 - accuracy: 0.0000e+00 - val_loss: 0.3884 - val_accuracy: 0.0000e+00\n",
            "Epoch 2814/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3539 - accuracy: 0.0000e+00 - val_loss: 0.3883 - val_accuracy: 0.0000e+00\n",
            "Epoch 2815/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3627 - accuracy: 0.0000e+00 - val_loss: 0.3883 - val_accuracy: 0.0000e+00\n",
            "Epoch 2816/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3571 - accuracy: 0.0000e+00 - val_loss: 0.3883 - val_accuracy: 0.0000e+00\n",
            "Epoch 2817/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3568 - accuracy: 0.0000e+00 - val_loss: 0.3884 - val_accuracy: 0.0000e+00\n",
            "Epoch 2818/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3551 - accuracy: 0.0000e+00 - val_loss: 0.3883 - val_accuracy: 0.0000e+00\n",
            "Epoch 2819/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3601 - accuracy: 0.0000e+00 - val_loss: 0.3884 - val_accuracy: 0.0000e+00\n",
            "Epoch 2820/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3600 - accuracy: 0.0000e+00 - val_loss: 0.3883 - val_accuracy: 0.0000e+00\n",
            "Epoch 2821/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3591 - accuracy: 0.0000e+00 - val_loss: 0.3884 - val_accuracy: 0.0000e+00\n",
            "Epoch 2822/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3639 - accuracy: 0.0000e+00 - val_loss: 0.3883 - val_accuracy: 0.0000e+00\n",
            "Epoch 2823/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3586 - accuracy: 0.0000e+00 - val_loss: 0.3883 - val_accuracy: 0.0000e+00\n",
            "Epoch 2824/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3546 - accuracy: 0.0000e+00 - val_loss: 0.3882 - val_accuracy: 0.0000e+00\n",
            "Epoch 2825/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3628 - accuracy: 0.0000e+00 - val_loss: 0.3882 - val_accuracy: 0.0000e+00\n",
            "Epoch 2826/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3587 - accuracy: 0.0000e+00 - val_loss: 0.3880 - val_accuracy: 0.0000e+00\n",
            "Epoch 2827/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3610 - accuracy: 0.0000e+00 - val_loss: 0.3879 - val_accuracy: 0.0000e+00\n",
            "Epoch 2828/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3550 - accuracy: 0.0000e+00 - val_loss: 0.3879 - val_accuracy: 0.0000e+00\n",
            "Epoch 2829/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3523 - accuracy: 0.0000e+00 - val_loss: 0.3878 - val_accuracy: 0.0000e+00\n",
            "Epoch 2830/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3539 - accuracy: 0.0000e+00 - val_loss: 0.3878 - val_accuracy: 0.0000e+00\n",
            "Epoch 2831/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3598 - accuracy: 0.0000e+00 - val_loss: 0.3878 - val_accuracy: 0.0000e+00\n",
            "Epoch 2832/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3500 - accuracy: 0.0000e+00 - val_loss: 0.3878 - val_accuracy: 0.0000e+00\n",
            "Epoch 2833/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3651 - accuracy: 0.0000e+00 - val_loss: 0.3878 - val_accuracy: 0.0000e+00\n",
            "Epoch 2834/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3607 - accuracy: 0.0000e+00 - val_loss: 0.3878 - val_accuracy: 0.0000e+00\n",
            "Epoch 2835/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3514 - accuracy: 0.0000e+00 - val_loss: 0.3878 - val_accuracy: 0.0000e+00\n",
            "Epoch 2836/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3618 - accuracy: 0.0000e+00 - val_loss: 0.3878 - val_accuracy: 0.0000e+00\n",
            "Epoch 2837/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3572 - accuracy: 0.0000e+00 - val_loss: 0.3878 - val_accuracy: 0.0000e+00\n",
            "Epoch 2838/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3596 - accuracy: 0.0000e+00 - val_loss: 0.3879 - val_accuracy: 0.0000e+00\n",
            "Epoch 2839/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3670 - accuracy: 0.0000e+00 - val_loss: 0.3878 - val_accuracy: 0.0000e+00\n",
            "Epoch 2840/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3458 - accuracy: 0.0000e+00 - val_loss: 0.3878 - val_accuracy: 0.0000e+00\n",
            "Epoch 2841/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3589 - accuracy: 0.0000e+00 - val_loss: 0.3878 - val_accuracy: 0.0000e+00\n",
            "Epoch 2842/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3582 - accuracy: 0.0000e+00 - val_loss: 0.3878 - val_accuracy: 0.0000e+00\n",
            "Epoch 2843/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3602 - accuracy: 0.0000e+00 - val_loss: 0.3878 - val_accuracy: 0.0000e+00\n",
            "Epoch 2844/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3635 - accuracy: 0.0000e+00 - val_loss: 0.3877 - val_accuracy: 0.0000e+00\n",
            "Epoch 2845/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3564 - accuracy: 0.0000e+00 - val_loss: 0.3877 - val_accuracy: 0.0000e+00\n",
            "Epoch 2846/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3575 - accuracy: 0.0000e+00 - val_loss: 0.3877 - val_accuracy: 0.0000e+00\n",
            "Epoch 2847/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3582 - accuracy: 0.0000e+00 - val_loss: 0.3876 - val_accuracy: 0.0000e+00\n",
            "Epoch 2848/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3552 - accuracy: 0.0000e+00 - val_loss: 0.3876 - val_accuracy: 0.0000e+00\n",
            "Epoch 2849/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3675 - accuracy: 0.0000e+00 - val_loss: 0.3875 - val_accuracy: 0.0000e+00\n",
            "Epoch 2850/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3605 - accuracy: 0.0000e+00 - val_loss: 0.3874 - val_accuracy: 0.0000e+00\n",
            "Epoch 2851/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3643 - accuracy: 0.0000e+00 - val_loss: 0.3875 - val_accuracy: 0.0000e+00\n",
            "Epoch 2852/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3532 - accuracy: 0.0000e+00 - val_loss: 0.3875 - val_accuracy: 0.0000e+00\n",
            "Epoch 2853/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3530 - accuracy: 0.0000e+00 - val_loss: 0.3874 - val_accuracy: 0.0000e+00\n",
            "Epoch 2854/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3607 - accuracy: 0.0000e+00 - val_loss: 0.3873 - val_accuracy: 0.0000e+00\n",
            "Epoch 2855/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3717 - accuracy: 0.0000e+00 - val_loss: 0.3872 - val_accuracy: 0.0000e+00\n",
            "Epoch 2856/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3527 - accuracy: 0.0000e+00 - val_loss: 0.3872 - val_accuracy: 0.0000e+00\n",
            "Epoch 2857/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3593 - accuracy: 0.0000e+00 - val_loss: 0.3872 - val_accuracy: 0.0000e+00\n",
            "Epoch 2858/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3651 - accuracy: 0.0000e+00 - val_loss: 0.3871 - val_accuracy: 0.0000e+00\n",
            "Epoch 2859/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3599 - accuracy: 0.0000e+00 - val_loss: 0.3871 - val_accuracy: 0.0000e+00\n",
            "Epoch 2860/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3576 - accuracy: 0.0000e+00 - val_loss: 0.3870 - val_accuracy: 0.0000e+00\n",
            "Epoch 2861/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3511 - accuracy: 0.0000e+00 - val_loss: 0.3870 - val_accuracy: 0.0000e+00\n",
            "Epoch 2862/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3571 - accuracy: 0.0000e+00 - val_loss: 0.3870 - val_accuracy: 0.0000e+00\n",
            "Epoch 2863/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3606 - accuracy: 0.0000e+00 - val_loss: 0.3870 - val_accuracy: 0.0000e+00\n",
            "Epoch 2864/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3438 - accuracy: 0.0000e+00 - val_loss: 0.3870 - val_accuracy: 0.0000e+00\n",
            "Epoch 2865/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3584 - accuracy: 0.0000e+00 - val_loss: 0.3869 - val_accuracy: 0.0000e+00\n",
            "Epoch 2866/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3528 - accuracy: 0.0000e+00 - val_loss: 0.3868 - val_accuracy: 0.0000e+00\n",
            "Epoch 2867/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3577 - accuracy: 0.0000e+00 - val_loss: 0.3867 - val_accuracy: 0.0000e+00\n",
            "Epoch 2868/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3590 - accuracy: 0.0000e+00 - val_loss: 0.3867 - val_accuracy: 0.0000e+00\n",
            "Epoch 2869/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3510 - accuracy: 0.0000e+00 - val_loss: 0.3866 - val_accuracy: 0.0000e+00\n",
            "Epoch 2870/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3548 - accuracy: 0.0000e+00 - val_loss: 0.3866 - val_accuracy: 0.0000e+00\n",
            "Epoch 2871/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3590 - accuracy: 0.0000e+00 - val_loss: 0.3866 - val_accuracy: 0.0000e+00\n",
            "Epoch 2872/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3598 - accuracy: 0.0000e+00 - val_loss: 0.3866 - val_accuracy: 0.0000e+00\n",
            "Epoch 2873/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3590 - accuracy: 0.0000e+00 - val_loss: 0.3866 - val_accuracy: 0.0000e+00\n",
            "Epoch 2874/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3541 - accuracy: 0.0000e+00 - val_loss: 0.3865 - val_accuracy: 0.0000e+00\n",
            "Epoch 2875/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3597 - accuracy: 0.0000e+00 - val_loss: 0.3865 - val_accuracy: 0.0000e+00\n",
            "Epoch 2876/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3532 - accuracy: 0.0000e+00 - val_loss: 0.3865 - val_accuracy: 0.0000e+00\n",
            "Epoch 2877/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3498 - accuracy: 0.0000e+00 - val_loss: 0.3864 - val_accuracy: 0.0000e+00\n",
            "Epoch 2878/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3608 - accuracy: 0.0000e+00 - val_loss: 0.3864 - val_accuracy: 0.0000e+00\n",
            "Epoch 2879/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3605 - accuracy: 0.0000e+00 - val_loss: 0.3863 - val_accuracy: 0.0000e+00\n",
            "Epoch 2880/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3521 - accuracy: 0.0000e+00 - val_loss: 0.3863 - val_accuracy: 0.0000e+00\n",
            "Epoch 2881/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3560 - accuracy: 0.0000e+00 - val_loss: 0.3862 - val_accuracy: 0.0000e+00\n",
            "Epoch 2882/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3489 - accuracy: 0.0000e+00 - val_loss: 0.3862 - val_accuracy: 0.0000e+00\n",
            "Epoch 2883/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3517 - accuracy: 0.0000e+00 - val_loss: 0.3862 - val_accuracy: 0.0000e+00\n",
            "Epoch 2884/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3536 - accuracy: 0.0000e+00 - val_loss: 0.3862 - val_accuracy: 0.0000e+00\n",
            "Epoch 2885/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3605 - accuracy: 0.0000e+00 - val_loss: 0.3862 - val_accuracy: 0.0000e+00\n",
            "Epoch 2886/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3616 - accuracy: 0.0000e+00 - val_loss: 0.3862 - val_accuracy: 0.0000e+00\n",
            "Epoch 2887/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3464 - accuracy: 0.0000e+00 - val_loss: 0.3861 - val_accuracy: 0.0000e+00\n",
            "Epoch 2888/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3552 - accuracy: 0.0000e+00 - val_loss: 0.3861 - val_accuracy: 0.0000e+00\n",
            "Epoch 2889/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3573 - accuracy: 0.0000e+00 - val_loss: 0.3861 - val_accuracy: 0.0000e+00\n",
            "Epoch 2890/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3559 - accuracy: 0.0000e+00 - val_loss: 0.3861 - val_accuracy: 0.0000e+00\n",
            "Epoch 2891/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3528 - accuracy: 0.0000e+00 - val_loss: 0.3861 - val_accuracy: 0.0000e+00\n",
            "Epoch 2892/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3543 - accuracy: 0.0000e+00 - val_loss: 0.3861 - val_accuracy: 0.0000e+00\n",
            "Epoch 2893/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3623 - accuracy: 0.0000e+00 - val_loss: 0.3862 - val_accuracy: 0.0000e+00\n",
            "Epoch 2894/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3677 - accuracy: 0.0000e+00 - val_loss: 0.3862 - val_accuracy: 0.0000e+00\n",
            "Epoch 2895/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3571 - accuracy: 0.0000e+00 - val_loss: 0.3860 - val_accuracy: 0.0000e+00\n",
            "Epoch 2896/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3530 - accuracy: 0.0000e+00 - val_loss: 0.3860 - val_accuracy: 0.0000e+00\n",
            "Epoch 2897/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3578 - accuracy: 0.0000e+00 - val_loss: 0.3859 - val_accuracy: 0.0000e+00\n",
            "Epoch 2898/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3527 - accuracy: 0.0000e+00 - val_loss: 0.3858 - val_accuracy: 0.0000e+00\n",
            "Epoch 2899/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3528 - accuracy: 0.0000e+00 - val_loss: 0.3858 - val_accuracy: 0.0000e+00\n",
            "Epoch 2900/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3562 - accuracy: 0.0000e+00 - val_loss: 0.3858 - val_accuracy: 0.0000e+00\n",
            "Epoch 2901/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3540 - accuracy: 0.0000e+00 - val_loss: 0.3857 - val_accuracy: 0.0000e+00\n",
            "Epoch 2902/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3505 - accuracy: 0.0000e+00 - val_loss: 0.3857 - val_accuracy: 0.0000e+00\n",
            "Epoch 2903/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3584 - accuracy: 0.0000e+00 - val_loss: 0.3857 - val_accuracy: 0.0000e+00\n",
            "Epoch 2904/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3535 - accuracy: 0.0000e+00 - val_loss: 0.3857 - val_accuracy: 0.0000e+00\n",
            "Epoch 2905/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3671 - accuracy: 0.0000e+00 - val_loss: 0.3857 - val_accuracy: 0.0000e+00\n",
            "Epoch 2906/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3556 - accuracy: 0.0000e+00 - val_loss: 0.3856 - val_accuracy: 0.0000e+00\n",
            "Epoch 2907/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3460 - accuracy: 0.0000e+00 - val_loss: 0.3855 - val_accuracy: 0.0000e+00\n",
            "Epoch 2908/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3541 - accuracy: 0.0000e+00 - val_loss: 0.3855 - val_accuracy: 0.0000e+00\n",
            "Epoch 2909/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3531 - accuracy: 0.0000e+00 - val_loss: 0.3854 - val_accuracy: 0.0000e+00\n",
            "Epoch 2910/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3604 - accuracy: 0.0000e+00 - val_loss: 0.3854 - val_accuracy: 0.0000e+00\n",
            "Epoch 2911/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3743 - accuracy: 0.0000e+00 - val_loss: 0.3854 - val_accuracy: 0.0000e+00\n",
            "Epoch 2912/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3644 - accuracy: 0.0000e+00 - val_loss: 0.3853 - val_accuracy: 0.0000e+00\n",
            "Epoch 2913/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3507 - accuracy: 0.0000e+00 - val_loss: 0.3853 - val_accuracy: 0.0000e+00\n",
            "Epoch 2914/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3514 - accuracy: 0.0000e+00 - val_loss: 0.3852 - val_accuracy: 0.0000e+00\n",
            "Epoch 2915/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3460 - accuracy: 0.0000e+00 - val_loss: 0.3852 - val_accuracy: 0.0000e+00\n",
            "Epoch 2916/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3502 - accuracy: 0.0000e+00 - val_loss: 0.3852 - val_accuracy: 0.0000e+00\n",
            "Epoch 2917/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3520 - accuracy: 0.0000e+00 - val_loss: 0.3851 - val_accuracy: 0.0000e+00\n",
            "Epoch 2918/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3504 - accuracy: 0.0000e+00 - val_loss: 0.3850 - val_accuracy: 0.0000e+00\n",
            "Epoch 2919/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3606 - accuracy: 0.0000e+00 - val_loss: 0.3849 - val_accuracy: 0.0000e+00\n",
            "Epoch 2920/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3590 - accuracy: 0.0000e+00 - val_loss: 0.3849 - val_accuracy: 0.0000e+00\n",
            "Epoch 2921/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3542 - accuracy: 0.0000e+00 - val_loss: 0.3849 - val_accuracy: 0.0000e+00\n",
            "Epoch 2922/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3572 - accuracy: 0.0000e+00 - val_loss: 0.3848 - val_accuracy: 0.0000e+00\n",
            "Epoch 2923/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3457 - accuracy: 0.0000e+00 - val_loss: 0.3848 - val_accuracy: 0.0000e+00\n",
            "Epoch 2924/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3591 - accuracy: 0.0000e+00 - val_loss: 0.3848 - val_accuracy: 0.0000e+00\n",
            "Epoch 2925/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3490 - accuracy: 0.0000e+00 - val_loss: 0.3848 - val_accuracy: 0.0000e+00\n",
            "Epoch 2926/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3561 - accuracy: 0.0000e+00 - val_loss: 0.3847 - val_accuracy: 0.0000e+00\n",
            "Epoch 2927/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3619 - accuracy: 0.0000e+00 - val_loss: 0.3847 - val_accuracy: 0.0000e+00\n",
            "Epoch 2928/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3556 - accuracy: 0.0000e+00 - val_loss: 0.3846 - val_accuracy: 0.0000e+00\n",
            "Epoch 2929/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3514 - accuracy: 0.0000e+00 - val_loss: 0.3846 - val_accuracy: 0.0000e+00\n",
            "Epoch 2930/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3533 - accuracy: 0.0000e+00 - val_loss: 0.3846 - val_accuracy: 0.0000e+00\n",
            "Epoch 2931/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3525 - accuracy: 0.0000e+00 - val_loss: 0.3845 - val_accuracy: 0.0000e+00\n",
            "Epoch 2932/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3534 - accuracy: 0.0000e+00 - val_loss: 0.3844 - val_accuracy: 0.0000e+00\n",
            "Epoch 2933/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3548 - accuracy: 0.0000e+00 - val_loss: 0.3844 - val_accuracy: 0.0000e+00\n",
            "Epoch 2934/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3508 - accuracy: 0.0000e+00 - val_loss: 0.3843 - val_accuracy: 0.0000e+00\n",
            "Epoch 2935/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3562 - accuracy: 0.0000e+00 - val_loss: 0.3844 - val_accuracy: 0.0000e+00\n",
            "Epoch 2936/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3568 - accuracy: 0.0000e+00 - val_loss: 0.3843 - val_accuracy: 0.0000e+00\n",
            "Epoch 2937/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3495 - accuracy: 0.0000e+00 - val_loss: 0.3842 - val_accuracy: 0.0000e+00\n",
            "Epoch 2938/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3530 - accuracy: 0.0000e+00 - val_loss: 0.3841 - val_accuracy: 0.0000e+00\n",
            "Epoch 2939/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3590 - accuracy: 0.0000e+00 - val_loss: 0.3841 - val_accuracy: 0.0000e+00\n",
            "Epoch 2940/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3533 - accuracy: 0.0000e+00 - val_loss: 0.3842 - val_accuracy: 0.0000e+00\n",
            "Epoch 2941/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3485 - accuracy: 0.0000e+00 - val_loss: 0.3841 - val_accuracy: 0.0000e+00\n",
            "Epoch 2942/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3568 - accuracy: 0.0000e+00 - val_loss: 0.3840 - val_accuracy: 0.0000e+00\n",
            "Epoch 2943/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3549 - accuracy: 0.0000e+00 - val_loss: 0.3840 - val_accuracy: 0.0000e+00\n",
            "Epoch 2944/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3626 - accuracy: 0.0000e+00 - val_loss: 0.3840 - val_accuracy: 0.0000e+00\n",
            "Epoch 2945/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3569 - accuracy: 0.0000e+00 - val_loss: 0.3840 - val_accuracy: 0.0000e+00\n",
            "Epoch 2946/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3645 - accuracy: 0.0000e+00 - val_loss: 0.3840 - val_accuracy: 0.0000e+00\n",
            "Epoch 2947/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3590 - accuracy: 0.0000e+00 - val_loss: 0.3841 - val_accuracy: 0.0000e+00\n",
            "Epoch 2948/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3559 - accuracy: 0.0000e+00 - val_loss: 0.3841 - val_accuracy: 0.0000e+00\n",
            "Epoch 2949/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3569 - accuracy: 0.0000e+00 - val_loss: 0.3840 - val_accuracy: 0.0000e+00\n",
            "Epoch 2950/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3542 - accuracy: 0.0000e+00 - val_loss: 0.3841 - val_accuracy: 0.0000e+00\n",
            "Epoch 2951/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3571 - accuracy: 0.0000e+00 - val_loss: 0.3840 - val_accuracy: 0.0000e+00\n",
            "Epoch 2952/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3547 - accuracy: 0.0000e+00 - val_loss: 0.3840 - val_accuracy: 0.0000e+00\n",
            "Epoch 2953/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3548 - accuracy: 0.0000e+00 - val_loss: 0.3840 - val_accuracy: 0.0000e+00\n",
            "Epoch 2954/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3521 - accuracy: 0.0000e+00 - val_loss: 0.3840 - val_accuracy: 0.0000e+00\n",
            "Epoch 2955/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3512 - accuracy: 0.0000e+00 - val_loss: 0.3839 - val_accuracy: 0.0000e+00\n",
            "Epoch 2956/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3579 - accuracy: 0.0000e+00 - val_loss: 0.3839 - val_accuracy: 0.0000e+00\n",
            "Epoch 2957/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3491 - accuracy: 0.0000e+00 - val_loss: 0.3839 - val_accuracy: 0.0000e+00\n",
            "Epoch 2958/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3589 - accuracy: 0.0000e+00 - val_loss: 0.3838 - val_accuracy: 0.0000e+00\n",
            "Epoch 2959/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3532 - accuracy: 0.0000e+00 - val_loss: 0.3838 - val_accuracy: 0.0000e+00\n",
            "Epoch 2960/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3569 - accuracy: 0.0000e+00 - val_loss: 0.3838 - val_accuracy: 0.0000e+00\n",
            "Epoch 2961/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3486 - accuracy: 0.0000e+00 - val_loss: 0.3838 - val_accuracy: 0.0000e+00\n",
            "Epoch 2962/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3565 - accuracy: 0.0000e+00 - val_loss: 0.3838 - val_accuracy: 0.0000e+00\n",
            "Epoch 2963/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3508 - accuracy: 0.0000e+00 - val_loss: 0.3838 - val_accuracy: 0.0000e+00\n",
            "Epoch 2964/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3566 - accuracy: 0.0000e+00 - val_loss: 0.3838 - val_accuracy: 0.0000e+00\n",
            "Epoch 2965/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3551 - accuracy: 0.0000e+00 - val_loss: 0.3838 - val_accuracy: 0.0000e+00\n",
            "Epoch 2966/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3555 - accuracy: 0.0000e+00 - val_loss: 0.3837 - val_accuracy: 0.0000e+00\n",
            "Epoch 2967/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3534 - accuracy: 0.0000e+00 - val_loss: 0.3838 - val_accuracy: 0.0000e+00\n",
            "Epoch 2968/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3412 - accuracy: 0.0000e+00 - val_loss: 0.3837 - val_accuracy: 0.0000e+00\n",
            "Epoch 2969/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3526 - accuracy: 0.0000e+00 - val_loss: 0.3837 - val_accuracy: 0.0000e+00\n",
            "Epoch 2970/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3484 - accuracy: 0.0000e+00 - val_loss: 0.3836 - val_accuracy: 0.0000e+00\n",
            "Epoch 2971/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3534 - accuracy: 0.0000e+00 - val_loss: 0.3837 - val_accuracy: 0.0000e+00\n",
            "Epoch 2972/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3494 - accuracy: 0.0000e+00 - val_loss: 0.3836 - val_accuracy: 0.0000e+00\n",
            "Epoch 2973/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3642 - accuracy: 0.0000e+00 - val_loss: 0.3836 - val_accuracy: 0.0000e+00\n",
            "Epoch 2974/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3457 - accuracy: 0.0000e+00 - val_loss: 0.3835 - val_accuracy: 0.0000e+00\n",
            "Epoch 2975/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3507 - accuracy: 0.0000e+00 - val_loss: 0.3835 - val_accuracy: 0.0000e+00\n",
            "Epoch 2976/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3545 - accuracy: 0.0000e+00 - val_loss: 0.3834 - val_accuracy: 0.0000e+00\n",
            "Epoch 2977/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3554 - accuracy: 0.0000e+00 - val_loss: 0.3834 - val_accuracy: 0.0000e+00\n",
            "Epoch 2978/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3512 - accuracy: 0.0000e+00 - val_loss: 0.3833 - val_accuracy: 0.0000e+00\n",
            "Epoch 2979/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3574 - accuracy: 0.0000e+00 - val_loss: 0.3832 - val_accuracy: 0.0000e+00\n",
            "Epoch 2980/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3476 - accuracy: 0.0000e+00 - val_loss: 0.3832 - val_accuracy: 0.0000e+00\n",
            "Epoch 2981/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3475 - accuracy: 0.0000e+00 - val_loss: 0.3832 - val_accuracy: 0.0000e+00\n",
            "Epoch 2982/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3548 - accuracy: 0.0000e+00 - val_loss: 0.3832 - val_accuracy: 0.0000e+00\n",
            "Epoch 2983/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3490 - accuracy: 0.0000e+00 - val_loss: 0.3832 - val_accuracy: 0.0000e+00\n",
            "Epoch 2984/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3600 - accuracy: 0.0000e+00 - val_loss: 0.3832 - val_accuracy: 0.0000e+00\n",
            "Epoch 2985/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3476 - accuracy: 0.0000e+00 - val_loss: 0.3832 - val_accuracy: 0.0000e+00\n",
            "Epoch 2986/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3566 - accuracy: 0.0000e+00 - val_loss: 0.3831 - val_accuracy: 0.0000e+00\n",
            "Epoch 2987/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3556 - accuracy: 0.0000e+00 - val_loss: 0.3831 - val_accuracy: 0.0000e+00\n",
            "Epoch 2988/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3597 - accuracy: 0.0000e+00 - val_loss: 0.3831 - val_accuracy: 0.0000e+00\n",
            "Epoch 2989/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3577 - accuracy: 0.0000e+00 - val_loss: 0.3831 - val_accuracy: 0.0000e+00\n",
            "Epoch 2990/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3539 - accuracy: 0.0000e+00 - val_loss: 0.3830 - val_accuracy: 0.0000e+00\n",
            "Epoch 2991/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3644 - accuracy: 0.0000e+00 - val_loss: 0.3831 - val_accuracy: 0.0000e+00\n",
            "Epoch 2992/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3524 - accuracy: 0.0000e+00 - val_loss: 0.3830 - val_accuracy: 0.0000e+00\n",
            "Epoch 2993/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3480 - accuracy: 0.0000e+00 - val_loss: 0.3830 - val_accuracy: 0.0000e+00\n",
            "Epoch 2994/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3511 - accuracy: 0.0000e+00 - val_loss: 0.3829 - val_accuracy: 0.0000e+00\n",
            "Epoch 2995/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3500 - accuracy: 0.0000e+00 - val_loss: 0.3829 - val_accuracy: 0.0000e+00\n",
            "Epoch 2996/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3483 - accuracy: 0.0000e+00 - val_loss: 0.3828 - val_accuracy: 0.0000e+00\n",
            "Epoch 2997/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3542 - accuracy: 0.0000e+00 - val_loss: 0.3827 - val_accuracy: 0.0000e+00\n",
            "Epoch 2998/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3565 - accuracy: 0.0000e+00 - val_loss: 0.3826 - val_accuracy: 0.0000e+00\n",
            "Epoch 2999/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3602 - accuracy: 0.0000e+00 - val_loss: 0.3826 - val_accuracy: 0.0000e+00\n",
            "Epoch 3000/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3549 - accuracy: 0.0000e+00 - val_loss: 0.3826 - val_accuracy: 0.0000e+00\n",
            "Epoch 3001/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3478 - accuracy: 0.0000e+00 - val_loss: 0.3825 - val_accuracy: 0.0000e+00\n",
            "Epoch 3002/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3513 - accuracy: 0.0000e+00 - val_loss: 0.3825 - val_accuracy: 0.0000e+00\n",
            "Epoch 3003/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3530 - accuracy: 0.0000e+00 - val_loss: 0.3826 - val_accuracy: 0.0000e+00\n",
            "Epoch 3004/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3575 - accuracy: 0.0000e+00 - val_loss: 0.3825 - val_accuracy: 0.0000e+00\n",
            "Epoch 3005/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3523 - accuracy: 0.0000e+00 - val_loss: 0.3826 - val_accuracy: 0.0000e+00\n",
            "Epoch 3006/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3458 - accuracy: 0.0000e+00 - val_loss: 0.3826 - val_accuracy: 0.0000e+00\n",
            "Epoch 3007/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3501 - accuracy: 0.0000e+00 - val_loss: 0.3826 - val_accuracy: 0.0000e+00\n",
            "Epoch 3008/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3561 - accuracy: 0.0000e+00 - val_loss: 0.3827 - val_accuracy: 0.0000e+00\n",
            "Epoch 3009/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3507 - accuracy: 0.0000e+00 - val_loss: 0.3827 - val_accuracy: 0.0000e+00\n",
            "Epoch 3010/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3645 - accuracy: 0.0000e+00 - val_loss: 0.3826 - val_accuracy: 0.0000e+00\n",
            "Epoch 3011/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3500 - accuracy: 0.0000e+00 - val_loss: 0.3824 - val_accuracy: 0.0000e+00\n",
            "Epoch 3012/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3535 - accuracy: 0.0000e+00 - val_loss: 0.3824 - val_accuracy: 0.0000e+00\n",
            "Epoch 3013/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3508 - accuracy: 0.0000e+00 - val_loss: 0.3824 - val_accuracy: 0.0000e+00\n",
            "Epoch 3014/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3512 - accuracy: 0.0000e+00 - val_loss: 0.3824 - val_accuracy: 0.0000e+00\n",
            "Epoch 3015/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3579 - accuracy: 0.0000e+00 - val_loss: 0.3823 - val_accuracy: 0.0000e+00\n",
            "Epoch 3016/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3542 - accuracy: 0.0000e+00 - val_loss: 0.3821 - val_accuracy: 0.0000e+00\n",
            "Epoch 3017/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3495 - accuracy: 0.0000e+00 - val_loss: 0.3820 - val_accuracy: 0.0000e+00\n",
            "Epoch 3018/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3545 - accuracy: 0.0000e+00 - val_loss: 0.3820 - val_accuracy: 0.0000e+00\n",
            "Epoch 3019/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3563 - accuracy: 0.0000e+00 - val_loss: 0.3821 - val_accuracy: 0.0000e+00\n",
            "Epoch 3020/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3473 - accuracy: 0.0000e+00 - val_loss: 0.3821 - val_accuracy: 0.0000e+00\n",
            "Epoch 3021/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3571 - accuracy: 0.0000e+00 - val_loss: 0.3821 - val_accuracy: 0.0000e+00\n",
            "Epoch 3022/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3533 - accuracy: 0.0000e+00 - val_loss: 0.3821 - val_accuracy: 0.0000e+00\n",
            "Epoch 3023/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3537 - accuracy: 0.0000e+00 - val_loss: 0.3820 - val_accuracy: 0.0000e+00\n",
            "Epoch 3024/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3423 - accuracy: 0.0000e+00 - val_loss: 0.3820 - val_accuracy: 0.0000e+00\n",
            "Epoch 3025/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3469 - accuracy: 0.0000e+00 - val_loss: 0.3820 - val_accuracy: 0.0000e+00\n",
            "Epoch 3026/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3533 - accuracy: 0.0000e+00 - val_loss: 0.3820 - val_accuracy: 0.0000e+00\n",
            "Epoch 3027/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3471 - accuracy: 0.0000e+00 - val_loss: 0.3820 - val_accuracy: 0.0000e+00\n",
            "Epoch 3028/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3468 - accuracy: 0.0000e+00 - val_loss: 0.3819 - val_accuracy: 0.0000e+00\n",
            "Epoch 3029/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3534 - accuracy: 0.0000e+00 - val_loss: 0.3819 - val_accuracy: 0.0000e+00\n",
            "Epoch 3030/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3486 - accuracy: 0.0000e+00 - val_loss: 0.3819 - val_accuracy: 0.0000e+00\n",
            "Epoch 3031/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3537 - accuracy: 0.0000e+00 - val_loss: 0.3819 - val_accuracy: 0.0000e+00\n",
            "Epoch 3032/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3554 - accuracy: 0.0000e+00 - val_loss: 0.3818 - val_accuracy: 0.0000e+00\n",
            "Epoch 3033/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3596 - accuracy: 0.0000e+00 - val_loss: 0.3817 - val_accuracy: 0.0000e+00\n",
            "Epoch 3034/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3655 - accuracy: 0.0000e+00 - val_loss: 0.3817 - val_accuracy: 0.0000e+00\n",
            "Epoch 3035/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3513 - accuracy: 0.0000e+00 - val_loss: 0.3816 - val_accuracy: 0.0000e+00\n",
            "Epoch 3036/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3529 - accuracy: 0.0000e+00 - val_loss: 0.3816 - val_accuracy: 0.0000e+00\n",
            "Epoch 3037/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3562 - accuracy: 0.0000e+00 - val_loss: 0.3816 - val_accuracy: 0.0000e+00\n",
            "Epoch 3038/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3438 - accuracy: 0.0000e+00 - val_loss: 0.3815 - val_accuracy: 0.0000e+00\n",
            "Epoch 3039/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3563 - accuracy: 0.0000e+00 - val_loss: 0.3815 - val_accuracy: 0.0000e+00\n",
            "Epoch 3040/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3568 - accuracy: 0.0000e+00 - val_loss: 0.3815 - val_accuracy: 0.0000e+00\n",
            "Epoch 3041/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3539 - accuracy: 0.0000e+00 - val_loss: 0.3814 - val_accuracy: 0.0000e+00\n",
            "Epoch 3042/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3585 - accuracy: 0.0000e+00 - val_loss: 0.3814 - val_accuracy: 0.0000e+00\n",
            "Epoch 3043/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3534 - accuracy: 0.0000e+00 - val_loss: 0.3813 - val_accuracy: 0.0000e+00\n",
            "Epoch 3044/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3459 - accuracy: 0.0000e+00 - val_loss: 0.3813 - val_accuracy: 0.0000e+00\n",
            "Epoch 3045/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3510 - accuracy: 0.0000e+00 - val_loss: 0.3813 - val_accuracy: 0.0000e+00\n",
            "Epoch 3046/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3612 - accuracy: 0.0000e+00 - val_loss: 0.3813 - val_accuracy: 0.0000e+00\n",
            "Epoch 3047/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3521 - accuracy: 0.0000e+00 - val_loss: 0.3812 - val_accuracy: 0.0000e+00\n",
            "Epoch 3048/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3593 - accuracy: 0.0000e+00 - val_loss: 0.3813 - val_accuracy: 0.0000e+00\n",
            "Epoch 3049/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3512 - accuracy: 0.0000e+00 - val_loss: 0.3813 - val_accuracy: 0.0000e+00\n",
            "Epoch 3050/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3476 - accuracy: 0.0000e+00 - val_loss: 0.3813 - val_accuracy: 0.0000e+00\n",
            "Epoch 3051/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3506 - accuracy: 0.0000e+00 - val_loss: 0.3813 - val_accuracy: 0.0000e+00\n",
            "Epoch 3052/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3562 - accuracy: 0.0000e+00 - val_loss: 0.3813 - val_accuracy: 0.0000e+00\n",
            "Epoch 3053/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3489 - accuracy: 0.0000e+00 - val_loss: 0.3812 - val_accuracy: 0.0000e+00\n",
            "Epoch 3054/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3494 - accuracy: 0.0000e+00 - val_loss: 0.3812 - val_accuracy: 0.0000e+00\n",
            "Epoch 3055/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3474 - accuracy: 0.0000e+00 - val_loss: 0.3811 - val_accuracy: 0.0000e+00\n",
            "Epoch 3056/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3615 - accuracy: 0.0000e+00 - val_loss: 0.3811 - val_accuracy: 0.0000e+00\n",
            "Epoch 3057/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3483 - accuracy: 0.0000e+00 - val_loss: 0.3811 - val_accuracy: 0.0000e+00\n",
            "Epoch 3058/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3515 - accuracy: 0.0000e+00 - val_loss: 0.3811 - val_accuracy: 0.0000e+00\n",
            "Epoch 3059/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3558 - accuracy: 0.0000e+00 - val_loss: 0.3810 - val_accuracy: 0.0000e+00\n",
            "Epoch 3060/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3519 - accuracy: 0.0000e+00 - val_loss: 0.3809 - val_accuracy: 0.0000e+00\n",
            "Epoch 3061/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3468 - accuracy: 0.0000e+00 - val_loss: 0.3808 - val_accuracy: 0.0000e+00\n",
            "Epoch 3062/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3437 - accuracy: 0.0000e+00 - val_loss: 0.3809 - val_accuracy: 0.0000e+00\n",
            "Epoch 3063/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3592 - accuracy: 0.0000e+00 - val_loss: 0.3809 - val_accuracy: 0.0000e+00\n",
            "Epoch 3064/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3449 - accuracy: 0.0000e+00 - val_loss: 0.3809 - val_accuracy: 0.0000e+00\n",
            "Epoch 3065/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3493 - accuracy: 0.0000e+00 - val_loss: 0.3808 - val_accuracy: 0.0000e+00\n",
            "Epoch 3066/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3560 - accuracy: 0.0000e+00 - val_loss: 0.3808 - val_accuracy: 0.0000e+00\n",
            "Epoch 3067/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3441 - accuracy: 0.0000e+00 - val_loss: 0.3807 - val_accuracy: 0.0000e+00\n",
            "Epoch 3068/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3462 - accuracy: 0.0000e+00 - val_loss: 0.3807 - val_accuracy: 0.0000e+00\n",
            "Epoch 3069/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3489 - accuracy: 0.0000e+00 - val_loss: 0.3806 - val_accuracy: 0.0000e+00\n",
            "Epoch 3070/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3592 - accuracy: 0.0000e+00 - val_loss: 0.3806 - val_accuracy: 0.0000e+00\n",
            "Epoch 3071/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3503 - accuracy: 0.0000e+00 - val_loss: 0.3806 - val_accuracy: 0.0000e+00\n",
            "Epoch 3072/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3465 - accuracy: 0.0000e+00 - val_loss: 0.3806 - val_accuracy: 0.0000e+00\n",
            "Epoch 3073/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3503 - accuracy: 0.0000e+00 - val_loss: 0.3805 - val_accuracy: 0.0000e+00\n",
            "Epoch 3074/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3446 - accuracy: 0.0000e+00 - val_loss: 0.3805 - val_accuracy: 0.0000e+00\n",
            "Epoch 3075/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3636 - accuracy: 0.0000e+00 - val_loss: 0.3805 - val_accuracy: 0.0000e+00\n",
            "Epoch 3076/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3566 - accuracy: 0.0000e+00 - val_loss: 0.3804 - val_accuracy: 0.0000e+00\n",
            "Epoch 3077/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3502 - accuracy: 0.0000e+00 - val_loss: 0.3803 - val_accuracy: 0.0000e+00\n",
            "Epoch 3078/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3498 - accuracy: 0.0000e+00 - val_loss: 0.3802 - val_accuracy: 0.0000e+00\n",
            "Epoch 3079/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3583 - accuracy: 0.0000e+00 - val_loss: 0.3801 - val_accuracy: 0.0000e+00\n",
            "Epoch 3080/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3557 - accuracy: 0.0000e+00 - val_loss: 0.3801 - val_accuracy: 0.0000e+00\n",
            "Epoch 3081/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3528 - accuracy: 0.0000e+00 - val_loss: 0.3801 - val_accuracy: 0.0000e+00\n",
            "Epoch 3082/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3511 - accuracy: 0.0000e+00 - val_loss: 0.3800 - val_accuracy: 0.0000e+00\n",
            "Epoch 3083/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3510 - accuracy: 0.0000e+00 - val_loss: 0.3800 - val_accuracy: 0.0000e+00\n",
            "Epoch 3084/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3475 - accuracy: 0.0000e+00 - val_loss: 0.3799 - val_accuracy: 0.0000e+00\n",
            "Epoch 3085/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3589 - accuracy: 0.0000e+00 - val_loss: 0.3799 - val_accuracy: 0.0000e+00\n",
            "Epoch 3086/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3469 - accuracy: 0.0000e+00 - val_loss: 0.3800 - val_accuracy: 0.0000e+00\n",
            "Epoch 3087/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3509 - accuracy: 0.0000e+00 - val_loss: 0.3800 - val_accuracy: 0.0000e+00\n",
            "Epoch 3088/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3509 - accuracy: 0.0000e+00 - val_loss: 0.3799 - val_accuracy: 0.0000e+00\n",
            "Epoch 3089/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3493 - accuracy: 0.0000e+00 - val_loss: 0.3799 - val_accuracy: 0.0000e+00\n",
            "Epoch 3090/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3448 - accuracy: 0.0000e+00 - val_loss: 0.3798 - val_accuracy: 0.0000e+00\n",
            "Epoch 3091/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3583 - accuracy: 0.0000e+00 - val_loss: 0.3798 - val_accuracy: 0.0000e+00\n",
            "Epoch 3092/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3500 - accuracy: 0.0000e+00 - val_loss: 0.3798 - val_accuracy: 0.0000e+00\n",
            "Epoch 3093/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3568 - accuracy: 0.0000e+00 - val_loss: 0.3796 - val_accuracy: 0.0000e+00\n",
            "Epoch 3094/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3501 - accuracy: 0.0000e+00 - val_loss: 0.3796 - val_accuracy: 0.0000e+00\n",
            "Epoch 3095/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3532 - accuracy: 0.0000e+00 - val_loss: 0.3797 - val_accuracy: 0.0000e+00\n",
            "Epoch 3096/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3547 - accuracy: 0.0000e+00 - val_loss: 0.3797 - val_accuracy: 0.0000e+00\n",
            "Epoch 3097/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3469 - accuracy: 0.0000e+00 - val_loss: 0.3796 - val_accuracy: 0.0000e+00\n",
            "Epoch 3098/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3480 - accuracy: 0.0000e+00 - val_loss: 0.3795 - val_accuracy: 0.0000e+00\n",
            "Epoch 3099/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3505 - accuracy: 0.0000e+00 - val_loss: 0.3795 - val_accuracy: 0.0000e+00\n",
            "Epoch 3100/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3506 - accuracy: 0.0000e+00 - val_loss: 0.3796 - val_accuracy: 0.0000e+00\n",
            "Epoch 3101/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3443 - accuracy: 0.0000e+00 - val_loss: 0.3795 - val_accuracy: 0.0000e+00\n",
            "Epoch 3102/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3471 - accuracy: 0.0000e+00 - val_loss: 0.3795 - val_accuracy: 0.0000e+00\n",
            "Epoch 3103/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3533 - accuracy: 0.0000e+00 - val_loss: 0.3795 - val_accuracy: 0.0000e+00\n",
            "Epoch 3104/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3464 - accuracy: 0.0000e+00 - val_loss: 0.3795 - val_accuracy: 0.0000e+00\n",
            "Epoch 3105/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3488 - accuracy: 0.0000e+00 - val_loss: 0.3795 - val_accuracy: 0.0000e+00\n",
            "Epoch 3106/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3550 - accuracy: 0.0000e+00 - val_loss: 0.3795 - val_accuracy: 0.0000e+00\n",
            "Epoch 3107/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3510 - accuracy: 0.0000e+00 - val_loss: 0.3796 - val_accuracy: 0.0000e+00\n",
            "Epoch 3108/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3519 - accuracy: 0.0000e+00 - val_loss: 0.3796 - val_accuracy: 0.0000e+00\n",
            "Epoch 3109/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3557 - accuracy: 0.0000e+00 - val_loss: 0.3795 - val_accuracy: 0.0000e+00\n",
            "Epoch 3110/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3564 - accuracy: 0.0000e+00 - val_loss: 0.3795 - val_accuracy: 0.0000e+00\n",
            "Epoch 3111/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3564 - accuracy: 0.0000e+00 - val_loss: 0.3795 - val_accuracy: 0.0000e+00\n",
            "Epoch 3112/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3520 - accuracy: 0.0000e+00 - val_loss: 0.3794 - val_accuracy: 0.0000e+00\n",
            "Epoch 3113/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3516 - accuracy: 0.0000e+00 - val_loss: 0.3794 - val_accuracy: 0.0000e+00\n",
            "Epoch 3114/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3551 - accuracy: 0.0000e+00 - val_loss: 0.3793 - val_accuracy: 0.0000e+00\n",
            "Epoch 3115/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3539 - accuracy: 0.0000e+00 - val_loss: 0.3793 - val_accuracy: 0.0000e+00\n",
            "Epoch 3116/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3501 - accuracy: 0.0000e+00 - val_loss: 0.3793 - val_accuracy: 0.0000e+00\n",
            "Epoch 3117/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3514 - accuracy: 0.0000e+00 - val_loss: 0.3792 - val_accuracy: 0.0000e+00\n",
            "Epoch 3118/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3458 - accuracy: 0.0000e+00 - val_loss: 0.3790 - val_accuracy: 0.0000e+00\n",
            "Epoch 3119/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3506 - accuracy: 0.0000e+00 - val_loss: 0.3790 - val_accuracy: 0.0000e+00\n",
            "Epoch 3120/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3549 - accuracy: 0.0000e+00 - val_loss: 0.3789 - val_accuracy: 0.0000e+00\n",
            "Epoch 3121/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3528 - accuracy: 0.0000e+00 - val_loss: 0.3788 - val_accuracy: 0.0000e+00\n",
            "Epoch 3122/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3568 - accuracy: 0.0000e+00 - val_loss: 0.3789 - val_accuracy: 0.0000e+00\n",
            "Epoch 3123/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3403 - accuracy: 0.0000e+00 - val_loss: 0.3789 - val_accuracy: 0.0000e+00\n",
            "Epoch 3124/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3500 - accuracy: 0.0000e+00 - val_loss: 0.3789 - val_accuracy: 0.0000e+00\n",
            "Epoch 3125/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3462 - accuracy: 0.0000e+00 - val_loss: 0.3789 - val_accuracy: 0.0000e+00\n",
            "Epoch 3126/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3473 - accuracy: 0.0000e+00 - val_loss: 0.3790 - val_accuracy: 0.0000e+00\n",
            "Epoch 3127/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3479 - accuracy: 0.0000e+00 - val_loss: 0.3789 - val_accuracy: 0.0000e+00\n",
            "Epoch 3128/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3527 - accuracy: 0.0000e+00 - val_loss: 0.3789 - val_accuracy: 0.0000e+00\n",
            "Epoch 3129/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3445 - accuracy: 0.0000e+00 - val_loss: 0.3789 - val_accuracy: 0.0000e+00\n",
            "Epoch 3130/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3633 - accuracy: 0.0000e+00 - val_loss: 0.3788 - val_accuracy: 0.0000e+00\n",
            "Epoch 3131/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3434 - accuracy: 0.0000e+00 - val_loss: 0.3788 - val_accuracy: 0.0000e+00\n",
            "Epoch 3132/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3513 - accuracy: 0.0000e+00 - val_loss: 0.3788 - val_accuracy: 0.0000e+00\n",
            "Epoch 3133/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3435 - accuracy: 0.0000e+00 - val_loss: 0.3788 - val_accuracy: 0.0000e+00\n",
            "Epoch 3134/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3445 - accuracy: 0.0000e+00 - val_loss: 0.3788 - val_accuracy: 0.0000e+00\n",
            "Epoch 3135/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3505 - accuracy: 0.0000e+00 - val_loss: 0.3788 - val_accuracy: 0.0000e+00\n",
            "Epoch 3136/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3477 - accuracy: 0.0000e+00 - val_loss: 0.3788 - val_accuracy: 0.0000e+00\n",
            "Epoch 3137/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3434 - accuracy: 0.0000e+00 - val_loss: 0.3788 - val_accuracy: 0.0000e+00\n",
            "Epoch 3138/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3438 - accuracy: 0.0000e+00 - val_loss: 0.3786 - val_accuracy: 0.0000e+00\n",
            "Epoch 3139/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3542 - accuracy: 0.0000e+00 - val_loss: 0.3786 - val_accuracy: 0.0000e+00\n",
            "Epoch 3140/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3472 - accuracy: 0.0000e+00 - val_loss: 0.3786 - val_accuracy: 0.0000e+00\n",
            "Epoch 3141/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3436 - accuracy: 0.0000e+00 - val_loss: 0.3786 - val_accuracy: 0.0000e+00\n",
            "Epoch 3142/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3445 - accuracy: 0.0000e+00 - val_loss: 0.3786 - val_accuracy: 0.0000e+00\n",
            "Epoch 3143/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3505 - accuracy: 0.0000e+00 - val_loss: 0.3786 - val_accuracy: 0.0000e+00\n",
            "Epoch 3144/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3482 - accuracy: 0.0000e+00 - val_loss: 0.3785 - val_accuracy: 0.0000e+00\n",
            "Epoch 3145/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3468 - accuracy: 0.0000e+00 - val_loss: 0.3784 - val_accuracy: 0.0000e+00\n",
            "Epoch 3146/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3515 - accuracy: 0.0000e+00 - val_loss: 0.3785 - val_accuracy: 0.0000e+00\n",
            "Epoch 3147/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3596 - accuracy: 0.0000e+00 - val_loss: 0.3785 - val_accuracy: 0.0000e+00\n",
            "Epoch 3148/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3495 - accuracy: 0.0000e+00 - val_loss: 0.3784 - val_accuracy: 0.0000e+00\n",
            "Epoch 3149/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3438 - accuracy: 0.0000e+00 - val_loss: 0.3784 - val_accuracy: 0.0000e+00\n",
            "Epoch 3150/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3486 - accuracy: 0.0000e+00 - val_loss: 0.3784 - val_accuracy: 0.0000e+00\n",
            "Epoch 3151/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3443 - accuracy: 0.0000e+00 - val_loss: 0.3784 - val_accuracy: 0.0000e+00\n",
            "Epoch 3152/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3497 - accuracy: 0.0000e+00 - val_loss: 0.3783 - val_accuracy: 0.0000e+00\n",
            "Epoch 3153/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3489 - accuracy: 0.0000e+00 - val_loss: 0.3783 - val_accuracy: 0.0000e+00\n",
            "Epoch 3154/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3436 - accuracy: 0.0000e+00 - val_loss: 0.3783 - val_accuracy: 0.0000e+00\n",
            "Epoch 3155/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3464 - accuracy: 0.0000e+00 - val_loss: 0.3782 - val_accuracy: 0.0000e+00\n",
            "Epoch 3156/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3505 - accuracy: 0.0000e+00 - val_loss: 0.3782 - val_accuracy: 0.0000e+00\n",
            "Epoch 3157/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3464 - accuracy: 0.0000e+00 - val_loss: 0.3781 - val_accuracy: 0.0000e+00\n",
            "Epoch 3158/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3424 - accuracy: 0.0000e+00 - val_loss: 0.3780 - val_accuracy: 0.0000e+00\n",
            "Epoch 3159/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3642 - accuracy: 0.0000e+00 - val_loss: 0.3780 - val_accuracy: 0.0000e+00\n",
            "Epoch 3160/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3488 - accuracy: 0.0000e+00 - val_loss: 0.3780 - val_accuracy: 0.0000e+00\n",
            "Epoch 3161/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3447 - accuracy: 0.0000e+00 - val_loss: 0.3781 - val_accuracy: 0.0000e+00\n",
            "Epoch 3162/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3490 - accuracy: 0.0000e+00 - val_loss: 0.3780 - val_accuracy: 0.0000e+00\n",
            "Epoch 3163/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3603 - accuracy: 0.0000e+00 - val_loss: 0.3779 - val_accuracy: 0.0000e+00\n",
            "Epoch 3164/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3459 - accuracy: 0.0000e+00 - val_loss: 0.3779 - val_accuracy: 0.0000e+00\n",
            "Epoch 3165/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3508 - accuracy: 0.0000e+00 - val_loss: 0.3778 - val_accuracy: 0.0000e+00\n",
            "Epoch 3166/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3499 - accuracy: 0.0000e+00 - val_loss: 0.3777 - val_accuracy: 0.0000e+00\n",
            "Epoch 3167/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3461 - accuracy: 0.0000e+00 - val_loss: 0.3777 - val_accuracy: 0.0000e+00\n",
            "Epoch 3168/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3432 - accuracy: 0.0000e+00 - val_loss: 0.3776 - val_accuracy: 0.0000e+00\n",
            "Epoch 3169/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3425 - accuracy: 0.0000e+00 - val_loss: 0.3776 - val_accuracy: 0.0000e+00\n",
            "Epoch 3170/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3480 - accuracy: 0.0000e+00 - val_loss: 0.3776 - val_accuracy: 0.0000e+00\n",
            "Epoch 3171/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3476 - accuracy: 0.0000e+00 - val_loss: 0.3775 - val_accuracy: 0.0000e+00\n",
            "Epoch 3172/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3462 - accuracy: 0.0000e+00 - val_loss: 0.3775 - val_accuracy: 0.0000e+00\n",
            "Epoch 3173/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3552 - accuracy: 0.0000e+00 - val_loss: 0.3775 - val_accuracy: 0.0000e+00\n",
            "Epoch 3174/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3460 - accuracy: 0.0000e+00 - val_loss: 0.3775 - val_accuracy: 0.0000e+00\n",
            "Epoch 3175/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3463 - accuracy: 0.0000e+00 - val_loss: 0.3775 - val_accuracy: 0.0000e+00\n",
            "Epoch 3176/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3435 - accuracy: 0.0000e+00 - val_loss: 0.3775 - val_accuracy: 0.0000e+00\n",
            "Epoch 3177/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3522 - accuracy: 0.0000e+00 - val_loss: 0.3774 - val_accuracy: 0.0000e+00\n",
            "Epoch 3178/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3595 - accuracy: 0.0000e+00 - val_loss: 0.3773 - val_accuracy: 0.0000e+00\n",
            "Epoch 3179/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3460 - accuracy: 0.0000e+00 - val_loss: 0.3773 - val_accuracy: 0.0000e+00\n",
            "Epoch 3180/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3470 - accuracy: 0.0000e+00 - val_loss: 0.3772 - val_accuracy: 0.0000e+00\n",
            "Epoch 3181/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3550 - accuracy: 0.0000e+00 - val_loss: 0.3772 - val_accuracy: 0.0000e+00\n",
            "Epoch 3182/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3504 - accuracy: 0.0000e+00 - val_loss: 0.3772 - val_accuracy: 0.0000e+00\n",
            "Epoch 3183/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3455 - accuracy: 0.0000e+00 - val_loss: 0.3772 - val_accuracy: 0.0000e+00\n",
            "Epoch 3184/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3466 - accuracy: 0.0000e+00 - val_loss: 0.3771 - val_accuracy: 0.0000e+00\n",
            "Epoch 3185/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3458 - accuracy: 0.0000e+00 - val_loss: 0.3772 - val_accuracy: 0.0000e+00\n",
            "Epoch 3186/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3423 - accuracy: 0.0000e+00 - val_loss: 0.3771 - val_accuracy: 0.0000e+00\n",
            "Epoch 3187/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3500 - accuracy: 0.0000e+00 - val_loss: 0.3771 - val_accuracy: 0.0000e+00\n",
            "Epoch 3188/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3434 - accuracy: 0.0000e+00 - val_loss: 0.3771 - val_accuracy: 0.0000e+00\n",
            "Epoch 3189/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3561 - accuracy: 0.0000e+00 - val_loss: 0.3771 - val_accuracy: 0.0000e+00\n",
            "Epoch 3190/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3600 - accuracy: 0.0000e+00 - val_loss: 0.3771 - val_accuracy: 0.0000e+00\n",
            "Epoch 3191/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3459 - accuracy: 0.0000e+00 - val_loss: 0.3770 - val_accuracy: 0.0000e+00\n",
            "Epoch 3192/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3384 - accuracy: 0.0000e+00 - val_loss: 0.3770 - val_accuracy: 0.0000e+00\n",
            "Epoch 3193/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3444 - accuracy: 0.0000e+00 - val_loss: 0.3770 - val_accuracy: 0.0000e+00\n",
            "Epoch 3194/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3524 - accuracy: 0.0000e+00 - val_loss: 0.3770 - val_accuracy: 0.0000e+00\n",
            "Epoch 3195/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3449 - accuracy: 0.0000e+00 - val_loss: 0.3770 - val_accuracy: 0.0000e+00\n",
            "Epoch 3196/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3622 - accuracy: 0.0000e+00 - val_loss: 0.3770 - val_accuracy: 0.0000e+00\n",
            "Epoch 3197/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3438 - accuracy: 0.0000e+00 - val_loss: 0.3769 - val_accuracy: 0.0000e+00\n",
            "Epoch 3198/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3421 - accuracy: 0.0000e+00 - val_loss: 0.3768 - val_accuracy: 0.0000e+00\n",
            "Epoch 3199/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3470 - accuracy: 0.0000e+00 - val_loss: 0.3767 - val_accuracy: 0.0000e+00\n",
            "Epoch 3200/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3442 - accuracy: 0.0000e+00 - val_loss: 0.3767 - val_accuracy: 0.0000e+00\n",
            "Epoch 3201/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3525 - accuracy: 0.0000e+00 - val_loss: 0.3766 - val_accuracy: 0.0000e+00\n",
            "Epoch 3202/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3461 - accuracy: 0.0000e+00 - val_loss: 0.3767 - val_accuracy: 0.0000e+00\n",
            "Epoch 3203/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3427 - accuracy: 0.0000e+00 - val_loss: 0.3767 - val_accuracy: 0.0000e+00\n",
            "Epoch 3204/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3524 - accuracy: 0.0000e+00 - val_loss: 0.3766 - val_accuracy: 0.0000e+00\n",
            "Epoch 3205/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3624 - accuracy: 0.0000e+00 - val_loss: 0.3766 - val_accuracy: 0.0000e+00\n",
            "Epoch 3206/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3502 - accuracy: 0.0000e+00 - val_loss: 0.3766 - val_accuracy: 0.0000e+00\n",
            "Epoch 3207/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3427 - accuracy: 0.0000e+00 - val_loss: 0.3766 - val_accuracy: 0.0000e+00\n",
            "Epoch 3208/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3490 - accuracy: 0.0000e+00 - val_loss: 0.3766 - val_accuracy: 0.0000e+00\n",
            "Epoch 3209/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3500 - accuracy: 0.0000e+00 - val_loss: 0.3766 - val_accuracy: 0.0000e+00\n",
            "Epoch 3210/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3467 - accuracy: 0.0000e+00 - val_loss: 0.3765 - val_accuracy: 0.0000e+00\n",
            "Epoch 3211/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3419 - accuracy: 0.0000e+00 - val_loss: 0.3765 - val_accuracy: 0.0000e+00\n",
            "Epoch 3212/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3435 - accuracy: 0.0000e+00 - val_loss: 0.3765 - val_accuracy: 0.0000e+00\n",
            "Epoch 3213/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3473 - accuracy: 0.0000e+00 - val_loss: 0.3764 - val_accuracy: 0.0000e+00\n",
            "Epoch 3214/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3513 - accuracy: 0.0000e+00 - val_loss: 0.3765 - val_accuracy: 0.0000e+00\n",
            "Epoch 3215/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3469 - accuracy: 0.0000e+00 - val_loss: 0.3765 - val_accuracy: 0.0000e+00\n",
            "Epoch 3216/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3440 - accuracy: 0.0000e+00 - val_loss: 0.3765 - val_accuracy: 0.0000e+00\n",
            "Epoch 3217/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3529 - accuracy: 0.0000e+00 - val_loss: 0.3765 - val_accuracy: 0.0000e+00\n",
            "Epoch 3218/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3539 - accuracy: 0.0000e+00 - val_loss: 0.3763 - val_accuracy: 0.0000e+00\n",
            "Epoch 3219/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3443 - accuracy: 0.0000e+00 - val_loss: 0.3763 - val_accuracy: 0.0000e+00\n",
            "Epoch 3220/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3450 - accuracy: 0.0000e+00 - val_loss: 0.3763 - val_accuracy: 0.0000e+00\n",
            "Epoch 3221/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3508 - accuracy: 0.0000e+00 - val_loss: 0.3763 - val_accuracy: 0.0000e+00\n",
            "Epoch 3222/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3592 - accuracy: 0.0000e+00 - val_loss: 0.3763 - val_accuracy: 0.0000e+00\n",
            "Epoch 3223/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3433 - accuracy: 0.0000e+00 - val_loss: 0.3763 - val_accuracy: 0.0000e+00\n",
            "Epoch 3224/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3502 - accuracy: 0.0000e+00 - val_loss: 0.3763 - val_accuracy: 0.0000e+00\n",
            "Epoch 3225/5000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3497 - accuracy: 0.0000e+00 - val_loss: 0.3764 - val_accuracy: 0.0000e+00\n",
            "Epoch 3226/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3566 - accuracy: 0.0000e+00 - val_loss: 0.3764 - val_accuracy: 0.0000e+00\n",
            "Epoch 3227/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3395 - accuracy: 0.0000e+00 - val_loss: 0.3763 - val_accuracy: 0.0000e+00\n",
            "Epoch 3228/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3505 - accuracy: 0.0000e+00 - val_loss: 0.3763 - val_accuracy: 0.0000e+00\n",
            "Epoch 3229/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3513 - accuracy: 0.0000e+00 - val_loss: 0.3762 - val_accuracy: 0.0000e+00\n",
            "Epoch 3230/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3427 - accuracy: 0.0000e+00 - val_loss: 0.3762 - val_accuracy: 0.0000e+00\n",
            "Epoch 3231/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3659 - accuracy: 0.0000e+00 - val_loss: 0.3762 - val_accuracy: 0.0000e+00\n",
            "Epoch 3232/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3464 - accuracy: 0.0000e+00 - val_loss: 0.3762 - val_accuracy: 0.0000e+00\n",
            "Epoch 3233/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3442 - accuracy: 0.0000e+00 - val_loss: 0.3761 - val_accuracy: 0.0000e+00\n",
            "Epoch 3234/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3440 - accuracy: 0.0000e+00 - val_loss: 0.3761 - val_accuracy: 0.0000e+00\n",
            "Epoch 3235/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3506 - accuracy: 0.0000e+00 - val_loss: 0.3761 - val_accuracy: 0.0000e+00\n",
            "Epoch 3236/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3503 - accuracy: 0.0000e+00 - val_loss: 0.3760 - val_accuracy: 0.0000e+00\n",
            "Epoch 3237/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3503 - accuracy: 0.0000e+00 - val_loss: 0.3759 - val_accuracy: 0.0000e+00\n",
            "Epoch 3238/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3468 - accuracy: 0.0000e+00 - val_loss: 0.3759 - val_accuracy: 0.0000e+00\n",
            "Epoch 3239/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3446 - accuracy: 0.0000e+00 - val_loss: 0.3758 - val_accuracy: 0.0000e+00\n",
            "Epoch 3240/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3621 - accuracy: 0.0000e+00 - val_loss: 0.3758 - val_accuracy: 0.0000e+00\n",
            "Epoch 3241/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3408 - accuracy: 0.0000e+00 - val_loss: 0.3758 - val_accuracy: 0.0000e+00\n",
            "Epoch 3242/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3505 - accuracy: 0.0000e+00 - val_loss: 0.3759 - val_accuracy: 0.0000e+00\n",
            "Epoch 3243/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3463 - accuracy: 0.0000e+00 - val_loss: 0.3759 - val_accuracy: 0.0000e+00\n",
            "Epoch 3244/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3562 - accuracy: 0.0000e+00 - val_loss: 0.3759 - val_accuracy: 0.0000e+00\n",
            "Epoch 3245/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3463 - accuracy: 0.0000e+00 - val_loss: 0.3759 - val_accuracy: 0.0000e+00\n",
            "Epoch 3246/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3565 - accuracy: 0.0000e+00 - val_loss: 0.3760 - val_accuracy: 0.0000e+00\n",
            "Epoch 3247/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3542 - accuracy: 0.0000e+00 - val_loss: 0.3760 - val_accuracy: 0.0000e+00\n",
            "Epoch 3248/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3535 - accuracy: 0.0000e+00 - val_loss: 0.3759 - val_accuracy: 0.0000e+00\n",
            "Epoch 3249/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3458 - accuracy: 0.0000e+00 - val_loss: 0.3759 - val_accuracy: 0.0000e+00\n",
            "Epoch 3250/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3489 - accuracy: 0.0000e+00 - val_loss: 0.3758 - val_accuracy: 0.0000e+00\n",
            "Epoch 3251/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3490 - accuracy: 0.0000e+00 - val_loss: 0.3758 - val_accuracy: 0.0000e+00\n",
            "Epoch 3252/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3494 - accuracy: 0.0000e+00 - val_loss: 0.3758 - val_accuracy: 0.0000e+00\n",
            "Epoch 3253/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3434 - accuracy: 0.0000e+00 - val_loss: 0.3758 - val_accuracy: 0.0000e+00\n",
            "Epoch 3254/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3469 - accuracy: 0.0000e+00 - val_loss: 0.3757 - val_accuracy: 0.0000e+00\n",
            "Epoch 3255/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3487 - accuracy: 0.0000e+00 - val_loss: 0.3756 - val_accuracy: 0.0000e+00\n",
            "Epoch 3256/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3435 - accuracy: 0.0000e+00 - val_loss: 0.3756 - val_accuracy: 0.0000e+00\n",
            "Epoch 3257/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3645 - accuracy: 0.0000e+00 - val_loss: 0.3756 - val_accuracy: 0.0000e+00\n",
            "Epoch 3258/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3490 - accuracy: 0.0000e+00 - val_loss: 0.3756 - val_accuracy: 0.0000e+00\n",
            "Epoch 3259/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3481 - accuracy: 0.0000e+00 - val_loss: 0.3756 - val_accuracy: 0.0000e+00\n",
            "Epoch 3260/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3397 - accuracy: 0.0000e+00 - val_loss: 0.3755 - val_accuracy: 0.0000e+00\n",
            "Epoch 3261/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3484 - accuracy: 0.0000e+00 - val_loss: 0.3755 - val_accuracy: 0.0000e+00\n",
            "Epoch 3262/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3508 - accuracy: 0.0000e+00 - val_loss: 0.3754 - val_accuracy: 0.0000e+00\n",
            "Epoch 3263/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3418 - accuracy: 0.0000e+00 - val_loss: 0.3755 - val_accuracy: 0.0000e+00\n",
            "Epoch 3264/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3437 - accuracy: 0.0000e+00 - val_loss: 0.3755 - val_accuracy: 0.0000e+00\n",
            "Epoch 3265/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3469 - accuracy: 0.0000e+00 - val_loss: 0.3754 - val_accuracy: 0.0000e+00\n",
            "Epoch 3266/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3489 - accuracy: 0.0000e+00 - val_loss: 0.3754 - val_accuracy: 0.0000e+00\n",
            "Epoch 3267/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3560 - accuracy: 0.0000e+00 - val_loss: 0.3753 - val_accuracy: 0.0000e+00\n",
            "Epoch 3268/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3570 - accuracy: 0.0000e+00 - val_loss: 0.3752 - val_accuracy: 0.0000e+00\n",
            "Epoch 3269/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3530 - accuracy: 0.0000e+00 - val_loss: 0.3752 - val_accuracy: 0.0000e+00\n",
            "Epoch 3270/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3489 - accuracy: 0.0000e+00 - val_loss: 0.3752 - val_accuracy: 0.0000e+00\n",
            "Epoch 3271/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3398 - accuracy: 0.0000e+00 - val_loss: 0.3752 - val_accuracy: 0.0000e+00\n",
            "Epoch 3272/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3625 - accuracy: 0.0000e+00 - val_loss: 0.3752 - val_accuracy: 0.0000e+00\n",
            "Epoch 3273/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3493 - accuracy: 0.0000e+00 - val_loss: 0.3752 - val_accuracy: 0.0000e+00\n",
            "Epoch 3274/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3610 - accuracy: 0.0000e+00 - val_loss: 0.3752 - val_accuracy: 0.0000e+00\n",
            "Epoch 3275/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3489 - accuracy: 0.0000e+00 - val_loss: 0.3753 - val_accuracy: 0.0000e+00\n",
            "Epoch 3276/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3384 - accuracy: 0.0000e+00 - val_loss: 0.3752 - val_accuracy: 0.0000e+00\n",
            "Epoch 3277/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3485 - accuracy: 0.0000e+00 - val_loss: 0.3752 - val_accuracy: 0.0000e+00\n",
            "Epoch 3278/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3409 - accuracy: 0.0000e+00 - val_loss: 0.3752 - val_accuracy: 0.0000e+00\n",
            "Epoch 3279/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3458 - accuracy: 0.0000e+00 - val_loss: 0.3751 - val_accuracy: 0.0000e+00\n",
            "Epoch 3280/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3526 - accuracy: 0.0000e+00 - val_loss: 0.3752 - val_accuracy: 0.0000e+00\n",
            "Epoch 3281/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3441 - accuracy: 0.0000e+00 - val_loss: 0.3751 - val_accuracy: 0.0000e+00\n",
            "Epoch 3282/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3524 - accuracy: 0.0000e+00 - val_loss: 0.3749 - val_accuracy: 0.0000e+00\n",
            "Epoch 3283/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3518 - accuracy: 0.0000e+00 - val_loss: 0.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 3284/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3491 - accuracy: 0.0000e+00 - val_loss: 0.3749 - val_accuracy: 0.0000e+00\n",
            "Epoch 3285/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3355 - accuracy: 0.0000e+00 - val_loss: 0.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 3286/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3453 - accuracy: 0.0000e+00 - val_loss: 0.3749 - val_accuracy: 0.0000e+00\n",
            "Epoch 3287/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3574 - accuracy: 0.0000e+00 - val_loss: 0.3749 - val_accuracy: 0.0000e+00\n",
            "Epoch 3288/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3430 - accuracy: 0.0000e+00 - val_loss: 0.3749 - val_accuracy: 0.0000e+00\n",
            "Epoch 3289/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3418 - accuracy: 0.0000e+00 - val_loss: 0.3749 - val_accuracy: 0.0000e+00\n",
            "Epoch 3290/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3386 - accuracy: 0.0000e+00 - val_loss: 0.3749 - val_accuracy: 0.0000e+00\n",
            "Epoch 3291/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3480 - accuracy: 0.0000e+00 - val_loss: 0.3749 - val_accuracy: 0.0000e+00\n",
            "Epoch 3292/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3526 - accuracy: 0.0000e+00 - val_loss: 0.3749 - val_accuracy: 0.0000e+00\n",
            "Epoch 3293/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3400 - accuracy: 0.0000e+00 - val_loss: 0.3749 - val_accuracy: 0.0000e+00\n",
            "Epoch 3294/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3513 - accuracy: 0.0000e+00 - val_loss: 0.3749 - val_accuracy: 0.0000e+00\n",
            "Epoch 3295/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3457 - accuracy: 0.0000e+00 - val_loss: 0.3748 - val_accuracy: 0.0000e+00\n",
            "Epoch 3296/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3478 - accuracy: 0.0000e+00 - val_loss: 0.3748 - val_accuracy: 0.0000e+00\n",
            "Epoch 3297/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3621 - accuracy: 0.0000e+00 - val_loss: 0.3748 - val_accuracy: 0.0000e+00\n",
            "Epoch 3298/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3477 - accuracy: 0.0000e+00 - val_loss: 0.3748 - val_accuracy: 0.0000e+00\n",
            "Epoch 3299/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3493 - accuracy: 0.0000e+00 - val_loss: 0.3748 - val_accuracy: 0.0000e+00\n",
            "Epoch 3300/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3406 - accuracy: 0.0000e+00 - val_loss: 0.3746 - val_accuracy: 0.0000e+00\n",
            "Epoch 3301/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3443 - accuracy: 0.0000e+00 - val_loss: 0.3746 - val_accuracy: 0.0000e+00\n",
            "Epoch 3302/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3474 - accuracy: 0.0000e+00 - val_loss: 0.3746 - val_accuracy: 0.0000e+00\n",
            "Epoch 3303/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3446 - accuracy: 0.0000e+00 - val_loss: 0.3746 - val_accuracy: 0.0000e+00\n",
            "Epoch 3304/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3439 - accuracy: 0.0000e+00 - val_loss: 0.3745 - val_accuracy: 0.0000e+00\n",
            "Epoch 3305/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3487 - accuracy: 0.0000e+00 - val_loss: 0.3745 - val_accuracy: 0.0000e+00\n",
            "Epoch 3306/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3450 - accuracy: 0.0000e+00 - val_loss: 0.3745 - val_accuracy: 0.0000e+00\n",
            "Epoch 3307/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3480 - accuracy: 0.0000e+00 - val_loss: 0.3744 - val_accuracy: 0.0000e+00\n",
            "Epoch 3308/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3449 - accuracy: 0.0000e+00 - val_loss: 0.3743 - val_accuracy: 0.0000e+00\n",
            "Epoch 3309/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3364 - accuracy: 0.0000e+00 - val_loss: 0.3743 - val_accuracy: 0.0000e+00\n",
            "Epoch 3310/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3500 - accuracy: 0.0000e+00 - val_loss: 0.3743 - val_accuracy: 0.0000e+00\n",
            "Epoch 3311/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3354 - accuracy: 0.0000e+00 - val_loss: 0.3742 - val_accuracy: 0.0000e+00\n",
            "Epoch 3312/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3483 - accuracy: 0.0000e+00 - val_loss: 0.3742 - val_accuracy: 0.0000e+00\n",
            "Epoch 3313/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3466 - accuracy: 0.0000e+00 - val_loss: 0.3743 - val_accuracy: 0.0000e+00\n",
            "Epoch 3314/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3431 - accuracy: 0.0000e+00 - val_loss: 0.3742 - val_accuracy: 0.0000e+00\n",
            "Epoch 3315/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3572 - accuracy: 0.0000e+00 - val_loss: 0.3741 - val_accuracy: 0.0000e+00\n",
            "Epoch 3316/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3481 - accuracy: 0.0000e+00 - val_loss: 0.3742 - val_accuracy: 0.0000e+00\n",
            "Epoch 3317/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3460 - accuracy: 0.0000e+00 - val_loss: 0.3741 - val_accuracy: 0.0000e+00\n",
            "Epoch 3318/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3446 - accuracy: 0.0000e+00 - val_loss: 0.3741 - val_accuracy: 0.0000e+00\n",
            "Epoch 3319/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3723 - accuracy: 0.0000e+00 - val_loss: 0.3741 - val_accuracy: 0.0000e+00\n",
            "Epoch 3320/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3470 - accuracy: 0.0000e+00 - val_loss: 0.3741 - val_accuracy: 0.0000e+00\n",
            "Epoch 3321/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3424 - accuracy: 0.0000e+00 - val_loss: 0.3740 - val_accuracy: 0.0000e+00\n",
            "Epoch 3322/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3431 - accuracy: 0.0000e+00 - val_loss: 0.3740 - val_accuracy: 0.0000e+00\n",
            "Epoch 3323/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3455 - accuracy: 0.0000e+00 - val_loss: 0.3740 - val_accuracy: 0.0000e+00\n",
            "Epoch 3324/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3471 - accuracy: 0.0000e+00 - val_loss: 0.3740 - val_accuracy: 0.0000e+00\n",
            "Epoch 3325/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3482 - accuracy: 0.0000e+00 - val_loss: 0.3739 - val_accuracy: 0.0000e+00\n",
            "Epoch 3326/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3515 - accuracy: 0.0000e+00 - val_loss: 0.3739 - val_accuracy: 0.0000e+00\n",
            "Epoch 3327/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3425 - accuracy: 0.0000e+00 - val_loss: 0.3738 - val_accuracy: 0.0000e+00\n",
            "Epoch 3328/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3489 - accuracy: 0.0000e+00 - val_loss: 0.3738 - val_accuracy: 0.0000e+00\n",
            "Epoch 3329/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3437 - accuracy: 0.0000e+00 - val_loss: 0.3738 - val_accuracy: 0.0000e+00\n",
            "Epoch 3330/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3565 - accuracy: 0.0000e+00 - val_loss: 0.3737 - val_accuracy: 0.0000e+00\n",
            "Epoch 3331/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3384 - accuracy: 0.0000e+00 - val_loss: 0.3736 - val_accuracy: 0.0000e+00\n",
            "Epoch 3332/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3418 - accuracy: 0.0000e+00 - val_loss: 0.3736 - val_accuracy: 0.0000e+00\n",
            "Epoch 3333/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3417 - accuracy: 0.0000e+00 - val_loss: 0.3735 - val_accuracy: 0.0000e+00\n",
            "Epoch 3334/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3552 - accuracy: 0.0000e+00 - val_loss: 0.3734 - val_accuracy: 0.0000e+00\n",
            "Epoch 3335/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3368 - accuracy: 0.0000e+00 - val_loss: 0.3733 - val_accuracy: 0.0000e+00\n",
            "Epoch 3336/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3514 - accuracy: 0.0000e+00 - val_loss: 0.3733 - val_accuracy: 0.0000e+00\n",
            "Epoch 3337/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3514 - accuracy: 0.0000e+00 - val_loss: 0.3732 - val_accuracy: 0.0000e+00\n",
            "Epoch 3338/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3377 - accuracy: 0.0000e+00 - val_loss: 0.3732 - val_accuracy: 0.0000e+00\n",
            "Epoch 3339/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3355 - accuracy: 0.0000e+00 - val_loss: 0.3732 - val_accuracy: 0.0000e+00\n",
            "Epoch 3340/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3397 - accuracy: 0.0000e+00 - val_loss: 0.3731 - val_accuracy: 0.0000e+00\n",
            "Epoch 3341/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3430 - accuracy: 0.0000e+00 - val_loss: 0.3731 - val_accuracy: 0.0000e+00\n",
            "Epoch 3342/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3508 - accuracy: 0.0000e+00 - val_loss: 0.3729 - val_accuracy: 0.0000e+00\n",
            "Epoch 3343/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3448 - accuracy: 0.0000e+00 - val_loss: 0.3729 - val_accuracy: 0.0000e+00\n",
            "Epoch 3344/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3410 - accuracy: 0.0000e+00 - val_loss: 0.3729 - val_accuracy: 0.0000e+00\n",
            "Epoch 3345/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3556 - accuracy: 0.0000e+00 - val_loss: 0.3729 - val_accuracy: 0.0000e+00\n",
            "Epoch 3346/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3469 - accuracy: 0.0000e+00 - val_loss: 0.3729 - val_accuracy: 0.0000e+00\n",
            "Epoch 3347/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3392 - accuracy: 0.0000e+00 - val_loss: 0.3729 - val_accuracy: 0.0000e+00\n",
            "Epoch 3348/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3472 - accuracy: 0.0000e+00 - val_loss: 0.3729 - val_accuracy: 0.0000e+00\n",
            "Epoch 3349/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3547 - accuracy: 0.0000e+00 - val_loss: 0.3729 - val_accuracy: 0.0000e+00\n",
            "Epoch 3350/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3453 - accuracy: 0.0000e+00 - val_loss: 0.3729 - val_accuracy: 0.0000e+00\n",
            "Epoch 3351/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3410 - accuracy: 0.0000e+00 - val_loss: 0.3728 - val_accuracy: 0.0000e+00\n",
            "Epoch 3352/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3398 - accuracy: 0.0000e+00 - val_loss: 0.3728 - val_accuracy: 0.0000e+00\n",
            "Epoch 3353/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3404 - accuracy: 0.0000e+00 - val_loss: 0.3728 - val_accuracy: 0.0000e+00\n",
            "Epoch 3354/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3410 - accuracy: 0.0000e+00 - val_loss: 0.3728 - val_accuracy: 0.0000e+00\n",
            "Epoch 3355/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3451 - accuracy: 0.0000e+00 - val_loss: 0.3728 - val_accuracy: 0.0000e+00\n",
            "Epoch 3356/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3488 - accuracy: 0.0000e+00 - val_loss: 0.3727 - val_accuracy: 0.0000e+00\n",
            "Epoch 3357/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3477 - accuracy: 0.0000e+00 - val_loss: 0.3726 - val_accuracy: 0.0000e+00\n",
            "Epoch 3358/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3398 - accuracy: 0.0000e+00 - val_loss: 0.3726 - val_accuracy: 0.0000e+00\n",
            "Epoch 3359/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3486 - accuracy: 0.0000e+00 - val_loss: 0.3725 - val_accuracy: 0.0000e+00\n",
            "Epoch 3360/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3444 - accuracy: 0.0000e+00 - val_loss: 0.3726 - val_accuracy: 0.0000e+00\n",
            "Epoch 3361/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3481 - accuracy: 0.0000e+00 - val_loss: 0.3725 - val_accuracy: 0.0000e+00\n",
            "Epoch 3362/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3404 - accuracy: 0.0000e+00 - val_loss: 0.3725 - val_accuracy: 0.0000e+00\n",
            "Epoch 3363/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3464 - accuracy: 0.0000e+00 - val_loss: 0.3725 - val_accuracy: 0.0000e+00\n",
            "Epoch 3364/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3442 - accuracy: 0.0000e+00 - val_loss: 0.3725 - val_accuracy: 0.0000e+00\n",
            "Epoch 3365/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3389 - accuracy: 0.0000e+00 - val_loss: 0.3725 - val_accuracy: 0.0000e+00\n",
            "Epoch 3366/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3480 - accuracy: 0.0000e+00 - val_loss: 0.3725 - val_accuracy: 0.0000e+00\n",
            "Epoch 3367/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3472 - accuracy: 0.0000e+00 - val_loss: 0.3724 - val_accuracy: 0.0000e+00\n",
            "Epoch 3368/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3509 - accuracy: 0.0000e+00 - val_loss: 0.3723 - val_accuracy: 0.0000e+00\n",
            "Epoch 3369/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3424 - accuracy: 0.0000e+00 - val_loss: 0.3724 - val_accuracy: 0.0000e+00\n",
            "Epoch 3370/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3463 - accuracy: 0.0000e+00 - val_loss: 0.3723 - val_accuracy: 0.0000e+00\n",
            "Epoch 3371/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3372 - accuracy: 0.0000e+00 - val_loss: 0.3722 - val_accuracy: 0.0000e+00\n",
            "Epoch 3372/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3411 - accuracy: 0.0000e+00 - val_loss: 0.3721 - val_accuracy: 0.0000e+00\n",
            "Epoch 3373/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3458 - accuracy: 0.0000e+00 - val_loss: 0.3721 - val_accuracy: 0.0000e+00\n",
            "Epoch 3374/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3450 - accuracy: 0.0000e+00 - val_loss: 0.3721 - val_accuracy: 0.0000e+00\n",
            "Epoch 3375/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3542 - accuracy: 0.0000e+00 - val_loss: 0.3721 - val_accuracy: 0.0000e+00\n",
            "Epoch 3376/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3418 - accuracy: 0.0000e+00 - val_loss: 0.3722 - val_accuracy: 0.0000e+00\n",
            "Epoch 3377/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3408 - accuracy: 0.0000e+00 - val_loss: 0.3721 - val_accuracy: 0.0000e+00\n",
            "Epoch 3378/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3429 - accuracy: 0.0000e+00 - val_loss: 0.3722 - val_accuracy: 0.0000e+00\n",
            "Epoch 3379/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3412 - accuracy: 0.0000e+00 - val_loss: 0.3723 - val_accuracy: 0.0000e+00\n",
            "Epoch 3380/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3410 - accuracy: 0.0000e+00 - val_loss: 0.3723 - val_accuracy: 0.0000e+00\n",
            "Epoch 3381/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3433 - accuracy: 0.0000e+00 - val_loss: 0.3722 - val_accuracy: 0.0000e+00\n",
            "Epoch 3382/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3439 - accuracy: 0.0000e+00 - val_loss: 0.3722 - val_accuracy: 0.0000e+00\n",
            "Epoch 3383/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3471 - accuracy: 0.0000e+00 - val_loss: 0.3722 - val_accuracy: 0.0000e+00\n",
            "Epoch 3384/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3454 - accuracy: 0.0000e+00 - val_loss: 0.3721 - val_accuracy: 0.0000e+00\n",
            "Epoch 3385/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3600 - accuracy: 0.0000e+00 - val_loss: 0.3722 - val_accuracy: 0.0000e+00\n",
            "Epoch 3386/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3406 - accuracy: 0.0000e+00 - val_loss: 0.3720 - val_accuracy: 0.0000e+00\n",
            "Epoch 3387/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3447 - accuracy: 0.0000e+00 - val_loss: 0.3720 - val_accuracy: 0.0000e+00\n",
            "Epoch 3388/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3442 - accuracy: 0.0000e+00 - val_loss: 0.3720 - val_accuracy: 0.0000e+00\n",
            "Epoch 3389/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3418 - accuracy: 0.0000e+00 - val_loss: 0.3719 - val_accuracy: 0.0000e+00\n",
            "Epoch 3390/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3374 - accuracy: 0.0000e+00 - val_loss: 0.3719 - val_accuracy: 0.0000e+00\n",
            "Epoch 3391/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3403 - accuracy: 0.0000e+00 - val_loss: 0.3718 - val_accuracy: 0.0000e+00\n",
            "Epoch 3392/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3524 - accuracy: 0.0000e+00 - val_loss: 0.3717 - val_accuracy: 0.0000e+00\n",
            "Epoch 3393/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3555 - accuracy: 0.0000e+00 - val_loss: 0.3716 - val_accuracy: 0.0000e+00\n",
            "Epoch 3394/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3384 - accuracy: 0.0000e+00 - val_loss: 0.3716 - val_accuracy: 0.0000e+00\n",
            "Epoch 3395/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3413 - accuracy: 0.0000e+00 - val_loss: 0.3717 - val_accuracy: 0.0000e+00\n",
            "Epoch 3396/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3395 - accuracy: 0.0000e+00 - val_loss: 0.3716 - val_accuracy: 0.0000e+00\n",
            "Epoch 3397/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3373 - accuracy: 0.0000e+00 - val_loss: 0.3715 - val_accuracy: 0.0000e+00\n",
            "Epoch 3398/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3429 - accuracy: 0.0000e+00 - val_loss: 0.3714 - val_accuracy: 0.0000e+00\n",
            "Epoch 3399/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3424 - accuracy: 0.0000e+00 - val_loss: 0.3713 - val_accuracy: 0.0000e+00\n",
            "Epoch 3400/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3437 - accuracy: 0.0000e+00 - val_loss: 0.3713 - val_accuracy: 0.0000e+00\n",
            "Epoch 3401/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3479 - accuracy: 0.0000e+00 - val_loss: 0.3713 - val_accuracy: 0.0000e+00\n",
            "Epoch 3402/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3414 - accuracy: 0.0000e+00 - val_loss: 0.3712 - val_accuracy: 0.0000e+00\n",
            "Epoch 3403/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3438 - accuracy: 0.0000e+00 - val_loss: 0.3712 - val_accuracy: 0.0000e+00\n",
            "Epoch 3404/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3403 - accuracy: 0.0000e+00 - val_loss: 0.3712 - val_accuracy: 0.0000e+00\n",
            "Epoch 3405/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3488 - accuracy: 0.0000e+00 - val_loss: 0.3712 - val_accuracy: 0.0000e+00\n",
            "Epoch 3406/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3384 - accuracy: 0.0000e+00 - val_loss: 0.3712 - val_accuracy: 0.0000e+00\n",
            "Epoch 3407/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3451 - accuracy: 0.0000e+00 - val_loss: 0.3712 - val_accuracy: 0.0000e+00\n",
            "Epoch 3408/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3379 - accuracy: 0.0000e+00 - val_loss: 0.3712 - val_accuracy: 0.0000e+00\n",
            "Epoch 3409/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3476 - accuracy: 0.0000e+00 - val_loss: 0.3712 - val_accuracy: 0.0000e+00\n",
            "Epoch 3410/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3415 - accuracy: 0.0000e+00 - val_loss: 0.3711 - val_accuracy: 0.0000e+00\n",
            "Epoch 3411/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3397 - accuracy: 0.0000e+00 - val_loss: 0.3711 - val_accuracy: 0.0000e+00\n",
            "Epoch 3412/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3386 - accuracy: 0.0000e+00 - val_loss: 0.3711 - val_accuracy: 0.0000e+00\n",
            "Epoch 3413/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3504 - accuracy: 0.0000e+00 - val_loss: 0.3711 - val_accuracy: 0.0000e+00\n",
            "Epoch 3414/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3417 - accuracy: 0.0000e+00 - val_loss: 0.3710 - val_accuracy: 0.0000e+00\n",
            "Epoch 3415/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3420 - accuracy: 0.0000e+00 - val_loss: 0.3711 - val_accuracy: 0.0000e+00\n",
            "Epoch 3416/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3377 - accuracy: 0.0000e+00 - val_loss: 0.3711 - val_accuracy: 0.0000e+00\n",
            "Epoch 3417/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3489 - accuracy: 0.0000e+00 - val_loss: 0.3710 - val_accuracy: 0.0000e+00\n",
            "Epoch 3418/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3408 - accuracy: 0.0000e+00 - val_loss: 0.3709 - val_accuracy: 0.0000e+00\n",
            "Epoch 3419/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3507 - accuracy: 0.0000e+00 - val_loss: 0.3709 - val_accuracy: 0.0000e+00\n",
            "Epoch 3420/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3516 - accuracy: 0.0000e+00 - val_loss: 0.3709 - val_accuracy: 0.0000e+00\n",
            "Epoch 3421/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3402 - accuracy: 0.0000e+00 - val_loss: 0.3708 - val_accuracy: 0.0000e+00\n",
            "Epoch 3422/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3505 - accuracy: 0.0000e+00 - val_loss: 0.3707 - val_accuracy: 0.0000e+00\n",
            "Epoch 3423/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3392 - accuracy: 0.0000e+00 - val_loss: 0.3707 - val_accuracy: 0.0000e+00\n",
            "Epoch 3424/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3342 - accuracy: 0.0000e+00 - val_loss: 0.3708 - val_accuracy: 0.0000e+00\n",
            "Epoch 3425/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3397 - accuracy: 0.0000e+00 - val_loss: 0.3707 - val_accuracy: 0.0000e+00\n",
            "Epoch 3426/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3479 - accuracy: 0.0000e+00 - val_loss: 0.3706 - val_accuracy: 0.0000e+00\n",
            "Epoch 3427/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3412 - accuracy: 0.0000e+00 - val_loss: 0.3706 - val_accuracy: 0.0000e+00\n",
            "Epoch 3428/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3493 - accuracy: 0.0000e+00 - val_loss: 0.3706 - val_accuracy: 0.0000e+00\n",
            "Epoch 3429/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3354 - accuracy: 0.0000e+00 - val_loss: 0.3705 - val_accuracy: 0.0000e+00\n",
            "Epoch 3430/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3487 - accuracy: 0.0000e+00 - val_loss: 0.3705 - val_accuracy: 0.0000e+00\n",
            "Epoch 3431/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3435 - accuracy: 0.0000e+00 - val_loss: 0.3706 - val_accuracy: 0.0000e+00\n",
            "Epoch 3432/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3582 - accuracy: 0.0000e+00 - val_loss: 0.3706 - val_accuracy: 0.0000e+00\n",
            "Epoch 3433/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3325 - accuracy: 0.0000e+00 - val_loss: 0.3706 - val_accuracy: 0.0000e+00\n",
            "Epoch 3434/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3361 - accuracy: 0.0000e+00 - val_loss: 0.3705 - val_accuracy: 0.0000e+00\n",
            "Epoch 3435/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3538 - accuracy: 0.0000e+00 - val_loss: 0.3704 - val_accuracy: 0.0000e+00\n",
            "Epoch 3436/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3519 - accuracy: 0.0000e+00 - val_loss: 0.3704 - val_accuracy: 0.0000e+00\n",
            "Epoch 3437/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3383 - accuracy: 0.0000e+00 - val_loss: 0.3704 - val_accuracy: 0.0000e+00\n",
            "Epoch 3438/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3433 - accuracy: 0.0000e+00 - val_loss: 0.3704 - val_accuracy: 0.0000e+00\n",
            "Epoch 3439/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3574 - accuracy: 0.0000e+00 - val_loss: 0.3703 - val_accuracy: 0.0000e+00\n",
            "Epoch 3440/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3425 - accuracy: 0.0000e+00 - val_loss: 0.3703 - val_accuracy: 0.0000e+00\n",
            "Epoch 3441/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3524 - accuracy: 0.0000e+00 - val_loss: 0.3703 - val_accuracy: 0.0000e+00\n",
            "Epoch 3442/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3357 - accuracy: 0.0000e+00 - val_loss: 0.3703 - val_accuracy: 0.0000e+00\n",
            "Epoch 3443/5000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3480 - accuracy: 0.0000e+00 - val_loss: 0.3703 - val_accuracy: 0.0000e+00\n",
            "Epoch 3444/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3431 - accuracy: 0.0000e+00 - val_loss: 0.3703 - val_accuracy: 0.0000e+00\n",
            "Epoch 3445/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3457 - accuracy: 0.0000e+00 - val_loss: 0.3702 - val_accuracy: 0.0000e+00\n",
            "Epoch 3446/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3429 - accuracy: 0.0000e+00 - val_loss: 0.3702 - val_accuracy: 0.0000e+00\n",
            "Epoch 3447/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3409 - accuracy: 0.0000e+00 - val_loss: 0.3703 - val_accuracy: 0.0000e+00\n",
            "Epoch 3448/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3451 - accuracy: 0.0000e+00 - val_loss: 0.3703 - val_accuracy: 0.0000e+00\n",
            "Epoch 3449/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3414 - accuracy: 0.0000e+00 - val_loss: 0.3702 - val_accuracy: 0.0000e+00\n",
            "Epoch 3450/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3382 - accuracy: 0.0000e+00 - val_loss: 0.3702 - val_accuracy: 0.0000e+00\n",
            "Epoch 3451/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3321 - accuracy: 0.0000e+00 - val_loss: 0.3701 - val_accuracy: 0.0000e+00\n",
            "Epoch 3452/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3426 - accuracy: 0.0000e+00 - val_loss: 0.3700 - val_accuracy: 0.0000e+00\n",
            "Epoch 3453/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3365 - accuracy: 0.0000e+00 - val_loss: 0.3700 - val_accuracy: 0.0000e+00\n",
            "Epoch 3454/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3420 - accuracy: 0.0000e+00 - val_loss: 0.3701 - val_accuracy: 0.0000e+00\n",
            "Epoch 3455/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3386 - accuracy: 0.0000e+00 - val_loss: 0.3701 - val_accuracy: 0.0000e+00\n",
            "Epoch 3456/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3376 - accuracy: 0.0000e+00 - val_loss: 0.3701 - val_accuracy: 0.0000e+00\n",
            "Epoch 3457/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3400 - accuracy: 0.0000e+00 - val_loss: 0.3701 - val_accuracy: 0.0000e+00\n",
            "Epoch 3458/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3445 - accuracy: 0.0000e+00 - val_loss: 0.3701 - val_accuracy: 0.0000e+00\n",
            "Epoch 3459/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3359 - accuracy: 0.0000e+00 - val_loss: 0.3701 - val_accuracy: 0.0000e+00\n",
            "Epoch 3460/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3410 - accuracy: 0.0000e+00 - val_loss: 0.3701 - val_accuracy: 0.0000e+00\n",
            "Epoch 3461/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3454 - accuracy: 0.0000e+00 - val_loss: 0.3702 - val_accuracy: 0.0000e+00\n",
            "Epoch 3462/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3484 - accuracy: 0.0000e+00 - val_loss: 0.3702 - val_accuracy: 0.0000e+00\n",
            "Epoch 3463/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3388 - accuracy: 0.0000e+00 - val_loss: 0.3702 - val_accuracy: 0.0000e+00\n",
            "Epoch 3464/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3304 - accuracy: 0.0000e+00 - val_loss: 0.3702 - val_accuracy: 0.0000e+00\n",
            "Epoch 3465/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3414 - accuracy: 0.0000e+00 - val_loss: 0.3702 - val_accuracy: 0.0000e+00\n",
            "Epoch 3466/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3523 - accuracy: 0.0000e+00 - val_loss: 0.3701 - val_accuracy: 0.0000e+00\n",
            "Epoch 3467/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3435 - accuracy: 0.0000e+00 - val_loss: 0.3702 - val_accuracy: 0.0000e+00\n",
            "Epoch 3468/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3391 - accuracy: 0.0000e+00 - val_loss: 0.3702 - val_accuracy: 0.0000e+00\n",
            "Epoch 3469/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3411 - accuracy: 0.0000e+00 - val_loss: 0.3703 - val_accuracy: 0.0000e+00\n",
            "Epoch 3470/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3426 - accuracy: 0.0000e+00 - val_loss: 0.3701 - val_accuracy: 0.0000e+00\n",
            "Epoch 3471/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3371 - accuracy: 0.0000e+00 - val_loss: 0.3701 - val_accuracy: 0.0000e+00\n",
            "Epoch 3472/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3464 - accuracy: 0.0000e+00 - val_loss: 0.3701 - val_accuracy: 0.0000e+00\n",
            "Epoch 3473/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3394 - accuracy: 0.0000e+00 - val_loss: 0.3700 - val_accuracy: 0.0000e+00\n",
            "Epoch 3474/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3455 - accuracy: 0.0000e+00 - val_loss: 0.3700 - val_accuracy: 0.0000e+00\n",
            "Epoch 3475/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3375 - accuracy: 0.0000e+00 - val_loss: 0.3700 - val_accuracy: 0.0000e+00\n",
            "Epoch 3476/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3349 - accuracy: 0.0000e+00 - val_loss: 0.3699 - val_accuracy: 0.0000e+00\n",
            "Epoch 3477/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3479 - accuracy: 0.0000e+00 - val_loss: 0.3699 - val_accuracy: 0.0000e+00\n",
            "Epoch 3478/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3385 - accuracy: 0.0000e+00 - val_loss: 0.3698 - val_accuracy: 0.0000e+00\n",
            "Epoch 3479/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3383 - accuracy: 0.0000e+00 - val_loss: 0.3698 - val_accuracy: 0.0000e+00\n",
            "Epoch 3480/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3365 - accuracy: 0.0000e+00 - val_loss: 0.3698 - val_accuracy: 0.0000e+00\n",
            "Epoch 3481/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3344 - accuracy: 0.0000e+00 - val_loss: 0.3698 - val_accuracy: 0.0000e+00\n",
            "Epoch 3482/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3474 - accuracy: 0.0000e+00 - val_loss: 0.3698 - val_accuracy: 0.0000e+00\n",
            "Epoch 3483/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3427 - accuracy: 0.0000e+00 - val_loss: 0.3698 - val_accuracy: 0.0000e+00\n",
            "Epoch 3484/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3471 - accuracy: 0.0000e+00 - val_loss: 0.3697 - val_accuracy: 0.0000e+00\n",
            "Epoch 3485/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3418 - accuracy: 0.0000e+00 - val_loss: 0.3697 - val_accuracy: 0.0000e+00\n",
            "Epoch 3486/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3465 - accuracy: 0.0000e+00 - val_loss: 0.3697 - val_accuracy: 0.0000e+00\n",
            "Epoch 3487/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3385 - accuracy: 0.0000e+00 - val_loss: 0.3696 - val_accuracy: 0.0000e+00\n",
            "Epoch 3488/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3396 - accuracy: 0.0000e+00 - val_loss: 0.3696 - val_accuracy: 0.0000e+00\n",
            "Epoch 3489/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3386 - accuracy: 0.0000e+00 - val_loss: 0.3695 - val_accuracy: 0.0000e+00\n",
            "Epoch 3490/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3425 - accuracy: 0.0000e+00 - val_loss: 0.3696 - val_accuracy: 0.0000e+00\n",
            "Epoch 3491/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3449 - accuracy: 0.0000e+00 - val_loss: 0.3696 - val_accuracy: 0.0000e+00\n",
            "Epoch 3492/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3354 - accuracy: 0.0000e+00 - val_loss: 0.3697 - val_accuracy: 0.0000e+00\n",
            "Epoch 3493/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3363 - accuracy: 0.0000e+00 - val_loss: 0.3697 - val_accuracy: 0.0000e+00\n",
            "Epoch 3494/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3361 - accuracy: 0.0000e+00 - val_loss: 0.3696 - val_accuracy: 0.0000e+00\n",
            "Epoch 3495/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3429 - accuracy: 0.0000e+00 - val_loss: 0.3697 - val_accuracy: 0.0000e+00\n",
            "Epoch 3496/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3452 - accuracy: 0.0000e+00 - val_loss: 0.3697 - val_accuracy: 0.0000e+00\n",
            "Epoch 3497/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3391 - accuracy: 0.0000e+00 - val_loss: 0.3697 - val_accuracy: 0.0000e+00\n",
            "Epoch 3498/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3395 - accuracy: 0.0000e+00 - val_loss: 0.3697 - val_accuracy: 0.0000e+00\n",
            "Epoch 3499/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3377 - accuracy: 0.0000e+00 - val_loss: 0.3697 - val_accuracy: 0.0000e+00\n",
            "Epoch 3500/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3404 - accuracy: 0.0000e+00 - val_loss: 0.3696 - val_accuracy: 0.0000e+00\n",
            "Epoch 3501/5000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.3388 - accuracy: 0.0000e+00 - val_loss: 0.3695 - val_accuracy: 0.0000e+00\n",
            "Epoch 3502/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3358 - accuracy: 0.0000e+00 - val_loss: 0.3696 - val_accuracy: 0.0000e+00\n",
            "Epoch 3503/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3599 - accuracy: 0.0000e+00 - val_loss: 0.3695 - val_accuracy: 0.0000e+00\n",
            "Epoch 3504/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3455 - accuracy: 0.0000e+00 - val_loss: 0.3695 - val_accuracy: 0.0000e+00\n",
            "Epoch 3505/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3381 - accuracy: 0.0000e+00 - val_loss: 0.3694 - val_accuracy: 0.0000e+00\n",
            "Epoch 3506/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3464 - accuracy: 0.0000e+00 - val_loss: 0.3694 - val_accuracy: 0.0000e+00\n",
            "Epoch 3507/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3413 - accuracy: 0.0000e+00 - val_loss: 0.3693 - val_accuracy: 0.0000e+00\n",
            "Epoch 3508/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.0000e+00 - val_loss: 0.3693 - val_accuracy: 0.0000e+00\n",
            "Epoch 3509/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3395 - accuracy: 0.0000e+00 - val_loss: 0.3693 - val_accuracy: 0.0000e+00\n",
            "Epoch 3510/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3354 - accuracy: 0.0000e+00 - val_loss: 0.3692 - val_accuracy: 0.0000e+00\n",
            "Epoch 3511/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3411 - accuracy: 0.0000e+00 - val_loss: 0.3693 - val_accuracy: 0.0000e+00\n",
            "Epoch 3512/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3485 - accuracy: 0.0000e+00 - val_loss: 0.3692 - val_accuracy: 0.0000e+00\n",
            "Epoch 3513/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3367 - accuracy: 0.0000e+00 - val_loss: 0.3692 - val_accuracy: 0.0000e+00\n",
            "Epoch 3514/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3378 - accuracy: 0.0000e+00 - val_loss: 0.3691 - val_accuracy: 0.0000e+00\n",
            "Epoch 3515/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3292 - accuracy: 0.0000e+00 - val_loss: 0.3690 - val_accuracy: 0.0000e+00\n",
            "Epoch 3516/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3325 - accuracy: 0.0000e+00 - val_loss: 0.3689 - val_accuracy: 0.0000e+00\n",
            "Epoch 3517/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3409 - accuracy: 0.0000e+00 - val_loss: 0.3689 - val_accuracy: 0.0000e+00\n",
            "Epoch 3518/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3418 - accuracy: 0.0000e+00 - val_loss: 0.3688 - val_accuracy: 0.0000e+00\n",
            "Epoch 3519/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3303 - accuracy: 0.0000e+00 - val_loss: 0.3688 - val_accuracy: 0.0000e+00\n",
            "Epoch 3520/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3361 - accuracy: 0.0000e+00 - val_loss: 0.3687 - val_accuracy: 0.0000e+00\n",
            "Epoch 3521/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3370 - accuracy: 0.0000e+00 - val_loss: 0.3687 - val_accuracy: 0.0000e+00\n",
            "Epoch 3522/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3404 - accuracy: 0.0000e+00 - val_loss: 0.3687 - val_accuracy: 0.0000e+00\n",
            "Epoch 3523/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3440 - accuracy: 0.0000e+00 - val_loss: 0.3687 - val_accuracy: 0.0000e+00\n",
            "Epoch 3524/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3398 - accuracy: 0.0000e+00 - val_loss: 0.3687 - val_accuracy: 0.0000e+00\n",
            "Epoch 3525/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3480 - accuracy: 0.0000e+00 - val_loss: 0.3687 - val_accuracy: 0.0000e+00\n",
            "Epoch 3526/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3365 - accuracy: 0.0000e+00 - val_loss: 0.3686 - val_accuracy: 0.0000e+00\n",
            "Epoch 3527/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3304 - accuracy: 0.0000e+00 - val_loss: 0.3686 - val_accuracy: 0.0000e+00\n",
            "Epoch 3528/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3361 - accuracy: 0.0000e+00 - val_loss: 0.3686 - val_accuracy: 0.0000e+00\n",
            "Epoch 3529/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3305 - accuracy: 0.0000e+00 - val_loss: 0.3685 - val_accuracy: 0.0000e+00\n",
            "Epoch 3530/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3337 - accuracy: 0.0000e+00 - val_loss: 0.3685 - val_accuracy: 0.0000e+00\n",
            "Epoch 3531/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3413 - accuracy: 0.0000e+00 - val_loss: 0.3685 - val_accuracy: 0.0000e+00\n",
            "Epoch 3532/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3512 - accuracy: 0.0000e+00 - val_loss: 0.3686 - val_accuracy: 0.0000e+00\n",
            "Epoch 3533/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3398 - accuracy: 0.0000e+00 - val_loss: 0.3686 - val_accuracy: 0.0000e+00\n",
            "Epoch 3534/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3410 - accuracy: 0.0000e+00 - val_loss: 0.3685 - val_accuracy: 0.0000e+00\n",
            "Epoch 3535/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3335 - accuracy: 0.0000e+00 - val_loss: 0.3685 - val_accuracy: 0.0000e+00\n",
            "Epoch 3536/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3329 - accuracy: 0.0000e+00 - val_loss: 0.3684 - val_accuracy: 0.0000e+00\n",
            "Epoch 3537/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3463 - accuracy: 0.0000e+00 - val_loss: 0.3683 - val_accuracy: 0.0000e+00\n",
            "Epoch 3538/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3362 - accuracy: 0.0000e+00 - val_loss: 0.3683 - val_accuracy: 0.0000e+00\n",
            "Epoch 3539/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3347 - accuracy: 0.0000e+00 - val_loss: 0.3684 - val_accuracy: 0.0000e+00\n",
            "Epoch 3540/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3370 - accuracy: 0.0000e+00 - val_loss: 0.3684 - val_accuracy: 0.0000e+00\n",
            "Epoch 3541/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3422 - accuracy: 0.0000e+00 - val_loss: 0.3685 - val_accuracy: 0.0000e+00\n",
            "Epoch 3542/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3420 - accuracy: 0.0000e+00 - val_loss: 0.3684 - val_accuracy: 0.0000e+00\n",
            "Epoch 3543/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3383 - accuracy: 0.0000e+00 - val_loss: 0.3684 - val_accuracy: 0.0000e+00\n",
            "Epoch 3544/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3388 - accuracy: 0.0000e+00 - val_loss: 0.3683 - val_accuracy: 0.0000e+00\n",
            "Epoch 3545/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3323 - accuracy: 0.0000e+00 - val_loss: 0.3683 - val_accuracy: 0.0000e+00\n",
            "Epoch 3546/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3444 - accuracy: 0.0000e+00 - val_loss: 0.3681 - val_accuracy: 0.0000e+00\n",
            "Epoch 3547/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3372 - accuracy: 0.0000e+00 - val_loss: 0.3681 - val_accuracy: 0.0000e+00\n",
            "Epoch 3548/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3381 - accuracy: 0.0000e+00 - val_loss: 0.3680 - val_accuracy: 0.0000e+00\n",
            "Epoch 3549/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3448 - accuracy: 0.0000e+00 - val_loss: 0.3680 - val_accuracy: 0.0000e+00\n",
            "Epoch 3550/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3393 - accuracy: 0.0000e+00 - val_loss: 0.3680 - val_accuracy: 0.0000e+00\n",
            "Epoch 3551/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3400 - accuracy: 0.0000e+00 - val_loss: 0.3680 - val_accuracy: 0.0000e+00\n",
            "Epoch 3552/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3431 - accuracy: 0.0000e+00 - val_loss: 0.3679 - val_accuracy: 0.0000e+00\n",
            "Epoch 3553/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3450 - accuracy: 0.0000e+00 - val_loss: 0.3679 - val_accuracy: 0.0000e+00\n",
            "Epoch 3554/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3412 - accuracy: 0.0000e+00 - val_loss: 0.3679 - val_accuracy: 0.0000e+00\n",
            "Epoch 3555/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3432 - accuracy: 0.0000e+00 - val_loss: 0.3678 - val_accuracy: 0.0000e+00\n",
            "Epoch 3556/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3428 - accuracy: 0.0000e+00 - val_loss: 0.3678 - val_accuracy: 0.0000e+00\n",
            "Epoch 3557/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3433 - accuracy: 0.0000e+00 - val_loss: 0.3678 - val_accuracy: 0.0000e+00\n",
            "Epoch 3558/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3479 - accuracy: 0.0000e+00 - val_loss: 0.3678 - val_accuracy: 0.0000e+00\n",
            "Epoch 3559/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3380 - accuracy: 0.0000e+00 - val_loss: 0.3678 - val_accuracy: 0.0000e+00\n",
            "Epoch 3560/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3407 - accuracy: 0.0000e+00 - val_loss: 0.3677 - val_accuracy: 0.0000e+00\n",
            "Epoch 3561/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3542 - accuracy: 0.0000e+00 - val_loss: 0.3677 - val_accuracy: 0.0000e+00\n",
            "Epoch 3562/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3384 - accuracy: 0.0000e+00 - val_loss: 0.3677 - val_accuracy: 0.0000e+00\n",
            "Epoch 3563/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3342 - accuracy: 0.0000e+00 - val_loss: 0.3677 - val_accuracy: 0.0000e+00\n",
            "Epoch 3564/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3389 - accuracy: 0.0000e+00 - val_loss: 0.3676 - val_accuracy: 0.0000e+00\n",
            "Epoch 3565/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3424 - accuracy: 0.0000e+00 - val_loss: 0.3676 - val_accuracy: 0.0000e+00\n",
            "Epoch 3566/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3430 - accuracy: 0.0000e+00 - val_loss: 0.3675 - val_accuracy: 0.0000e+00\n",
            "Epoch 3567/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3345 - accuracy: 0.0000e+00 - val_loss: 0.3675 - val_accuracy: 0.0000e+00\n",
            "Epoch 3568/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3381 - accuracy: 0.0000e+00 - val_loss: 0.3675 - val_accuracy: 0.0000e+00\n",
            "Epoch 3569/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3385 - accuracy: 0.0000e+00 - val_loss: 0.3675 - val_accuracy: 0.0000e+00\n",
            "Epoch 3570/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3417 - accuracy: 0.0000e+00 - val_loss: 0.3675 - val_accuracy: 0.0000e+00\n",
            "Epoch 3571/5000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3317 - accuracy: 0.0000e+00 - val_loss: 0.3675 - val_accuracy: 0.0000e+00\n",
            "Epoch 3572/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3383 - accuracy: 0.0000e+00 - val_loss: 0.3675 - val_accuracy: 0.0000e+00\n",
            "Epoch 3573/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3345 - accuracy: 0.0000e+00 - val_loss: 0.3675 - val_accuracy: 0.0000e+00\n",
            "Epoch 3574/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3396 - accuracy: 0.0000e+00 - val_loss: 0.3675 - val_accuracy: 0.0000e+00\n",
            "Epoch 3575/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3423 - accuracy: 0.0000e+00 - val_loss: 0.3674 - val_accuracy: 0.0000e+00\n",
            "Epoch 3576/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3373 - accuracy: 0.0000e+00 - val_loss: 0.3673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3577/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3322 - accuracy: 0.0000e+00 - val_loss: 0.3673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3578/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3360 - accuracy: 0.0000e+00 - val_loss: 0.3673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3579/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3373 - accuracy: 0.0000e+00 - val_loss: 0.3673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3580/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3357 - accuracy: 0.0000e+00 - val_loss: 0.3673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3581/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3383 - accuracy: 0.0000e+00 - val_loss: 0.3672 - val_accuracy: 0.0000e+00\n",
            "Epoch 3582/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3428 - accuracy: 0.0000e+00 - val_loss: 0.3672 - val_accuracy: 0.0000e+00\n",
            "Epoch 3583/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3367 - accuracy: 0.0000e+00 - val_loss: 0.3672 - val_accuracy: 0.0000e+00\n",
            "Epoch 3584/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3416 - accuracy: 0.0000e+00 - val_loss: 0.3672 - val_accuracy: 0.0000e+00\n",
            "Epoch 3585/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3448 - accuracy: 0.0000e+00 - val_loss: 0.3673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3586/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3419 - accuracy: 0.0000e+00 - val_loss: 0.3673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3587/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3430 - accuracy: 0.0000e+00 - val_loss: 0.3673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3588/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3356 - accuracy: 0.0000e+00 - val_loss: 0.3673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3589/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3365 - accuracy: 0.0000e+00 - val_loss: 0.3673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3590/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3445 - accuracy: 0.0000e+00 - val_loss: 0.3673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3591/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3319 - accuracy: 0.0000e+00 - val_loss: 0.3674 - val_accuracy: 0.0000e+00\n",
            "Epoch 3592/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3373 - accuracy: 0.0000e+00 - val_loss: 0.3673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3593/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3440 - accuracy: 0.0000e+00 - val_loss: 0.3673 - val_accuracy: 0.0000e+00\n",
            "Epoch 3594/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3406 - accuracy: 0.0000e+00 - val_loss: 0.3671 - val_accuracy: 0.0000e+00\n",
            "Epoch 3595/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3361 - accuracy: 0.0000e+00 - val_loss: 0.3671 - val_accuracy: 0.0000e+00\n",
            "Epoch 3596/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3438 - accuracy: 0.0000e+00 - val_loss: 0.3671 - val_accuracy: 0.0000e+00\n",
            "Epoch 3597/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3306 - accuracy: 0.0000e+00 - val_loss: 0.3670 - val_accuracy: 0.0000e+00\n",
            "Epoch 3598/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3463 - accuracy: 0.0000e+00 - val_loss: 0.3669 - val_accuracy: 0.0000e+00\n",
            "Epoch 3599/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3383 - accuracy: 0.0000e+00 - val_loss: 0.3668 - val_accuracy: 0.0000e+00\n",
            "Epoch 3600/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3432 - accuracy: 0.0000e+00 - val_loss: 0.3668 - val_accuracy: 0.0000e+00\n",
            "Epoch 3601/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3326 - accuracy: 0.0000e+00 - val_loss: 0.3669 - val_accuracy: 0.0000e+00\n",
            "Epoch 3602/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3351 - accuracy: 0.0000e+00 - val_loss: 0.3668 - val_accuracy: 0.0000e+00\n",
            "Epoch 3603/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3402 - accuracy: 0.0000e+00 - val_loss: 0.3667 - val_accuracy: 0.0000e+00\n",
            "Epoch 3604/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3377 - accuracy: 0.0000e+00 - val_loss: 0.3667 - val_accuracy: 0.0000e+00\n",
            "Epoch 3605/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3470 - accuracy: 0.0000e+00 - val_loss: 0.3668 - val_accuracy: 0.0000e+00\n",
            "Epoch 3606/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3332 - accuracy: 0.0000e+00 - val_loss: 0.3667 - val_accuracy: 0.0000e+00\n",
            "Epoch 3607/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3371 - accuracy: 0.0000e+00 - val_loss: 0.3667 - val_accuracy: 0.0000e+00\n",
            "Epoch 3608/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3299 - accuracy: 0.0000e+00 - val_loss: 0.3666 - val_accuracy: 0.0000e+00\n",
            "Epoch 3609/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3343 - accuracy: 0.0000e+00 - val_loss: 0.3666 - val_accuracy: 0.0000e+00\n",
            "Epoch 3610/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3389 - accuracy: 0.0000e+00 - val_loss: 0.3666 - val_accuracy: 0.0000e+00\n",
            "Epoch 3611/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3309 - accuracy: 0.0000e+00 - val_loss: 0.3665 - val_accuracy: 0.0000e+00\n",
            "Epoch 3612/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3296 - accuracy: 0.0000e+00 - val_loss: 0.3664 - val_accuracy: 0.0000e+00\n",
            "Epoch 3613/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3304 - accuracy: 0.0000e+00 - val_loss: 0.3663 - val_accuracy: 0.0000e+00\n",
            "Epoch 3614/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3446 - accuracy: 0.0000e+00 - val_loss: 0.3663 - val_accuracy: 0.0000e+00\n",
            "Epoch 3615/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3344 - accuracy: 0.0000e+00 - val_loss: 0.3664 - val_accuracy: 0.0000e+00\n",
            "Epoch 3616/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3428 - accuracy: 0.0000e+00 - val_loss: 0.3664 - val_accuracy: 0.0000e+00\n",
            "Epoch 3617/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3488 - accuracy: 0.0000e+00 - val_loss: 0.3663 - val_accuracy: 0.0000e+00\n",
            "Epoch 3618/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3389 - accuracy: 0.0000e+00 - val_loss: 0.3662 - val_accuracy: 0.0000e+00\n",
            "Epoch 3619/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3362 - accuracy: 0.0000e+00 - val_loss: 0.3662 - val_accuracy: 0.0000e+00\n",
            "Epoch 3620/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3377 - accuracy: 0.0000e+00 - val_loss: 0.3661 - val_accuracy: 0.0000e+00\n",
            "Epoch 3621/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3384 - accuracy: 0.0000e+00 - val_loss: 0.3661 - val_accuracy: 0.0000e+00\n",
            "Epoch 3622/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3320 - accuracy: 0.0000e+00 - val_loss: 0.3662 - val_accuracy: 0.0000e+00\n",
            "Epoch 3623/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3468 - accuracy: 0.0000e+00 - val_loss: 0.3662 - val_accuracy: 0.0000e+00\n",
            "Epoch 3624/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3390 - accuracy: 0.0000e+00 - val_loss: 0.3662 - val_accuracy: 0.0000e+00\n",
            "Epoch 3625/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3390 - accuracy: 0.0000e+00 - val_loss: 0.3661 - val_accuracy: 0.0000e+00\n",
            "Epoch 3626/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3382 - accuracy: 0.0000e+00 - val_loss: 0.3661 - val_accuracy: 0.0000e+00\n",
            "Epoch 3627/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3368 - accuracy: 0.0000e+00 - val_loss: 0.3661 - val_accuracy: 0.0000e+00\n",
            "Epoch 3628/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3323 - accuracy: 0.0000e+00 - val_loss: 0.3660 - val_accuracy: 0.0000e+00\n",
            "Epoch 3629/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3323 - accuracy: 0.0000e+00 - val_loss: 0.3661 - val_accuracy: 0.0000e+00\n",
            "Epoch 3630/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3375 - accuracy: 0.0000e+00 - val_loss: 0.3660 - val_accuracy: 0.0000e+00\n",
            "Epoch 3631/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3395 - accuracy: 0.0000e+00 - val_loss: 0.3660 - val_accuracy: 0.0000e+00\n",
            "Epoch 3632/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3352 - accuracy: 0.0000e+00 - val_loss: 0.3661 - val_accuracy: 0.0000e+00\n",
            "Epoch 3633/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3349 - accuracy: 0.0000e+00 - val_loss: 0.3661 - val_accuracy: 0.0000e+00\n",
            "Epoch 3634/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3324 - accuracy: 0.0000e+00 - val_loss: 0.3660 - val_accuracy: 0.0000e+00\n",
            "Epoch 3635/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3327 - accuracy: 0.0000e+00 - val_loss: 0.3660 - val_accuracy: 0.0000e+00\n",
            "Epoch 3636/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3374 - accuracy: 0.0000e+00 - val_loss: 0.3661 - val_accuracy: 0.0000e+00\n",
            "Epoch 3637/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3365 - accuracy: 0.0000e+00 - val_loss: 0.3660 - val_accuracy: 0.0000e+00\n",
            "Epoch 3638/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3436 - accuracy: 0.0000e+00 - val_loss: 0.3660 - val_accuracy: 0.0000e+00\n",
            "Epoch 3639/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3359 - accuracy: 0.0000e+00 - val_loss: 0.3660 - val_accuracy: 0.0000e+00\n",
            "Epoch 3640/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3406 - accuracy: 0.0000e+00 - val_loss: 0.3659 - val_accuracy: 0.0000e+00\n",
            "Epoch 3641/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3425 - accuracy: 0.0000e+00 - val_loss: 0.3660 - val_accuracy: 0.0000e+00\n",
            "Epoch 3642/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3306 - accuracy: 0.0000e+00 - val_loss: 0.3660 - val_accuracy: 0.0000e+00\n",
            "Epoch 3643/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3391 - accuracy: 0.0000e+00 - val_loss: 0.3659 - val_accuracy: 0.0000e+00\n",
            "Epoch 3644/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3272 - accuracy: 0.0000e+00 - val_loss: 0.3659 - val_accuracy: 0.0000e+00\n",
            "Epoch 3645/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3278 - accuracy: 0.0000e+00 - val_loss: 0.3658 - val_accuracy: 0.0000e+00\n",
            "Epoch 3646/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3425 - accuracy: 0.0000e+00 - val_loss: 0.3658 - val_accuracy: 0.0000e+00\n",
            "Epoch 3647/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3377 - accuracy: 0.0000e+00 - val_loss: 0.3657 - val_accuracy: 0.0000e+00\n",
            "Epoch 3648/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3665 - accuracy: 0.0000e+00 - val_loss: 0.3657 - val_accuracy: 0.0000e+00\n",
            "Epoch 3649/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3329 - accuracy: 0.0000e+00 - val_loss: 0.3656 - val_accuracy: 0.0000e+00\n",
            "Epoch 3650/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3390 - accuracy: 0.0000e+00 - val_loss: 0.3657 - val_accuracy: 0.0000e+00\n",
            "Epoch 3651/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3338 - accuracy: 0.0000e+00 - val_loss: 0.3656 - val_accuracy: 0.0000e+00\n",
            "Epoch 3652/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3406 - accuracy: 0.0000e+00 - val_loss: 0.3656 - val_accuracy: 0.0000e+00\n",
            "Epoch 3653/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3431 - accuracy: 0.0000e+00 - val_loss: 0.3656 - val_accuracy: 0.0000e+00\n",
            "Epoch 3654/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3350 - accuracy: 0.0000e+00 - val_loss: 0.3654 - val_accuracy: 0.0000e+00\n",
            "Epoch 3655/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3394 - accuracy: 0.0000e+00 - val_loss: 0.3654 - val_accuracy: 0.0000e+00\n",
            "Epoch 3656/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3343 - accuracy: 0.0000e+00 - val_loss: 0.3654 - val_accuracy: 0.0000e+00\n",
            "Epoch 3657/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3575 - accuracy: 0.0000e+00 - val_loss: 0.3654 - val_accuracy: 0.0000e+00\n",
            "Epoch 3658/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3374 - accuracy: 0.0000e+00 - val_loss: 0.3654 - val_accuracy: 0.0000e+00\n",
            "Epoch 3659/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3356 - accuracy: 0.0000e+00 - val_loss: 0.3655 - val_accuracy: 0.0000e+00\n",
            "Epoch 3660/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3436 - accuracy: 0.0000e+00 - val_loss: 0.3655 - val_accuracy: 0.0000e+00\n",
            "Epoch 3661/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3345 - accuracy: 0.0000e+00 - val_loss: 0.3654 - val_accuracy: 0.0000e+00\n",
            "Epoch 3662/5000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3367 - accuracy: 0.0000e+00 - val_loss: 0.3655 - val_accuracy: 0.0000e+00\n",
            "Epoch 3663/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.0000e+00 - val_loss: 0.3654 - val_accuracy: 0.0000e+00\n",
            "Epoch 3664/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3311 - accuracy: 0.0000e+00 - val_loss: 0.3654 - val_accuracy: 0.0000e+00\n",
            "Epoch 3665/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3376 - accuracy: 0.0000e+00 - val_loss: 0.3654 - val_accuracy: 0.0000e+00\n",
            "Epoch 3666/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3355 - accuracy: 0.0000e+00 - val_loss: 0.3654 - val_accuracy: 0.0000e+00\n",
            "Epoch 3667/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3331 - accuracy: 0.0000e+00 - val_loss: 0.3653 - val_accuracy: 0.0000e+00\n",
            "Epoch 3668/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3406 - accuracy: 0.0000e+00 - val_loss: 0.3653 - val_accuracy: 0.0000e+00\n",
            "Epoch 3669/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3402 - accuracy: 0.0000e+00 - val_loss: 0.3654 - val_accuracy: 0.0000e+00\n",
            "Epoch 3670/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3365 - accuracy: 0.0000e+00 - val_loss: 0.3653 - val_accuracy: 0.0000e+00\n",
            "Epoch 3671/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3293 - accuracy: 0.0000e+00 - val_loss: 0.3653 - val_accuracy: 0.0000e+00\n",
            "Epoch 3672/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3389 - accuracy: 0.0000e+00 - val_loss: 0.3654 - val_accuracy: 0.0000e+00\n",
            "Epoch 3673/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3332 - accuracy: 0.0000e+00 - val_loss: 0.3654 - val_accuracy: 0.0000e+00\n",
            "Epoch 3674/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3452 - accuracy: 0.0000e+00 - val_loss: 0.3654 - val_accuracy: 0.0000e+00\n",
            "Epoch 3675/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3372 - accuracy: 0.0000e+00 - val_loss: 0.3653 - val_accuracy: 0.0000e+00\n",
            "Epoch 3676/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3401 - accuracy: 0.0000e+00 - val_loss: 0.3652 - val_accuracy: 0.0000e+00\n",
            "Epoch 3677/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3341 - accuracy: 0.0000e+00 - val_loss: 0.3653 - val_accuracy: 0.0000e+00\n",
            "Epoch 3678/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3324 - accuracy: 0.0000e+00 - val_loss: 0.3652 - val_accuracy: 0.0000e+00\n",
            "Epoch 3679/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3315 - accuracy: 0.0000e+00 - val_loss: 0.3652 - val_accuracy: 0.0000e+00\n",
            "Epoch 3680/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3303 - accuracy: 0.0000e+00 - val_loss: 0.3653 - val_accuracy: 0.0000e+00\n",
            "Epoch 3681/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3287 - accuracy: 0.0000e+00 - val_loss: 0.3652 - val_accuracy: 0.0000e+00\n",
            "Epoch 3682/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3452 - accuracy: 0.0000e+00 - val_loss: 0.3652 - val_accuracy: 0.0000e+00\n",
            "Epoch 3683/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3405 - accuracy: 0.0000e+00 - val_loss: 0.3652 - val_accuracy: 0.0000e+00\n",
            "Epoch 3684/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3450 - accuracy: 0.0000e+00 - val_loss: 0.3651 - val_accuracy: 0.0000e+00\n",
            "Epoch 3685/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3374 - accuracy: 0.0000e+00 - val_loss: 0.3651 - val_accuracy: 0.0000e+00\n",
            "Epoch 3686/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3320 - accuracy: 0.0000e+00 - val_loss: 0.3650 - val_accuracy: 0.0000e+00\n",
            "Epoch 3687/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3350 - accuracy: 0.0000e+00 - val_loss: 0.3649 - val_accuracy: 0.0000e+00\n",
            "Epoch 3688/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3342 - accuracy: 0.0000e+00 - val_loss: 0.3648 - val_accuracy: 0.0000e+00\n",
            "Epoch 3689/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3282 - accuracy: 0.0000e+00 - val_loss: 0.3647 - val_accuracy: 0.0000e+00\n",
            "Epoch 3690/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3538 - accuracy: 0.0000e+00 - val_loss: 0.3646 - val_accuracy: 0.0000e+00\n",
            "Epoch 3691/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3354 - accuracy: 0.0000e+00 - val_loss: 0.3645 - val_accuracy: 0.0000e+00\n",
            "Epoch 3692/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3341 - accuracy: 0.0000e+00 - val_loss: 0.3644 - val_accuracy: 0.0000e+00\n",
            "Epoch 3693/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3318 - accuracy: 0.0000e+00 - val_loss: 0.3643 - val_accuracy: 0.0000e+00\n",
            "Epoch 3694/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3460 - accuracy: 0.0000e+00 - val_loss: 0.3644 - val_accuracy: 0.0000e+00\n",
            "Epoch 3695/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3310 - accuracy: 0.0000e+00 - val_loss: 0.3645 - val_accuracy: 0.0000e+00\n",
            "Epoch 3696/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3402 - accuracy: 0.0000e+00 - val_loss: 0.3644 - val_accuracy: 0.0000e+00\n",
            "Epoch 3697/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3313 - accuracy: 0.0000e+00 - val_loss: 0.3644 - val_accuracy: 0.0000e+00\n",
            "Epoch 3698/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3433 - accuracy: 0.0000e+00 - val_loss: 0.3643 - val_accuracy: 0.0000e+00\n",
            "Epoch 3699/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3314 - accuracy: 0.0000e+00 - val_loss: 0.3643 - val_accuracy: 0.0000e+00\n",
            "Epoch 3700/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3359 - accuracy: 0.0000e+00 - val_loss: 0.3642 - val_accuracy: 0.0000e+00\n",
            "Epoch 3701/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3316 - accuracy: 0.0000e+00 - val_loss: 0.3642 - val_accuracy: 0.0000e+00\n",
            "Epoch 3702/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3314 - accuracy: 0.0000e+00 - val_loss: 0.3643 - val_accuracy: 0.0000e+00\n",
            "Epoch 3703/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3309 - accuracy: 0.0000e+00 - val_loss: 0.3642 - val_accuracy: 0.0000e+00\n",
            "Epoch 3704/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3360 - accuracy: 0.0000e+00 - val_loss: 0.3642 - val_accuracy: 0.0000e+00\n",
            "Epoch 3705/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3404 - accuracy: 0.0000e+00 - val_loss: 0.3642 - val_accuracy: 0.0000e+00\n",
            "Epoch 3706/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3338 - accuracy: 0.0000e+00 - val_loss: 0.3642 - val_accuracy: 0.0000e+00\n",
            "Epoch 3707/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3403 - accuracy: 0.0000e+00 - val_loss: 0.3641 - val_accuracy: 0.0000e+00\n",
            "Epoch 3708/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3247 - accuracy: 0.0000e+00 - val_loss: 0.3641 - val_accuracy: 0.0000e+00\n",
            "Epoch 3709/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3347 - accuracy: 0.0000e+00 - val_loss: 0.3640 - val_accuracy: 0.0000e+00\n",
            "Epoch 3710/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3320 - accuracy: 0.0000e+00 - val_loss: 0.3640 - val_accuracy: 0.0000e+00\n",
            "Epoch 3711/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3258 - accuracy: 0.0000e+00 - val_loss: 0.3640 - val_accuracy: 0.0000e+00\n",
            "Epoch 3712/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3358 - accuracy: 0.0000e+00 - val_loss: 0.3639 - val_accuracy: 0.0000e+00\n",
            "Epoch 3713/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3387 - accuracy: 0.0000e+00 - val_loss: 0.3640 - val_accuracy: 0.0000e+00\n",
            "Epoch 3714/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3388 - accuracy: 0.0000e+00 - val_loss: 0.3640 - val_accuracy: 0.0000e+00\n",
            "Epoch 3715/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3352 - accuracy: 0.0000e+00 - val_loss: 0.3640 - val_accuracy: 0.0000e+00\n",
            "Epoch 3716/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3268 - accuracy: 0.0000e+00 - val_loss: 0.3639 - val_accuracy: 0.0000e+00\n",
            "Epoch 3717/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3448 - accuracy: 0.0000e+00 - val_loss: 0.3639 - val_accuracy: 0.0000e+00\n",
            "Epoch 3718/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3309 - accuracy: 0.0000e+00 - val_loss: 0.3639 - val_accuracy: 0.0000e+00\n",
            "Epoch 3719/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3336 - accuracy: 0.0000e+00 - val_loss: 0.3639 - val_accuracy: 0.0000e+00\n",
            "Epoch 3720/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3388 - accuracy: 0.0000e+00 - val_loss: 0.3638 - val_accuracy: 0.0000e+00\n",
            "Epoch 3721/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3340 - accuracy: 0.0000e+00 - val_loss: 0.3638 - val_accuracy: 0.0000e+00\n",
            "Epoch 3722/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3411 - accuracy: 0.0000e+00 - val_loss: 0.3637 - val_accuracy: 0.0000e+00\n",
            "Epoch 3723/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3412 - accuracy: 0.0000e+00 - val_loss: 0.3637 - val_accuracy: 0.0000e+00\n",
            "Epoch 3724/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3329 - accuracy: 0.0000e+00 - val_loss: 0.3637 - val_accuracy: 0.0000e+00\n",
            "Epoch 3725/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3359 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3726/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3300 - accuracy: 0.0000e+00 - val_loss: 0.3635 - val_accuracy: 0.0000e+00\n",
            "Epoch 3727/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3345 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3728/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3354 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3729/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3350 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3730/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3401 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3731/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3354 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3732/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3337 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3733/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3294 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3734/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3311 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3735/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3322 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3736/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3354 - accuracy: 0.0000e+00 - val_loss: 0.3637 - val_accuracy: 0.0000e+00\n",
            "Epoch 3737/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3395 - accuracy: 0.0000e+00 - val_loss: 0.3637 - val_accuracy: 0.0000e+00\n",
            "Epoch 3738/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3314 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3739/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3343 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3740/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3302 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3741/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3387 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3742/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3379 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3743/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3343 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3744/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3423 - accuracy: 0.0000e+00 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3745/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3278 - accuracy: 0.0000e+00 - val_loss: 0.3635 - val_accuracy: 0.0000e+00\n",
            "Epoch 3746/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3381 - accuracy: 0.0000e+00 - val_loss: 0.3635 - val_accuracy: 0.0000e+00\n",
            "Epoch 3747/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3311 - accuracy: 0.0000e+00 - val_loss: 0.3635 - val_accuracy: 0.0000e+00\n",
            "Epoch 3748/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3409 - accuracy: 0.0000e+00 - val_loss: 0.3634 - val_accuracy: 0.0000e+00\n",
            "Epoch 3749/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3329 - accuracy: 0.0000e+00 - val_loss: 0.3632 - val_accuracy: 0.0000e+00\n",
            "Epoch 3750/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3336 - accuracy: 0.0000e+00 - val_loss: 0.3632 - val_accuracy: 0.0000e+00\n",
            "Epoch 3751/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3381 - accuracy: 0.0000e+00 - val_loss: 0.3632 - val_accuracy: 0.0000e+00\n",
            "Epoch 3752/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3360 - accuracy: 0.0000e+00 - val_loss: 0.3632 - val_accuracy: 0.0000e+00\n",
            "Epoch 3753/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3437 - accuracy: 0.0000e+00 - val_loss: 0.3632 - val_accuracy: 0.0000e+00\n",
            "Epoch 3754/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3412 - accuracy: 0.0000e+00 - val_loss: 0.3632 - val_accuracy: 0.0000e+00\n",
            "Epoch 3755/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3326 - accuracy: 0.0000e+00 - val_loss: 0.3631 - val_accuracy: 0.0000e+00\n",
            "Epoch 3756/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3419 - accuracy: 0.0000e+00 - val_loss: 0.3632 - val_accuracy: 0.0000e+00\n",
            "Epoch 3757/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3364 - accuracy: 0.0000e+00 - val_loss: 0.3632 - val_accuracy: 0.0000e+00\n",
            "Epoch 3758/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3323 - accuracy: 0.0000e+00 - val_loss: 0.3631 - val_accuracy: 0.0000e+00\n",
            "Epoch 3759/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3348 - accuracy: 0.0000e+00 - val_loss: 0.3632 - val_accuracy: 0.0000e+00\n",
            "Epoch 3760/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3429 - accuracy: 0.0000e+00 - val_loss: 0.3631 - val_accuracy: 0.0000e+00\n",
            "Epoch 3761/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3405 - accuracy: 0.0000e+00 - val_loss: 0.3631 - val_accuracy: 0.0000e+00\n",
            "Epoch 3762/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3402 - accuracy: 0.0000e+00 - val_loss: 0.3630 - val_accuracy: 0.0000e+00\n",
            "Epoch 3763/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3354 - accuracy: 0.0000e+00 - val_loss: 0.3629 - val_accuracy: 0.0000e+00\n",
            "Epoch 3764/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3332 - accuracy: 0.0000e+00 - val_loss: 0.3628 - val_accuracy: 0.0000e+00\n",
            "Epoch 3765/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3329 - accuracy: 0.0000e+00 - val_loss: 0.3627 - val_accuracy: 0.0000e+00\n",
            "Epoch 3766/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3306 - accuracy: 0.0000e+00 - val_loss: 0.3628 - val_accuracy: 0.0000e+00\n",
            "Epoch 3767/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3354 - accuracy: 0.0000e+00 - val_loss: 0.3628 - val_accuracy: 0.0000e+00\n",
            "Epoch 3768/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3418 - accuracy: 0.0000e+00 - val_loss: 0.3628 - val_accuracy: 0.0000e+00\n",
            "Epoch 3769/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3395 - accuracy: 0.0000e+00 - val_loss: 0.3628 - val_accuracy: 0.0000e+00\n",
            "Epoch 3770/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3298 - accuracy: 0.0000e+00 - val_loss: 0.3627 - val_accuracy: 0.0000e+00\n",
            "Epoch 3771/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3377 - accuracy: 0.0000e+00 - val_loss: 0.3627 - val_accuracy: 0.0000e+00\n",
            "Epoch 3772/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3405 - accuracy: 0.0000e+00 - val_loss: 0.3626 - val_accuracy: 0.0000e+00\n",
            "Epoch 3773/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3340 - accuracy: 0.0000e+00 - val_loss: 0.3626 - val_accuracy: 0.0000e+00\n",
            "Epoch 3774/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3294 - accuracy: 0.0000e+00 - val_loss: 0.3626 - val_accuracy: 0.0000e+00\n",
            "Epoch 3775/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3334 - accuracy: 0.0000e+00 - val_loss: 0.3626 - val_accuracy: 0.0000e+00\n",
            "Epoch 3776/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3417 - accuracy: 0.0000e+00 - val_loss: 0.3626 - val_accuracy: 0.0000e+00\n",
            "Epoch 3777/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3306 - accuracy: 0.0000e+00 - val_loss: 0.3626 - val_accuracy: 0.0000e+00\n",
            "Epoch 3778/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3291 - accuracy: 0.0000e+00 - val_loss: 0.3625 - val_accuracy: 0.0000e+00\n",
            "Epoch 3779/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3351 - accuracy: 0.0000e+00 - val_loss: 0.3626 - val_accuracy: 0.0000e+00\n",
            "Epoch 3780/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3322 - accuracy: 0.0000e+00 - val_loss: 0.3626 - val_accuracy: 0.0000e+00\n",
            "Epoch 3781/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3348 - accuracy: 0.0000e+00 - val_loss: 0.3626 - val_accuracy: 0.0000e+00\n",
            "Epoch 3782/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3345 - accuracy: 0.0000e+00 - val_loss: 0.3626 - val_accuracy: 0.0000e+00\n",
            "Epoch 3783/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3384 - accuracy: 0.0000e+00 - val_loss: 0.3624 - val_accuracy: 0.0000e+00\n",
            "Epoch 3784/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3316 - accuracy: 0.0000e+00 - val_loss: 0.3624 - val_accuracy: 0.0000e+00\n",
            "Epoch 3785/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3445 - accuracy: 0.0000e+00 - val_loss: 0.3623 - val_accuracy: 0.0000e+00\n",
            "Epoch 3786/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3316 - accuracy: 0.0000e+00 - val_loss: 0.3623 - val_accuracy: 0.0000e+00\n",
            "Epoch 3787/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3394 - accuracy: 0.0000e+00 - val_loss: 0.3623 - val_accuracy: 0.0000e+00\n",
            "Epoch 3788/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3300 - accuracy: 0.0000e+00 - val_loss: 0.3622 - val_accuracy: 0.0000e+00\n",
            "Epoch 3789/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3325 - accuracy: 0.0000e+00 - val_loss: 0.3622 - val_accuracy: 0.0000e+00\n",
            "Epoch 3790/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3329 - accuracy: 0.0000e+00 - val_loss: 0.3623 - val_accuracy: 0.0000e+00\n",
            "Epoch 3791/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3379 - accuracy: 0.0000e+00 - val_loss: 0.3623 - val_accuracy: 0.0000e+00\n",
            "Epoch 3792/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3285 - accuracy: 0.0000e+00 - val_loss: 0.3622 - val_accuracy: 0.0000e+00\n",
            "Epoch 3793/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3335 - accuracy: 0.0000e+00 - val_loss: 0.3622 - val_accuracy: 0.0000e+00\n",
            "Epoch 3794/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3339 - accuracy: 0.0000e+00 - val_loss: 0.3622 - val_accuracy: 0.0000e+00\n",
            "Epoch 3795/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3347 - accuracy: 0.0000e+00 - val_loss: 0.3621 - val_accuracy: 0.0000e+00\n",
            "Epoch 3796/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3298 - accuracy: 0.0000e+00 - val_loss: 0.3621 - val_accuracy: 0.0000e+00\n",
            "Epoch 3797/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3435 - accuracy: 0.0000e+00 - val_loss: 0.3621 - val_accuracy: 0.0000e+00\n",
            "Epoch 3798/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3329 - accuracy: 0.0000e+00 - val_loss: 0.3621 - val_accuracy: 0.0000e+00\n",
            "Epoch 3799/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3234 - accuracy: 0.0000e+00 - val_loss: 0.3622 - val_accuracy: 0.0000e+00\n",
            "Epoch 3800/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3340 - accuracy: 0.0000e+00 - val_loss: 0.3622 - val_accuracy: 0.0000e+00\n",
            "Epoch 3801/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3350 - accuracy: 0.0000e+00 - val_loss: 0.3621 - val_accuracy: 0.0000e+00\n",
            "Epoch 3802/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3348 - accuracy: 0.0000e+00 - val_loss: 0.3621 - val_accuracy: 0.0000e+00\n",
            "Epoch 3803/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3338 - accuracy: 0.0000e+00 - val_loss: 0.3619 - val_accuracy: 0.0000e+00\n",
            "Epoch 3804/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3385 - accuracy: 0.0000e+00 - val_loss: 0.3619 - val_accuracy: 0.0000e+00\n",
            "Epoch 3805/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3315 - accuracy: 0.0000e+00 - val_loss: 0.3619 - val_accuracy: 0.0000e+00\n",
            "Epoch 3806/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3240 - accuracy: 0.0000e+00 - val_loss: 0.3618 - val_accuracy: 0.0000e+00\n",
            "Epoch 3807/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3312 - accuracy: 0.0000e+00 - val_loss: 0.3618 - val_accuracy: 0.0000e+00\n",
            "Epoch 3808/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3368 - accuracy: 0.0000e+00 - val_loss: 0.3618 - val_accuracy: 0.0000e+00\n",
            "Epoch 3809/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3304 - accuracy: 0.0000e+00 - val_loss: 0.3618 - val_accuracy: 0.0000e+00\n",
            "Epoch 3810/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3342 - accuracy: 0.0000e+00 - val_loss: 0.3618 - val_accuracy: 0.0000e+00\n",
            "Epoch 3811/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3364 - accuracy: 0.0000e+00 - val_loss: 0.3618 - val_accuracy: 0.0000e+00\n",
            "Epoch 3812/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3319 - accuracy: 0.0000e+00 - val_loss: 0.3617 - val_accuracy: 0.0000e+00\n",
            "Epoch 3813/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3274 - accuracy: 0.0000e+00 - val_loss: 0.3617 - val_accuracy: 0.0000e+00\n",
            "Epoch 3814/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3360 - accuracy: 0.0000e+00 - val_loss: 0.3616 - val_accuracy: 0.0000e+00\n",
            "Epoch 3815/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3374 - accuracy: 0.0000e+00 - val_loss: 0.3616 - val_accuracy: 0.0000e+00\n",
            "Epoch 3816/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3331 - accuracy: 0.0000e+00 - val_loss: 0.3616 - val_accuracy: 0.0000e+00\n",
            "Epoch 3817/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3351 - accuracy: 0.0000e+00 - val_loss: 0.3616 - val_accuracy: 0.0000e+00\n",
            "Epoch 3818/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3413 - accuracy: 0.0000e+00 - val_loss: 0.3616 - val_accuracy: 0.0000e+00\n",
            "Epoch 3819/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3303 - accuracy: 0.0000e+00 - val_loss: 0.3616 - val_accuracy: 0.0000e+00\n",
            "Epoch 3820/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3288 - accuracy: 0.0000e+00 - val_loss: 0.3615 - val_accuracy: 0.0000e+00\n",
            "Epoch 3821/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3260 - accuracy: 0.0000e+00 - val_loss: 0.3614 - val_accuracy: 0.0000e+00\n",
            "Epoch 3822/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3245 - accuracy: 0.0000e+00 - val_loss: 0.3614 - val_accuracy: 0.0000e+00\n",
            "Epoch 3823/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3334 - accuracy: 0.0000e+00 - val_loss: 0.3614 - val_accuracy: 0.0000e+00\n",
            "Epoch 3824/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3373 - accuracy: 0.0000e+00 - val_loss: 0.3614 - val_accuracy: 0.0000e+00\n",
            "Epoch 3825/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3304 - accuracy: 0.0000e+00 - val_loss: 0.3614 - val_accuracy: 0.0000e+00\n",
            "Epoch 3826/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3307 - accuracy: 0.0000e+00 - val_loss: 0.3614 - val_accuracy: 0.0000e+00\n",
            "Epoch 3827/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3242 - accuracy: 0.0000e+00 - val_loss: 0.3613 - val_accuracy: 0.0000e+00\n",
            "Epoch 3828/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3297 - accuracy: 0.0000e+00 - val_loss: 0.3613 - val_accuracy: 0.0000e+00\n",
            "Epoch 3829/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3285 - accuracy: 0.0000e+00 - val_loss: 0.3613 - val_accuracy: 0.0000e+00\n",
            "Epoch 3830/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3342 - accuracy: 0.0000e+00 - val_loss: 0.3613 - val_accuracy: 0.0000e+00\n",
            "Epoch 3831/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3340 - accuracy: 0.0000e+00 - val_loss: 0.3613 - val_accuracy: 0.0000e+00\n",
            "Epoch 3832/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3309 - accuracy: 0.0000e+00 - val_loss: 0.3613 - val_accuracy: 0.0000e+00\n",
            "Epoch 3833/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3328 - accuracy: 0.0000e+00 - val_loss: 0.3613 - val_accuracy: 0.0000e+00\n",
            "Epoch 3834/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3298 - accuracy: 0.0000e+00 - val_loss: 0.3612 - val_accuracy: 0.0000e+00\n",
            "Epoch 3835/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3412 - accuracy: 0.0000e+00 - val_loss: 0.3613 - val_accuracy: 0.0000e+00\n",
            "Epoch 3836/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3316 - accuracy: 0.0000e+00 - val_loss: 0.3611 - val_accuracy: 0.0000e+00\n",
            "Epoch 3837/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3325 - accuracy: 0.0000e+00 - val_loss: 0.3612 - val_accuracy: 0.0000e+00\n",
            "Epoch 3838/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3309 - accuracy: 0.0000e+00 - val_loss: 0.3612 - val_accuracy: 0.0000e+00\n",
            "Epoch 3839/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3384 - accuracy: 0.0000e+00 - val_loss: 0.3612 - val_accuracy: 0.0000e+00\n",
            "Epoch 3840/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3338 - accuracy: 0.0000e+00 - val_loss: 0.3611 - val_accuracy: 0.0000e+00\n",
            "Epoch 3841/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3322 - accuracy: 0.0000e+00 - val_loss: 0.3611 - val_accuracy: 0.0000e+00\n",
            "Epoch 3842/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3235 - accuracy: 0.0000e+00 - val_loss: 0.3611 - val_accuracy: 0.0000e+00\n",
            "Epoch 3843/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3346 - accuracy: 0.0000e+00 - val_loss: 0.3611 - val_accuracy: 0.0000e+00\n",
            "Epoch 3844/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3318 - accuracy: 0.0000e+00 - val_loss: 0.3611 - val_accuracy: 0.0000e+00\n",
            "Epoch 3845/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3399 - accuracy: 0.0000e+00 - val_loss: 0.3610 - val_accuracy: 0.0000e+00\n",
            "Epoch 3846/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3318 - accuracy: 0.0000e+00 - val_loss: 0.3610 - val_accuracy: 0.0000e+00\n",
            "Epoch 3847/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3350 - accuracy: 0.0000e+00 - val_loss: 0.3610 - val_accuracy: 0.0000e+00\n",
            "Epoch 3848/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3276 - accuracy: 0.0000e+00 - val_loss: 0.3610 - val_accuracy: 0.0000e+00\n",
            "Epoch 3849/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3343 - accuracy: 0.0000e+00 - val_loss: 0.3609 - val_accuracy: 0.0000e+00\n",
            "Epoch 3850/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3333 - accuracy: 0.0000e+00 - val_loss: 0.3610 - val_accuracy: 0.0000e+00\n",
            "Epoch 3851/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3402 - accuracy: 0.0000e+00 - val_loss: 0.3610 - val_accuracy: 0.0000e+00\n",
            "Epoch 3852/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3395 - accuracy: 0.0000e+00 - val_loss: 0.3611 - val_accuracy: 0.0000e+00\n",
            "Epoch 3853/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3281 - accuracy: 0.0000e+00 - val_loss: 0.3610 - val_accuracy: 0.0000e+00\n",
            "Epoch 3854/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3352 - accuracy: 0.0000e+00 - val_loss: 0.3609 - val_accuracy: 0.0000e+00\n",
            "Epoch 3855/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3264 - accuracy: 0.0000e+00 - val_loss: 0.3608 - val_accuracy: 0.0000e+00\n",
            "Epoch 3856/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3271 - accuracy: 0.0000e+00 - val_loss: 0.3607 - val_accuracy: 0.0000e+00\n",
            "Epoch 3857/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3279 - accuracy: 0.0000e+00 - val_loss: 0.3607 - val_accuracy: 0.0000e+00\n",
            "Epoch 3858/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3406 - accuracy: 0.0000e+00 - val_loss: 0.3607 - val_accuracy: 0.0000e+00\n",
            "Epoch 3859/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3402 - accuracy: 0.0000e+00 - val_loss: 0.3606 - val_accuracy: 0.0000e+00\n",
            "Epoch 3860/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3315 - accuracy: 0.0000e+00 - val_loss: 0.3605 - val_accuracy: 0.0000e+00\n",
            "Epoch 3861/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3291 - accuracy: 0.0000e+00 - val_loss: 0.3604 - val_accuracy: 0.0000e+00\n",
            "Epoch 3862/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3287 - accuracy: 0.0000e+00 - val_loss: 0.3604 - val_accuracy: 0.0000e+00\n",
            "Epoch 3863/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3211 - accuracy: 0.0000e+00 - val_loss: 0.3604 - val_accuracy: 0.0000e+00\n",
            "Epoch 3864/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3278 - accuracy: 0.0000e+00 - val_loss: 0.3604 - val_accuracy: 0.0000e+00\n",
            "Epoch 3865/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3262 - accuracy: 0.0000e+00 - val_loss: 0.3604 - val_accuracy: 0.0000e+00\n",
            "Epoch 3866/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3338 - accuracy: 0.0000e+00 - val_loss: 0.3605 - val_accuracy: 0.0000e+00\n",
            "Epoch 3867/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3292 - accuracy: 0.0000e+00 - val_loss: 0.3605 - val_accuracy: 0.0000e+00\n",
            "Epoch 3868/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3341 - accuracy: 0.0000e+00 - val_loss: 0.3605 - val_accuracy: 0.0000e+00\n",
            "Epoch 3869/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3399 - accuracy: 0.0000e+00 - val_loss: 0.3605 - val_accuracy: 0.0000e+00\n",
            "Epoch 3870/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3342 - accuracy: 0.0000e+00 - val_loss: 0.3606 - val_accuracy: 0.0000e+00\n",
            "Epoch 3871/5000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3308 - accuracy: 0.0000e+00 - val_loss: 0.3605 - val_accuracy: 0.0000e+00\n",
            "Epoch 3872/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3341 - accuracy: 0.0000e+00 - val_loss: 0.3605 - val_accuracy: 0.0000e+00\n",
            "Epoch 3873/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3280 - accuracy: 0.0000e+00 - val_loss: 0.3605 - val_accuracy: 0.0000e+00\n",
            "Epoch 3874/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3261 - accuracy: 0.0000e+00 - val_loss: 0.3605 - val_accuracy: 0.0000e+00\n",
            "Epoch 3875/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.0000e+00 - val_loss: 0.3603 - val_accuracy: 0.0000e+00\n",
            "Epoch 3876/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3314 - accuracy: 0.0000e+00 - val_loss: 0.3603 - val_accuracy: 0.0000e+00\n",
            "Epoch 3877/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3240 - accuracy: 0.0000e+00 - val_loss: 0.3604 - val_accuracy: 0.0000e+00\n",
            "Epoch 3878/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3302 - accuracy: 0.0000e+00 - val_loss: 0.3604 - val_accuracy: 0.0000e+00\n",
            "Epoch 3879/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3472 - accuracy: 0.0000e+00 - val_loss: 0.3604 - val_accuracy: 0.0000e+00\n",
            "Epoch 3880/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3316 - accuracy: 0.0000e+00 - val_loss: 0.3604 - val_accuracy: 0.0000e+00\n",
            "Epoch 3881/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3407 - accuracy: 0.0000e+00 - val_loss: 0.3605 - val_accuracy: 0.0000e+00\n",
            "Epoch 3882/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3272 - accuracy: 0.0000e+00 - val_loss: 0.3604 - val_accuracy: 0.0000e+00\n",
            "Epoch 3883/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3277 - accuracy: 0.0000e+00 - val_loss: 0.3604 - val_accuracy: 0.0000e+00\n",
            "Epoch 3884/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3302 - accuracy: 0.0000e+00 - val_loss: 0.3602 - val_accuracy: 0.0000e+00\n",
            "Epoch 3885/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3440 - accuracy: 0.0000e+00 - val_loss: 0.3602 - val_accuracy: 0.0000e+00\n",
            "Epoch 3886/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3261 - accuracy: 0.0000e+00 - val_loss: 0.3602 - val_accuracy: 0.0000e+00\n",
            "Epoch 3887/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3420 - accuracy: 0.0000e+00 - val_loss: 0.3601 - val_accuracy: 0.0000e+00\n",
            "Epoch 3888/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.0000e+00 - val_loss: 0.3601 - val_accuracy: 0.0000e+00\n",
            "Epoch 3889/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3435 - accuracy: 0.0000e+00 - val_loss: 0.3601 - val_accuracy: 0.0000e+00\n",
            "Epoch 3890/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3330 - accuracy: 0.0000e+00 - val_loss: 0.3601 - val_accuracy: 0.0000e+00\n",
            "Epoch 3891/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3312 - accuracy: 0.0000e+00 - val_loss: 0.3601 - val_accuracy: 0.0000e+00\n",
            "Epoch 3892/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3311 - accuracy: 0.0000e+00 - val_loss: 0.3600 - val_accuracy: 0.0000e+00\n",
            "Epoch 3893/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3314 - accuracy: 0.0000e+00 - val_loss: 0.3600 - val_accuracy: 0.0000e+00\n",
            "Epoch 3894/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3308 - accuracy: 0.0000e+00 - val_loss: 0.3600 - val_accuracy: 0.0000e+00\n",
            "Epoch 3895/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3394 - accuracy: 0.0000e+00 - val_loss: 0.3599 - val_accuracy: 0.0000e+00\n",
            "Epoch 3896/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3284 - accuracy: 0.0000e+00 - val_loss: 0.3600 - val_accuracy: 0.0000e+00\n",
            "Epoch 3897/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3292 - accuracy: 0.0000e+00 - val_loss: 0.3599 - val_accuracy: 0.0000e+00\n",
            "Epoch 3898/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3342 - accuracy: 0.0000e+00 - val_loss: 0.3598 - val_accuracy: 0.0000e+00\n",
            "Epoch 3899/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3313 - accuracy: 0.0000e+00 - val_loss: 0.3598 - val_accuracy: 0.0000e+00\n",
            "Epoch 3900/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3291 - accuracy: 0.0000e+00 - val_loss: 0.3598 - val_accuracy: 0.0000e+00\n",
            "Epoch 3901/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3361 - accuracy: 0.0000e+00 - val_loss: 0.3597 - val_accuracy: 0.0000e+00\n",
            "Epoch 3902/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3341 - accuracy: 0.0000e+00 - val_loss: 0.3597 - val_accuracy: 0.0000e+00\n",
            "Epoch 3903/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3285 - accuracy: 0.0000e+00 - val_loss: 0.3598 - val_accuracy: 0.0000e+00\n",
            "Epoch 3904/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3475 - accuracy: 0.0000e+00 - val_loss: 0.3597 - val_accuracy: 0.0000e+00\n",
            "Epoch 3905/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3336 - accuracy: 0.0000e+00 - val_loss: 0.3596 - val_accuracy: 0.0000e+00\n",
            "Epoch 3906/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3311 - accuracy: 0.0000e+00 - val_loss: 0.3597 - val_accuracy: 0.0000e+00\n",
            "Epoch 3907/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3333 - accuracy: 0.0000e+00 - val_loss: 0.3596 - val_accuracy: 0.0000e+00\n",
            "Epoch 3908/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3309 - accuracy: 0.0000e+00 - val_loss: 0.3596 - val_accuracy: 0.0000e+00\n",
            "Epoch 3909/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3355 - accuracy: 0.0000e+00 - val_loss: 0.3595 - val_accuracy: 0.0000e+00\n",
            "Epoch 3910/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3285 - accuracy: 0.0000e+00 - val_loss: 0.3596 - val_accuracy: 0.0000e+00\n",
            "Epoch 3911/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3289 - accuracy: 0.0000e+00 - val_loss: 0.3596 - val_accuracy: 0.0000e+00\n",
            "Epoch 3912/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3324 - accuracy: 0.0000e+00 - val_loss: 0.3595 - val_accuracy: 0.0000e+00\n",
            "Epoch 3913/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3370 - accuracy: 0.0000e+00 - val_loss: 0.3595 - val_accuracy: 0.0000e+00\n",
            "Epoch 3914/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3335 - accuracy: 0.0000e+00 - val_loss: 0.3595 - val_accuracy: 0.0000e+00\n",
            "Epoch 3915/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3281 - accuracy: 0.0000e+00 - val_loss: 0.3594 - val_accuracy: 0.0000e+00\n",
            "Epoch 3916/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3307 - accuracy: 0.0000e+00 - val_loss: 0.3593 - val_accuracy: 0.0000e+00\n",
            "Epoch 3917/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3328 - accuracy: 0.0000e+00 - val_loss: 0.3593 - val_accuracy: 0.0000e+00\n",
            "Epoch 3918/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3294 - accuracy: 0.0000e+00 - val_loss: 0.3593 - val_accuracy: 0.0000e+00\n",
            "Epoch 3919/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3316 - accuracy: 0.0000e+00 - val_loss: 0.3592 - val_accuracy: 0.0000e+00\n",
            "Epoch 3920/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3331 - accuracy: 0.0000e+00 - val_loss: 0.3592 - val_accuracy: 0.0000e+00\n",
            "Epoch 3921/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3312 - accuracy: 0.0000e+00 - val_loss: 0.3591 - val_accuracy: 0.0000e+00\n",
            "Epoch 3922/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3275 - accuracy: 0.0000e+00 - val_loss: 0.3591 - val_accuracy: 0.0000e+00\n",
            "Epoch 3923/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3387 - accuracy: 0.0000e+00 - val_loss: 0.3591 - val_accuracy: 0.0000e+00\n",
            "Epoch 3924/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3324 - accuracy: 0.0000e+00 - val_loss: 0.3591 - val_accuracy: 0.0000e+00\n",
            "Epoch 3925/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3289 - accuracy: 0.0000e+00 - val_loss: 0.3591 - val_accuracy: 0.0000e+00\n",
            "Epoch 3926/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3387 - accuracy: 0.0000e+00 - val_loss: 0.3590 - val_accuracy: 0.0000e+00\n",
            "Epoch 3927/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3401 - accuracy: 0.0000e+00 - val_loss: 0.3589 - val_accuracy: 0.0000e+00\n",
            "Epoch 3928/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3271 - accuracy: 0.0000e+00 - val_loss: 0.3589 - val_accuracy: 0.0000e+00\n",
            "Epoch 3929/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3350 - accuracy: 0.0000e+00 - val_loss: 0.3589 - val_accuracy: 0.0000e+00\n",
            "Epoch 3930/5000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.3323 - accuracy: 0.0000e+00 - val_loss: 0.3589 - val_accuracy: 0.0000e+00\n",
            "Epoch 3931/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3270 - accuracy: 0.0000e+00 - val_loss: 0.3589 - val_accuracy: 0.0000e+00\n",
            "Epoch 3932/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3331 - accuracy: 0.0000e+00 - val_loss: 0.3589 - val_accuracy: 0.0000e+00\n",
            "Epoch 3933/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3286 - accuracy: 0.0000e+00 - val_loss: 0.3589 - val_accuracy: 0.0000e+00\n",
            "Epoch 3934/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3334 - accuracy: 0.0000e+00 - val_loss: 0.3590 - val_accuracy: 0.0000e+00\n",
            "Epoch 3935/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3305 - accuracy: 0.0000e+00 - val_loss: 0.3590 - val_accuracy: 0.0000e+00\n",
            "Epoch 3936/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.0000e+00 - val_loss: 0.3590 - val_accuracy: 0.0000e+00\n",
            "Epoch 3937/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3324 - accuracy: 0.0000e+00 - val_loss: 0.3589 - val_accuracy: 0.0000e+00\n",
            "Epoch 3938/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3285 - accuracy: 0.0000e+00 - val_loss: 0.3589 - val_accuracy: 0.0000e+00\n",
            "Epoch 3939/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3297 - accuracy: 0.0000e+00 - val_loss: 0.3589 - val_accuracy: 0.0000e+00\n",
            "Epoch 3940/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3316 - accuracy: 0.0000e+00 - val_loss: 0.3588 - val_accuracy: 0.0000e+00\n",
            "Epoch 3941/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3288 - accuracy: 0.0000e+00 - val_loss: 0.3588 - val_accuracy: 0.0000e+00\n",
            "Epoch 3942/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3288 - accuracy: 0.0000e+00 - val_loss: 0.3588 - val_accuracy: 0.0000e+00\n",
            "Epoch 3943/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3296 - accuracy: 0.0000e+00 - val_loss: 0.3587 - val_accuracy: 0.0000e+00\n",
            "Epoch 3944/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3283 - accuracy: 0.0000e+00 - val_loss: 0.3587 - val_accuracy: 0.0000e+00\n",
            "Epoch 3945/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3413 - accuracy: 0.0000e+00 - val_loss: 0.3588 - val_accuracy: 0.0000e+00\n",
            "Epoch 3946/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3302 - accuracy: 0.0000e+00 - val_loss: 0.3587 - val_accuracy: 0.0000e+00\n",
            "Epoch 3947/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3258 - accuracy: 0.0000e+00 - val_loss: 0.3588 - val_accuracy: 0.0000e+00\n",
            "Epoch 3948/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3322 - accuracy: 0.0000e+00 - val_loss: 0.3587 - val_accuracy: 0.0000e+00\n",
            "Epoch 3949/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3363 - accuracy: 0.0000e+00 - val_loss: 0.3586 - val_accuracy: 0.0000e+00\n",
            "Epoch 3950/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3376 - accuracy: 0.0000e+00 - val_loss: 0.3585 - val_accuracy: 0.0000e+00\n",
            "Epoch 3951/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3383 - accuracy: 0.0000e+00 - val_loss: 0.3585 - val_accuracy: 0.0000e+00\n",
            "Epoch 3952/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3371 - accuracy: 0.0000e+00 - val_loss: 0.3585 - val_accuracy: 0.0000e+00\n",
            "Epoch 3953/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3277 - accuracy: 0.0000e+00 - val_loss: 0.3584 - val_accuracy: 0.0000e+00\n",
            "Epoch 3954/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3305 - accuracy: 0.0000e+00 - val_loss: 0.3584 - val_accuracy: 0.0000e+00\n",
            "Epoch 3955/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3348 - accuracy: 0.0000e+00 - val_loss: 0.3584 - val_accuracy: 0.0000e+00\n",
            "Epoch 3956/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3298 - accuracy: 0.0000e+00 - val_loss: 0.3584 - val_accuracy: 0.0000e+00\n",
            "Epoch 3957/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3402 - accuracy: 0.0000e+00 - val_loss: 0.3584 - val_accuracy: 0.0000e+00\n",
            "Epoch 3958/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3381 - accuracy: 0.0000e+00 - val_loss: 0.3584 - val_accuracy: 0.0000e+00\n",
            "Epoch 3959/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3254 - accuracy: 0.0000e+00 - val_loss: 0.3583 - val_accuracy: 0.0000e+00\n",
            "Epoch 3960/5000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3386 - accuracy: 0.0000e+00 - val_loss: 0.3582 - val_accuracy: 0.0000e+00\n",
            "Epoch 3961/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3250 - accuracy: 0.0000e+00 - val_loss: 0.3582 - val_accuracy: 0.0000e+00\n",
            "Epoch 3962/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3344 - accuracy: 0.0000e+00 - val_loss: 0.3582 - val_accuracy: 0.0000e+00\n",
            "Epoch 3963/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3370 - accuracy: 0.0000e+00 - val_loss: 0.3581 - val_accuracy: 0.0000e+00\n",
            "Epoch 3964/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3245 - accuracy: 0.0000e+00 - val_loss: 0.3581 - val_accuracy: 0.0000e+00\n",
            "Epoch 3965/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3407 - accuracy: 0.0000e+00 - val_loss: 0.3581 - val_accuracy: 0.0000e+00\n",
            "Epoch 3966/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3270 - accuracy: 0.0000e+00 - val_loss: 0.3581 - val_accuracy: 0.0000e+00\n",
            "Epoch 3967/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3327 - accuracy: 0.0000e+00 - val_loss: 0.3580 - val_accuracy: 0.0000e+00\n",
            "Epoch 3968/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3278 - accuracy: 0.0000e+00 - val_loss: 0.3581 - val_accuracy: 0.0000e+00\n",
            "Epoch 3969/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3318 - accuracy: 0.0000e+00 - val_loss: 0.3580 - val_accuracy: 0.0000e+00\n",
            "Epoch 3970/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.0000e+00 - val_loss: 0.3579 - val_accuracy: 0.0000e+00\n",
            "Epoch 3971/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3289 - accuracy: 0.0000e+00 - val_loss: 0.3579 - val_accuracy: 0.0000e+00\n",
            "Epoch 3972/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3294 - accuracy: 0.0000e+00 - val_loss: 0.3579 - val_accuracy: 0.0000e+00\n",
            "Epoch 3973/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3268 - accuracy: 0.0000e+00 - val_loss: 0.3579 - val_accuracy: 0.0000e+00\n",
            "Epoch 3974/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3279 - accuracy: 0.0000e+00 - val_loss: 0.3579 - val_accuracy: 0.0000e+00\n",
            "Epoch 3975/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3297 - accuracy: 0.0000e+00 - val_loss: 0.3578 - val_accuracy: 0.0000e+00\n",
            "Epoch 3976/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3273 - accuracy: 0.0000e+00 - val_loss: 0.3579 - val_accuracy: 0.0000e+00\n",
            "Epoch 3977/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3280 - accuracy: 0.0000e+00 - val_loss: 0.3578 - val_accuracy: 0.0000e+00\n",
            "Epoch 3978/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3442 - accuracy: 0.0000e+00 - val_loss: 0.3578 - val_accuracy: 0.0000e+00\n",
            "Epoch 3979/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3275 - accuracy: 0.0000e+00 - val_loss: 0.3579 - val_accuracy: 0.0000e+00\n",
            "Epoch 3980/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3285 - accuracy: 0.0000e+00 - val_loss: 0.3579 - val_accuracy: 0.0000e+00\n",
            "Epoch 3981/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3287 - accuracy: 0.0000e+00 - val_loss: 0.3578 - val_accuracy: 0.0000e+00\n",
            "Epoch 3982/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3266 - accuracy: 0.0000e+00 - val_loss: 0.3579 - val_accuracy: 0.0000e+00\n",
            "Epoch 3983/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3283 - accuracy: 0.0000e+00 - val_loss: 0.3578 - val_accuracy: 0.0000e+00\n",
            "Epoch 3984/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3311 - accuracy: 0.0000e+00 - val_loss: 0.3578 - val_accuracy: 0.0000e+00\n",
            "Epoch 3985/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3274 - accuracy: 0.0000e+00 - val_loss: 0.3577 - val_accuracy: 0.0000e+00\n",
            "Epoch 3986/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3295 - accuracy: 0.0000e+00 - val_loss: 0.3577 - val_accuracy: 0.0000e+00\n",
            "Epoch 3987/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3253 - accuracy: 0.0000e+00 - val_loss: 0.3577 - val_accuracy: 0.0000e+00\n",
            "Epoch 3988/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3224 - accuracy: 0.0000e+00 - val_loss: 0.3577 - val_accuracy: 0.0000e+00\n",
            "Epoch 3989/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3326 - accuracy: 0.0000e+00 - val_loss: 0.3577 - val_accuracy: 0.0000e+00\n",
            "Epoch 3990/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3294 - accuracy: 0.0000e+00 - val_loss: 0.3577 - val_accuracy: 0.0000e+00\n",
            "Epoch 3991/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3309 - accuracy: 0.0000e+00 - val_loss: 0.3576 - val_accuracy: 0.0000e+00\n",
            "Epoch 3992/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3241 - accuracy: 0.0000e+00 - val_loss: 0.3576 - val_accuracy: 0.0000e+00\n",
            "Epoch 3993/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3289 - accuracy: 0.0000e+00 - val_loss: 0.3575 - val_accuracy: 0.0000e+00\n",
            "Epoch 3994/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3316 - accuracy: 0.0000e+00 - val_loss: 0.3575 - val_accuracy: 0.0000e+00\n",
            "Epoch 3995/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3420 - accuracy: 0.0000e+00 - val_loss: 0.3574 - val_accuracy: 0.0000e+00\n",
            "Epoch 3996/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3287 - accuracy: 0.0000e+00 - val_loss: 0.3574 - val_accuracy: 0.0000e+00\n",
            "Epoch 3997/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3293 - accuracy: 0.0000e+00 - val_loss: 0.3574 - val_accuracy: 0.0000e+00\n",
            "Epoch 3998/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3249 - accuracy: 0.0000e+00 - val_loss: 0.3575 - val_accuracy: 0.0000e+00\n",
            "Epoch 3999/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3343 - accuracy: 0.0000e+00 - val_loss: 0.3574 - val_accuracy: 0.0000e+00\n",
            "Epoch 4000/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3375 - accuracy: 0.0000e+00 - val_loss: 0.3575 - val_accuracy: 0.0000e+00\n",
            "Epoch 4001/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3182 - accuracy: 0.0000e+00 - val_loss: 0.3574 - val_accuracy: 0.0000e+00\n",
            "Epoch 4002/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3268 - accuracy: 0.0000e+00 - val_loss: 0.3574 - val_accuracy: 0.0000e+00\n",
            "Epoch 4003/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3256 - accuracy: 0.0000e+00 - val_loss: 0.3573 - val_accuracy: 0.0000e+00\n",
            "Epoch 4004/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3325 - accuracy: 0.0000e+00 - val_loss: 0.3572 - val_accuracy: 0.0000e+00\n",
            "Epoch 4005/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3221 - accuracy: 0.0000e+00 - val_loss: 0.3572 - val_accuracy: 0.0000e+00\n",
            "Epoch 4006/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3260 - accuracy: 0.0000e+00 - val_loss: 0.3572 - val_accuracy: 0.0000e+00\n",
            "Epoch 4007/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3459 - accuracy: 0.0000e+00 - val_loss: 0.3571 - val_accuracy: 0.0000e+00\n",
            "Epoch 4008/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3261 - accuracy: 0.0000e+00 - val_loss: 0.3571 - val_accuracy: 0.0000e+00\n",
            "Epoch 4009/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3294 - accuracy: 0.0000e+00 - val_loss: 0.3572 - val_accuracy: 0.0000e+00\n",
            "Epoch 4010/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3309 - accuracy: 0.0000e+00 - val_loss: 0.3571 - val_accuracy: 0.0000e+00\n",
            "Epoch 4011/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3263 - accuracy: 0.0000e+00 - val_loss: 0.3571 - val_accuracy: 0.0000e+00\n",
            "Epoch 4012/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3392 - accuracy: 0.0000e+00 - val_loss: 0.3571 - val_accuracy: 0.0000e+00\n",
            "Epoch 4013/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3340 - accuracy: 0.0000e+00 - val_loss: 0.3571 - val_accuracy: 0.0000e+00\n",
            "Epoch 4014/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3326 - accuracy: 0.0000e+00 - val_loss: 0.3571 - val_accuracy: 0.0000e+00\n",
            "Epoch 4015/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3232 - accuracy: 0.0000e+00 - val_loss: 0.3571 - val_accuracy: 0.0000e+00\n",
            "Epoch 4016/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3340 - accuracy: 0.0000e+00 - val_loss: 0.3571 - val_accuracy: 0.0000e+00\n",
            "Epoch 4017/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3277 - accuracy: 0.0000e+00 - val_loss: 0.3571 - val_accuracy: 0.0000e+00\n",
            "Epoch 4018/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3249 - accuracy: 0.0000e+00 - val_loss: 0.3570 - val_accuracy: 0.0000e+00\n",
            "Epoch 4019/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3291 - accuracy: 0.0000e+00 - val_loss: 0.3570 - val_accuracy: 0.0000e+00\n",
            "Epoch 4020/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3435 - accuracy: 0.0000e+00 - val_loss: 0.3570 - val_accuracy: 0.0000e+00\n",
            "Epoch 4021/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3276 - accuracy: 0.0000e+00 - val_loss: 0.3569 - val_accuracy: 0.0000e+00\n",
            "Epoch 4022/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3303 - accuracy: 0.0000e+00 - val_loss: 0.3569 - val_accuracy: 0.0000e+00\n",
            "Epoch 4023/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3351 - accuracy: 0.0000e+00 - val_loss: 0.3569 - val_accuracy: 0.0000e+00\n",
            "Epoch 4024/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3390 - accuracy: 0.0000e+00 - val_loss: 0.3568 - val_accuracy: 0.0000e+00\n",
            "Epoch 4025/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3268 - accuracy: 0.0000e+00 - val_loss: 0.3568 - val_accuracy: 0.0000e+00\n",
            "Epoch 4026/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3350 - accuracy: 0.0000e+00 - val_loss: 0.3567 - val_accuracy: 0.0000e+00\n",
            "Epoch 4027/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3248 - accuracy: 0.0000e+00 - val_loss: 0.3567 - val_accuracy: 0.0000e+00\n",
            "Epoch 4028/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3380 - accuracy: 0.0000e+00 - val_loss: 0.3568 - val_accuracy: 0.0000e+00\n",
            "Epoch 4029/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3269 - accuracy: 0.0000e+00 - val_loss: 0.3568 - val_accuracy: 0.0000e+00\n",
            "Epoch 4030/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3307 - accuracy: 0.0000e+00 - val_loss: 0.3567 - val_accuracy: 0.0000e+00\n",
            "Epoch 4031/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3318 - accuracy: 0.0000e+00 - val_loss: 0.3567 - val_accuracy: 0.0000e+00\n",
            "Epoch 4032/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3287 - accuracy: 0.0000e+00 - val_loss: 0.3567 - val_accuracy: 0.0000e+00\n",
            "Epoch 4033/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3211 - accuracy: 0.0000e+00 - val_loss: 0.3567 - val_accuracy: 0.0000e+00\n",
            "Epoch 4034/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3292 - accuracy: 0.0000e+00 - val_loss: 0.3566 - val_accuracy: 0.0000e+00\n",
            "Epoch 4035/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3268 - accuracy: 0.0000e+00 - val_loss: 0.3566 - val_accuracy: 0.0000e+00\n",
            "Epoch 4036/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3222 - accuracy: 0.0000e+00 - val_loss: 0.3566 - val_accuracy: 0.0000e+00\n",
            "Epoch 4037/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3261 - accuracy: 0.0000e+00 - val_loss: 0.3566 - val_accuracy: 0.0000e+00\n",
            "Epoch 4038/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3271 - accuracy: 0.0000e+00 - val_loss: 0.3566 - val_accuracy: 0.0000e+00\n",
            "Epoch 4039/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3350 - accuracy: 0.0000e+00 - val_loss: 0.3565 - val_accuracy: 0.0000e+00\n",
            "Epoch 4040/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3257 - accuracy: 0.0000e+00 - val_loss: 0.3565 - val_accuracy: 0.0000e+00\n",
            "Epoch 4041/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3305 - accuracy: 0.0000e+00 - val_loss: 0.3566 - val_accuracy: 0.0000e+00\n",
            "Epoch 4042/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3261 - accuracy: 0.0000e+00 - val_loss: 0.3565 - val_accuracy: 0.0000e+00\n",
            "Epoch 4043/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3282 - accuracy: 0.0000e+00 - val_loss: 0.3564 - val_accuracy: 0.0000e+00\n",
            "Epoch 4044/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3259 - accuracy: 0.0000e+00 - val_loss: 0.3564 - val_accuracy: 0.0000e+00\n",
            "Epoch 4045/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3314 - accuracy: 0.0000e+00 - val_loss: 0.3563 - val_accuracy: 0.0000e+00\n",
            "Epoch 4046/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3277 - accuracy: 0.0000e+00 - val_loss: 0.3563 - val_accuracy: 0.0000e+00\n",
            "Epoch 4047/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3242 - accuracy: 0.0000e+00 - val_loss: 0.3563 - val_accuracy: 0.0000e+00\n",
            "Epoch 4048/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3285 - accuracy: 0.0000e+00 - val_loss: 0.3563 - val_accuracy: 0.0000e+00\n",
            "Epoch 4049/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3276 - accuracy: 0.0000e+00 - val_loss: 0.3563 - val_accuracy: 0.0000e+00\n",
            "Epoch 4050/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3262 - accuracy: 0.0000e+00 - val_loss: 0.3563 - val_accuracy: 0.0000e+00\n",
            "Epoch 4051/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3299 - accuracy: 0.0000e+00 - val_loss: 0.3563 - val_accuracy: 0.0000e+00\n",
            "Epoch 4052/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3305 - accuracy: 0.0000e+00 - val_loss: 0.3563 - val_accuracy: 0.0000e+00\n",
            "Epoch 4053/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3240 - accuracy: 0.0000e+00 - val_loss: 0.3562 - val_accuracy: 0.0000e+00\n",
            "Epoch 4054/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3264 - accuracy: 0.0000e+00 - val_loss: 0.3562 - val_accuracy: 0.0000e+00\n",
            "Epoch 4055/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3428 - accuracy: 0.0000e+00 - val_loss: 0.3562 - val_accuracy: 0.0000e+00\n",
            "Epoch 4056/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3329 - accuracy: 0.0000e+00 - val_loss: 0.3562 - val_accuracy: 0.0000e+00\n",
            "Epoch 4057/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3258 - accuracy: 0.0000e+00 - val_loss: 0.3562 - val_accuracy: 0.0000e+00\n",
            "Epoch 4058/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3301 - accuracy: 0.0000e+00 - val_loss: 0.3562 - val_accuracy: 0.0000e+00\n",
            "Epoch 4059/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3255 - accuracy: 0.0000e+00 - val_loss: 0.3562 - val_accuracy: 0.0000e+00\n",
            "Epoch 4060/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3244 - accuracy: 0.0000e+00 - val_loss: 0.3562 - val_accuracy: 0.0000e+00\n",
            "Epoch 4061/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3280 - accuracy: 0.0000e+00 - val_loss: 0.3561 - val_accuracy: 0.0000e+00\n",
            "Epoch 4062/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3292 - accuracy: 0.0000e+00 - val_loss: 0.3560 - val_accuracy: 0.0000e+00\n",
            "Epoch 4063/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3205 - accuracy: 0.0000e+00 - val_loss: 0.3559 - val_accuracy: 0.0000e+00\n",
            "Epoch 4064/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3307 - accuracy: 0.0000e+00 - val_loss: 0.3560 - val_accuracy: 0.0000e+00\n",
            "Epoch 4065/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3300 - accuracy: 0.0000e+00 - val_loss: 0.3559 - val_accuracy: 0.0000e+00\n",
            "Epoch 4066/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3239 - accuracy: 0.0000e+00 - val_loss: 0.3559 - val_accuracy: 0.0000e+00\n",
            "Epoch 4067/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3253 - accuracy: 0.0000e+00 - val_loss: 0.3559 - val_accuracy: 0.0000e+00\n",
            "Epoch 4068/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3235 - accuracy: 0.0000e+00 - val_loss: 0.3559 - val_accuracy: 0.0000e+00\n",
            "Epoch 4069/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3269 - accuracy: 0.0000e+00 - val_loss: 0.3558 - val_accuracy: 0.0000e+00\n",
            "Epoch 4070/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3255 - accuracy: 0.0000e+00 - val_loss: 0.3558 - val_accuracy: 0.0000e+00\n",
            "Epoch 4071/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3276 - accuracy: 0.0000e+00 - val_loss: 0.3558 - val_accuracy: 0.0000e+00\n",
            "Epoch 4072/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3243 - accuracy: 0.0000e+00 - val_loss: 0.3557 - val_accuracy: 0.0000e+00\n",
            "Epoch 4073/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3218 - accuracy: 0.0000e+00 - val_loss: 0.3557 - val_accuracy: 0.0000e+00\n",
            "Epoch 4074/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3297 - accuracy: 0.0000e+00 - val_loss: 0.3558 - val_accuracy: 0.0000e+00\n",
            "Epoch 4075/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3311 - accuracy: 0.0000e+00 - val_loss: 0.3557 - val_accuracy: 0.0000e+00\n",
            "Epoch 4076/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3280 - accuracy: 0.0000e+00 - val_loss: 0.3557 - val_accuracy: 0.0000e+00\n",
            "Epoch 4077/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3218 - accuracy: 0.0000e+00 - val_loss: 0.3556 - val_accuracy: 0.0000e+00\n",
            "Epoch 4078/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3367 - accuracy: 0.0000e+00 - val_loss: 0.3557 - val_accuracy: 0.0000e+00\n",
            "Epoch 4079/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3348 - accuracy: 0.0000e+00 - val_loss: 0.3557 - val_accuracy: 0.0000e+00\n",
            "Epoch 4080/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3239 - accuracy: 0.0000e+00 - val_loss: 0.3557 - val_accuracy: 0.0000e+00\n",
            "Epoch 4081/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3296 - accuracy: 0.0000e+00 - val_loss: 0.3556 - val_accuracy: 0.0000e+00\n",
            "Epoch 4082/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3272 - accuracy: 0.0000e+00 - val_loss: 0.3556 - val_accuracy: 0.0000e+00\n",
            "Epoch 4083/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3304 - accuracy: 0.0000e+00 - val_loss: 0.3556 - val_accuracy: 0.0000e+00\n",
            "Epoch 4084/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3278 - accuracy: 0.0000e+00 - val_loss: 0.3556 - val_accuracy: 0.0000e+00\n",
            "Epoch 4085/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3275 - accuracy: 0.0000e+00 - val_loss: 0.3556 - val_accuracy: 0.0000e+00\n",
            "Epoch 4086/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3330 - accuracy: 0.0000e+00 - val_loss: 0.3556 - val_accuracy: 0.0000e+00\n",
            "Epoch 4087/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3279 - accuracy: 0.0000e+00 - val_loss: 0.3555 - val_accuracy: 0.0000e+00\n",
            "Epoch 4088/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3254 - accuracy: 0.0000e+00 - val_loss: 0.3555 - val_accuracy: 0.0000e+00\n",
            "Epoch 4089/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3269 - accuracy: 0.0000e+00 - val_loss: 0.3556 - val_accuracy: 0.0000e+00\n",
            "Epoch 4090/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3352 - accuracy: 0.0000e+00 - val_loss: 0.3555 - val_accuracy: 0.0000e+00\n",
            "Epoch 4091/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3290 - accuracy: 0.0000e+00 - val_loss: 0.3555 - val_accuracy: 0.0000e+00\n",
            "Epoch 4092/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3340 - accuracy: 0.0000e+00 - val_loss: 0.3555 - val_accuracy: 0.0000e+00\n",
            "Epoch 4093/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3562 - accuracy: 0.0000e+00 - val_loss: 0.3556 - val_accuracy: 0.0000e+00\n",
            "Epoch 4094/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3450 - accuracy: 0.0000e+00 - val_loss: 0.3556 - val_accuracy: 0.0000e+00\n",
            "Epoch 4095/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3260 - accuracy: 0.0000e+00 - val_loss: 0.3554 - val_accuracy: 0.0000e+00\n",
            "Epoch 4096/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3302 - accuracy: 0.0000e+00 - val_loss: 0.3554 - val_accuracy: 0.0000e+00\n",
            "Epoch 4097/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3272 - accuracy: 0.0000e+00 - val_loss: 0.3555 - val_accuracy: 0.0000e+00\n",
            "Epoch 4098/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3299 - accuracy: 0.0000e+00 - val_loss: 0.3554 - val_accuracy: 0.0000e+00\n",
            "Epoch 4099/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3258 - accuracy: 0.0000e+00 - val_loss: 0.3552 - val_accuracy: 0.0000e+00\n",
            "Epoch 4100/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3287 - accuracy: 0.0000e+00 - val_loss: 0.3552 - val_accuracy: 0.0000e+00\n",
            "Epoch 4101/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3293 - accuracy: 0.0000e+00 - val_loss: 0.3552 - val_accuracy: 0.0000e+00\n",
            "Epoch 4102/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3343 - accuracy: 0.0000e+00 - val_loss: 0.3551 - val_accuracy: 0.0000e+00\n",
            "Epoch 4103/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3364 - accuracy: 0.0000e+00 - val_loss: 0.3550 - val_accuracy: 0.0000e+00\n",
            "Epoch 4104/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3206 - accuracy: 0.0000e+00 - val_loss: 0.3550 - val_accuracy: 0.0000e+00\n",
            "Epoch 4105/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3284 - accuracy: 0.0000e+00 - val_loss: 0.3550 - val_accuracy: 0.0000e+00\n",
            "Epoch 4106/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3271 - accuracy: 0.0000e+00 - val_loss: 0.3550 - val_accuracy: 0.0000e+00\n",
            "Epoch 4107/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3278 - accuracy: 0.0000e+00 - val_loss: 0.3550 - val_accuracy: 0.0000e+00\n",
            "Epoch 4108/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3386 - accuracy: 0.0000e+00 - val_loss: 0.3549 - val_accuracy: 0.0000e+00\n",
            "Epoch 4109/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3246 - accuracy: 0.0000e+00 - val_loss: 0.3549 - val_accuracy: 0.0000e+00\n",
            "Epoch 4110/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3239 - accuracy: 0.0000e+00 - val_loss: 0.3549 - val_accuracy: 0.0000e+00\n",
            "Epoch 4111/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3312 - accuracy: 0.0000e+00 - val_loss: 0.3549 - val_accuracy: 0.0000e+00\n",
            "Epoch 4112/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3281 - accuracy: 0.0000e+00 - val_loss: 0.3548 - val_accuracy: 0.0000e+00\n",
            "Epoch 4113/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3223 - accuracy: 0.0000e+00 - val_loss: 0.3548 - val_accuracy: 0.0000e+00\n",
            "Epoch 4114/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3263 - accuracy: 0.0000e+00 - val_loss: 0.3549 - val_accuracy: 0.0000e+00\n",
            "Epoch 4115/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3309 - accuracy: 0.0000e+00 - val_loss: 0.3549 - val_accuracy: 0.0000e+00\n",
            "Epoch 4116/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3190 - accuracy: 0.0000e+00 - val_loss: 0.3549 - val_accuracy: 0.0000e+00\n",
            "Epoch 4117/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3217 - accuracy: 0.0000e+00 - val_loss: 0.3549 - val_accuracy: 0.0000e+00\n",
            "Epoch 4118/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3268 - accuracy: 0.0000e+00 - val_loss: 0.3549 - val_accuracy: 0.0000e+00\n",
            "Epoch 4119/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3224 - accuracy: 0.0000e+00 - val_loss: 0.3549 - val_accuracy: 0.0000e+00\n",
            "Epoch 4120/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3270 - accuracy: 0.0000e+00 - val_loss: 0.3550 - val_accuracy: 0.0000e+00\n",
            "Epoch 4121/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3290 - accuracy: 0.0000e+00 - val_loss: 0.3550 - val_accuracy: 0.0000e+00\n",
            "Epoch 4122/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3429 - accuracy: 0.0000e+00 - val_loss: 0.3550 - val_accuracy: 0.0000e+00\n",
            "Epoch 4123/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3342 - accuracy: 0.0000e+00 - val_loss: 0.3550 - val_accuracy: 0.0000e+00\n",
            "Epoch 4124/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3297 - accuracy: 0.0000e+00 - val_loss: 0.3549 - val_accuracy: 0.0000e+00\n",
            "Epoch 4125/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3392 - accuracy: 0.0000e+00 - val_loss: 0.3548 - val_accuracy: 0.0000e+00\n",
            "Epoch 4126/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3219 - accuracy: 0.0000e+00 - val_loss: 0.3548 - val_accuracy: 0.0000e+00\n",
            "Epoch 4127/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3273 - accuracy: 0.0000e+00 - val_loss: 0.3547 - val_accuracy: 0.0000e+00\n",
            "Epoch 4128/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3216 - accuracy: 0.0000e+00 - val_loss: 0.3546 - val_accuracy: 0.0000e+00\n",
            "Epoch 4129/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3237 - accuracy: 0.0000e+00 - val_loss: 0.3546 - val_accuracy: 0.0000e+00\n",
            "Epoch 4130/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3239 - accuracy: 0.0000e+00 - val_loss: 0.3545 - val_accuracy: 0.0000e+00\n",
            "Epoch 4131/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3225 - accuracy: 0.0000e+00 - val_loss: 0.3545 - val_accuracy: 0.0000e+00\n",
            "Epoch 4132/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3272 - accuracy: 0.0000e+00 - val_loss: 0.3544 - val_accuracy: 0.0000e+00\n",
            "Epoch 4133/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3382 - accuracy: 0.0000e+00 - val_loss: 0.3544 - val_accuracy: 0.0000e+00\n",
            "Epoch 4134/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3208 - accuracy: 0.0000e+00 - val_loss: 0.3544 - val_accuracy: 0.0000e+00\n",
            "Epoch 4135/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3278 - accuracy: 0.0000e+00 - val_loss: 0.3544 - val_accuracy: 0.0000e+00\n",
            "Epoch 4136/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3307 - accuracy: 0.0000e+00 - val_loss: 0.3545 - val_accuracy: 0.0000e+00\n",
            "Epoch 4137/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3252 - accuracy: 0.0000e+00 - val_loss: 0.3545 - val_accuracy: 0.0000e+00\n",
            "Epoch 4138/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3224 - accuracy: 0.0000e+00 - val_loss: 0.3545 - val_accuracy: 0.0000e+00\n",
            "Epoch 4139/5000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3285 - accuracy: 0.0000e+00 - val_loss: 0.3544 - val_accuracy: 0.0000e+00\n",
            "Epoch 4140/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3317 - accuracy: 0.0000e+00 - val_loss: 0.3543 - val_accuracy: 0.0000e+00\n",
            "Epoch 4141/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3216 - accuracy: 0.0000e+00 - val_loss: 0.3543 - val_accuracy: 0.0000e+00\n",
            "Epoch 4142/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3292 - accuracy: 0.0000e+00 - val_loss: 0.3543 - val_accuracy: 0.0000e+00\n",
            "Epoch 4143/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3243 - accuracy: 0.0000e+00 - val_loss: 0.3542 - val_accuracy: 0.0000e+00\n",
            "Epoch 4144/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3356 - accuracy: 0.0000e+00 - val_loss: 0.3542 - val_accuracy: 0.0000e+00\n",
            "Epoch 4145/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3311 - accuracy: 0.0000e+00 - val_loss: 0.3542 - val_accuracy: 0.0000e+00\n",
            "Epoch 4146/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3277 - accuracy: 0.0000e+00 - val_loss: 0.3543 - val_accuracy: 0.0000e+00\n",
            "Epoch 4147/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3224 - accuracy: 0.0000e+00 - val_loss: 0.3543 - val_accuracy: 0.0000e+00\n",
            "Epoch 4148/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3218 - accuracy: 0.0000e+00 - val_loss: 0.3542 - val_accuracy: 0.0000e+00\n",
            "Epoch 4149/5000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3270 - accuracy: 0.0000e+00 - val_loss: 0.3542 - val_accuracy: 0.0000e+00\n",
            "Epoch 4150/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3240 - accuracy: 0.0000e+00 - val_loss: 0.3542 - val_accuracy: 0.0000e+00\n",
            "Epoch 4151/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3291 - accuracy: 0.0000e+00 - val_loss: 0.3542 - val_accuracy: 0.0000e+00\n",
            "Epoch 4152/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3214 - accuracy: 0.0000e+00 - val_loss: 0.3542 - val_accuracy: 0.0000e+00\n",
            "Epoch 4153/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3195 - accuracy: 0.0000e+00 - val_loss: 0.3542 - val_accuracy: 0.0000e+00\n",
            "Epoch 4154/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3263 - accuracy: 0.0000e+00 - val_loss: 0.3542 - val_accuracy: 0.0000e+00\n",
            "Epoch 4155/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3348 - accuracy: 0.0000e+00 - val_loss: 0.3542 - val_accuracy: 0.0000e+00\n",
            "Epoch 4156/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3231 - accuracy: 0.0000e+00 - val_loss: 0.3540 - val_accuracy: 0.0000e+00\n",
            "Epoch 4157/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3206 - accuracy: 0.0000e+00 - val_loss: 0.3540 - val_accuracy: 0.0000e+00\n",
            "Epoch 4158/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3284 - accuracy: 0.0000e+00 - val_loss: 0.3540 - val_accuracy: 0.0000e+00\n",
            "Epoch 4159/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3313 - accuracy: 0.0000e+00 - val_loss: 0.3540 - val_accuracy: 0.0000e+00\n",
            "Epoch 4160/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3309 - accuracy: 0.0000e+00 - val_loss: 0.3539 - val_accuracy: 0.0000e+00\n",
            "Epoch 4161/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3261 - accuracy: 0.0000e+00 - val_loss: 0.3539 - val_accuracy: 0.0000e+00\n",
            "Epoch 4162/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3392 - accuracy: 0.0000e+00 - val_loss: 0.3539 - val_accuracy: 0.0000e+00\n",
            "Epoch 4163/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3226 - accuracy: 0.0000e+00 - val_loss: 0.3540 - val_accuracy: 0.0000e+00\n",
            "Epoch 4164/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3327 - accuracy: 0.0000e+00 - val_loss: 0.3540 - val_accuracy: 0.0000e+00\n",
            "Epoch 4165/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3226 - accuracy: 0.0000e+00 - val_loss: 0.3539 - val_accuracy: 0.0000e+00\n",
            "Epoch 4166/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3432 - accuracy: 0.0000e+00 - val_loss: 0.3540 - val_accuracy: 0.0000e+00\n",
            "Epoch 4167/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3262 - accuracy: 0.0000e+00 - val_loss: 0.3540 - val_accuracy: 0.0000e+00\n",
            "Epoch 4168/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3254 - accuracy: 0.0000e+00 - val_loss: 0.3540 - val_accuracy: 0.0000e+00\n",
            "Epoch 4169/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3242 - accuracy: 0.0000e+00 - val_loss: 0.3539 - val_accuracy: 0.0000e+00\n",
            "Epoch 4170/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3306 - accuracy: 0.0000e+00 - val_loss: 0.3540 - val_accuracy: 0.0000e+00\n",
            "Epoch 4171/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3187 - accuracy: 0.0000e+00 - val_loss: 0.3540 - val_accuracy: 0.0000e+00\n",
            "Epoch 4172/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3289 - accuracy: 0.0000e+00 - val_loss: 0.3539 - val_accuracy: 0.0000e+00\n",
            "Epoch 4173/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3259 - accuracy: 0.0000e+00 - val_loss: 0.3538 - val_accuracy: 0.0000e+00\n",
            "Epoch 4174/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3263 - accuracy: 0.0000e+00 - val_loss: 0.3537 - val_accuracy: 0.0000e+00\n",
            "Epoch 4175/5000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.3228 - accuracy: 0.0000e+00 - val_loss: 0.3537 - val_accuracy: 0.0000e+00\n",
            "Epoch 4176/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3452 - accuracy: 0.0000e+00 - val_loss: 0.3537 - val_accuracy: 0.0000e+00\n",
            "Epoch 4177/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3381 - accuracy: 0.0000e+00 - val_loss: 0.3537 - val_accuracy: 0.0000e+00\n",
            "Epoch 4178/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3226 - accuracy: 0.0000e+00 - val_loss: 0.3536 - val_accuracy: 0.0000e+00\n",
            "Epoch 4179/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3229 - accuracy: 0.0000e+00 - val_loss: 0.3536 - val_accuracy: 0.0000e+00\n",
            "Epoch 4180/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3199 - accuracy: 0.0000e+00 - val_loss: 0.3536 - val_accuracy: 0.0000e+00\n",
            "Epoch 4181/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3284 - accuracy: 0.0000e+00 - val_loss: 0.3536 - val_accuracy: 0.0000e+00\n",
            "Epoch 4182/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3214 - accuracy: 0.0000e+00 - val_loss: 0.3535 - val_accuracy: 0.0000e+00\n",
            "Epoch 4183/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3259 - accuracy: 0.0000e+00 - val_loss: 0.3534 - val_accuracy: 0.0000e+00\n",
            "Epoch 4184/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3255 - accuracy: 0.0000e+00 - val_loss: 0.3534 - val_accuracy: 0.0000e+00\n",
            "Epoch 4185/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3215 - accuracy: 0.0000e+00 - val_loss: 0.3534 - val_accuracy: 0.0000e+00\n",
            "Epoch 4186/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3292 - accuracy: 0.0000e+00 - val_loss: 0.3534 - val_accuracy: 0.0000e+00\n",
            "Epoch 4187/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3365 - accuracy: 0.0000e+00 - val_loss: 0.3535 - val_accuracy: 0.0000e+00\n",
            "Epoch 4188/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3257 - accuracy: 0.0000e+00 - val_loss: 0.3535 - val_accuracy: 0.0000e+00\n",
            "Epoch 4189/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3314 - accuracy: 0.0000e+00 - val_loss: 0.3534 - val_accuracy: 0.0000e+00\n",
            "Epoch 4190/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3273 - accuracy: 0.0000e+00 - val_loss: 0.3534 - val_accuracy: 0.0000e+00\n",
            "Epoch 4191/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3299 - accuracy: 0.0000e+00 - val_loss: 0.3535 - val_accuracy: 0.0000e+00\n",
            "Epoch 4192/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3201 - accuracy: 0.0000e+00 - val_loss: 0.3534 - val_accuracy: 0.0000e+00\n",
            "Epoch 4193/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3198 - accuracy: 0.0000e+00 - val_loss: 0.3534 - val_accuracy: 0.0000e+00\n",
            "Epoch 4194/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3282 - accuracy: 0.0000e+00 - val_loss: 0.3534 - val_accuracy: 0.0000e+00\n",
            "Epoch 4195/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3386 - accuracy: 0.0000e+00 - val_loss: 0.3534 - val_accuracy: 0.0000e+00\n",
            "Epoch 4196/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3323 - accuracy: 0.0000e+00 - val_loss: 0.3533 - val_accuracy: 0.0000e+00\n",
            "Epoch 4197/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3228 - accuracy: 0.0000e+00 - val_loss: 0.3532 - val_accuracy: 0.0000e+00\n",
            "Epoch 4198/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3312 - accuracy: 0.0000e+00 - val_loss: 0.3533 - val_accuracy: 0.0000e+00\n",
            "Epoch 4199/5000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3219 - accuracy: 0.0000e+00 - val_loss: 0.3532 - val_accuracy: 0.0000e+00\n",
            "Epoch 4200/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3249 - accuracy: 0.0000e+00 - val_loss: 0.3531 - val_accuracy: 0.0000e+00\n",
            "Epoch 4201/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3257 - accuracy: 0.0000e+00 - val_loss: 0.3531 - val_accuracy: 0.0000e+00\n",
            "Epoch 4202/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3257 - accuracy: 0.0000e+00 - val_loss: 0.3530 - val_accuracy: 0.0000e+00\n",
            "Epoch 4203/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3254 - accuracy: 0.0000e+00 - val_loss: 0.3530 - val_accuracy: 0.0000e+00\n",
            "Epoch 4204/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3302 - accuracy: 0.0000e+00 - val_loss: 0.3531 - val_accuracy: 0.0000e+00\n",
            "Epoch 4205/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3227 - accuracy: 0.0000e+00 - val_loss: 0.3530 - val_accuracy: 0.0000e+00\n",
            "Epoch 4206/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3296 - accuracy: 0.0000e+00 - val_loss: 0.3530 - val_accuracy: 0.0000e+00\n",
            "Epoch 4207/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3330 - accuracy: 0.0000e+00 - val_loss: 0.3530 - val_accuracy: 0.0000e+00\n",
            "Epoch 4208/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3262 - accuracy: 0.0000e+00 - val_loss: 0.3529 - val_accuracy: 0.0000e+00\n",
            "Epoch 4209/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3302 - accuracy: 0.0000e+00 - val_loss: 0.3529 - val_accuracy: 0.0000e+00\n",
            "Epoch 4210/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3301 - accuracy: 0.0000e+00 - val_loss: 0.3528 - val_accuracy: 0.0000e+00\n",
            "Epoch 4211/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3267 - accuracy: 0.0000e+00 - val_loss: 0.3528 - val_accuracy: 0.0000e+00\n",
            "Epoch 4212/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3241 - accuracy: 0.0000e+00 - val_loss: 0.3528 - val_accuracy: 0.0000e+00\n",
            "Epoch 4213/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3365 - accuracy: 0.0000e+00 - val_loss: 0.3528 - val_accuracy: 0.0000e+00\n",
            "Epoch 4214/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3221 - accuracy: 0.0000e+00 - val_loss: 0.3528 - val_accuracy: 0.0000e+00\n",
            "Epoch 4215/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3228 - accuracy: 0.0000e+00 - val_loss: 0.3528 - val_accuracy: 0.0000e+00\n",
            "Epoch 4216/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3191 - accuracy: 0.0000e+00 - val_loss: 0.3528 - val_accuracy: 0.0000e+00\n",
            "Epoch 4217/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3216 - accuracy: 0.0000e+00 - val_loss: 0.3527 - val_accuracy: 0.0000e+00\n",
            "Epoch 4218/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3307 - accuracy: 0.0000e+00 - val_loss: 0.3526 - val_accuracy: 0.0000e+00\n",
            "Epoch 4219/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3311 - accuracy: 0.0000e+00 - val_loss: 0.3526 - val_accuracy: 0.0000e+00\n",
            "Epoch 4220/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3199 - accuracy: 0.0000e+00 - val_loss: 0.3526 - val_accuracy: 0.0000e+00\n",
            "Epoch 4221/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3215 - accuracy: 0.0000e+00 - val_loss: 0.3526 - val_accuracy: 0.0000e+00\n",
            "Epoch 4222/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3269 - accuracy: 0.0000e+00 - val_loss: 0.3525 - val_accuracy: 0.0000e+00\n",
            "Epoch 4223/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3195 - accuracy: 0.0000e+00 - val_loss: 0.3525 - val_accuracy: 0.0000e+00\n",
            "Epoch 4224/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3213 - accuracy: 0.0000e+00 - val_loss: 0.3525 - val_accuracy: 0.0000e+00\n",
            "Epoch 4225/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3230 - accuracy: 0.0000e+00 - val_loss: 0.3525 - val_accuracy: 0.0000e+00\n",
            "Epoch 4226/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3202 - accuracy: 0.0000e+00 - val_loss: 0.3525 - val_accuracy: 0.0000e+00\n",
            "Epoch 4227/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3310 - accuracy: 0.0000e+00 - val_loss: 0.3527 - val_accuracy: 0.0000e+00\n",
            "Epoch 4228/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3261 - accuracy: 0.0000e+00 - val_loss: 0.3527 - val_accuracy: 0.0000e+00\n",
            "Epoch 4229/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3363 - accuracy: 0.0000e+00 - val_loss: 0.3526 - val_accuracy: 0.0000e+00\n",
            "Epoch 4230/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3336 - accuracy: 0.0000e+00 - val_loss: 0.3526 - val_accuracy: 0.0000e+00\n",
            "Epoch 4231/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3259 - accuracy: 0.0000e+00 - val_loss: 0.3525 - val_accuracy: 0.0000e+00\n",
            "Epoch 4232/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3174 - accuracy: 0.0000e+00 - val_loss: 0.3525 - val_accuracy: 0.0000e+00\n",
            "Epoch 4233/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3236 - accuracy: 0.0000e+00 - val_loss: 0.3525 - val_accuracy: 0.0000e+00\n",
            "Epoch 4234/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3238 - accuracy: 0.0000e+00 - val_loss: 0.3526 - val_accuracy: 0.0000e+00\n",
            "Epoch 4235/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3280 - accuracy: 0.0000e+00 - val_loss: 0.3525 - val_accuracy: 0.0000e+00\n",
            "Epoch 4236/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3156 - accuracy: 0.0000e+00 - val_loss: 0.3525 - val_accuracy: 0.0000e+00\n",
            "Epoch 4237/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3251 - accuracy: 0.0000e+00 - val_loss: 0.3525 - val_accuracy: 0.0000e+00\n",
            "Epoch 4238/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3210 - accuracy: 0.0000e+00 - val_loss: 0.3524 - val_accuracy: 0.0000e+00\n",
            "Epoch 4239/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3186 - accuracy: 0.0000e+00 - val_loss: 0.3524 - val_accuracy: 0.0000e+00\n",
            "Epoch 4240/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3278 - accuracy: 0.0000e+00 - val_loss: 0.3524 - val_accuracy: 0.0000e+00\n",
            "Epoch 4241/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3337 - accuracy: 0.0000e+00 - val_loss: 0.3524 - val_accuracy: 0.0000e+00\n",
            "Epoch 4242/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3243 - accuracy: 0.0000e+00 - val_loss: 0.3524 - val_accuracy: 0.0000e+00\n",
            "Epoch 4243/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3219 - accuracy: 0.0000e+00 - val_loss: 0.3523 - val_accuracy: 0.0000e+00\n",
            "Epoch 4244/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3235 - accuracy: 0.0000e+00 - val_loss: 0.3523 - val_accuracy: 0.0000e+00\n",
            "Epoch 4245/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3225 - accuracy: 0.0000e+00 - val_loss: 0.3522 - val_accuracy: 0.0000e+00\n",
            "Epoch 4246/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3198 - accuracy: 0.0000e+00 - val_loss: 0.3522 - val_accuracy: 0.0000e+00\n",
            "Epoch 4247/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3335 - accuracy: 0.0000e+00 - val_loss: 0.3522 - val_accuracy: 0.0000e+00\n",
            "Epoch 4248/5000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3219 - accuracy: 0.0000e+00 - val_loss: 0.3521 - val_accuracy: 0.0000e+00\n",
            "Epoch 4249/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3196 - accuracy: 0.0000e+00 - val_loss: 0.3521 - val_accuracy: 0.0000e+00\n",
            "Epoch 4250/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3255 - accuracy: 0.0000e+00 - val_loss: 0.3521 - val_accuracy: 0.0000e+00\n",
            "Epoch 4251/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3279 - accuracy: 0.0000e+00 - val_loss: 0.3520 - val_accuracy: 0.0000e+00\n",
            "Epoch 4252/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3343 - accuracy: 0.0000e+00 - val_loss: 0.3521 - val_accuracy: 0.0000e+00\n",
            "Epoch 4253/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3273 - accuracy: 0.0000e+00 - val_loss: 0.3520 - val_accuracy: 0.0000e+00\n",
            "Epoch 4254/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3341 - accuracy: 0.0000e+00 - val_loss: 0.3520 - val_accuracy: 0.0000e+00\n",
            "Epoch 4255/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3248 - accuracy: 0.0000e+00 - val_loss: 0.3520 - val_accuracy: 0.0000e+00\n",
            "Epoch 4256/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3217 - accuracy: 0.0000e+00 - val_loss: 0.3519 - val_accuracy: 0.0000e+00\n",
            "Epoch 4257/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3259 - accuracy: 0.0000e+00 - val_loss: 0.3518 - val_accuracy: 0.0000e+00\n",
            "Epoch 4258/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3227 - accuracy: 0.0000e+00 - val_loss: 0.3517 - val_accuracy: 0.0000e+00\n",
            "Epoch 4259/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3173 - accuracy: 0.0000e+00 - val_loss: 0.3517 - val_accuracy: 0.0000e+00\n",
            "Epoch 4260/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3359 - accuracy: 0.0000e+00 - val_loss: 0.3518 - val_accuracy: 0.0000e+00\n",
            "Epoch 4261/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3252 - accuracy: 0.0000e+00 - val_loss: 0.3518 - val_accuracy: 0.0000e+00\n",
            "Epoch 4262/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3167 - accuracy: 0.0000e+00 - val_loss: 0.3518 - val_accuracy: 0.0000e+00\n",
            "Epoch 4263/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3221 - accuracy: 0.0000e+00 - val_loss: 0.3517 - val_accuracy: 0.0000e+00\n",
            "Epoch 4264/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3207 - accuracy: 0.0000e+00 - val_loss: 0.3517 - val_accuracy: 0.0000e+00\n",
            "Epoch 4265/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3250 - accuracy: 0.0000e+00 - val_loss: 0.3516 - val_accuracy: 0.0000e+00\n",
            "Epoch 4266/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3252 - accuracy: 0.0000e+00 - val_loss: 0.3516 - val_accuracy: 0.0000e+00\n",
            "Epoch 4267/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3299 - accuracy: 0.0000e+00 - val_loss: 0.3516 - val_accuracy: 0.0000e+00\n",
            "Epoch 4268/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3266 - accuracy: 0.0000e+00 - val_loss: 0.3516 - val_accuracy: 0.0000e+00\n",
            "Epoch 4269/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3251 - accuracy: 0.0000e+00 - val_loss: 0.3516 - val_accuracy: 0.0000e+00\n",
            "Epoch 4270/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3202 - accuracy: 0.0000e+00 - val_loss: 0.3515 - val_accuracy: 0.0000e+00\n",
            "Epoch 4271/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3318 - accuracy: 0.0000e+00 - val_loss: 0.3515 - val_accuracy: 0.0000e+00\n",
            "Epoch 4272/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3244 - accuracy: 0.0000e+00 - val_loss: 0.3515 - val_accuracy: 0.0000e+00\n",
            "Epoch 4273/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3283 - accuracy: 0.0000e+00 - val_loss: 0.3514 - val_accuracy: 0.0000e+00\n",
            "Epoch 4274/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3241 - accuracy: 0.0000e+00 - val_loss: 0.3514 - val_accuracy: 0.0000e+00\n",
            "Epoch 4275/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3306 - accuracy: 0.0000e+00 - val_loss: 0.3515 - val_accuracy: 0.0000e+00\n",
            "Epoch 4276/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3224 - accuracy: 0.0000e+00 - val_loss: 0.3514 - val_accuracy: 0.0000e+00\n",
            "Epoch 4277/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3202 - accuracy: 0.0000e+00 - val_loss: 0.3513 - val_accuracy: 0.0000e+00\n",
            "Epoch 4278/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3175 - accuracy: 0.0000e+00 - val_loss: 0.3514 - val_accuracy: 0.0000e+00\n",
            "Epoch 4279/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3227 - accuracy: 0.0000e+00 - val_loss: 0.3514 - val_accuracy: 0.0000e+00\n",
            "Epoch 4280/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3243 - accuracy: 0.0000e+00 - val_loss: 0.3514 - val_accuracy: 0.0000e+00\n",
            "Epoch 4281/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3208 - accuracy: 0.0000e+00 - val_loss: 0.3513 - val_accuracy: 0.0000e+00\n",
            "Epoch 4282/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3252 - accuracy: 0.0000e+00 - val_loss: 0.3513 - val_accuracy: 0.0000e+00\n",
            "Epoch 4283/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3251 - accuracy: 0.0000e+00 - val_loss: 0.3513 - val_accuracy: 0.0000e+00\n",
            "Epoch 4284/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3186 - accuracy: 0.0000e+00 - val_loss: 0.3512 - val_accuracy: 0.0000e+00\n",
            "Epoch 4285/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3406 - accuracy: 0.0000e+00 - val_loss: 0.3512 - val_accuracy: 0.0000e+00\n",
            "Epoch 4286/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3202 - accuracy: 0.0000e+00 - val_loss: 0.3511 - val_accuracy: 0.0000e+00\n",
            "Epoch 4287/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3290 - accuracy: 0.0000e+00 - val_loss: 0.3511 - val_accuracy: 0.0000e+00\n",
            "Epoch 4288/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3303 - accuracy: 0.0000e+00 - val_loss: 0.3511 - val_accuracy: 0.0000e+00\n",
            "Epoch 4289/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3268 - accuracy: 0.0000e+00 - val_loss: 0.3511 - val_accuracy: 0.0000e+00\n",
            "Epoch 4290/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3233 - accuracy: 0.0000e+00 - val_loss: 0.3511 - val_accuracy: 0.0000e+00\n",
            "Epoch 4291/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3245 - accuracy: 0.0000e+00 - val_loss: 0.3510 - val_accuracy: 0.0000e+00\n",
            "Epoch 4292/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3250 - accuracy: 0.0000e+00 - val_loss: 0.3510 - val_accuracy: 0.0000e+00\n",
            "Epoch 4293/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3221 - accuracy: 0.0000e+00 - val_loss: 0.3510 - val_accuracy: 0.0000e+00\n",
            "Epoch 4294/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3200 - accuracy: 0.0000e+00 - val_loss: 0.3509 - val_accuracy: 0.0000e+00\n",
            "Epoch 4295/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3242 - accuracy: 0.0000e+00 - val_loss: 0.3510 - val_accuracy: 0.0000e+00\n",
            "Epoch 4296/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3228 - accuracy: 0.0000e+00 - val_loss: 0.3509 - val_accuracy: 0.0000e+00\n",
            "Epoch 4297/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3251 - accuracy: 0.0000e+00 - val_loss: 0.3510 - val_accuracy: 0.0000e+00\n",
            "Epoch 4298/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3225 - accuracy: 0.0000e+00 - val_loss: 0.3510 - val_accuracy: 0.0000e+00\n",
            "Epoch 4299/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3230 - accuracy: 0.0000e+00 - val_loss: 0.3510 - val_accuracy: 0.0000e+00\n",
            "Epoch 4300/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3265 - accuracy: 0.0000e+00 - val_loss: 0.3510 - val_accuracy: 0.0000e+00\n",
            "Epoch 4301/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3253 - accuracy: 0.0000e+00 - val_loss: 0.3510 - val_accuracy: 0.0000e+00\n",
            "Epoch 4302/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3238 - accuracy: 0.0000e+00 - val_loss: 0.3510 - val_accuracy: 0.0000e+00\n",
            "Epoch 4303/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3235 - accuracy: 0.0000e+00 - val_loss: 0.3509 - val_accuracy: 0.0000e+00\n",
            "Epoch 4304/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3241 - accuracy: 0.0000e+00 - val_loss: 0.3509 - val_accuracy: 0.0000e+00\n",
            "Epoch 4305/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3349 - accuracy: 0.0000e+00 - val_loss: 0.3509 - val_accuracy: 0.0000e+00\n",
            "Epoch 4306/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3254 - accuracy: 0.0000e+00 - val_loss: 0.3508 - val_accuracy: 0.0000e+00\n",
            "Epoch 4307/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3112 - accuracy: 0.0000e+00 - val_loss: 0.3508 - val_accuracy: 0.0000e+00\n",
            "Epoch 4308/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3413 - accuracy: 0.0000e+00 - val_loss: 0.3508 - val_accuracy: 0.0000e+00\n",
            "Epoch 4309/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3385 - accuracy: 0.0000e+00 - val_loss: 0.3507 - val_accuracy: 0.0000e+00\n",
            "Epoch 4310/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3227 - accuracy: 0.0000e+00 - val_loss: 0.3507 - val_accuracy: 0.0000e+00\n",
            "Epoch 4311/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3216 - accuracy: 0.0000e+00 - val_loss: 0.3507 - val_accuracy: 0.0000e+00\n",
            "Epoch 4312/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3210 - accuracy: 0.0000e+00 - val_loss: 0.3507 - val_accuracy: 0.0000e+00\n",
            "Epoch 4313/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3312 - accuracy: 0.0000e+00 - val_loss: 0.3507 - val_accuracy: 0.0000e+00\n",
            "Epoch 4314/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3328 - accuracy: 0.0000e+00 - val_loss: 0.3507 - val_accuracy: 0.0000e+00\n",
            "Epoch 4315/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3223 - accuracy: 0.0000e+00 - val_loss: 0.3507 - val_accuracy: 0.0000e+00\n",
            "Epoch 4316/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3277 - accuracy: 0.0000e+00 - val_loss: 0.3507 - val_accuracy: 0.0000e+00\n",
            "Epoch 4317/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3370 - accuracy: 0.0000e+00 - val_loss: 0.3506 - val_accuracy: 0.0000e+00\n",
            "Epoch 4318/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3176 - accuracy: 0.0000e+00 - val_loss: 0.3506 - val_accuracy: 0.0000e+00\n",
            "Epoch 4319/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3178 - accuracy: 0.0000e+00 - val_loss: 0.3505 - val_accuracy: 0.0000e+00\n",
            "Epoch 4320/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3197 - accuracy: 0.0000e+00 - val_loss: 0.3506 - val_accuracy: 0.0000e+00\n",
            "Epoch 4321/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3222 - accuracy: 0.0000e+00 - val_loss: 0.3505 - val_accuracy: 0.0000e+00\n",
            "Epoch 4322/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3329 - accuracy: 0.0000e+00 - val_loss: 0.3506 - val_accuracy: 0.0000e+00\n",
            "Epoch 4323/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3293 - accuracy: 0.0000e+00 - val_loss: 0.3506 - val_accuracy: 0.0000e+00\n",
            "Epoch 4324/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3267 - accuracy: 0.0000e+00 - val_loss: 0.3505 - val_accuracy: 0.0000e+00\n",
            "Epoch 4325/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3315 - accuracy: 0.0000e+00 - val_loss: 0.3504 - val_accuracy: 0.0000e+00\n",
            "Epoch 4326/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3274 - accuracy: 0.0000e+00 - val_loss: 0.3504 - val_accuracy: 0.0000e+00\n",
            "Epoch 4327/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3327 - accuracy: 0.0000e+00 - val_loss: 0.3504 - val_accuracy: 0.0000e+00\n",
            "Epoch 4328/5000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3353 - accuracy: 0.0000e+00 - val_loss: 0.3504 - val_accuracy: 0.0000e+00\n",
            "Epoch 4329/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3256 - accuracy: 0.0000e+00 - val_loss: 0.3503 - val_accuracy: 0.0000e+00\n",
            "Epoch 4330/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3269 - accuracy: 0.0000e+00 - val_loss: 0.3504 - val_accuracy: 0.0000e+00\n",
            "Epoch 4331/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3188 - accuracy: 0.0000e+00 - val_loss: 0.3503 - val_accuracy: 0.0000e+00\n",
            "Epoch 4332/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3173 - accuracy: 0.0000e+00 - val_loss: 0.3502 - val_accuracy: 0.0000e+00\n",
            "Epoch 4333/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3214 - accuracy: 0.0000e+00 - val_loss: 0.3502 - val_accuracy: 0.0000e+00\n",
            "Epoch 4334/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3180 - accuracy: 0.0000e+00 - val_loss: 0.3502 - val_accuracy: 0.0000e+00\n",
            "Epoch 4335/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3191 - accuracy: 0.0000e+00 - val_loss: 0.3502 - val_accuracy: 0.0000e+00\n",
            "Epoch 4336/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3188 - accuracy: 0.0000e+00 - val_loss: 0.3502 - val_accuracy: 0.0000e+00\n",
            "Epoch 4337/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3224 - accuracy: 0.0000e+00 - val_loss: 0.3502 - val_accuracy: 0.0000e+00\n",
            "Epoch 4338/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3226 - accuracy: 0.0000e+00 - val_loss: 0.3503 - val_accuracy: 0.0000e+00\n",
            "Epoch 4339/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3286 - accuracy: 0.0000e+00 - val_loss: 0.3502 - val_accuracy: 0.0000e+00\n",
            "Epoch 4340/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3192 - accuracy: 0.0000e+00 - val_loss: 0.3502 - val_accuracy: 0.0000e+00\n",
            "Epoch 4341/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3234 - accuracy: 0.0000e+00 - val_loss: 0.3502 - val_accuracy: 0.0000e+00\n",
            "Epoch 4342/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3216 - accuracy: 0.0000e+00 - val_loss: 0.3502 - val_accuracy: 0.0000e+00\n",
            "Epoch 4343/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3283 - accuracy: 0.0000e+00 - val_loss: 0.3502 - val_accuracy: 0.0000e+00\n",
            "Epoch 4344/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3200 - accuracy: 0.0000e+00 - val_loss: 0.3503 - val_accuracy: 0.0000e+00\n",
            "Epoch 4345/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3217 - accuracy: 0.0000e+00 - val_loss: 0.3502 - val_accuracy: 0.0000e+00\n",
            "Epoch 4346/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3213 - accuracy: 0.0000e+00 - val_loss: 0.3502 - val_accuracy: 0.0000e+00\n",
            "Epoch 4347/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3248 - accuracy: 0.0000e+00 - val_loss: 0.3501 - val_accuracy: 0.0000e+00\n",
            "Epoch 4348/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3234 - accuracy: 0.0000e+00 - val_loss: 0.3501 - val_accuracy: 0.0000e+00\n",
            "Epoch 4349/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3216 - accuracy: 0.0000e+00 - val_loss: 0.3500 - val_accuracy: 0.0000e+00\n",
            "Epoch 4350/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3287 - accuracy: 0.0000e+00 - val_loss: 0.3500 - val_accuracy: 0.0000e+00\n",
            "Epoch 4351/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3247 - accuracy: 0.0000e+00 - val_loss: 0.3500 - val_accuracy: 0.0000e+00\n",
            "Epoch 4352/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3216 - accuracy: 0.0000e+00 - val_loss: 0.3499 - val_accuracy: 0.0000e+00\n",
            "Epoch 4353/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3273 - accuracy: 0.0000e+00 - val_loss: 0.3499 - val_accuracy: 0.0000e+00\n",
            "Epoch 4354/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3213 - accuracy: 0.0000e+00 - val_loss: 0.3498 - val_accuracy: 0.0000e+00\n",
            "Epoch 4355/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3162 - accuracy: 0.0000e+00 - val_loss: 0.3498 - val_accuracy: 0.0000e+00\n",
            "Epoch 4356/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3330 - accuracy: 0.0000e+00 - val_loss: 0.3498 - val_accuracy: 0.0000e+00\n",
            "Epoch 4357/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3224 - accuracy: 0.0000e+00 - val_loss: 0.3499 - val_accuracy: 0.0000e+00\n",
            "Epoch 4358/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3195 - accuracy: 0.0000e+00 - val_loss: 0.3498 - val_accuracy: 0.0000e+00\n",
            "Epoch 4359/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3227 - accuracy: 0.0000e+00 - val_loss: 0.3497 - val_accuracy: 0.0000e+00\n",
            "Epoch 4360/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3285 - accuracy: 0.0000e+00 - val_loss: 0.3497 - val_accuracy: 0.0000e+00\n",
            "Epoch 4361/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3260 - accuracy: 0.0000e+00 - val_loss: 0.3497 - val_accuracy: 0.0000e+00\n",
            "Epoch 4362/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3207 - accuracy: 0.0000e+00 - val_loss: 0.3497 - val_accuracy: 0.0000e+00\n",
            "Epoch 4363/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3219 - accuracy: 0.0000e+00 - val_loss: 0.3496 - val_accuracy: 0.0000e+00\n",
            "Epoch 4364/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3215 - accuracy: 0.0000e+00 - val_loss: 0.3496 - val_accuracy: 0.0000e+00\n",
            "Epoch 4365/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3244 - accuracy: 0.0000e+00 - val_loss: 0.3496 - val_accuracy: 0.0000e+00\n",
            "Epoch 4366/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3236 - accuracy: 0.0000e+00 - val_loss: 0.3496 - val_accuracy: 0.0000e+00\n",
            "Epoch 4367/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3262 - accuracy: 0.0000e+00 - val_loss: 0.3495 - val_accuracy: 0.0000e+00\n",
            "Epoch 4368/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3161 - accuracy: 0.0000e+00 - val_loss: 0.3496 - val_accuracy: 0.0000e+00\n",
            "Epoch 4369/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3202 - accuracy: 0.0000e+00 - val_loss: 0.3495 - val_accuracy: 0.0000e+00\n",
            "Epoch 4370/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3181 - accuracy: 0.0000e+00 - val_loss: 0.3495 - val_accuracy: 0.0000e+00\n",
            "Epoch 4371/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3183 - accuracy: 0.0000e+00 - val_loss: 0.3495 - val_accuracy: 0.0000e+00\n",
            "Epoch 4372/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3275 - accuracy: 0.0000e+00 - val_loss: 0.3495 - val_accuracy: 0.0000e+00\n",
            "Epoch 4373/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3241 - accuracy: 0.0000e+00 - val_loss: 0.3495 - val_accuracy: 0.0000e+00\n",
            "Epoch 4374/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3244 - accuracy: 0.0000e+00 - val_loss: 0.3495 - val_accuracy: 0.0000e+00\n",
            "Epoch 4375/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3293 - accuracy: 0.0000e+00 - val_loss: 0.3494 - val_accuracy: 0.0000e+00\n",
            "Epoch 4376/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3226 - accuracy: 0.0000e+00 - val_loss: 0.3494 - val_accuracy: 0.0000e+00\n",
            "Epoch 4377/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3195 - accuracy: 0.0000e+00 - val_loss: 0.3494 - val_accuracy: 0.0000e+00\n",
            "Epoch 4378/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3202 - accuracy: 0.0000e+00 - val_loss: 0.3494 - val_accuracy: 0.0000e+00\n",
            "Epoch 4379/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3180 - accuracy: 0.0000e+00 - val_loss: 0.3493 - val_accuracy: 0.0000e+00\n",
            "Epoch 4380/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3265 - accuracy: 0.0000e+00 - val_loss: 0.3493 - val_accuracy: 0.0000e+00\n",
            "Epoch 4381/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3182 - accuracy: 0.0000e+00 - val_loss: 0.3493 - val_accuracy: 0.0000e+00\n",
            "Epoch 4382/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3172 - accuracy: 0.0000e+00 - val_loss: 0.3493 - val_accuracy: 0.0000e+00\n",
            "Epoch 4383/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3171 - accuracy: 0.0000e+00 - val_loss: 0.3492 - val_accuracy: 0.0000e+00\n",
            "Epoch 4384/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3202 - accuracy: 0.0000e+00 - val_loss: 0.3492 - val_accuracy: 0.0000e+00\n",
            "Epoch 4385/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3242 - accuracy: 0.0000e+00 - val_loss: 0.3492 - val_accuracy: 0.0000e+00\n",
            "Epoch 4386/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3189 - accuracy: 0.0000e+00 - val_loss: 0.3491 - val_accuracy: 0.0000e+00\n",
            "Epoch 4387/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3281 - accuracy: 0.0000e+00 - val_loss: 0.3491 - val_accuracy: 0.0000e+00\n",
            "Epoch 4388/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3213 - accuracy: 0.0000e+00 - val_loss: 0.3490 - val_accuracy: 0.0000e+00\n",
            "Epoch 4389/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3269 - accuracy: 0.0000e+00 - val_loss: 0.3490 - val_accuracy: 0.0000e+00\n",
            "Epoch 4390/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3217 - accuracy: 0.0000e+00 - val_loss: 0.3490 - val_accuracy: 0.0000e+00\n",
            "Epoch 4391/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3340 - accuracy: 0.0000e+00 - val_loss: 0.3491 - val_accuracy: 0.0000e+00\n",
            "Epoch 4392/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3288 - accuracy: 0.0000e+00 - val_loss: 0.3490 - val_accuracy: 0.0000e+00\n",
            "Epoch 4393/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3262 - accuracy: 0.0000e+00 - val_loss: 0.3490 - val_accuracy: 0.0000e+00\n",
            "Epoch 4394/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3183 - accuracy: 0.0000e+00 - val_loss: 0.3490 - val_accuracy: 0.0000e+00\n",
            "Epoch 4395/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3259 - accuracy: 0.0000e+00 - val_loss: 0.3490 - val_accuracy: 0.0000e+00\n",
            "Epoch 4396/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3182 - accuracy: 0.0000e+00 - val_loss: 0.3490 - val_accuracy: 0.0000e+00\n",
            "Epoch 4397/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3187 - accuracy: 0.0000e+00 - val_loss: 0.3489 - val_accuracy: 0.0000e+00\n",
            "Epoch 4398/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3235 - accuracy: 0.0000e+00 - val_loss: 0.3489 - val_accuracy: 0.0000e+00\n",
            "Epoch 4399/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3220 - accuracy: 0.0000e+00 - val_loss: 0.3488 - val_accuracy: 0.0000e+00\n",
            "Epoch 4400/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3322 - accuracy: 0.0000e+00 - val_loss: 0.3488 - val_accuracy: 0.0000e+00\n",
            "Epoch 4401/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3150 - accuracy: 0.0000e+00 - val_loss: 0.3488 - val_accuracy: 0.0000e+00\n",
            "Epoch 4402/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3189 - accuracy: 0.0000e+00 - val_loss: 0.3488 - val_accuracy: 0.0000e+00\n",
            "Epoch 4403/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3217 - accuracy: 0.0000e+00 - val_loss: 0.3488 - val_accuracy: 0.0000e+00\n",
            "Epoch 4404/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3191 - accuracy: 0.0000e+00 - val_loss: 0.3488 - val_accuracy: 0.0000e+00\n",
            "Epoch 4405/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3200 - accuracy: 0.0000e+00 - val_loss: 0.3487 - val_accuracy: 0.0000e+00\n",
            "Epoch 4406/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3202 - accuracy: 0.0000e+00 - val_loss: 0.3487 - val_accuracy: 0.0000e+00\n",
            "Epoch 4407/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3199 - accuracy: 0.0000e+00 - val_loss: 0.3487 - val_accuracy: 0.0000e+00\n",
            "Epoch 4408/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3199 - accuracy: 0.0000e+00 - val_loss: 0.3487 - val_accuracy: 0.0000e+00\n",
            "Epoch 4409/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3195 - accuracy: 0.0000e+00 - val_loss: 0.3487 - val_accuracy: 0.0000e+00\n",
            "Epoch 4410/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3267 - accuracy: 0.0000e+00 - val_loss: 0.3486 - val_accuracy: 0.0000e+00\n",
            "Epoch 4411/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3226 - accuracy: 0.0000e+00 - val_loss: 0.3485 - val_accuracy: 0.0000e+00\n",
            "Epoch 4412/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3192 - accuracy: 0.0000e+00 - val_loss: 0.3486 - val_accuracy: 0.0000e+00\n",
            "Epoch 4413/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3264 - accuracy: 0.0000e+00 - val_loss: 0.3486 - val_accuracy: 0.0000e+00\n",
            "Epoch 4414/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3271 - accuracy: 0.0000e+00 - val_loss: 0.3485 - val_accuracy: 0.0000e+00\n",
            "Epoch 4415/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3166 - accuracy: 0.0000e+00 - val_loss: 0.3486 - val_accuracy: 0.0000e+00\n",
            "Epoch 4416/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3205 - accuracy: 0.0000e+00 - val_loss: 0.3486 - val_accuracy: 0.0000e+00\n",
            "Epoch 4417/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3181 - accuracy: 0.0000e+00 - val_loss: 0.3486 - val_accuracy: 0.0000e+00\n",
            "Epoch 4418/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3169 - accuracy: 0.0000e+00 - val_loss: 0.3486 - val_accuracy: 0.0000e+00\n",
            "Epoch 4419/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3144 - accuracy: 0.0000e+00 - val_loss: 0.3485 - val_accuracy: 0.0000e+00\n",
            "Epoch 4420/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3278 - accuracy: 0.0000e+00 - val_loss: 0.3486 - val_accuracy: 0.0000e+00\n",
            "Epoch 4421/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3190 - accuracy: 0.0000e+00 - val_loss: 0.3485 - val_accuracy: 0.0000e+00\n",
            "Epoch 4422/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3211 - accuracy: 0.0000e+00 - val_loss: 0.3485 - val_accuracy: 0.0000e+00\n",
            "Epoch 4423/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3277 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 4424/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3205 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 4425/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3158 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 4426/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3263 - accuracy: 0.0000e+00 - val_loss: 0.3485 - val_accuracy: 0.0000e+00\n",
            "Epoch 4427/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3197 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 4428/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3156 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 4429/5000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3189 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 4430/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3258 - accuracy: 0.0000e+00 - val_loss: 0.3485 - val_accuracy: 0.0000e+00\n",
            "Epoch 4431/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3272 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 4432/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3270 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 4433/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3259 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 4434/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3189 - accuracy: 0.0000e+00 - val_loss: 0.3483 - val_accuracy: 0.0000e+00\n",
            "Epoch 4435/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3146 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 4436/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3275 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 4437/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3239 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 4438/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3221 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 4439/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3304 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 4440/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3188 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 4441/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3222 - accuracy: 0.0000e+00 - val_loss: 0.3483 - val_accuracy: 0.0000e+00\n",
            "Epoch 4442/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3219 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\n",
            "Epoch 4443/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3156 - accuracy: 0.0000e+00 - val_loss: 0.3483 - val_accuracy: 0.0000e+00\n",
            "Epoch 4444/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3187 - accuracy: 0.0000e+00 - val_loss: 0.3482 - val_accuracy: 0.0000e+00\n",
            "Epoch 4445/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3178 - accuracy: 0.0000e+00 - val_loss: 0.3482 - val_accuracy: 0.0000e+00\n",
            "Epoch 4446/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3169 - accuracy: 0.0000e+00 - val_loss: 0.3482 - val_accuracy: 0.0000e+00\n",
            "Epoch 4447/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3193 - accuracy: 0.0000e+00 - val_loss: 0.3482 - val_accuracy: 0.0000e+00\n",
            "Epoch 4448/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3176 - accuracy: 0.0000e+00 - val_loss: 0.3482 - val_accuracy: 0.0000e+00\n",
            "Epoch 4449/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3263 - accuracy: 0.0000e+00 - val_loss: 0.3481 - val_accuracy: 0.0000e+00\n",
            "Epoch 4450/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3162 - accuracy: 0.0000e+00 - val_loss: 0.3481 - val_accuracy: 0.0000e+00\n",
            "Epoch 4451/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.0000e+00 - val_loss: 0.3481 - val_accuracy: 0.0000e+00\n",
            "Epoch 4452/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3120 - accuracy: 0.0000e+00 - val_loss: 0.3481 - val_accuracy: 0.0000e+00\n",
            "Epoch 4453/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3214 - accuracy: 0.0000e+00 - val_loss: 0.3480 - val_accuracy: 0.0000e+00\n",
            "Epoch 4454/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3292 - accuracy: 0.0000e+00 - val_loss: 0.3480 - val_accuracy: 0.0000e+00\n",
            "Epoch 4455/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3158 - accuracy: 0.0000e+00 - val_loss: 0.3479 - val_accuracy: 0.0000e+00\n",
            "Epoch 4456/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3122 - accuracy: 0.0000e+00 - val_loss: 0.3479 - val_accuracy: 0.0000e+00\n",
            "Epoch 4457/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3199 - accuracy: 0.0000e+00 - val_loss: 0.3479 - val_accuracy: 0.0000e+00\n",
            "Epoch 4458/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3116 - accuracy: 0.0000e+00 - val_loss: 0.3479 - val_accuracy: 0.0000e+00\n",
            "Epoch 4459/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3174 - accuracy: 0.0000e+00 - val_loss: 0.3479 - val_accuracy: 0.0000e+00\n",
            "Epoch 4460/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3191 - accuracy: 0.0000e+00 - val_loss: 0.3479 - val_accuracy: 0.0000e+00\n",
            "Epoch 4461/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3191 - accuracy: 0.0000e+00 - val_loss: 0.3479 - val_accuracy: 0.0000e+00\n",
            "Epoch 4462/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3127 - accuracy: 0.0000e+00 - val_loss: 0.3479 - val_accuracy: 0.0000e+00\n",
            "Epoch 4463/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3159 - accuracy: 0.0000e+00 - val_loss: 0.3478 - val_accuracy: 0.0000e+00\n",
            "Epoch 4464/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3191 - accuracy: 0.0000e+00 - val_loss: 0.3479 - val_accuracy: 0.0000e+00\n",
            "Epoch 4465/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3289 - accuracy: 0.0000e+00 - val_loss: 0.3479 - val_accuracy: 0.0000e+00\n",
            "Epoch 4466/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3262 - accuracy: 0.0000e+00 - val_loss: 0.3478 - val_accuracy: 0.0000e+00\n",
            "Epoch 4467/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3144 - accuracy: 0.0000e+00 - val_loss: 0.3478 - val_accuracy: 0.0000e+00\n",
            "Epoch 4468/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3222 - accuracy: 0.0000e+00 - val_loss: 0.3478 - val_accuracy: 0.0000e+00\n",
            "Epoch 4469/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3197 - accuracy: 0.0000e+00 - val_loss: 0.3478 - val_accuracy: 0.0000e+00\n",
            "Epoch 4470/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3140 - accuracy: 0.0000e+00 - val_loss: 0.3477 - val_accuracy: 0.0000e+00\n",
            "Epoch 4471/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3162 - accuracy: 0.0000e+00 - val_loss: 0.3477 - val_accuracy: 0.0000e+00\n",
            "Epoch 4472/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3205 - accuracy: 0.0000e+00 - val_loss: 0.3477 - val_accuracy: 0.0000e+00\n",
            "Epoch 4473/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3166 - accuracy: 0.0000e+00 - val_loss: 0.3477 - val_accuracy: 0.0000e+00\n",
            "Epoch 4474/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3209 - accuracy: 0.0000e+00 - val_loss: 0.3476 - val_accuracy: 0.0000e+00\n",
            "Epoch 4475/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3221 - accuracy: 0.0000e+00 - val_loss: 0.3477 - val_accuracy: 0.0000e+00\n",
            "Epoch 4476/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3201 - accuracy: 0.0000e+00 - val_loss: 0.3476 - val_accuracy: 0.0000e+00\n",
            "Epoch 4477/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3162 - accuracy: 0.0000e+00 - val_loss: 0.3477 - val_accuracy: 0.0000e+00\n",
            "Epoch 4478/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3230 - accuracy: 0.0000e+00 - val_loss: 0.3476 - val_accuracy: 0.0000e+00\n",
            "Epoch 4479/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3208 - accuracy: 0.0000e+00 - val_loss: 0.3476 - val_accuracy: 0.0000e+00\n",
            "Epoch 4480/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3259 - accuracy: 0.0000e+00 - val_loss: 0.3476 - val_accuracy: 0.0000e+00\n",
            "Epoch 4481/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3324 - accuracy: 0.0000e+00 - val_loss: 0.3475 - val_accuracy: 0.0000e+00\n",
            "Epoch 4482/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3194 - accuracy: 0.0000e+00 - val_loss: 0.3476 - val_accuracy: 0.0000e+00\n",
            "Epoch 4483/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3211 - accuracy: 0.0000e+00 - val_loss: 0.3476 - val_accuracy: 0.0000e+00\n",
            "Epoch 4484/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3210 - accuracy: 0.0000e+00 - val_loss: 0.3476 - val_accuracy: 0.0000e+00\n",
            "Epoch 4485/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3289 - accuracy: 0.0000e+00 - val_loss: 0.3476 - val_accuracy: 0.0000e+00\n",
            "Epoch 4486/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3206 - accuracy: 0.0000e+00 - val_loss: 0.3475 - val_accuracy: 0.0000e+00\n",
            "Epoch 4487/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3218 - accuracy: 0.0000e+00 - val_loss: 0.3475 - val_accuracy: 0.0000e+00\n",
            "Epoch 4488/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3191 - accuracy: 0.0000e+00 - val_loss: 0.3475 - val_accuracy: 0.0000e+00\n",
            "Epoch 4489/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3188 - accuracy: 0.0000e+00 - val_loss: 0.3475 - val_accuracy: 0.0000e+00\n",
            "Epoch 4490/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3344 - accuracy: 0.0000e+00 - val_loss: 0.3475 - val_accuracy: 0.0000e+00\n",
            "Epoch 4491/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3214 - accuracy: 0.0000e+00 - val_loss: 0.3475 - val_accuracy: 0.0000e+00\n",
            "Epoch 4492/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3242 - accuracy: 0.0000e+00 - val_loss: 0.3475 - val_accuracy: 0.0000e+00\n",
            "Epoch 4493/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3219 - accuracy: 0.0000e+00 - val_loss: 0.3474 - val_accuracy: 0.0000e+00\n",
            "Epoch 4494/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3231 - accuracy: 0.0000e+00 - val_loss: 0.3473 - val_accuracy: 0.0000e+00\n",
            "Epoch 4495/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3159 - accuracy: 0.0000e+00 - val_loss: 0.3472 - val_accuracy: 0.0000e+00\n",
            "Epoch 4496/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3234 - accuracy: 0.0000e+00 - val_loss: 0.3472 - val_accuracy: 0.0000e+00\n",
            "Epoch 4497/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3200 - accuracy: 0.0000e+00 - val_loss: 0.3472 - val_accuracy: 0.0000e+00\n",
            "Epoch 4498/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3223 - accuracy: 0.0000e+00 - val_loss: 0.3473 - val_accuracy: 0.0000e+00\n",
            "Epoch 4499/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3265 - accuracy: 0.0000e+00 - val_loss: 0.3473 - val_accuracy: 0.0000e+00\n",
            "Epoch 4500/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3266 - accuracy: 0.0000e+00 - val_loss: 0.3472 - val_accuracy: 0.0000e+00\n",
            "Epoch 4501/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3240 - accuracy: 0.0000e+00 - val_loss: 0.3473 - val_accuracy: 0.0000e+00\n",
            "Epoch 4502/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3176 - accuracy: 0.0000e+00 - val_loss: 0.3472 - val_accuracy: 0.0000e+00\n",
            "Epoch 4503/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3222 - accuracy: 0.0000e+00 - val_loss: 0.3472 - val_accuracy: 0.0000e+00\n",
            "Epoch 4504/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3206 - accuracy: 0.0000e+00 - val_loss: 0.3473 - val_accuracy: 0.0000e+00\n",
            "Epoch 4505/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3221 - accuracy: 0.0000e+00 - val_loss: 0.3473 - val_accuracy: 0.0000e+00\n",
            "Epoch 4506/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3198 - accuracy: 0.0000e+00 - val_loss: 0.3473 - val_accuracy: 0.0000e+00\n",
            "Epoch 4507/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3186 - accuracy: 0.0000e+00 - val_loss: 0.3473 - val_accuracy: 0.0000e+00\n",
            "Epoch 4508/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3271 - accuracy: 0.0000e+00 - val_loss: 0.3472 - val_accuracy: 0.0000e+00\n",
            "Epoch 4509/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3272 - accuracy: 0.0000e+00 - val_loss: 0.3473 - val_accuracy: 0.0000e+00\n",
            "Epoch 4510/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3270 - accuracy: 0.0000e+00 - val_loss: 0.3473 - val_accuracy: 0.0000e+00\n",
            "Epoch 4511/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3198 - accuracy: 0.0000e+00 - val_loss: 0.3473 - val_accuracy: 0.0000e+00\n",
            "Epoch 4512/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3218 - accuracy: 0.0000e+00 - val_loss: 0.3472 - val_accuracy: 0.0000e+00\n",
            "Epoch 4513/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3189 - accuracy: 0.0000e+00 - val_loss: 0.3472 - val_accuracy: 0.0000e+00\n",
            "Epoch 4514/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3171 - accuracy: 0.0000e+00 - val_loss: 0.3472 - val_accuracy: 0.0000e+00\n",
            "Epoch 4515/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3245 - accuracy: 0.0000e+00 - val_loss: 0.3471 - val_accuracy: 0.0000e+00\n",
            "Epoch 4516/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3193 - accuracy: 0.0000e+00 - val_loss: 0.3471 - val_accuracy: 0.0000e+00\n",
            "Epoch 4517/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3131 - accuracy: 0.0000e+00 - val_loss: 0.3470 - val_accuracy: 0.0000e+00\n",
            "Epoch 4518/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3273 - accuracy: 0.0000e+00 - val_loss: 0.3470 - val_accuracy: 0.0000e+00\n",
            "Epoch 4519/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3174 - accuracy: 0.0000e+00 - val_loss: 0.3469 - val_accuracy: 0.0000e+00\n",
            "Epoch 4520/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3169 - accuracy: 0.0000e+00 - val_loss: 0.3469 - val_accuracy: 0.0000e+00\n",
            "Epoch 4521/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3178 - accuracy: 0.0000e+00 - val_loss: 0.3468 - val_accuracy: 0.0000e+00\n",
            "Epoch 4522/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3183 - accuracy: 0.0000e+00 - val_loss: 0.3468 - val_accuracy: 0.0000e+00\n",
            "Epoch 4523/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3214 - accuracy: 0.0000e+00 - val_loss: 0.3467 - val_accuracy: 0.0000e+00\n",
            "Epoch 4524/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3162 - accuracy: 0.0000e+00 - val_loss: 0.3467 - val_accuracy: 0.0000e+00\n",
            "Epoch 4525/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3107 - accuracy: 0.0000e+00 - val_loss: 0.3467 - val_accuracy: 0.0000e+00\n",
            "Epoch 4526/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3179 - accuracy: 0.0000e+00 - val_loss: 0.3466 - val_accuracy: 0.0000e+00\n",
            "Epoch 4527/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3116 - accuracy: 0.0000e+00 - val_loss: 0.3466 - val_accuracy: 0.0000e+00\n",
            "Epoch 4528/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3166 - accuracy: 0.0000e+00 - val_loss: 0.3466 - val_accuracy: 0.0000e+00\n",
            "Epoch 4529/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3236 - accuracy: 0.0000e+00 - val_loss: 0.3466 - val_accuracy: 0.0000e+00\n",
            "Epoch 4530/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3268 - accuracy: 0.0000e+00 - val_loss: 0.3466 - val_accuracy: 0.0000e+00\n",
            "Epoch 4531/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3164 - accuracy: 0.0000e+00 - val_loss: 0.3466 - val_accuracy: 0.0000e+00\n",
            "Epoch 4532/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3187 - accuracy: 0.0000e+00 - val_loss: 0.3465 - val_accuracy: 0.0000e+00\n",
            "Epoch 4533/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3321 - accuracy: 0.0000e+00 - val_loss: 0.3464 - val_accuracy: 0.0000e+00\n",
            "Epoch 4534/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3158 - accuracy: 0.0000e+00 - val_loss: 0.3464 - val_accuracy: 0.0000e+00\n",
            "Epoch 4535/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3163 - accuracy: 0.0000e+00 - val_loss: 0.3463 - val_accuracy: 0.0000e+00\n",
            "Epoch 4536/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3130 - accuracy: 0.0000e+00 - val_loss: 0.3463 - val_accuracy: 0.0000e+00\n",
            "Epoch 4537/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3328 - accuracy: 0.0000e+00 - val_loss: 0.3463 - val_accuracy: 0.0000e+00\n",
            "Epoch 4538/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3196 - accuracy: 0.0000e+00 - val_loss: 0.3463 - val_accuracy: 0.0000e+00\n",
            "Epoch 4539/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3268 - accuracy: 0.0000e+00 - val_loss: 0.3462 - val_accuracy: 0.0000e+00\n",
            "Epoch 4540/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3191 - accuracy: 0.0000e+00 - val_loss: 0.3462 - val_accuracy: 0.0000e+00\n",
            "Epoch 4541/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3155 - accuracy: 0.0000e+00 - val_loss: 0.3462 - val_accuracy: 0.0000e+00\n",
            "Epoch 4542/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3162 - accuracy: 0.0000e+00 - val_loss: 0.3462 - val_accuracy: 0.0000e+00\n",
            "Epoch 4543/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3174 - accuracy: 0.0000e+00 - val_loss: 0.3463 - val_accuracy: 0.0000e+00\n",
            "Epoch 4544/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3206 - accuracy: 0.0000e+00 - val_loss: 0.3464 - val_accuracy: 0.0000e+00\n",
            "Epoch 4545/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3104 - accuracy: 0.0000e+00 - val_loss: 0.3464 - val_accuracy: 0.0000e+00\n",
            "Epoch 4546/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3206 - accuracy: 0.0000e+00 - val_loss: 0.3463 - val_accuracy: 0.0000e+00\n",
            "Epoch 4547/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3173 - accuracy: 0.0000e+00 - val_loss: 0.3463 - val_accuracy: 0.0000e+00\n",
            "Epoch 4548/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3213 - accuracy: 0.0000e+00 - val_loss: 0.3463 - val_accuracy: 0.0000e+00\n",
            "Epoch 4549/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3139 - accuracy: 0.0000e+00 - val_loss: 0.3462 - val_accuracy: 0.0000e+00\n",
            "Epoch 4550/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3222 - accuracy: 0.0000e+00 - val_loss: 0.3462 - val_accuracy: 0.0000e+00\n",
            "Epoch 4551/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3214 - accuracy: 0.0000e+00 - val_loss: 0.3461 - val_accuracy: 0.0000e+00\n",
            "Epoch 4552/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3153 - accuracy: 0.0000e+00 - val_loss: 0.3461 - val_accuracy: 0.0000e+00\n",
            "Epoch 4553/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3168 - accuracy: 0.0000e+00 - val_loss: 0.3461 - val_accuracy: 0.0000e+00\n",
            "Epoch 4554/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3202 - accuracy: 0.0000e+00 - val_loss: 0.3462 - val_accuracy: 0.0000e+00\n",
            "Epoch 4555/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3181 - accuracy: 0.0000e+00 - val_loss: 0.3462 - val_accuracy: 0.0000e+00\n",
            "Epoch 4556/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3127 - accuracy: 0.0000e+00 - val_loss: 0.3462 - val_accuracy: 0.0000e+00\n",
            "Epoch 4557/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3237 - accuracy: 0.0000e+00 - val_loss: 0.3462 - val_accuracy: 0.0000e+00\n",
            "Epoch 4558/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3173 - accuracy: 0.0000e+00 - val_loss: 0.3462 - val_accuracy: 0.0000e+00\n",
            "Epoch 4559/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3182 - accuracy: 0.0000e+00 - val_loss: 0.3460 - val_accuracy: 0.0000e+00\n",
            "Epoch 4560/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3155 - accuracy: 0.0000e+00 - val_loss: 0.3460 - val_accuracy: 0.0000e+00\n",
            "Epoch 4561/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3211 - accuracy: 0.0000e+00 - val_loss: 0.3460 - val_accuracy: 0.0000e+00\n",
            "Epoch 4562/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3218 - accuracy: 0.0000e+00 - val_loss: 0.3460 - val_accuracy: 0.0000e+00\n",
            "Epoch 4563/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3200 - accuracy: 0.0000e+00 - val_loss: 0.3459 - val_accuracy: 0.0000e+00\n",
            "Epoch 4564/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3233 - accuracy: 0.0000e+00 - val_loss: 0.3459 - val_accuracy: 0.0000e+00\n",
            "Epoch 4565/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3148 - accuracy: 0.0000e+00 - val_loss: 0.3458 - val_accuracy: 0.0000e+00\n",
            "Epoch 4566/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3268 - accuracy: 0.0000e+00 - val_loss: 0.3458 - val_accuracy: 0.0000e+00\n",
            "Epoch 4567/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3156 - accuracy: 0.0000e+00 - val_loss: 0.3458 - val_accuracy: 0.0000e+00\n",
            "Epoch 4568/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3290 - accuracy: 0.0000e+00 - val_loss: 0.3459 - val_accuracy: 0.0000e+00\n",
            "Epoch 4569/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3196 - accuracy: 0.0000e+00 - val_loss: 0.3459 - val_accuracy: 0.0000e+00\n",
            "Epoch 4570/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3176 - accuracy: 0.0000e+00 - val_loss: 0.3459 - val_accuracy: 0.0000e+00\n",
            "Epoch 4571/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3166 - accuracy: 0.0000e+00 - val_loss: 0.3458 - val_accuracy: 0.0000e+00\n",
            "Epoch 4572/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3139 - accuracy: 0.0000e+00 - val_loss: 0.3458 - val_accuracy: 0.0000e+00\n",
            "Epoch 4573/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3153 - accuracy: 0.0000e+00 - val_loss: 0.3459 - val_accuracy: 0.0000e+00\n",
            "Epoch 4574/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3158 - accuracy: 0.0000e+00 - val_loss: 0.3458 - val_accuracy: 0.0000e+00\n",
            "Epoch 4575/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3154 - accuracy: 0.0000e+00 - val_loss: 0.3458 - val_accuracy: 0.0000e+00\n",
            "Epoch 4576/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3161 - accuracy: 0.0000e+00 - val_loss: 0.3457 - val_accuracy: 0.0000e+00\n",
            "Epoch 4577/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3269 - accuracy: 0.0000e+00 - val_loss: 0.3457 - val_accuracy: 0.0000e+00\n",
            "Epoch 4578/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3138 - accuracy: 0.0000e+00 - val_loss: 0.3457 - val_accuracy: 0.0000e+00\n",
            "Epoch 4579/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3266 - accuracy: 0.0000e+00 - val_loss: 0.3457 - val_accuracy: 0.0000e+00\n",
            "Epoch 4580/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3140 - accuracy: 0.0000e+00 - val_loss: 0.3457 - val_accuracy: 0.0000e+00\n",
            "Epoch 4581/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3192 - accuracy: 0.0000e+00 - val_loss: 0.3456 - val_accuracy: 0.0000e+00\n",
            "Epoch 4582/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.0000e+00 - val_loss: 0.3457 - val_accuracy: 0.0000e+00\n",
            "Epoch 4583/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3233 - accuracy: 0.0000e+00 - val_loss: 0.3455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4584/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3323 - accuracy: 0.0000e+00 - val_loss: 0.3455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4585/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3210 - accuracy: 0.0000e+00 - val_loss: 0.3456 - val_accuracy: 0.0000e+00\n",
            "Epoch 4586/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3206 - accuracy: 0.0000e+00 - val_loss: 0.3456 - val_accuracy: 0.0000e+00\n",
            "Epoch 4587/5000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3212 - accuracy: 0.0000e+00 - val_loss: 0.3455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4588/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3205 - accuracy: 0.0000e+00 - val_loss: 0.3455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4589/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3151 - accuracy: 0.0000e+00 - val_loss: 0.3455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4590/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3178 - accuracy: 0.0000e+00 - val_loss: 0.3455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4591/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3338 - accuracy: 0.0000e+00 - val_loss: 0.3454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4592/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3308 - accuracy: 0.0000e+00 - val_loss: 0.3454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4593/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3135 - accuracy: 0.0000e+00 - val_loss: 0.3454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4594/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3238 - accuracy: 0.0000e+00 - val_loss: 0.3454 - val_accuracy: 0.0000e+00\n",
            "Epoch 4595/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3280 - accuracy: 0.0000e+00 - val_loss: 0.3453 - val_accuracy: 0.0000e+00\n",
            "Epoch 4596/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3138 - accuracy: 0.0000e+00 - val_loss: 0.3452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4597/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3162 - accuracy: 0.0000e+00 - val_loss: 0.3452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4598/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3151 - accuracy: 0.0000e+00 - val_loss: 0.3452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4599/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3163 - accuracy: 0.0000e+00 - val_loss: 0.3453 - val_accuracy: 0.0000e+00\n",
            "Epoch 4600/5000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3135 - accuracy: 0.0000e+00 - val_loss: 0.3452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4601/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3185 - accuracy: 0.0000e+00 - val_loss: 0.3452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4602/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3209 - accuracy: 0.0000e+00 - val_loss: 0.3452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4603/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3247 - accuracy: 0.0000e+00 - val_loss: 0.3453 - val_accuracy: 0.0000e+00\n",
            "Epoch 4604/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3201 - accuracy: 0.0000e+00 - val_loss: 0.3452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4605/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3192 - accuracy: 0.0000e+00 - val_loss: 0.3452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4606/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3308 - accuracy: 0.0000e+00 - val_loss: 0.3453 - val_accuracy: 0.0000e+00\n",
            "Epoch 4607/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3164 - accuracy: 0.0000e+00 - val_loss: 0.3452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4608/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3145 - accuracy: 0.0000e+00 - val_loss: 0.3451 - val_accuracy: 0.0000e+00\n",
            "Epoch 4609/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3158 - accuracy: 0.0000e+00 - val_loss: 0.3450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4610/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3133 - accuracy: 0.0000e+00 - val_loss: 0.3449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4611/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3120 - accuracy: 0.0000e+00 - val_loss: 0.3449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4612/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3148 - accuracy: 0.0000e+00 - val_loss: 0.3449 - val_accuracy: 0.0000e+00\n",
            "Epoch 4613/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3101 - accuracy: 0.0000e+00 - val_loss: 0.3448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4614/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3087 - accuracy: 0.0000e+00 - val_loss: 0.3448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4615/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3318 - accuracy: 0.0000e+00 - val_loss: 0.3448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4616/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3140 - accuracy: 0.0000e+00 - val_loss: 0.3448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4617/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3228 - accuracy: 0.0000e+00 - val_loss: 0.3448 - val_accuracy: 0.0000e+00\n",
            "Epoch 4618/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3195 - accuracy: 0.0000e+00 - val_loss: 0.3447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4619/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3273 - accuracy: 0.0000e+00 - val_loss: 0.3446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4620/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3218 - accuracy: 0.0000e+00 - val_loss: 0.3446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4621/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3268 - accuracy: 0.0000e+00 - val_loss: 0.3447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4622/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3182 - accuracy: 0.0000e+00 - val_loss: 0.3447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4623/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3189 - accuracy: 0.0000e+00 - val_loss: 0.3447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4624/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3174 - accuracy: 0.0000e+00 - val_loss: 0.3447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4625/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3223 - accuracy: 0.0000e+00 - val_loss: 0.3446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4626/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3208 - accuracy: 0.0000e+00 - val_loss: 0.3446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4627/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3162 - accuracy: 0.0000e+00 - val_loss: 0.3445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4628/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3205 - accuracy: 0.0000e+00 - val_loss: 0.3446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4629/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3149 - accuracy: 0.0000e+00 - val_loss: 0.3446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4630/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3239 - accuracy: 0.0000e+00 - val_loss: 0.3444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4631/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3133 - accuracy: 0.0000e+00 - val_loss: 0.3444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4632/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3146 - accuracy: 0.0000e+00 - val_loss: 0.3444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4633/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3175 - accuracy: 0.0000e+00 - val_loss: 0.3443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4634/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3173 - accuracy: 0.0000e+00 - val_loss: 0.3444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4635/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3098 - accuracy: 0.0000e+00 - val_loss: 0.3444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4636/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3164 - accuracy: 0.0000e+00 - val_loss: 0.3444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4637/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3171 - accuracy: 0.0000e+00 - val_loss: 0.3444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4638/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3273 - accuracy: 0.0000e+00 - val_loss: 0.3444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4639/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3155 - accuracy: 0.0000e+00 - val_loss: 0.3444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4640/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3123 - accuracy: 0.0000e+00 - val_loss: 0.3445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4641/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3174 - accuracy: 0.0000e+00 - val_loss: 0.3446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4642/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3225 - accuracy: 0.0000e+00 - val_loss: 0.3446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4643/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3256 - accuracy: 0.0000e+00 - val_loss: 0.3446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4644/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3125 - accuracy: 0.0000e+00 - val_loss: 0.3445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4645/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3238 - accuracy: 0.0000e+00 - val_loss: 0.3446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4646/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3154 - accuracy: 0.0000e+00 - val_loss: 0.3445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4647/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3146 - accuracy: 0.0000e+00 - val_loss: 0.3445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4648/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3233 - accuracy: 0.0000e+00 - val_loss: 0.3445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4649/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3171 - accuracy: 0.0000e+00 - val_loss: 0.3446 - val_accuracy: 0.0000e+00\n",
            "Epoch 4650/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3241 - accuracy: 0.0000e+00 - val_loss: 0.3445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4651/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3163 - accuracy: 0.0000e+00 - val_loss: 0.3445 - val_accuracy: 0.0000e+00\n",
            "Epoch 4652/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3215 - accuracy: 0.0000e+00 - val_loss: 0.3444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4653/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3093 - accuracy: 0.0000e+00 - val_loss: 0.3443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4654/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3152 - accuracy: 0.0000e+00 - val_loss: 0.3444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4655/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3234 - accuracy: 0.0000e+00 - val_loss: 0.3444 - val_accuracy: 0.0000e+00\n",
            "Epoch 4656/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3190 - accuracy: 0.0000e+00 - val_loss: 0.3443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4657/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3123 - accuracy: 0.0000e+00 - val_loss: 0.3443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4658/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3191 - accuracy: 0.0000e+00 - val_loss: 0.3443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4659/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3252 - accuracy: 0.0000e+00 - val_loss: 0.3443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4660/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3196 - accuracy: 0.0000e+00 - val_loss: 0.3443 - val_accuracy: 0.0000e+00\n",
            "Epoch 4661/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3162 - accuracy: 0.0000e+00 - val_loss: 0.3442 - val_accuracy: 0.0000e+00\n",
            "Epoch 4662/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3239 - accuracy: 0.0000e+00 - val_loss: 0.3441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4663/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3139 - accuracy: 0.0000e+00 - val_loss: 0.3441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4664/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3168 - accuracy: 0.0000e+00 - val_loss: 0.3440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4665/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3226 - accuracy: 0.0000e+00 - val_loss: 0.3440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4666/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3175 - accuracy: 0.0000e+00 - val_loss: 0.3439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4667/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3134 - accuracy: 0.0000e+00 - val_loss: 0.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4668/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3194 - accuracy: 0.0000e+00 - val_loss: 0.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4669/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3237 - accuracy: 0.0000e+00 - val_loss: 0.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4670/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3180 - accuracy: 0.0000e+00 - val_loss: 0.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4671/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3156 - accuracy: 0.0000e+00 - val_loss: 0.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4672/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3192 - accuracy: 0.0000e+00 - val_loss: 0.3439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4673/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3214 - accuracy: 0.0000e+00 - val_loss: 0.3439 - val_accuracy: 0.0000e+00\n",
            "Epoch 4674/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3211 - accuracy: 0.0000e+00 - val_loss: 0.3440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4675/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3173 - accuracy: 0.0000e+00 - val_loss: 0.3440 - val_accuracy: 0.0000e+00\n",
            "Epoch 4676/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3062 - accuracy: 0.0000e+00 - val_loss: 0.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4677/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3192 - accuracy: 0.0000e+00 - val_loss: 0.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4678/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3237 - accuracy: 0.0000e+00 - val_loss: 0.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4679/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3155 - accuracy: 0.0000e+00 - val_loss: 0.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 4680/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3167 - accuracy: 0.0000e+00 - val_loss: 0.3437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4681/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3254 - accuracy: 0.0000e+00 - val_loss: 0.3437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4682/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3176 - accuracy: 0.0000e+00 - val_loss: 0.3436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4683/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3131 - accuracy: 0.0000e+00 - val_loss: 0.3436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4684/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3083 - accuracy: 0.0000e+00 - val_loss: 0.3436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4685/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3084 - accuracy: 0.0000e+00 - val_loss: 0.3435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4686/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3231 - accuracy: 0.0000e+00 - val_loss: 0.3435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4687/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3131 - accuracy: 0.0000e+00 - val_loss: 0.3434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4688/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3146 - accuracy: 0.0000e+00 - val_loss: 0.3434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4689/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3111 - accuracy: 0.0000e+00 - val_loss: 0.3434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4690/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3182 - accuracy: 0.0000e+00 - val_loss: 0.3434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4691/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3258 - accuracy: 0.0000e+00 - val_loss: 0.3434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4692/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3173 - accuracy: 0.0000e+00 - val_loss: 0.3434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4693/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3255 - accuracy: 0.0000e+00 - val_loss: 0.3435 - val_accuracy: 0.0000e+00\n",
            "Epoch 4694/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3169 - accuracy: 0.0000e+00 - val_loss: 0.3434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4695/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3139 - accuracy: 0.0000e+00 - val_loss: 0.3434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4696/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3162 - accuracy: 0.0000e+00 - val_loss: 0.3434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4697/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3129 - accuracy: 0.0000e+00 - val_loss: 0.3434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4698/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3135 - accuracy: 0.0000e+00 - val_loss: 0.3434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4699/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3143 - accuracy: 0.0000e+00 - val_loss: 0.3433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4700/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3121 - accuracy: 0.0000e+00 - val_loss: 0.3433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4701/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3119 - accuracy: 0.0000e+00 - val_loss: 0.3433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4702/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3243 - accuracy: 0.0000e+00 - val_loss: 0.3433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4703/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3131 - accuracy: 0.0000e+00 - val_loss: 0.3433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4704/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3112 - accuracy: 0.0000e+00 - val_loss: 0.3434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4705/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3195 - accuracy: 0.0000e+00 - val_loss: 0.3434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4706/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3138 - accuracy: 0.0000e+00 - val_loss: 0.3434 - val_accuracy: 0.0000e+00\n",
            "Epoch 4707/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3164 - accuracy: 0.0000e+00 - val_loss: 0.3433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4708/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3182 - accuracy: 0.0000e+00 - val_loss: 0.3433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4709/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3228 - accuracy: 0.0000e+00 - val_loss: 0.3433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4710/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3220 - accuracy: 0.0000e+00 - val_loss: 0.3432 - val_accuracy: 0.0000e+00\n",
            "Epoch 4711/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3200 - accuracy: 0.0000e+00 - val_loss: 0.3432 - val_accuracy: 0.0000e+00\n",
            "Epoch 4712/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3157 - accuracy: 0.0000e+00 - val_loss: 0.3431 - val_accuracy: 0.0000e+00\n",
            "Epoch 4713/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3115 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4714/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3151 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4715/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3188 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4716/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3091 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4717/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3112 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4718/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3146 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4719/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3147 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4720/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3190 - accuracy: 0.0000e+00 - val_loss: 0.3429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4721/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3160 - accuracy: 0.0000e+00 - val_loss: 0.3429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4722/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3165 - accuracy: 0.0000e+00 - val_loss: 0.3429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4723/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3216 - accuracy: 0.0000e+00 - val_loss: 0.3429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4724/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3153 - accuracy: 0.0000e+00 - val_loss: 0.3429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4725/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3180 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4726/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3128 - accuracy: 0.0000e+00 - val_loss: 0.3429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4727/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3158 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4728/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3127 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4729/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3202 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4730/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3158 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4731/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3223 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4732/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3175 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4733/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3169 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4734/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3095 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4735/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3152 - accuracy: 0.0000e+00 - val_loss: 0.3429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4736/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3153 - accuracy: 0.0000e+00 - val_loss: 0.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 4737/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3086 - accuracy: 0.0000e+00 - val_loss: 0.3429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4738/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3221 - accuracy: 0.0000e+00 - val_loss: 0.3429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4739/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3162 - accuracy: 0.0000e+00 - val_loss: 0.3428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4740/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3119 - accuracy: 0.0000e+00 - val_loss: 0.3427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4741/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3220 - accuracy: 0.0000e+00 - val_loss: 0.3427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4742/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3187 - accuracy: 0.0000e+00 - val_loss: 0.3427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4743/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3181 - accuracy: 0.0000e+00 - val_loss: 0.3427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4744/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3107 - accuracy: 0.0000e+00 - val_loss: 0.3427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4745/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3272 - accuracy: 0.0000e+00 - val_loss: 0.3427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4746/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3127 - accuracy: 0.0000e+00 - val_loss: 0.3428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4747/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3213 - accuracy: 0.0000e+00 - val_loss: 0.3429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4748/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3153 - accuracy: 0.0000e+00 - val_loss: 0.3428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4749/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3143 - accuracy: 0.0000e+00 - val_loss: 0.3428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4750/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3151 - accuracy: 0.0000e+00 - val_loss: 0.3429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4751/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3129 - accuracy: 0.0000e+00 - val_loss: 0.3429 - val_accuracy: 0.0000e+00\n",
            "Epoch 4752/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3181 - accuracy: 0.0000e+00 - val_loss: 0.3428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4753/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3147 - accuracy: 0.0000e+00 - val_loss: 0.3427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4754/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3150 - accuracy: 0.0000e+00 - val_loss: 0.3428 - val_accuracy: 0.0000e+00\n",
            "Epoch 4755/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3112 - accuracy: 0.0000e+00 - val_loss: 0.3427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4756/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3198 - accuracy: 0.0000e+00 - val_loss: 0.3427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4757/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3275 - accuracy: 0.0000e+00 - val_loss: 0.3427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4758/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3085 - accuracy: 0.0000e+00 - val_loss: 0.3427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4759/5000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3072 - accuracy: 0.0000e+00 - val_loss: 0.3427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4760/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3188 - accuracy: 0.0000e+00 - val_loss: 0.3426 - val_accuracy: 0.0000e+00\n",
            "Epoch 4761/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3156 - accuracy: 0.0000e+00 - val_loss: 0.3426 - val_accuracy: 0.0000e+00\n",
            "Epoch 4762/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3130 - accuracy: 0.0000e+00 - val_loss: 0.3426 - val_accuracy: 0.0000e+00\n",
            "Epoch 4763/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3203 - accuracy: 0.0000e+00 - val_loss: 0.3427 - val_accuracy: 0.0000e+00\n",
            "Epoch 4764/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3168 - accuracy: 0.0000e+00 - val_loss: 0.3426 - val_accuracy: 0.0000e+00\n",
            "Epoch 4765/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3112 - accuracy: 0.0000e+00 - val_loss: 0.3426 - val_accuracy: 0.0000e+00\n",
            "Epoch 4766/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3195 - accuracy: 0.0000e+00 - val_loss: 0.3425 - val_accuracy: 0.0000e+00\n",
            "Epoch 4767/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3116 - accuracy: 0.0000e+00 - val_loss: 0.3425 - val_accuracy: 0.0000e+00\n",
            "Epoch 4768/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3128 - accuracy: 0.0000e+00 - val_loss: 0.3423 - val_accuracy: 0.0000e+00\n",
            "Epoch 4769/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3212 - accuracy: 0.0000e+00 - val_loss: 0.3424 - val_accuracy: 0.0000e+00\n",
            "Epoch 4770/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3241 - accuracy: 0.0000e+00 - val_loss: 0.3424 - val_accuracy: 0.0000e+00\n",
            "Epoch 4771/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3157 - accuracy: 0.0000e+00 - val_loss: 0.3423 - val_accuracy: 0.0000e+00\n",
            "Epoch 4772/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3254 - accuracy: 0.0000e+00 - val_loss: 0.3422 - val_accuracy: 0.0000e+00\n",
            "Epoch 4773/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3110 - accuracy: 0.0000e+00 - val_loss: 0.3423 - val_accuracy: 0.0000e+00\n",
            "Epoch 4774/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3156 - accuracy: 0.0000e+00 - val_loss: 0.3422 - val_accuracy: 0.0000e+00\n",
            "Epoch 4775/5000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.3113 - accuracy: 0.0000e+00 - val_loss: 0.3421 - val_accuracy: 0.0000e+00\n",
            "Epoch 4776/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3112 - accuracy: 0.0000e+00 - val_loss: 0.3421 - val_accuracy: 0.0000e+00\n",
            "Epoch 4777/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3124 - accuracy: 0.0000e+00 - val_loss: 0.3420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4778/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3123 - accuracy: 0.0000e+00 - val_loss: 0.3420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4779/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3166 - accuracy: 0.0000e+00 - val_loss: 0.3420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4780/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3249 - accuracy: 0.0000e+00 - val_loss: 0.3420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4781/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3154 - accuracy: 0.0000e+00 - val_loss: 0.3420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4782/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3199 - accuracy: 0.0000e+00 - val_loss: 0.3421 - val_accuracy: 0.0000e+00\n",
            "Epoch 4783/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3199 - accuracy: 0.0000e+00 - val_loss: 0.3420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4784/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3147 - accuracy: 0.0000e+00 - val_loss: 0.3420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4785/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3134 - accuracy: 0.0000e+00 - val_loss: 0.3420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4786/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3245 - accuracy: 0.0000e+00 - val_loss: 0.3420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4787/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3166 - accuracy: 0.0000e+00 - val_loss: 0.3420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4788/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3227 - accuracy: 0.0000e+00 - val_loss: 0.3421 - val_accuracy: 0.0000e+00\n",
            "Epoch 4789/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3156 - accuracy: 0.0000e+00 - val_loss: 0.3420 - val_accuracy: 0.0000e+00\n",
            "Epoch 4790/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3244 - accuracy: 0.0000e+00 - val_loss: 0.3419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4791/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3141 - accuracy: 0.0000e+00 - val_loss: 0.3419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4792/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3174 - accuracy: 0.0000e+00 - val_loss: 0.3419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4793/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3182 - accuracy: 0.0000e+00 - val_loss: 0.3419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4794/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3130 - accuracy: 0.0000e+00 - val_loss: 0.3419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4795/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3212 - accuracy: 0.0000e+00 - val_loss: 0.3419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4796/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3122 - accuracy: 0.0000e+00 - val_loss: 0.3419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4797/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3189 - accuracy: 0.0000e+00 - val_loss: 0.3419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4798/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3070 - accuracy: 0.0000e+00 - val_loss: 0.3419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4799/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3146 - accuracy: 0.0000e+00 - val_loss: 0.3418 - val_accuracy: 0.0000e+00\n",
            "Epoch 4800/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3264 - accuracy: 0.0000e+00 - val_loss: 0.3419 - val_accuracy: 0.0000e+00\n",
            "Epoch 4801/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3260 - accuracy: 0.0000e+00 - val_loss: 0.3418 - val_accuracy: 0.0000e+00\n",
            "Epoch 4802/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3222 - accuracy: 0.0000e+00 - val_loss: 0.3417 - val_accuracy: 0.0000e+00\n",
            "Epoch 4803/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3123 - accuracy: 0.0000e+00 - val_loss: 0.3416 - val_accuracy: 0.0000e+00\n",
            "Epoch 4804/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3156 - accuracy: 0.0000e+00 - val_loss: 0.3416 - val_accuracy: 0.0000e+00\n",
            "Epoch 4805/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3205 - accuracy: 0.0000e+00 - val_loss: 0.3416 - val_accuracy: 0.0000e+00\n",
            "Epoch 4806/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3135 - accuracy: 0.0000e+00 - val_loss: 0.3416 - val_accuracy: 0.0000e+00\n",
            "Epoch 4807/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3124 - accuracy: 0.0000e+00 - val_loss: 0.3416 - val_accuracy: 0.0000e+00\n",
            "Epoch 4808/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3139 - accuracy: 0.0000e+00 - val_loss: 0.3416 - val_accuracy: 0.0000e+00\n",
            "Epoch 4809/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3106 - accuracy: 0.0000e+00 - val_loss: 0.3416 - val_accuracy: 0.0000e+00\n",
            "Epoch 4810/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3151 - accuracy: 0.0000e+00 - val_loss: 0.3415 - val_accuracy: 0.0000e+00\n",
            "Epoch 4811/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3152 - accuracy: 0.0000e+00 - val_loss: 0.3415 - val_accuracy: 0.0000e+00\n",
            "Epoch 4812/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3149 - accuracy: 0.0000e+00 - val_loss: 0.3415 - val_accuracy: 0.0000e+00\n",
            "Epoch 4813/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3146 - accuracy: 0.0000e+00 - val_loss: 0.3415 - val_accuracy: 0.0000e+00\n",
            "Epoch 4814/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3134 - accuracy: 0.0000e+00 - val_loss: 0.3414 - val_accuracy: 0.0000e+00\n",
            "Epoch 4815/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3106 - accuracy: 0.0000e+00 - val_loss: 0.3414 - val_accuracy: 0.0000e+00\n",
            "Epoch 4816/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3240 - accuracy: 0.0000e+00 - val_loss: 0.3414 - val_accuracy: 0.0000e+00\n",
            "Epoch 4817/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3108 - accuracy: 0.0000e+00 - val_loss: 0.3413 - val_accuracy: 0.0000e+00\n",
            "Epoch 4818/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3119 - accuracy: 0.0000e+00 - val_loss: 0.3413 - val_accuracy: 0.0000e+00\n",
            "Epoch 4819/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3196 - accuracy: 0.0000e+00 - val_loss: 0.3412 - val_accuracy: 0.0000e+00\n",
            "Epoch 4820/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3119 - accuracy: 0.0000e+00 - val_loss: 0.3412 - val_accuracy: 0.0000e+00\n",
            "Epoch 4821/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3138 - accuracy: 0.0000e+00 - val_loss: 0.3413 - val_accuracy: 0.0000e+00\n",
            "Epoch 4822/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3136 - accuracy: 0.0000e+00 - val_loss: 0.3413 - val_accuracy: 0.0000e+00\n",
            "Epoch 4823/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3160 - accuracy: 0.0000e+00 - val_loss: 0.3414 - val_accuracy: 0.0000e+00\n",
            "Epoch 4824/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3118 - accuracy: 0.0000e+00 - val_loss: 0.3413 - val_accuracy: 0.0000e+00\n",
            "Epoch 4825/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3289 - accuracy: 0.0000e+00 - val_loss: 0.3413 - val_accuracy: 0.0000e+00\n",
            "Epoch 4826/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3137 - accuracy: 0.0000e+00 - val_loss: 0.3412 - val_accuracy: 0.0000e+00\n",
            "Epoch 4827/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3117 - accuracy: 0.0000e+00 - val_loss: 0.3412 - val_accuracy: 0.0000e+00\n",
            "Epoch 4828/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3107 - accuracy: 0.0000e+00 - val_loss: 0.3411 - val_accuracy: 0.0000e+00\n",
            "Epoch 4829/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3225 - accuracy: 0.0000e+00 - val_loss: 0.3412 - val_accuracy: 0.0000e+00\n",
            "Epoch 4830/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3191 - accuracy: 0.0000e+00 - val_loss: 0.3411 - val_accuracy: 0.0000e+00\n",
            "Epoch 4831/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3113 - accuracy: 0.0000e+00 - val_loss: 0.3411 - val_accuracy: 0.0000e+00\n",
            "Epoch 4832/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3131 - accuracy: 0.0000e+00 - val_loss: 0.3410 - val_accuracy: 0.0000e+00\n",
            "Epoch 4833/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3120 - accuracy: 0.0000e+00 - val_loss: 0.3411 - val_accuracy: 0.0000e+00\n",
            "Epoch 4834/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3163 - accuracy: 0.0000e+00 - val_loss: 0.3410 - val_accuracy: 0.0000e+00\n",
            "Epoch 4835/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3132 - accuracy: 0.0000e+00 - val_loss: 0.3411 - val_accuracy: 0.0000e+00\n",
            "Epoch 4836/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3114 - accuracy: 0.0000e+00 - val_loss: 0.3410 - val_accuracy: 0.0000e+00\n",
            "Epoch 4837/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3183 - accuracy: 0.0000e+00 - val_loss: 0.3409 - val_accuracy: 0.0000e+00\n",
            "Epoch 4838/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3122 - accuracy: 0.0000e+00 - val_loss: 0.3408 - val_accuracy: 0.0000e+00\n",
            "Epoch 4839/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3103 - accuracy: 0.0000e+00 - val_loss: 0.3408 - val_accuracy: 0.0000e+00\n",
            "Epoch 4840/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3069 - accuracy: 0.0000e+00 - val_loss: 0.3409 - val_accuracy: 0.0000e+00\n",
            "Epoch 4841/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3160 - accuracy: 0.0000e+00 - val_loss: 0.3409 - val_accuracy: 0.0000e+00\n",
            "Epoch 4842/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3185 - accuracy: 0.0000e+00 - val_loss: 0.3409 - val_accuracy: 0.0000e+00\n",
            "Epoch 4843/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3113 - accuracy: 0.0000e+00 - val_loss: 0.3409 - val_accuracy: 0.0000e+00\n",
            "Epoch 4844/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3170 - accuracy: 0.0000e+00 - val_loss: 0.3408 - val_accuracy: 0.0000e+00\n",
            "Epoch 4845/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3163 - accuracy: 0.0000e+00 - val_loss: 0.3408 - val_accuracy: 0.0000e+00\n",
            "Epoch 4846/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3100 - accuracy: 0.0000e+00 - val_loss: 0.3408 - val_accuracy: 0.0000e+00\n",
            "Epoch 4847/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3153 - accuracy: 0.0000e+00 - val_loss: 0.3407 - val_accuracy: 0.0000e+00\n",
            "Epoch 4848/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3161 - accuracy: 0.0000e+00 - val_loss: 0.3407 - val_accuracy: 0.0000e+00\n",
            "Epoch 4849/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3142 - accuracy: 0.0000e+00 - val_loss: 0.3406 - val_accuracy: 0.0000e+00\n",
            "Epoch 4850/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3180 - accuracy: 0.0000e+00 - val_loss: 0.3406 - val_accuracy: 0.0000e+00\n",
            "Epoch 4851/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3190 - accuracy: 0.0000e+00 - val_loss: 0.3407 - val_accuracy: 0.0000e+00\n",
            "Epoch 4852/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3166 - accuracy: 0.0000e+00 - val_loss: 0.3407 - val_accuracy: 0.0000e+00\n",
            "Epoch 4853/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3122 - accuracy: 0.0000e+00 - val_loss: 0.3406 - val_accuracy: 0.0000e+00\n",
            "Epoch 4854/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3120 - accuracy: 0.0000e+00 - val_loss: 0.3406 - val_accuracy: 0.0000e+00\n",
            "Epoch 4855/5000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3145 - accuracy: 0.0000e+00 - val_loss: 0.3406 - val_accuracy: 0.0000e+00\n",
            "Epoch 4856/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3104 - accuracy: 0.0000e+00 - val_loss: 0.3406 - val_accuracy: 0.0000e+00\n",
            "Epoch 4857/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3150 - accuracy: 0.0000e+00 - val_loss: 0.3406 - val_accuracy: 0.0000e+00\n",
            "Epoch 4858/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3068 - accuracy: 0.0000e+00 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4859/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3113 - accuracy: 0.0000e+00 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4860/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3107 - accuracy: 0.0000e+00 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4861/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3137 - accuracy: 0.0000e+00 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4862/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3186 - accuracy: 0.0000e+00 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4863/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3134 - accuracy: 0.0000e+00 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4864/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3161 - accuracy: 0.0000e+00 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4865/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3194 - accuracy: 0.0000e+00 - val_loss: 0.3406 - val_accuracy: 0.0000e+00\n",
            "Epoch 4866/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3136 - accuracy: 0.0000e+00 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4867/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3217 - accuracy: 0.0000e+00 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4868/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3078 - accuracy: 0.0000e+00 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4869/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3073 - accuracy: 0.0000e+00 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4870/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3160 - accuracy: 0.0000e+00 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4871/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3146 - accuracy: 0.0000e+00 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4872/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3303 - accuracy: 0.0000e+00 - val_loss: 0.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 4873/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3133 - accuracy: 0.0000e+00 - val_loss: 0.3404 - val_accuracy: 0.0000e+00\n",
            "Epoch 4874/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3126 - accuracy: 0.0000e+00 - val_loss: 0.3403 - val_accuracy: 0.0000e+00\n",
            "Epoch 4875/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3194 - accuracy: 0.0000e+00 - val_loss: 0.3403 - val_accuracy: 0.0000e+00\n",
            "Epoch 4876/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3167 - accuracy: 0.0000e+00 - val_loss: 0.3403 - val_accuracy: 0.0000e+00\n",
            "Epoch 4877/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3156 - accuracy: 0.0000e+00 - val_loss: 0.3403 - val_accuracy: 0.0000e+00\n",
            "Epoch 4878/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3130 - accuracy: 0.0000e+00 - val_loss: 0.3402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4879/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3069 - accuracy: 0.0000e+00 - val_loss: 0.3402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4880/5000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3111 - accuracy: 0.0000e+00 - val_loss: 0.3402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4881/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3073 - accuracy: 0.0000e+00 - val_loss: 0.3402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4882/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3076 - accuracy: 0.0000e+00 - val_loss: 0.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4883/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3232 - accuracy: 0.0000e+00 - val_loss: 0.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4884/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3097 - accuracy: 0.0000e+00 - val_loss: 0.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4885/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3181 - accuracy: 0.0000e+00 - val_loss: 0.3402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4886/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3107 - accuracy: 0.0000e+00 - val_loss: 0.3402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4887/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3116 - accuracy: 0.0000e+00 - val_loss: 0.3402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4888/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3106 - accuracy: 0.0000e+00 - val_loss: 0.3402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4889/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3088 - accuracy: 0.0000e+00 - val_loss: 0.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4890/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3121 - accuracy: 0.0000e+00 - val_loss: 0.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4891/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3085 - accuracy: 0.0000e+00 - val_loss: 0.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4892/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3116 - accuracy: 0.0000e+00 - val_loss: 0.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4893/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3156 - accuracy: 0.0000e+00 - val_loss: 0.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4894/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3113 - accuracy: 0.0000e+00 - val_loss: 0.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4895/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3143 - accuracy: 0.0000e+00 - val_loss: 0.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4896/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3123 - accuracy: 0.0000e+00 - val_loss: 0.3402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4897/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3161 - accuracy: 0.0000e+00 - val_loss: 0.3402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4898/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3105 - accuracy: 0.0000e+00 - val_loss: 0.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4899/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3070 - accuracy: 0.0000e+00 - val_loss: 0.3402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4900/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3134 - accuracy: 0.0000e+00 - val_loss: 0.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4901/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3117 - accuracy: 0.0000e+00 - val_loss: 0.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4902/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3220 - accuracy: 0.0000e+00 - val_loss: 0.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4903/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3188 - accuracy: 0.0000e+00 - val_loss: 0.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4904/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3164 - accuracy: 0.0000e+00 - val_loss: 0.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 4905/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3059 - accuracy: 0.0000e+00 - val_loss: 0.3399 - val_accuracy: 0.0000e+00\n",
            "Epoch 4906/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3183 - accuracy: 0.0000e+00 - val_loss: 0.3399 - val_accuracy: 0.0000e+00\n",
            "Epoch 4907/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3189 - accuracy: 0.0000e+00 - val_loss: 0.3398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4908/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3085 - accuracy: 0.0000e+00 - val_loss: 0.3398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4909/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3155 - accuracy: 0.0000e+00 - val_loss: 0.3398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4910/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3106 - accuracy: 0.0000e+00 - val_loss: 0.3398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4911/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3186 - accuracy: 0.0000e+00 - val_loss: 0.3397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4912/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3121 - accuracy: 0.0000e+00 - val_loss: 0.3397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4913/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3136 - accuracy: 0.0000e+00 - val_loss: 0.3397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4914/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3163 - accuracy: 0.0000e+00 - val_loss: 0.3398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4915/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3132 - accuracy: 0.0000e+00 - val_loss: 0.3397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4916/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3168 - accuracy: 0.0000e+00 - val_loss: 0.3398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4917/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3028 - accuracy: 0.0000e+00 - val_loss: 0.3397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4918/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3151 - accuracy: 0.0000e+00 - val_loss: 0.3397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4919/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3213 - accuracy: 0.0000e+00 - val_loss: 0.3398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4920/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3270 - accuracy: 0.0000e+00 - val_loss: 0.3398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4921/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3112 - accuracy: 0.0000e+00 - val_loss: 0.3398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4922/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3318 - accuracy: 0.0000e+00 - val_loss: 0.3399 - val_accuracy: 0.0000e+00\n",
            "Epoch 4923/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3140 - accuracy: 0.0000e+00 - val_loss: 0.3399 - val_accuracy: 0.0000e+00\n",
            "Epoch 4924/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3154 - accuracy: 0.0000e+00 - val_loss: 0.3398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4925/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3151 - accuracy: 0.0000e+00 - val_loss: 0.3399 - val_accuracy: 0.0000e+00\n",
            "Epoch 4926/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3082 - accuracy: 0.0000e+00 - val_loss: 0.3398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4927/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3180 - accuracy: 0.0000e+00 - val_loss: 0.3399 - val_accuracy: 0.0000e+00\n",
            "Epoch 4928/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3239 - accuracy: 0.0000e+00 - val_loss: 0.3398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4929/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3110 - accuracy: 0.0000e+00 - val_loss: 0.3398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4930/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3107 - accuracy: 0.0000e+00 - val_loss: 0.3397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4931/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3156 - accuracy: 0.0000e+00 - val_loss: 0.3397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4932/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3178 - accuracy: 0.0000e+00 - val_loss: 0.3397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4933/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3187 - accuracy: 0.0000e+00 - val_loss: 0.3396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4934/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3150 - accuracy: 0.0000e+00 - val_loss: 0.3397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4935/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3093 - accuracy: 0.0000e+00 - val_loss: 0.3396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4936/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3192 - accuracy: 0.0000e+00 - val_loss: 0.3396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4937/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3168 - accuracy: 0.0000e+00 - val_loss: 0.3397 - val_accuracy: 0.0000e+00\n",
            "Epoch 4938/5000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3138 - accuracy: 0.0000e+00 - val_loss: 0.3396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4939/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3093 - accuracy: 0.0000e+00 - val_loss: 0.3396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4940/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3082 - accuracy: 0.0000e+00 - val_loss: 0.3396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4941/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3068 - accuracy: 0.0000e+00 - val_loss: 0.3396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4942/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3146 - accuracy: 0.0000e+00 - val_loss: 0.3396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4943/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3091 - accuracy: 0.0000e+00 - val_loss: 0.3396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4944/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3221 - accuracy: 0.0000e+00 - val_loss: 0.3396 - val_accuracy: 0.0000e+00\n",
            "Epoch 4945/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3101 - accuracy: 0.0000e+00 - val_loss: 0.3395 - val_accuracy: 0.0000e+00\n",
            "Epoch 4946/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3286 - accuracy: 0.0000e+00 - val_loss: 0.3395 - val_accuracy: 0.0000e+00\n",
            "Epoch 4947/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3074 - accuracy: 0.0000e+00 - val_loss: 0.3394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4948/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3031 - accuracy: 0.0000e+00 - val_loss: 0.3393 - val_accuracy: 0.0000e+00\n",
            "Epoch 4949/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3110 - accuracy: 0.0000e+00 - val_loss: 0.3394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4950/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3137 - accuracy: 0.0000e+00 - val_loss: 0.3394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4951/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3116 - accuracy: 0.0000e+00 - val_loss: 0.3394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4952/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3257 - accuracy: 0.0000e+00 - val_loss: 0.3394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4953/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3252 - accuracy: 0.0000e+00 - val_loss: 0.3395 - val_accuracy: 0.0000e+00\n",
            "Epoch 4954/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3082 - accuracy: 0.0000e+00 - val_loss: 0.3395 - val_accuracy: 0.0000e+00\n",
            "Epoch 4955/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3060 - accuracy: 0.0000e+00 - val_loss: 0.3394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4956/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3124 - accuracy: 0.0000e+00 - val_loss: 0.3394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4957/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3140 - accuracy: 0.0000e+00 - val_loss: 0.3393 - val_accuracy: 0.0000e+00\n",
            "Epoch 4958/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3132 - accuracy: 0.0000e+00 - val_loss: 0.3393 - val_accuracy: 0.0000e+00\n",
            "Epoch 4959/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3068 - accuracy: 0.0000e+00 - val_loss: 0.3393 - val_accuracy: 0.0000e+00\n",
            "Epoch 4960/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3089 - accuracy: 0.0000e+00 - val_loss: 0.3393 - val_accuracy: 0.0000e+00\n",
            "Epoch 4961/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3114 - accuracy: 0.0000e+00 - val_loss: 0.3392 - val_accuracy: 0.0000e+00\n",
            "Epoch 4962/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3105 - accuracy: 0.0000e+00 - val_loss: 0.3391 - val_accuracy: 0.0000e+00\n",
            "Epoch 4963/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3110 - accuracy: 0.0000e+00 - val_loss: 0.3391 - val_accuracy: 0.0000e+00\n",
            "Epoch 4964/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3069 - accuracy: 0.0000e+00 - val_loss: 0.3390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4965/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3184 - accuracy: 0.0000e+00 - val_loss: 0.3390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4966/5000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3106 - accuracy: 0.0000e+00 - val_loss: 0.3390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4967/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3198 - accuracy: 0.0000e+00 - val_loss: 0.3390 - val_accuracy: 0.0000e+00\n",
            "Epoch 4968/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3120 - accuracy: 0.0000e+00 - val_loss: 0.3389 - val_accuracy: 0.0000e+00\n",
            "Epoch 4969/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3122 - accuracy: 0.0000e+00 - val_loss: 0.3388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4970/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3089 - accuracy: 0.0000e+00 - val_loss: 0.3387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4971/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3185 - accuracy: 0.0000e+00 - val_loss: 0.3387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4972/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3090 - accuracy: 0.0000e+00 - val_loss: 0.3386 - val_accuracy: 0.0000e+00\n",
            "Epoch 4973/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3166 - accuracy: 0.0000e+00 - val_loss: 0.3387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4974/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3249 - accuracy: 0.0000e+00 - val_loss: 0.3387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4975/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3179 - accuracy: 0.0000e+00 - val_loss: 0.3386 - val_accuracy: 0.0000e+00\n",
            "Epoch 4976/5000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3113 - accuracy: 0.0000e+00 - val_loss: 0.3387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4977/5000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3183 - accuracy: 0.0000e+00 - val_loss: 0.3387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4978/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3157 - accuracy: 0.0000e+00 - val_loss: 0.3388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4979/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3198 - accuracy: 0.0000e+00 - val_loss: 0.3388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4980/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3092 - accuracy: 0.0000e+00 - val_loss: 0.3388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4981/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3118 - accuracy: 0.0000e+00 - val_loss: 0.3388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4982/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3118 - accuracy: 0.0000e+00 - val_loss: 0.3388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4983/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3102 - accuracy: 0.0000e+00 - val_loss: 0.3388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4984/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3174 - accuracy: 0.0000e+00 - val_loss: 0.3387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4985/5000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3214 - accuracy: 0.0000e+00 - val_loss: 0.3388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4986/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3070 - accuracy: 0.0000e+00 - val_loss: 0.3387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4987/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3158 - accuracy: 0.0000e+00 - val_loss: 0.3388 - val_accuracy: 0.0000e+00\n",
            "Epoch 4988/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3091 - accuracy: 0.0000e+00 - val_loss: 0.3387 - val_accuracy: 0.0000e+00\n",
            "Epoch 4989/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3065 - accuracy: 0.0000e+00 - val_loss: 0.3386 - val_accuracy: 0.0000e+00\n",
            "Epoch 4990/5000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3057 - accuracy: 0.0000e+00 - val_loss: 0.3385 - val_accuracy: 0.0000e+00\n",
            "Epoch 4991/5000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3206 - accuracy: 0.0000e+00 - val_loss: 0.3384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4992/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3098 - accuracy: 0.0000e+00 - val_loss: 0.3384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4993/5000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3148 - accuracy: 0.0000e+00 - val_loss: 0.3384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4994/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3123 - accuracy: 0.0000e+00 - val_loss: 0.3384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4995/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3074 - accuracy: 0.0000e+00 - val_loss: 0.3385 - val_accuracy: 0.0000e+00\n",
            "Epoch 4996/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3101 - accuracy: 0.0000e+00 - val_loss: 0.3385 - val_accuracy: 0.0000e+00\n",
            "Epoch 4997/5000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3113 - accuracy: 0.0000e+00 - val_loss: 0.3385 - val_accuracy: 0.0000e+00\n",
            "Epoch 4998/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3116 - accuracy: 0.0000e+00 - val_loss: 0.3384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4999/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3136 - accuracy: 0.0000e+00 - val_loss: 0.3384 - val_accuracy: 0.0000e+00\n",
            "Epoch 5000/5000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3103 - accuracy: 0.0000e+00 - val_loss: 0.3384 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(fittedModel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "UmTYs-XFZneQ",
        "outputId": "e06a97fe-71b5-4730-9798-37a843c22c58"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análise da performance \n",
        "Como esperado, o resultado foi muito semelhante aos anteriores por apenas mudarmos de sequencial para funcional, não alterando a estrutura da rede. "
      ],
      "metadata": {
        "id": "wYAx3-tglc42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusão\n",
        "Neste tutorial foram usadas 3 diferentes metodologias de criar o mesmo modelo, implementando redes neuronais para resolver o problema de prever a força do cimento dados 8 atributos relativamente à sua constituição. Relativamente ao tensorflow sem APIs high-level, este foi bom para perceber como as coisas funcionam a um nível mais detalhado mas por questões de praticalidade, ambos os modelos do Keras oferecem muito mais. Outro aspeto importante de reiterar é a questão da seleção dos hiperparâmetros, cujas alternativas poderiam ser exploradas para melhorar ainda mais os modelos desenvolvidos."
      ],
      "metadata": {
        "id": "xavsSC0fmq1L"
      }
    }
  ]
}